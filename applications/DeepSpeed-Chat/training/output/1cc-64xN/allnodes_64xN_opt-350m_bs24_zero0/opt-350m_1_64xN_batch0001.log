ml-512-node-001 slots=8
ml-512-node-002 slots=8
ml-512-node-003 slots=8
ml-512-node-004 slots=8
ml-512-node-005 slots=8
ml-512-node-006 slots=8
ml-512-node-007 slots=8
ml-512-node-008 slots=8
ml-512-node-009 slots=8
ml-512-node-010 slots=8
ml-512-node-011 slots=8
ml-512-node-012 slots=8
ml-512-node-013 slots=8
ml-512-node-014 slots=8
ml-512-node-015 slots=8
ml-512-node-016 slots=8
ml-512-node-017 slots=8
ml-512-node-018 slots=8
ml-512-node-019 slots=8
ml-512-node-020 slots=8
ml-512-node-021 slots=8
ml-512-node-022 slots=8
ml-512-node-023 slots=8
ml-512-node-024 slots=8
ml-512-node-025 slots=8
ml-512-node-026 slots=8
ml-512-node-027 slots=8
ml-512-node-028 slots=8
ml-512-node-029 slots=8
ml-512-node-030 slots=8
ml-512-node-031 slots=8
ml-512-node-032 slots=8
ml-512-node-033 slots=8
ml-512-node-034 slots=8
ml-512-node-035 slots=8
ml-512-node-036 slots=8
ml-512-node-037 slots=8
ml-512-node-038 slots=8
ml-512-node-039 slots=8
ml-512-node-040 slots=8
ml-512-node-041 slots=8
ml-512-node-042 slots=8
ml-512-node-043 slots=8
ml-512-node-044 slots=8
ml-512-node-045 slots=8
ml-512-node-046 slots=8
ml-512-node-047 slots=8
ml-512-node-048 slots=8
ml-512-node-049 slots=8
ml-512-node-050 slots=8
ml-512-node-051 slots=8
ml-512-node-052 slots=8
ml-512-node-053 slots=8
ml-512-node-054 slots=8
ml-512-node-055 slots=8
ml-512-node-056 slots=8
ml-512-node-057 slots=8
ml-512-node-058 slots=8
ml-512-node-059 slots=8
ml-512-node-060 slots=8
ml-512-node-061 slots=8
ml-512-node-062 slots=8
ml-512-node-063 slots=8
ml-512-node-064 slots=8
[2024-07-08 06:05:36,357] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-07-08 06:05:37.715761: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-07-08 06:05:37.754482: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[2024-07-08 06:05:39,211] [INFO] [runner.py:557:main] deepspeed_env file = ./.deepspeed_env
[2024-07-08 06:05:39,212] [INFO] [multinode_runner.py:81:get_cmd] Running on the following workers: ml-512-node-001,ml-512-node-002,ml-512-node-003,ml-512-node-004,ml-512-node-005,ml-512-node-006,ml-512-node-007,ml-512-node-008,ml-512-node-009,ml-512-node-010,ml-512-node-011,ml-512-node-012,ml-512-node-013,ml-512-node-014,ml-512-node-015,ml-512-node-016,ml-512-node-017,ml-512-node-018,ml-512-node-019,ml-512-node-020,ml-512-node-021,ml-512-node-022,ml-512-node-023,ml-512-node-024,ml-512-node-025,ml-512-node-026,ml-512-node-027,ml-512-node-028,ml-512-node-029,ml-512-node-030,ml-512-node-031,ml-512-node-032,ml-512-node-033,ml-512-node-034,ml-512-node-035,ml-512-node-036,ml-512-node-037,ml-512-node-038,ml-512-node-039,ml-512-node-040,ml-512-node-041,ml-512-node-042,ml-512-node-043,ml-512-node-044,ml-512-node-045,ml-512-node-046,ml-512-node-047,ml-512-node-048,ml-512-node-049,ml-512-node-050,ml-512-node-051,ml-512-node-052,ml-512-node-053,ml-512-node-054,ml-512-node-055,ml-512-node-056,ml-512-node-057,ml-512-node-058,ml-512-node-059,ml-512-node-060,ml-512-node-061,ml-512-node-062,ml-512-node-063,ml-512-node-064
[2024-07-08 06:05:39,212] [INFO] [runner.py:568:main] cmd = pdsh -S -f 1024 -w ml-512-node-001,ml-512-node-002,ml-512-node-003,ml-512-node-004,ml-512-node-005,ml-512-node-006,ml-512-node-007,ml-512-node-008,ml-512-node-009,ml-512-node-010,ml-512-node-011,ml-512-node-012,ml-512-node-013,ml-512-node-014,ml-512-node-015,ml-512-node-016,ml-512-node-017,ml-512-node-018,ml-512-node-019,ml-512-node-020,ml-512-node-021,ml-512-node-022,ml-512-node-023,ml-512-node-024,ml-512-node-025,ml-512-node-026,ml-512-node-027,ml-512-node-028,ml-512-node-029,ml-512-node-030,ml-512-node-031,ml-512-node-032,ml-512-node-033,ml-512-node-034,ml-512-node-035,ml-512-node-036,ml-512-node-037,ml-512-node-038,ml-512-node-039,ml-512-node-040,ml-512-node-041,ml-512-node-042,ml-512-node-043,ml-512-node-044,ml-512-node-045,ml-512-node-046,ml-512-node-047,ml-512-node-048,ml-512-node-049,ml-512-node-050,ml-512-node-051,ml-512-node-052,ml-512-node-053,ml-512-node-054,ml-512-node-055,ml-512-node-056,ml-512-node-057,ml-512-node-058,ml-512-node-059,ml-512-node-060,ml-512-node-061,ml-512-node-062,ml-512-node-063,ml-512-node-064 export PYTHONPATH=/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training; export PROJECT_PATH=/home/ubuntu/ml-1cc/benchmark; export OMPI_MCA_btl_tcp_if_include=eno1; export UCX_TLS=self,shm,tcp; export NCCL_P2P_LEVEL=NVL; export NCCL_NET_GDR_LEVEL=PIX; export NCCL_IB_HCA='=mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8'; export NCCL_IB_PCI_RELAXED_ORDERING=1; export NCCL_SOCKET_IFNAME=eno1; export NCCL_DEBUG=WARN;  cd /home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training; /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJtbC01MTItbm9kZS0wMDEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --node_rank=%n --master_addr=ml-512-node-001 --master_port=29500 /home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py --data_path Dahoas/full-hh-rlhf --data_split 2,4,4 --data_output_path /home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1 --model_name_or_path facebook/opt-350m --per_device_train_batch_size 24 --per_device_eval_batch_size 4 --max_seq_len 512 --learning_rate 1e-10 --weight_decay 0.1 --disable_dropout --gradient_accumulation_steps 1 --lr_scheduler_type cosine --seed 1234 --zero_stage 0 --deepspeed --num_warmup_steps 10 --num_train_epochs 100 --max_steps 100
ml-512-node-001: [2024-07-08 06:05:40,723] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: 2024-07-08 06:05:42.111954: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-001: 2024-07-08 06:05:42.149722: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-001: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-016: [2024-07-08 06:05:42,800] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [2024-07-08 06:05:42,807] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 06:05:42,806] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 06:05:42,814] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 06:05:42,822] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 06:05:42,826] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [2024-07-08 06:05:42,828] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 06:05:42,832] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 06:05:42,840] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [2024-07-08 06:05:42,844] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [2024-07-08 06:05:42,846] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 06:05:42,846] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 06:05:42,848] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 06:05:42,850] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [2024-07-08 06:05:42,853] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [2024-07-08 06:05:42,852] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [2024-07-08 06:05:42,855] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 06:05:42,856] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 06:05:42,861] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-021: [2024-07-08 06:05:42,864] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 06:05:42,866] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [2024-07-08 06:05:42,872] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 06:05:42,877] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 06:05:42,877] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 06:05:42,881] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 06:05:42,884] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 06:05:42,901] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 06:05:42,900] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 06:05:42,902] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 06:05:42,909] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 06:05:42,954] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:139:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:139:main] 0 NCCL_SOCKET_IFNAME=eno1
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:139:main] 0 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:139:main] 0 NCCL_P2P_LEVEL=NVL
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:139:main] 0 NCCL_DEBUG=WARN
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:139:main] 0 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=0
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-001: [2024-07-08 06:05:43,414] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-001: [2024-07-08 06:05:43,415] [INFO] [launch.py:256:main] process 1992104 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 06:05:43,416] [INFO] [launch.py:256:main] process 1992105 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 06:05:43,417] [INFO] [launch.py:256:main] process 1992106 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 06:05:43,417] [INFO] [launch.py:256:main] process 1992107 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 06:05:43,418] [INFO] [launch.py:256:main] process 1992108 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [2024-07-08 06:05:43,419] [INFO] [launch.py:256:main] process 1992109 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 06:05:43,419] [INFO] [launch.py:256:main] process 1992110 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 06:05:43,420] [INFO] [launch.py:256:main] process 1992111 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 06:05:43,628] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 06:05:43,670] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:05:43,680] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:05:43,688] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 06:05:43,698] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:05:43,698] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [2024-07-08 06:05:43,701] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 06:05:43,714] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 06:05:43,715] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:05:43,718] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:05:43,720] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-063: [2024-07-08 06:05:43,720] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 06:05:43,730] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:05:43,730] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:05:43,731] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [2024-07-08 06:05:43,736] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [2024-07-08 06:05:43,741] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [2024-07-08 06:05:43,750] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [2024-07-08 06:05:43,757] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [2024-07-08 06:05:43,763] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [2024-07-08 06:05:43,766] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:05:43,774] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [2024-07-08 06:05:43,775] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [2024-07-08 06:05:43,786] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 06:05:43,790] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:05:43,790] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [2024-07-08 06:05:43,810] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:05:43,811] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 06:05:43,887] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-056: [2024-07-08 06:05:43,924] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-040: [2024-07-08 06:05:43,936] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: 2024-07-08 06:05:44.160213: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-010: 2024-07-08 06:05:44.172941: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: 2024-07-08 06:05:44.197983: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-007: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-008: 2024-07-08 06:05:44.200817: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: 2024-07-08 06:05:44.205602: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-010: 2024-07-08 06:05:44.210664: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-010: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-020: 2024-07-08 06:05:44.207276: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: 2024-07-08 06:05:44.215405: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-019: 2024-07-08 06:05:44.216185: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-018: 2024-07-08 06:05:44.217494: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: 2024-07-08 06:05:44.218290: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-022: 2024-07-08 06:05:44.222045: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-005: 2024-07-08 06:05:44.222128: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-024: 2024-07-08 06:05:44.224552: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: 2024-07-08 06:05:44.225771: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-023: 2024-07-08 06:05:44.226385: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: 2024-07-08 06:05:44.226964: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-002: 2024-07-08 06:05:44.227650: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: 2024-07-08 06:05:44.229996: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: 2024-07-08 06:05:44.234677: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: 2024-07-08 06:05:44.238654: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-008: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-026: 2024-07-08 06:05:44.238411: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: 2024-07-08 06:05:44.242020: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: 2024-07-08 06:05:44.243789: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-016: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-028: 2024-07-08 06:05:44.247038: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-020: 2024-07-08 06:05:44.245486: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-020: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: 2024-07-08 06:05:44.249188: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: 2024-07-08 06:05:44.252634: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: 2024-07-08 06:05:44.253487: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-006: 2024-07-08 06:05:44.253177: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-006: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: 2024-07-08 06:05:44.255241: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-018: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-009: 2024-07-08 06:05:44.255817: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-009: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: 2024-07-08 06:05:44.259717: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-005: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-022: 2024-07-08 06:05:44.259899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-022: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: 2024-07-08 06:05:44.260451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-019: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: 2024-07-08 06:05:44.262702: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-024: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: 2024-07-08 06:05:44.264522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-023: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-012: 2024-07-08 06:05:44.264999: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-012: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-027: 2024-07-08 06:05:44.265917: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-027: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-002: 2024-07-08 06:05:44.266147: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-002: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-029: 2024-07-08 06:05:44.267346: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-029: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: 2024-07-08 06:05:44.272218: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-003: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: 2024-07-08 06:05:44.276508: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-026: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: 2024-07-08 06:05:44.277561: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-004: 2024-07-08 06:05:44.279987: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-004: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-014: 2024-07-08 06:05:44.279909: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: 2024-07-08 06:05:44.284388: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-028: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-021: 2024-07-08 06:05:44.287195: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: 2024-07-08 06:05:44.290078: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-025: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-017: 2024-07-08 06:05:44.288950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-017: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-011: 2024-07-08 06:05:44.292399: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-011: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: 2024-07-08 06:05:44.298269: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-031: 2024-07-08 06:05:44.301618: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: 2024-07-08 06:05:44.317085: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-030: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-014: 2024-07-08 06:05:44.318523: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-014: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: 2024-07-08 06:05:44.324898: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-021: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: 2024-07-08 06:05:44.336595: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-013: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-031: 2024-07-08 06:05:44.340558: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-031: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-060: 2024-07-08 06:05:44.340587: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-060: 2024-07-08 06:05:44.379909: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-060: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-015: 2024-07-08 06:05:44.385362: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: 2024-07-08 06:05:44.428190: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-015: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [2024-07-08 06:05:44,773] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: 2024-07-08 06:05:45.025518: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-036: 2024-07-08 06:05:45.037141: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-037: 2024-07-08 06:05:45.041664: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-041: 2024-07-08 06:05:45.041257: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-055: 2024-07-08 06:05:45.060202: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-042: 2024-07-08 06:05:45.062704: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-042: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-057: 2024-07-08 06:05:45.066871: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-047: 2024-07-08 06:05:45.067572: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-034: 2024-07-08 06:05:45.074505: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-063: 2024-07-08 06:05:45.074516: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-036: 2024-07-08 06:05:45.075293: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-036: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-035: 2024-07-08 06:05:45.076648: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-037: 2024-07-08 06:05:45.079175: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-037: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-041: 2024-07-08 06:05:45.080177: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-041: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-055: 2024-07-08 06:05:45.098126: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-055: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-051: 2024-07-08 06:05:45.098060: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-044: 2024-07-08 06:05:45.099681: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-047: 2024-07-08 06:05:45.105246: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-047: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-057: 2024-07-08 06:05:45.105124: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-057: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-059: 2024-07-08 06:05:45.107121: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-063: 2024-07-08 06:05:45.112599: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-063: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-034: 2024-07-08 06:05:45.113313: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-034: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-035: 2024-07-08 06:05:45.115537: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-035: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-045: 2024-07-08 06:05:45.119631: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-054: 2024-07-08 06:05:45.120558: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-052: 2024-07-08 06:05:45.126518: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-051: 2024-07-08 06:05:45.137128: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-051: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-044: 2024-07-08 06:05:45.138886: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-044: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-050: 2024-07-08 06:05:45.140572: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-059: 2024-07-08 06:05:45.145537: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-059: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-033: 2024-07-08 06:05:45.146580: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-045: 2024-07-08 06:05:45.157459: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-045: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-054: 2024-07-08 06:05:45.158669: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-054: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-061: 2024-07-08 06:05:45.161096: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-053: 2024-07-08 06:05:45.161780: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-052: 2024-07-08 06:05:45.165484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-052: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-039: 2024-07-08 06:05:45.175359: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-050: 2024-07-08 06:05:45.177882: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-050: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-049: 2024-07-08 06:05:45.179428: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-058: 2024-07-08 06:05:45.189068: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-033: 2024-07-08 06:05:45.184830: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-033: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-038: 2024-07-08 06:05:45.196998: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-061: 2024-07-08 06:05:45.199946: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-061: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-053: 2024-07-08 06:05:45.200832: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-053: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-043: 2024-07-08 06:05:45.204907: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-046: 2024-07-08 06:05:45.210952: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-039: 2024-07-08 06:05:45.213520: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-039: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-049: 2024-07-08 06:05:45.218731: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-049: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-048: 2024-07-08 06:05:45.221304: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-058: 2024-07-08 06:05:45.228113: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-058: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-038: 2024-07-08 06:05:45.236726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-038: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-043: 2024-07-08 06:05:45.244100: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-043: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-064: 2024-07-08 06:05:45.244659: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-046: 2024-07-08 06:05:45.249916: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-046: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-048: 2024-07-08 06:05:45.263371: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-048: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-032: 2024-07-08 06:05:45.268616: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-064: 2024-07-08 06:05:45.285046: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-064: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: 2024-07-08 06:05:45.307970: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-032: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:139:main] 9 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:139:main] 9 NCCL_SOCKET_IFNAME=eno1
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:139:main] 9 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:139:main] 9 NCCL_P2P_LEVEL=NVL
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:139:main] 9 NCCL_DEBUG=WARN
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:139:main] 9 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=9
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-010: [2024-07-08 06:05:45,468] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-010: [2024-07-08 06:05:45,469] [INFO] [launch.py:256:main] process 1067579 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 06:05:45,470] [INFO] [launch.py:256:main] process 1067580 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 06:05:45,471] [INFO] [launch.py:256:main] process 1067581 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 06:05:45,471] [INFO] [launch.py:256:main] process 1067582 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 06:05:45,472] [INFO] [launch.py:256:main] process 1067583 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 06:05:45,473] [INFO] [launch.py:256:main] process 1067584 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 06:05:45,473] [INFO] [launch.py:256:main] process 1067585 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 06:05:45,474] [INFO] [launch.py:256:main] process 1067586 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 06:05:45,482] [INFO] [launch.py:139:main] 6 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-007: [2024-07-08 06:05:45,482] [INFO] [launch.py:139:main] 6 NCCL_SOCKET_IFNAME=eno1
ml-512-node-007: [2024-07-08 06:05:45,482] [INFO] [launch.py:139:main] 6 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-007: [2024-07-08 06:05:45,482] [INFO] [launch.py:139:main] 6 NCCL_P2P_LEVEL=NVL
ml-512-node-007: [2024-07-08 06:05:45,482] [INFO] [launch.py:139:main] 6 NCCL_DEBUG=WARN
ml-512-node-007: [2024-07-08 06:05:45,482] [INFO] [launch.py:139:main] 6 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-007: [2024-07-08 06:05:45,483] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-007: [2024-07-08 06:05:45,483] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=6
ml-512-node-007: [2024-07-08 06:05:45,483] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-007: [2024-07-08 06:05:45,483] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-007: [2024-07-08 06:05:45,483] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-007: [2024-07-08 06:05:45,484] [INFO] [launch.py:256:main] process 1076131 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 06:05:45,484] [INFO] [launch.py:256:main] process 1076132 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 06:05:45,485] [INFO] [launch.py:256:main] process 1076133 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 06:05:45,486] [INFO] [launch.py:256:main] process 1076134 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 06:05:45,486] [INFO] [launch.py:256:main] process 1076135 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 06:05:45,487] [INFO] [launch.py:256:main] process 1076136 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 06:05:45,488] [INFO] [launch.py:256:main] process 1076137 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 06:05:45,488] [INFO] [launch.py:256:main] process 1076138 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:139:main] 7 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:139:main] 7 NCCL_SOCKET_IFNAME=eno1
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:139:main] 7 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:139:main] 7 NCCL_P2P_LEVEL=NVL
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:139:main] 7 NCCL_DEBUG=WARN
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:139:main] 7 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=7
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-008: [2024-07-08 06:05:45,510] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-008: [2024-07-08 06:05:45,511] [INFO] [launch.py:256:main] process 1069901 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 06:05:45,512] [INFO] [launch.py:256:main] process 1069902 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 06:05:45,512] [INFO] [launch.py:256:main] process 1069903 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 06:05:45,513] [INFO] [launch.py:256:main] process 1069904 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 06:05:45,514] [INFO] [launch.py:256:main] process 1069905 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:139:main] 5 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:139:main] 5 NCCL_SOCKET_IFNAME=eno1
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:139:main] 5 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:139:main] 5 NCCL_P2P_LEVEL=NVL
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:139:main] 5 NCCL_DEBUG=WARN
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:139:main] 5 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=5
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-006: [2024-07-08 06:05:45,513] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-008: [2024-07-08 06:05:45,514] [INFO] [launch.py:256:main] process 1069906 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 06:05:45,514] [INFO] [launch.py:256:main] process 1070989 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 06:05:45,515] [INFO] [launch.py:256:main] process 1069907 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 06:05:45,515] [INFO] [launch.py:256:main] process 1070990 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 06:05:45,516] [INFO] [launch.py:256:main] process 1069908 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 06:05:45,516] [INFO] [launch.py:256:main] process 1070991 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 06:05:45,516] [INFO] [launch.py:256:main] process 1070992 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 06:05:45,517] [INFO] [launch.py:256:main] process 1070993 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 06:05:45,517] [INFO] [launch.py:256:main] process 1070994 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 06:05:45,518] [INFO] [launch.py:256:main] process 1070995 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 06:05:45,519] [INFO] [launch.py:256:main] process 1070996 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:139:main] 17 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:139:main] 17 NCCL_SOCKET_IFNAME=eno1
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:139:main] 17 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:139:main] 17 NCCL_P2P_LEVEL=NVL
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:139:main] 17 NCCL_DEBUG=WARN
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:139:main] 17 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=17
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-018: [2024-07-08 06:05:45,520] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-018: [2024-07-08 06:05:45,521] [INFO] [launch.py:256:main] process 1066671 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 06:05:45,522] [INFO] [launch.py:256:main] process 1066672 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 06:05:45,523] [INFO] [launch.py:256:main] process 1066673 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 06:05:45,523] [INFO] [launch.py:256:main] process 1066674 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 06:05:45,524] [INFO] [launch.py:256:main] process 1066675 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 06:05:45,518] [INFO] [launch.py:139:main] 19 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-020: [2024-07-08 06:05:45,518] [INFO] [launch.py:139:main] 19 NCCL_SOCKET_IFNAME=eno1
ml-512-node-020: [2024-07-08 06:05:45,518] [INFO] [launch.py:139:main] 19 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-020: [2024-07-08 06:05:45,518] [INFO] [launch.py:139:main] 19 NCCL_P2P_LEVEL=NVL
ml-512-node-020: [2024-07-08 06:05:45,518] [INFO] [launch.py:139:main] 19 NCCL_DEBUG=WARN
ml-512-node-020: [2024-07-08 06:05:45,518] [INFO] [launch.py:139:main] 19 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-020: [2024-07-08 06:05:45,518] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-020: [2024-07-08 06:05:45,518] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=19
ml-512-node-020: [2024-07-08 06:05:45,519] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-020: [2024-07-08 06:05:45,519] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-020: [2024-07-08 06:05:45,519] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-020: [2024-07-08 06:05:45,519] [INFO] [launch.py:256:main] process 1065693 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 06:05:45,524] [INFO] [launch.py:256:main] process 1066676 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 06:05:45,520] [INFO] [launch.py:256:main] process 1065694 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 06:05:45,525] [INFO] [launch.py:256:main] process 1066677 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 06:05:45,521] [INFO] [launch.py:256:main] process 1065695 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 06:05:45,526] [INFO] [launch.py:256:main] process 1066678 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 06:05:45,522] [INFO] [launch.py:256:main] process 1065696 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:139:main] 22 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:139:main] 22 NCCL_SOCKET_IFNAME=eno1
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:139:main] 22 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:139:main] 22 NCCL_P2P_LEVEL=NVL
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:139:main] 22 NCCL_DEBUG=WARN
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:139:main] 22 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=22
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-023: [2024-07-08 06:05:45,526] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-016: [2024-07-08 06:05:45,524] [INFO] [launch.py:139:main] 15 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-016: [2024-07-08 06:05:45,524] [INFO] [launch.py:139:main] 15 NCCL_SOCKET_IFNAME=eno1
ml-512-node-016: [2024-07-08 06:05:45,524] [INFO] [launch.py:139:main] 15 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-016: [2024-07-08 06:05:45,524] [INFO] [launch.py:139:main] 15 NCCL_P2P_LEVEL=NVL
ml-512-node-016: [2024-07-08 06:05:45,524] [INFO] [launch.py:139:main] 15 NCCL_DEBUG=WARN
ml-512-node-016: [2024-07-08 06:05:45,524] [INFO] [launch.py:139:main] 15 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-016: [2024-07-08 06:05:45,524] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-016: [2024-07-08 06:05:45,524] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=15
ml-512-node-016: [2024-07-08 06:05:45,524] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-016: [2024-07-08 06:05:45,524] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-016: [2024-07-08 06:05:45,525] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-020: [2024-07-08 06:05:45,522] [INFO] [launch.py:256:main] process 1065697 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 06:05:45,527] [INFO] [launch.py:256:main] process 1069912 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 06:05:45,525] [INFO] [launch.py:256:main] process 1066669 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 06:05:45,523] [INFO] [launch.py:256:main] process 1065698 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 06:05:45,528] [INFO] [launch.py:256:main] process 1069913 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:139:main] 18 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:139:main] 18 NCCL_SOCKET_IFNAME=eno1
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:139:main] 18 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:139:main] 18 NCCL_P2P_LEVEL=NVL
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:139:main] 18 NCCL_DEBUG=WARN
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:139:main] 18 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=18
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-019: [2024-07-08 06:05:45,527] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-016: [2024-07-08 06:05:45,526] [INFO] [launch.py:256:main] process 1066670 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 06:05:45,524] [INFO] [launch.py:256:main] process 1065699 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 06:05:45,529] [INFO] [launch.py:256:main] process 1069914 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 06:05:45,528] [INFO] [launch.py:256:main] process 1071641 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 06:05:45,527] [INFO] [launch.py:256:main] process 1066671 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 06:05:45,524] [INFO] [launch.py:256:main] process 1065700 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 06:05:45,529] [INFO] [launch.py:256:main] process 1069915 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 06:05:45,529] [INFO] [launch.py:256:main] process 1071642 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 06:05:45,528] [INFO] [launch.py:256:main] process 1066672 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 06:05:45,530] [INFO] [launch.py:256:main] process 1069916 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 06:05:45,529] [INFO] [launch.py:256:main] process 1071643 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 06:05:45,528] [INFO] [launch.py:256:main] process 1066673 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 06:05:45,530] [INFO] [launch.py:256:main] process 1069917 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 06:05:45,530] [INFO] [launch.py:256:main] process 1071644 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 06:05:45,531] [INFO] [launch.py:256:main] process 1069918 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 06:05:45,530] [INFO] [launch.py:256:main] process 1071645 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 06:05:45,529] [INFO] [launch.py:256:main] process 1066674 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 06:05:45,531] [INFO] [launch.py:139:main] 21 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-022: [2024-07-08 06:05:45,531] [INFO] [launch.py:139:main] 21 NCCL_SOCKET_IFNAME=eno1
ml-512-node-022: [2024-07-08 06:05:45,531] [INFO] [launch.py:139:main] 21 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-022: [2024-07-08 06:05:45,531] [INFO] [launch.py:139:main] 21 NCCL_P2P_LEVEL=NVL
ml-512-node-022: [2024-07-08 06:05:45,531] [INFO] [launch.py:139:main] 21 NCCL_DEBUG=WARN
ml-512-node-022: [2024-07-08 06:05:45,531] [INFO] [launch.py:139:main] 21 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-022: [2024-07-08 06:05:45,531] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-022: [2024-07-08 06:05:45,531] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=21
ml-512-node-022: [2024-07-08 06:05:45,531] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-022: [2024-07-08 06:05:45,532] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-022: [2024-07-08 06:05:45,532] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-019: [2024-07-08 06:05:45,531] [INFO] [launch.py:256:main] process 1071646 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 06:05:45,532] [INFO] [launch.py:256:main] process 1069919 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 06:05:45,530] [INFO] [launch.py:256:main] process 1066675 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 06:05:45,531] [INFO] [launch.py:139:main] 25 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-026: [2024-07-08 06:05:45,532] [INFO] [launch.py:139:main] 25 NCCL_SOCKET_IFNAME=eno1
ml-512-node-026: [2024-07-08 06:05:45,532] [INFO] [launch.py:139:main] 25 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-026: [2024-07-08 06:05:45,532] [INFO] [launch.py:139:main] 25 NCCL_P2P_LEVEL=NVL
ml-512-node-026: [2024-07-08 06:05:45,532] [INFO] [launch.py:139:main] 25 NCCL_DEBUG=WARN
ml-512-node-026: [2024-07-08 06:05:45,532] [INFO] [launch.py:139:main] 25 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-026: [2024-07-08 06:05:45,532] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-026: [2024-07-08 06:05:45,532] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=25
ml-512-node-026: [2024-07-08 06:05:45,532] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-026: [2024-07-08 06:05:45,532] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-026: [2024-07-08 06:05:45,532] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-019: [2024-07-08 06:05:45,532] [INFO] [launch.py:256:main] process 1071647 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 06:05:45,532] [INFO] [launch.py:256:main] process 1065736 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 06:05:45,531] [INFO] [launch.py:256:main] process 1066676 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 06:05:45,533] [INFO] [launch.py:256:main] process 1064743 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 06:05:45,532] [INFO] [launch.py:256:main] process 1071648 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 06:05:45,533] [INFO] [launch.py:256:main] process 1065737 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 06:05:45,533] [INFO] [launch.py:256:main] process 1064744 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:139:main] 26 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:139:main] 26 NCCL_SOCKET_IFNAME=eno1
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:139:main] 26 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:139:main] 26 NCCL_P2P_LEVEL=NVL
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:139:main] 26 NCCL_DEBUG=WARN
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:139:main] 26 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=26
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-027: [2024-07-08 06:05:45,534] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-022: [2024-07-08 06:05:45,534] [INFO] [launch.py:256:main] process 1065738 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 06:05:45,534] [INFO] [launch.py:256:main] process 1064745 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 06:05:45,535] [INFO] [launch.py:256:main] process 1075128 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 06:05:45,535] [INFO] [launch.py:256:main] process 1065739 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 06:05:45,535] [INFO] [launch.py:256:main] process 1064746 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 06:05:45,535] [INFO] [launch.py:256:main] process 1075129 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 06:05:45,535] [INFO] [launch.py:256:main] process 1065740 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 06:05:45,535] [INFO] [launch.py:256:main] process 1064747 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 06:05:45,536] [INFO] [launch.py:256:main] process 1075130 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 06:05:45,536] [INFO] [launch.py:256:main] process 1065741 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 06:05:45,536] [INFO] [launch.py:256:main] process 1064748 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 06:05:45,537] [INFO] [launch.py:256:main] process 1075131 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 06:05:45,537] [INFO] [launch.py:256:main] process 1065742 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 06:05:45,537] [INFO] [launch.py:256:main] process 1064749 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 06:05:45,537] [INFO] [launch.py:256:main] process 1075132 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 06:05:45,537] [INFO] [launch.py:256:main] process 1065743 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 06:05:45,537] [INFO] [launch.py:256:main] process 1064750 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 06:05:45,538] [INFO] [launch.py:256:main] process 1075133 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 06:05:45,539] [INFO] [launch.py:256:main] process 1075134 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 06:05:45,539] [INFO] [launch.py:256:main] process 1075135 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:139:main] 28 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:139:main] 28 NCCL_SOCKET_IFNAME=eno1
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:139:main] 28 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:139:main] 28 NCCL_P2P_LEVEL=NVL
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:139:main] 28 NCCL_DEBUG=WARN
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:139:main] 28 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=28
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-029: [2024-07-08 06:05:45,539] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-029: [2024-07-08 06:05:45,540] [INFO] [launch.py:256:main] process 1069227 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 06:05:45,541] [INFO] [launch.py:256:main] process 1069228 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 06:05:45,541] [INFO] [launch.py:256:main] process 1069229 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:139:main] 8 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:139:main] 8 NCCL_SOCKET_IFNAME=eno1
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:139:main] 8 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:139:main] 8 NCCL_P2P_LEVEL=NVL
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:139:main] 8 NCCL_DEBUG=WARN
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:139:main] 8 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=8
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-009: [2024-07-08 06:05:45,540] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-012: [2024-07-08 06:05:45,542] [INFO] [launch.py:139:main] 11 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-012: [2024-07-08 06:05:45,542] [INFO] [launch.py:139:main] 11 NCCL_SOCKET_IFNAME=eno1
ml-512-node-012: [2024-07-08 06:05:45,542] [INFO] [launch.py:139:main] 11 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-012: [2024-07-08 06:05:45,542] [INFO] [launch.py:139:main] 11 NCCL_P2P_LEVEL=NVL
ml-512-node-012: [2024-07-08 06:05:45,542] [INFO] [launch.py:139:main] 11 NCCL_DEBUG=WARN
ml-512-node-012: [2024-07-08 06:05:45,542] [INFO] [launch.py:139:main] 11 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-012: [2024-07-08 06:05:45,542] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-012: [2024-07-08 06:05:45,542] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=11
ml-512-node-012: [2024-07-08 06:05:45,543] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-012: [2024-07-08 06:05:45,543] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-012: [2024-07-08 06:05:45,543] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-029: [2024-07-08 06:05:45,542] [INFO] [launch.py:256:main] process 1069230 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 06:05:45,541] [INFO] [launch.py:256:main] process 1072941 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 06:05:45,543] [INFO] [launch.py:256:main] process 1069231 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 06:05:45,543] [INFO] [launch.py:256:main] process 1067898 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 06:05:45,542] [INFO] [launch.py:256:main] process 1072942 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 06:05:45,543] [INFO] [launch.py:256:main] process 1069232 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 06:05:45,544] [INFO] [launch.py:256:main] process 1067899 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 06:05:45,543] [INFO] [launch.py:256:main] process 1072943 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 06:05:45,544] [INFO] [launch.py:256:main] process 1069233 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 06:05:45,545] [INFO] [launch.py:256:main] process 1067900 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 06:05:45,543] [INFO] [launch.py:256:main] process 1072944 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 06:05:45,544] [INFO] [launch.py:256:main] process 1069234 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 06:05:45,546] [INFO] [launch.py:256:main] process 1067901 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 06:05:45,544] [INFO] [launch.py:256:main] process 1072945 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 06:05:45,546] [INFO] [launch.py:256:main] process 1067902 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 06:05:45,544] [INFO] [launch.py:256:main] process 1072946 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 06:05:45,545] [INFO] [launch.py:256:main] process 1072947 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 06:05:45,547] [INFO] [launch.py:256:main] process 1067903 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 06:05:45,546] [INFO] [launch.py:256:main] process 1072948 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 06:05:45,548] [INFO] [launch.py:256:main] process 1067904 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 06:05:45,548] [INFO] [launch.py:256:main] process 1067905 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 06:05:45,551] [INFO] [launch.py:139:main] 3 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-004: [2024-07-08 06:05:45,552] [INFO] [launch.py:139:main] 3 NCCL_SOCKET_IFNAME=eno1
ml-512-node-004: [2024-07-08 06:05:45,552] [INFO] [launch.py:139:main] 3 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-004: [2024-07-08 06:05:45,552] [INFO] [launch.py:139:main] 3 NCCL_P2P_LEVEL=NVL
ml-512-node-004: [2024-07-08 06:05:45,552] [INFO] [launch.py:139:main] 3 NCCL_DEBUG=WARN
ml-512-node-004: [2024-07-08 06:05:45,552] [INFO] [launch.py:139:main] 3 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-004: [2024-07-08 06:05:45,552] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-004: [2024-07-08 06:05:45,552] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=3
ml-512-node-004: [2024-07-08 06:05:45,552] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-004: [2024-07-08 06:05:45,552] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-004: [2024-07-08 06:05:45,552] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-004: [2024-07-08 06:05:45,553] [INFO] [launch.py:256:main] process 1071428 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 06:05:45,554] [INFO] [launch.py:256:main] process 1071429 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 06:05:45,554] [INFO] [launch.py:256:main] process 1071430 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 06:05:45,555] [INFO] [launch.py:256:main] process 1071431 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 06:05:45,555] [INFO] [launch.py:256:main] process 1071432 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 06:05:45,556] [INFO] [launch.py:256:main] process 1071433 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 06:05:45,556] [INFO] [launch.py:256:main] process 1071434 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 06:05:45,557] [INFO] [launch.py:256:main] process 1071435 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: 2024-07-08 06:05:45.558835: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:139:main] 1 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:139:main] 1 NCCL_SOCKET_IFNAME=eno1
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:139:main] 1 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:139:main] 1 NCCL_P2P_LEVEL=NVL
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:139:main] 1 NCCL_DEBUG=WARN
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:139:main] 1 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=1
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-002: [2024-07-08 06:05:45,564] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-002: [2024-07-08 06:05:45,565] [INFO] [launch.py:256:main] process 1083143 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:139:main] 4 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:139:main] 4 NCCL_SOCKET_IFNAME=eno1
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:139:main] 4 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:139:main] 4 NCCL_P2P_LEVEL=NVL
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:139:main] 4 NCCL_DEBUG=WARN
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:139:main] 4 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=4
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-005: [2024-07-08 06:05:45,565] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-002: [2024-07-08 06:05:45,566] [INFO] [launch.py:256:main] process 1083144 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 06:05:45,566] [INFO] [launch.py:256:main] process 1089306 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:139:main] 23 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:139:main] 23 NCCL_SOCKET_IFNAME=eno1
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:139:main] 23 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:139:main] 23 NCCL_P2P_LEVEL=NVL
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:139:main] 23 NCCL_DEBUG=WARN
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:139:main] 23 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=23
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-024: [2024-07-08 06:05:45,566] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-002: [2024-07-08 06:05:45,566] [INFO] [launch.py:256:main] process 1083145 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 06:05:45,567] [INFO] [launch.py:256:main] process 1089307 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 06:05:45,567] [INFO] [launch.py:256:main] process 1066063 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 06:05:45,567] [INFO] [launch.py:256:main] process 1083146 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 06:05:45,567] [INFO] [launch.py:256:main] process 1089308 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 06:05:45,568] [INFO] [launch.py:256:main] process 1083147 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 06:05:45,568] [INFO] [launch.py:256:main] process 1066064 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 06:05:45,568] [INFO] [launch.py:256:main] process 1089309 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 06:05:45,568] [INFO] [launch.py:256:main] process 1083148 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 06:05:45,569] [INFO] [launch.py:256:main] process 1066065 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 06:05:45,569] [INFO] [launch.py:256:main] process 1089310 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 06:05:45,569] [INFO] [launch.py:256:main] process 1083149 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 06:05:45,569] [INFO] [launch.py:256:main] process 1066066 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 06:05:45,570] [INFO] [launch.py:256:main] process 1083150 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 06:05:45,569] [INFO] [launch.py:256:main] process 1089311 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 06:05:45,569] [INFO] [launch.py:139:main] 10 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-011: [2024-07-08 06:05:45,569] [INFO] [launch.py:139:main] 10 NCCL_SOCKET_IFNAME=eno1
ml-512-node-024: [2024-07-08 06:05:45,570] [INFO] [launch.py:256:main] process 1066067 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 06:05:45,569] [INFO] [launch.py:139:main] 10 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-011: [2024-07-08 06:05:45,569] [INFO] [launch.py:139:main] 10 NCCL_P2P_LEVEL=NVL
ml-512-node-011: [2024-07-08 06:05:45,569] [INFO] [launch.py:139:main] 10 NCCL_DEBUG=WARN
ml-512-node-011: [2024-07-08 06:05:45,570] [INFO] [launch.py:139:main] 10 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-011: [2024-07-08 06:05:45,570] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-011: [2024-07-08 06:05:45,570] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=10
ml-512-node-011: [2024-07-08 06:05:45,570] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-011: [2024-07-08 06:05:45,570] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-011: [2024-07-08 06:05:45,570] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-005: [2024-07-08 06:05:45,570] [INFO] [launch.py:256:main] process 1089312 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 06:05:45,571] [INFO] [launch.py:256:main] process 1073324 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 06:05:45,571] [INFO] [launch.py:256:main] process 1066068 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 06:05:45,571] [INFO] [launch.py:256:main] process 1089313 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 06:05:45,571] [INFO] [launch.py:256:main] process 1073325 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 06:05:45,571] [INFO] [launch.py:256:main] process 1066069 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:139:main] 27 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:139:main] 27 NCCL_SOCKET_IFNAME=eno1
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:139:main] 27 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:139:main] 27 NCCL_P2P_LEVEL=NVL
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:139:main] 27 NCCL_DEBUG=WARN
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:139:main] 27 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=27
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-028: [2024-07-08 06:05:45,570] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-024: [2024-07-08 06:05:45,572] [INFO] [launch.py:256:main] process 1066070 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 06:05:45,572] [INFO] [launch.py:256:main] process 1073326 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 06:05:45,571] [INFO] [launch.py:256:main] process 1064963 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 06:05:45,573] [INFO] [launch.py:256:main] process 1073327 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 06:05:45,572] [INFO] [launch.py:256:main] process 1064964 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 06:05:45,573] [INFO] [launch.py:256:main] process 1073328 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 06:05:45,572] [INFO] [launch.py:256:main] process 1064965 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 06:05:45,574] [INFO] [launch.py:256:main] process 1073329 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 06:05:45,573] [INFO] [launch.py:256:main] process 1064966 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 06:05:45,575] [INFO] [launch.py:256:main] process 1073330 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 06:05:45,574] [INFO] [launch.py:256:main] process 1064967 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 06:05:45,575] [INFO] [launch.py:256:main] process 1073331 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 06:05:45,574] [INFO] [launch.py:256:main] process 1064968 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 06:05:45,575] [INFO] [launch.py:256:main] process 1064969 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:139:main] 16 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:139:main] 16 NCCL_SOCKET_IFNAME=eno1
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:139:main] 16 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:139:main] 16 NCCL_P2P_LEVEL=NVL
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:139:main] 16 NCCL_DEBUG=WARN
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:139:main] 16 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=16
ml-512-node-028: [2024-07-08 06:05:45,575] [INFO] [launch.py:256:main] process 1064970 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-017: [2024-07-08 06:05:45,574] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-017: [2024-07-08 06:05:45,575] [INFO] [launch.py:256:main] process 1074917 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 06:05:45,576] [INFO] [launch.py:256:main] process 1074918 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 06:05:45,576] [INFO] [launch.py:256:main] process 1074919 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 06:05:45,577] [INFO] [launch.py:256:main] process 1074920 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 06:05:45,577] [INFO] [launch.py:256:main] process 1074921 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 06:05:45,578] [INFO] [launch.py:256:main] process 1074922 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 06:05:45,579] [INFO] [launch.py:256:main] process 1074923 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 06:05:45,580] [INFO] [launch.py:139:main] 20 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-021: [2024-07-08 06:05:45,580] [INFO] [launch.py:139:main] 20 NCCL_SOCKET_IFNAME=eno1
ml-512-node-021: [2024-07-08 06:05:45,580] [INFO] [launch.py:139:main] 20 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-021: [2024-07-08 06:05:45,580] [INFO] [launch.py:139:main] 20 NCCL_P2P_LEVEL=NVL
ml-512-node-021: [2024-07-08 06:05:45,580] [INFO] [launch.py:139:main] 20 NCCL_DEBUG=WARN
ml-512-node-021: [2024-07-08 06:05:45,580] [INFO] [launch.py:139:main] 20 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-021: [2024-07-08 06:05:45,581] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-021: [2024-07-08 06:05:45,581] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=20
ml-512-node-021: [2024-07-08 06:05:45,581] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-021: [2024-07-08 06:05:45,581] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-021: [2024-07-08 06:05:45,581] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-017: [2024-07-08 06:05:45,579] [INFO] [launch.py:256:main] process 1074924 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 06:05:45,582] [INFO] [launch.py:256:main] process 1071498 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:139:main] 24 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:139:main] 24 NCCL_SOCKET_IFNAME=eno1
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:139:main] 24 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:139:main] 24 NCCL_P2P_LEVEL=NVL
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:139:main] 24 NCCL_DEBUG=WARN
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:139:main] 24 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=24
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-025: [2024-07-08 06:05:45,582] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-021: [2024-07-08 06:05:45,582] [INFO] [launch.py:256:main] process 1071499 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 06:05:45,583] [INFO] [launch.py:256:main] process 1071752 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 06:05:45,583] [INFO] [launch.py:256:main] process 1071753 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 06:05:45,583] [INFO] [launch.py:256:main] process 1071500 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 06:05:45,584] [INFO] [launch.py:256:main] process 1071754 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 06:05:45,584] [INFO] [launch.py:256:main] process 1071501 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 06:05:45,585] [INFO] [launch.py:256:main] process 1071755 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 06:05:45,585] [INFO] [launch.py:256:main] process 1071502 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 06:05:45,585] [INFO] [launch.py:256:main] process 1071756 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 06:05:45,585] [INFO] [launch.py:256:main] process 1071503 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 06:05:45,586] [INFO] [launch.py:256:main] process 1071757 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 06:05:45,586] [INFO] [launch.py:256:main] process 1071504 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 06:05:45,586] [INFO] [launch.py:256:main] process 1071758 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 06:05:45,586] [INFO] [launch.py:256:main] process 1071505 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 06:05:45,587] [INFO] [launch.py:256:main] process 1071759 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: 2024-07-08 06:05:45.594717: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-040: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-056: 2024-07-08 06:05:45.610503: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-014: [2024-07-08 06:05:45,611] [INFO] [launch.py:139:main] 13 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-014: [2024-07-08 06:05:45,612] [INFO] [launch.py:139:main] 13 NCCL_SOCKET_IFNAME=eno1
ml-512-node-014: [2024-07-08 06:05:45,612] [INFO] [launch.py:139:main] 13 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-014: [2024-07-08 06:05:45,612] [INFO] [launch.py:139:main] 13 NCCL_P2P_LEVEL=NVL
ml-512-node-014: [2024-07-08 06:05:45,612] [INFO] [launch.py:139:main] 13 NCCL_DEBUG=WARN
ml-512-node-014: [2024-07-08 06:05:45,612] [INFO] [launch.py:139:main] 13 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-014: [2024-07-08 06:05:45,612] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-014: [2024-07-08 06:05:45,612] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=13
ml-512-node-014: [2024-07-08 06:05:45,612] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-014: [2024-07-08 06:05:45,612] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-014: [2024-07-08 06:05:45,612] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-014: [2024-07-08 06:05:45,613] [INFO] [launch.py:256:main] process 1065801 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 06:05:45,614] [INFO] [launch.py:256:main] process 1065802 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 06:05:45,614] [INFO] [launch.py:256:main] process 1065803 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 06:05:45,615] [INFO] [launch.py:256:main] process 1065804 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 06:05:45,616] [INFO] [launch.py:256:main] process 1065805 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 06:05:45,616] [INFO] [launch.py:256:main] process 1065806 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 06:05:45,617] [INFO] [launch.py:256:main] process 1065807 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:139:main] 12 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:139:main] 12 NCCL_SOCKET_IFNAME=eno1
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:139:main] 12 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:139:main] 12 NCCL_P2P_LEVEL=NVL
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:139:main] 12 NCCL_DEBUG=WARN
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:139:main] 12 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=12
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-013: [2024-07-08 06:05:45,618] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-014: [2024-07-08 06:05:45,618] [INFO] [launch.py:256:main] process 1065808 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 06:05:45,619] [INFO] [launch.py:256:main] process 1072362 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 06:05:45,619] [INFO] [launch.py:256:main] process 1072363 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 06:05:45,620] [INFO] [launch.py:256:main] process 1072364 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 06:05:45,621] [INFO] [launch.py:256:main] process 1072365 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 06:05:45,622] [INFO] [launch.py:256:main] process 1072366 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 06:05:45,622] [INFO] [launch.py:256:main] process 1072367 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 06:05:45,623] [INFO] [launch.py:256:main] process 1072368 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 06:05:45,623] [INFO] [launch.py:256:main] process 1072369 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 06:05:45,627] [INFO] [launch.py:139:main] 29 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:139:main] 29 NCCL_SOCKET_IFNAME=eno1
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:139:main] 29 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:139:main] 29 NCCL_P2P_LEVEL=NVL
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:139:main] 29 NCCL_DEBUG=WARN
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:139:main] 29 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=29
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-030: [2024-07-08 06:05:45,628] [INFO] [launch.py:256:main] process 1070032 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 06:05:45,629] [INFO] [launch.py:256:main] process 1070033 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 06:05:45,630] [INFO] [launch.py:256:main] process 1070034 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:139:main] 2 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:139:main] 2 NCCL_SOCKET_IFNAME=eno1
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:139:main] 2 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:139:main] 2 NCCL_P2P_LEVEL=NVL
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:139:main] 2 NCCL_DEBUG=WARN
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:139:main] 2 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=2
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-003: [2024-07-08 06:05:45,631] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-030: [2024-07-08 06:05:45,631] [INFO] [launch.py:256:main] process 1070035 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 06:05:45,632] [INFO] [launch.py:256:main] process 1075241 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 06:05:45,631] [INFO] [launch.py:256:main] process 1070036 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 06:05:45,632] [INFO] [launch.py:256:main] process 1070037 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 06:05:45,633] [INFO] [launch.py:256:main] process 1075242 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 06:05:45,632] [INFO] [launch.py:256:main] process 1070038 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 06:05:45,634] [INFO] [launch.py:256:main] process 1075243 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 06:05:45,633] [INFO] [launch.py:256:main] process 1070039 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 06:05:45,634] [INFO] [launch.py:256:main] process 1075244 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 06:05:45,635] [INFO] [launch.py:256:main] process 1075245 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:139:main] 30 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:139:main] 30 NCCL_SOCKET_IFNAME=eno1
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:139:main] 30 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:139:main] 30 NCCL_P2P_LEVEL=NVL
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:139:main] 30 NCCL_DEBUG=WARN
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:139:main] 30 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=30
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-031: [2024-07-08 06:05:45,634] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-003: [2024-07-08 06:05:45,635] [INFO] [launch.py:256:main] process 1075246 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 06:05:45,635] [INFO] [launch.py:256:main] process 1067931 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 06:05:45,636] [INFO] [launch.py:256:main] process 1067932 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 06:05:45,636] [INFO] [launch.py:256:main] process 1075247 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 06:05:45,636] [INFO] [launch.py:256:main] process 1075248 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 06:05:45,636] [INFO] [launch.py:256:main] process 1067933 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 06:05:45,637] [INFO] [launch.py:256:main] process 1067934 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 06:05:45,638] [INFO] [launch.py:256:main] process 1067935 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:139:main] 59 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:139:main] 59 NCCL_SOCKET_IFNAME=eno1
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:139:main] 59 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:139:main] 59 NCCL_P2P_LEVEL=NVL
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:139:main] 59 NCCL_DEBUG=WARN
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:139:main] 59 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=59
ml-512-node-031: [2024-07-08 06:05:45,639] [INFO] [launch.py:256:main] process 1067936 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-060: [2024-07-08 06:05:45,638] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-031: [2024-07-08 06:05:45,639] [INFO] [launch.py:256:main] process 1067937 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:05:45,639] [INFO] [launch.py:256:main] process 1056127 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 06:05:45,640] [INFO] [launch.py:256:main] process 1067938 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:05:45,640] [INFO] [launch.py:256:main] process 1056128 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:05:45,640] [INFO] [launch.py:256:main] process 1056129 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:05:45,641] [INFO] [launch.py:256:main] process 1056130 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:05:45,642] [INFO] [launch.py:256:main] process 1056131 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:05:45,642] [INFO] [launch.py:256:main] process 1056132 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:05:45,643] [INFO] [launch.py:256:main] process 1056133 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:05:45,644] [INFO] [launch.py:256:main] process 1056134 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: 2024-07-08 06:05:45.647767: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-056: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [2024-07-08 06:05:45,746] [INFO] [launch.py:139:main] 14 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-015: [2024-07-08 06:05:45,746] [INFO] [launch.py:139:main] 14 NCCL_SOCKET_IFNAME=eno1
ml-512-node-015: [2024-07-08 06:05:45,746] [INFO] [launch.py:139:main] 14 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-015: [2024-07-08 06:05:45,747] [INFO] [launch.py:139:main] 14 NCCL_P2P_LEVEL=NVL
ml-512-node-015: [2024-07-08 06:05:45,747] [INFO] [launch.py:139:main] 14 NCCL_DEBUG=WARN
ml-512-node-015: [2024-07-08 06:05:45,747] [INFO] [launch.py:139:main] 14 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-015: [2024-07-08 06:05:45,747] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-015: [2024-07-08 06:05:45,747] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=14
ml-512-node-015: [2024-07-08 06:05:45,747] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-015: [2024-07-08 06:05:45,747] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-015: [2024-07-08 06:05:45,747] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-015: [2024-07-08 06:05:45,748] [INFO] [launch.py:256:main] process 1071242 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 06:05:45,748] [INFO] [launch.py:256:main] process 1071243 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 06:05:45,749] [INFO] [launch.py:256:main] process 1071244 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 06:05:45,750] [INFO] [launch.py:256:main] process 1071245 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 06:05:45,750] [INFO] [launch.py:256:main] process 1071246 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 06:05:45,751] [INFO] [launch.py:256:main] process 1071247 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 06:05:45,751] [INFO] [launch.py:256:main] process 1071248 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 06:05:45,752] [INFO] [launch.py:256:main] process 1071249 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: 2024-07-08 06:05:46.145723: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-062: 2024-07-08 06:05:46.184970: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-062: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-042: [2024-07-08 06:05:46,313] [INFO] [launch.py:139:main] 41 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-042: [2024-07-08 06:05:46,313] [INFO] [launch.py:139:main] 41 NCCL_SOCKET_IFNAME=eno1
ml-512-node-042: [2024-07-08 06:05:46,313] [INFO] [launch.py:139:main] 41 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-042: [2024-07-08 06:05:46,313] [INFO] [launch.py:139:main] 41 NCCL_P2P_LEVEL=NVL
ml-512-node-042: [2024-07-08 06:05:46,313] [INFO] [launch.py:139:main] 41 NCCL_DEBUG=WARN
ml-512-node-042: [2024-07-08 06:05:46,313] [INFO] [launch.py:139:main] 41 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-042: [2024-07-08 06:05:46,314] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-042: [2024-07-08 06:05:46,314] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=41
ml-512-node-042: [2024-07-08 06:05:46,314] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-042: [2024-07-08 06:05:46,314] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-042: [2024-07-08 06:05:46,314] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-042: [2024-07-08 06:05:46,315] [INFO] [launch.py:256:main] process 1060926 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:05:46,315] [INFO] [launch.py:256:main] process 1060927 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:05:46,316] [INFO] [launch.py:256:main] process 1060928 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:05:46,317] [INFO] [launch.py:256:main] process 1060929 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:05:46,318] [INFO] [launch.py:256:main] process 1060930 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:05:46,318] [INFO] [launch.py:256:main] process 1060931 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:05:46,319] [INFO] [launch.py:256:main] process 1060932 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:05:46,320] [INFO] [launch.py:256:main] process 1060933 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:139:main] 40 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:139:main] 40 NCCL_SOCKET_IFNAME=eno1
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:139:main] 40 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:139:main] 40 NCCL_P2P_LEVEL=NVL
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:139:main] 40 NCCL_DEBUG=WARN
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:139:main] 40 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=40
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-041: [2024-07-08 06:05:46,328] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-041: [2024-07-08 06:05:46,329] [INFO] [launch.py:256:main] process 1067393 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:05:46,330] [INFO] [launch.py:256:main] process 1067394 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:05:46,330] [INFO] [launch.py:256:main] process 1067395 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:05:46,331] [INFO] [launch.py:256:main] process 1067396 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:05:46,332] [INFO] [launch.py:256:main] process 1067397 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:05:46,333] [INFO] [launch.py:256:main] process 1067398 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:05:46,333] [INFO] [launch.py:256:main] process 1067399 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:05:46,333] [INFO] [launch.py:256:main] process 1067400 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:139:main] 54 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:139:main] 54 NCCL_SOCKET_IFNAME=eno1
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:139:main] 54 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:139:main] 54 NCCL_P2P_LEVEL=NVL
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:139:main] 54 NCCL_DEBUG=WARN
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:139:main] 54 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=54
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-055: [2024-07-08 06:05:46,353] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-055: [2024-07-08 06:05:46,354] [INFO] [launch.py:256:main] process 1080547 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:05:46,355] [INFO] [launch.py:139:main] 35 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-036: [2024-07-08 06:05:46,355] [INFO] [launch.py:139:main] 35 NCCL_SOCKET_IFNAME=eno1
ml-512-node-036: [2024-07-08 06:05:46,355] [INFO] [launch.py:139:main] 35 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-036: [2024-07-08 06:05:46,355] [INFO] [launch.py:139:main] 35 NCCL_P2P_LEVEL=NVL
ml-512-node-036: [2024-07-08 06:05:46,355] [INFO] [launch.py:139:main] 35 NCCL_DEBUG=WARN
ml-512-node-036: [2024-07-08 06:05:46,355] [INFO] [launch.py:139:main] 35 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-055: [2024-07-08 06:05:46,355] [INFO] [launch.py:256:main] process 1080548 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:05:46,355] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-036: [2024-07-08 06:05:46,355] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=35
ml-512-node-036: [2024-07-08 06:05:46,355] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-036: [2024-07-08 06:05:46,356] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-036: [2024-07-08 06:05:46,356] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-055: [2024-07-08 06:05:46,356] [INFO] [launch.py:256:main] process 1080549 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:05:46,356] [INFO] [launch.py:256:main] process 1061830 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:139:main] 36 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:139:main] 36 NCCL_SOCKET_IFNAME=eno1
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:139:main] 36 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:139:main] 36 NCCL_P2P_LEVEL=NVL
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:139:main] 36 NCCL_DEBUG=WARN
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:139:main] 36 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=36
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-037: [2024-07-08 06:05:46,357] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-055: [2024-07-08 06:05:46,356] [INFO] [launch.py:256:main] process 1080550 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:05:46,357] [INFO] [launch.py:256:main] process 1061831 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:05:46,357] [INFO] [launch.py:256:main] process 1080551 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:05:46,358] [INFO] [launch.py:256:main] process 1065881 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:05:46,358] [INFO] [launch.py:256:main] process 1061832 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:05:46,358] [INFO] [launch.py:256:main] process 1080552 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:05:46,359] [INFO] [launch.py:256:main] process 1065882 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:05:46,359] [INFO] [launch.py:256:main] process 1061833 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:05:46,358] [INFO] [launch.py:256:main] process 1080553 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:05:46,359] [INFO] [launch.py:256:main] process 1065883 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:05:46,359] [INFO] [launch.py:256:main] process 1080554 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:05:46,359] [INFO] [launch.py:256:main] process 1061834 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:05:46,360] [INFO] [launch.py:256:main] process 1065884 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:05:46,360] [INFO] [launch.py:256:main] process 1061835 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:05:46,360] [INFO] [launch.py:256:main] process 1065885 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:05:46,360] [INFO] [launch.py:256:main] process 1061836 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:05:46,361] [INFO] [launch.py:256:main] process 1065886 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:05:46,361] [INFO] [launch.py:256:main] process 1061837 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:05:46,362] [INFO] [launch.py:256:main] process 1065887 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:05:46,362] [INFO] [launch.py:256:main] process 1065888 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:139:main] 62 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:139:main] 62 NCCL_SOCKET_IFNAME=eno1
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:139:main] 62 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:139:main] 62 NCCL_P2P_LEVEL=NVL
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:139:main] 62 NCCL_DEBUG=WARN
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:139:main] 62 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=62
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-063: [2024-07-08 06:05:46,371] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-063: [2024-07-08 06:05:46,372] [INFO] [launch.py:256:main] process 1059523 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:05:46,373] [INFO] [launch.py:256:main] process 1059524 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:05:46,373] [INFO] [launch.py:256:main] process 1059525 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:05:46,374] [INFO] [launch.py:256:main] process 1059526 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:05:46,375] [INFO] [launch.py:256:main] process 1059527 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:05:46,375] [INFO] [launch.py:256:main] process 1059528 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:05:46,376] [INFO] [launch.py:256:main] process 1059529 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:05:46,377] [INFO] [launch.py:256:main] process 1059530 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 46 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 46 NCCL_SOCKET_IFNAME=eno1
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 46 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 46 NCCL_P2P_LEVEL=NVL
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 46 NCCL_DEBUG=WARN
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 46 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=46
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-047: [2024-07-08 06:05:46,381] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-047: [2024-07-08 06:05:46,382] [INFO] [launch.py:256:main] process 1062888 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:139:main] 33 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:139:main] 33 NCCL_SOCKET_IFNAME=eno1
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:139:main] 33 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:139:main] 33 NCCL_P2P_LEVEL=NVL
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:139:main] 33 NCCL_DEBUG=WARN
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:139:main] 33 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=33
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-034: [2024-07-08 06:05:46,382] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-051: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 50 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-051: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 50 NCCL_SOCKET_IFNAME=eno1
ml-512-node-051: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 50 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-051: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 50 NCCL_P2P_LEVEL=NVL
ml-512-node-051: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 50 NCCL_DEBUG=WARN
ml-512-node-051: [2024-07-08 06:05:46,381] [INFO] [launch.py:139:main] 50 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-051: [2024-07-08 06:05:46,381] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-051: [2024-07-08 06:05:46,381] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=50
ml-512-node-051: [2024-07-08 06:05:46,381] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-051: [2024-07-08 06:05:46,381] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-051: [2024-07-08 06:05:46,382] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-034: [2024-07-08 06:05:46,383] [INFO] [launch.py:256:main] process 1062489 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:05:46,383] [INFO] [launch.py:256:main] process 1062889 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:05:46,382] [INFO] [launch.py:256:main] process 1062698 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:05:46,384] [INFO] [launch.py:256:main] process 1062490 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:05:46,384] [INFO] [launch.py:256:main] process 1062890 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:05:46,383] [INFO] [launch.py:256:main] process 1062699 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:05:46,385] [INFO] [launch.py:256:main] process 1062491 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:05:46,384] [INFO] [launch.py:256:main] process 1062891 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:05:46,384] [INFO] [launch.py:256:main] process 1062700 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:05:46,385] [INFO] [launch.py:256:main] process 1062892 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:05:46,385] [INFO] [launch.py:256:main] process 1062492 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:05:46,385] [INFO] [launch.py:256:main] process 1062701 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:05:46,386] [INFO] [launch.py:256:main] process 1062893 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:05:46,386] [INFO] [launch.py:256:main] process 1062493 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:05:46,385] [INFO] [launch.py:256:main] process 1062702 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:05:46,386] [INFO] [launch.py:256:main] process 1062494 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:05:46,386] [INFO] [launch.py:256:main] process 1062894 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:05:46,387] [INFO] [launch.py:256:main] process 1062495 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:05:46,386] [INFO] [launch.py:256:main] process 1062703 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:05:46,387] [INFO] [launch.py:256:main] process 1062895 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:05:46,387] [INFO] [launch.py:256:main] process 1062496 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:05:46,387] [INFO] [launch.py:256:main] process 1062704 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:139:main] 34 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:139:main] 34 NCCL_SOCKET_IFNAME=eno1
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:139:main] 34 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:139:main] 34 NCCL_P2P_LEVEL=NVL
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:139:main] 34 NCCL_DEBUG=WARN
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:139:main] 34 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=34
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-035: [2024-07-08 06:05:46,387] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-051: [2024-07-08 06:05:46,387] [INFO] [launch.py:256:main] process 1062705 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:05:46,388] [INFO] [launch.py:256:main] process 1069327 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:05:46,388] [INFO] [launch.py:256:main] process 1069328 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:05:46,389] [INFO] [launch.py:256:main] process 1069329 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:05:46,390] [INFO] [launch.py:256:main] process 1069330 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:05:46,390] [INFO] [launch.py:256:main] process 1069331 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:05:46,391] [INFO] [launch.py:256:main] process 1069332 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:05:46,392] [INFO] [launch.py:256:main] process 1069333 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:05:46,392] [INFO] [launch.py:256:main] process 1069334 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:05:46,399] [INFO] [launch.py:139:main] 56 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-057: [2024-07-08 06:05:46,399] [INFO] [launch.py:139:main] 56 NCCL_SOCKET_IFNAME=eno1
ml-512-node-057: [2024-07-08 06:05:46,399] [INFO] [launch.py:139:main] 56 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-057: [2024-07-08 06:05:46,399] [INFO] [launch.py:139:main] 56 NCCL_P2P_LEVEL=NVL
ml-512-node-057: [2024-07-08 06:05:46,399] [INFO] [launch.py:139:main] 56 NCCL_DEBUG=WARN
ml-512-node-057: [2024-07-08 06:05:46,399] [INFO] [launch.py:139:main] 56 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-057: [2024-07-08 06:05:46,399] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-057: [2024-07-08 06:05:46,400] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=56
ml-512-node-057: [2024-07-08 06:05:46,400] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-057: [2024-07-08 06:05:46,400] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-057: [2024-07-08 06:05:46,400] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-057: [2024-07-08 06:05:46,401] [INFO] [launch.py:256:main] process 1062196 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:05:46,402] [INFO] [launch.py:256:main] process 1062197 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:05:46,402] [INFO] [launch.py:256:main] process 1062198 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:05:46,403] [INFO] [launch.py:256:main] process 1062199 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:05:46,404] [INFO] [launch.py:256:main] process 1062200 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:05:46,404] [INFO] [launch.py:256:main] process 1062201 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:05:46,405] [INFO] [launch.py:256:main] process 1062202 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:05:46,405] [INFO] [launch.py:139:main] 43 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-044: [2024-07-08 06:05:46,405] [INFO] [launch.py:139:main] 43 NCCL_SOCKET_IFNAME=eno1
ml-512-node-044: [2024-07-08 06:05:46,405] [INFO] [launch.py:139:main] 43 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-044: [2024-07-08 06:05:46,405] [INFO] [launch.py:139:main] 43 NCCL_P2P_LEVEL=NVL
ml-512-node-044: [2024-07-08 06:05:46,405] [INFO] [launch.py:139:main] 43 NCCL_DEBUG=WARN
ml-512-node-044: [2024-07-08 06:05:46,405] [INFO] [launch.py:139:main] 43 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-044: [2024-07-08 06:05:46,406] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-044: [2024-07-08 06:05:46,406] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=43
ml-512-node-044: [2024-07-08 06:05:46,406] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-044: [2024-07-08 06:05:46,406] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-044: [2024-07-08 06:05:46,406] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-057: [2024-07-08 06:05:46,406] [INFO] [launch.py:256:main] process 1062203 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:05:46,407] [INFO] [launch.py:256:main] process 1059256 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:05:46,407] [INFO] [launch.py:256:main] process 1059257 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:05:46,408] [INFO] [launch.py:256:main] process 1059258 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:05:46,409] [INFO] [launch.py:256:main] process 1059259 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:05:46,409] [INFO] [launch.py:256:main] process 1059260 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:05:46,410] [INFO] [launch.py:256:main] process 1059261 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:05:46,411] [INFO] [launch.py:256:main] process 1059262 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:05:46,412] [INFO] [launch.py:256:main] process 1059263 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:05:46,439] [INFO] [launch.py:139:main] 49 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-050: [2024-07-08 06:05:46,439] [INFO] [launch.py:139:main] 49 NCCL_SOCKET_IFNAME=eno1
ml-512-node-050: [2024-07-08 06:05:46,439] [INFO] [launch.py:139:main] 49 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-050: [2024-07-08 06:05:46,439] [INFO] [launch.py:139:main] 49 NCCL_P2P_LEVEL=NVL
ml-512-node-050: [2024-07-08 06:05:46,439] [INFO] [launch.py:139:main] 49 NCCL_DEBUG=WARN
ml-512-node-050: [2024-07-08 06:05:46,439] [INFO] [launch.py:139:main] 49 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-050: [2024-07-08 06:05:46,440] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-050: [2024-07-08 06:05:46,440] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=49
ml-512-node-050: [2024-07-08 06:05:46,440] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-050: [2024-07-08 06:05:46,440] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-050: [2024-07-08 06:05:46,440] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-050: [2024-07-08 06:05:46,441] [INFO] [launch.py:256:main] process 1058649 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:05:46,441] [INFO] [launch.py:256:main] process 1058650 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:05:46,442] [INFO] [launch.py:256:main] process 1058651 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:05:46,443] [INFO] [launch.py:256:main] process 1058652 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:139:main] 53 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:139:main] 53 NCCL_SOCKET_IFNAME=eno1
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:139:main] 53 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:139:main] 53 NCCL_P2P_LEVEL=NVL
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:139:main] 53 NCCL_DEBUG=WARN
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:139:main] 53 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=53
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-054: [2024-07-08 06:05:46,442] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-050: [2024-07-08 06:05:46,443] [INFO] [launch.py:256:main] process 1058653 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:05:46,444] [INFO] [launch.py:256:main] process 1058654 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:05:46,443] [INFO] [launch.py:256:main] process 1056114 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:05:46,444] [INFO] [launch.py:256:main] process 1058655 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:05:46,444] [INFO] [launch.py:256:main] process 1056115 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:05:46,445] [INFO] [launch.py:256:main] process 1058656 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:05:46,445] [INFO] [launch.py:256:main] process 1056116 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:05:46,445] [INFO] [launch.py:256:main] process 1056117 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:139:main] 32 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:139:main] 32 NCCL_SOCKET_IFNAME=eno1
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:139:main] 32 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:139:main] 32 NCCL_P2P_LEVEL=NVL
ml-512-node-054: [2024-07-08 06:05:46,446] [INFO] [launch.py:256:main] process 1056118 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:139:main] 32 NCCL_DEBUG=WARN
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:139:main] 32 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=32
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-033: [2024-07-08 06:05:46,441] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-033: [2024-07-08 06:05:46,442] [INFO] [launch.py:256:main] process 1072281 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:05:46,447] [INFO] [launch.py:256:main] process 1056119 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:05:46,443] [INFO] [launch.py:256:main] process 1072282 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:05:46,447] [INFO] [launch.py:256:main] process 1056120 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:05:46,448] [INFO] [launch.py:256:main] process 1056121 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:05:46,444] [INFO] [launch.py:256:main] process 1072283 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:05:46,444] [INFO] [launch.py:256:main] process 1072284 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:05:46,445] [INFO] [launch.py:256:main] process 1072285 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:05:46,446] [INFO] [launch.py:256:main] process 1072286 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:05:46,449] [INFO] [launch.py:139:main] 51 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-052: [2024-07-08 06:05:46,449] [INFO] [launch.py:139:main] 51 NCCL_SOCKET_IFNAME=eno1
ml-512-node-052: [2024-07-08 06:05:46,449] [INFO] [launch.py:139:main] 51 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-052: [2024-07-08 06:05:46,449] [INFO] [launch.py:139:main] 51 NCCL_P2P_LEVEL=NVL
ml-512-node-052: [2024-07-08 06:05:46,449] [INFO] [launch.py:139:main] 51 NCCL_DEBUG=WARN
ml-512-node-052: [2024-07-08 06:05:46,449] [INFO] [launch.py:139:main] 51 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-052: [2024-07-08 06:05:46,450] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-052: [2024-07-08 06:05:46,450] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=51
ml-512-node-052: [2024-07-08 06:05:46,450] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-052: [2024-07-08 06:05:46,450] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-052: [2024-07-08 06:05:46,450] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-033: [2024-07-08 06:05:46,446] [INFO] [launch.py:256:main] process 1072287 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:05:46,450] [INFO] [launch.py:256:main] process 1058137 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:05:46,447] [INFO] [launch.py:256:main] process 1072288 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:05:46,451] [INFO] [launch.py:256:main] process 1058138 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:05:46,452] [INFO] [launch.py:256:main] process 1058139 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:05:46,453] [INFO] [launch.py:256:main] process 1058140 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:05:46,454] [INFO] [launch.py:256:main] process 1058141 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:05:46,454] [INFO] [launch.py:256:main] process 1058142 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:05:46,455] [INFO] [launch.py:256:main] process 1058143 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:05:46,456] [INFO] [launch.py:256:main] process 1058144 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:139:main] 44 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:139:main] 44 NCCL_SOCKET_IFNAME=eno1
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:139:main] 44 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:139:main] 44 NCCL_P2P_LEVEL=NVL
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:139:main] 44 NCCL_DEBUG=WARN
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:139:main] 44 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=44
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-045: [2024-07-08 06:05:46,461] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-045: [2024-07-08 06:05:46,462] [INFO] [launch.py:256:main] process 1064732 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:05:46,463] [INFO] [launch.py:256:main] process 1064733 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:05:46,464] [INFO] [launch.py:256:main] process 1064734 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:05:46,464] [INFO] [launch.py:256:main] process 1064735 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:05:46,465] [INFO] [launch.py:256:main] process 1064736 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:139:main] 58 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:139:main] 58 NCCL_SOCKET_IFNAME=eno1
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:139:main] 58 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:139:main] 58 NCCL_P2P_LEVEL=NVL
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:139:main] 58 NCCL_DEBUG=WARN
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:139:main] 58 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=58
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-059: [2024-07-08 06:05:46,465] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-045: [2024-07-08 06:05:46,466] [INFO] [launch.py:256:main] process 1064737 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:05:46,466] [INFO] [launch.py:256:main] process 1064738 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:05:46,467] [INFO] [launch.py:256:main] process 1059649 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:05:46,467] [INFO] [launch.py:256:main] process 1064739 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:05:46,467] [INFO] [launch.py:256:main] process 1059650 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:05:46,468] [INFO] [launch.py:256:main] process 1059651 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:05:46,469] [INFO] [launch.py:256:main] process 1059652 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:05:46,469] [INFO] [launch.py:256:main] process 1059653 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:05:46,470] [INFO] [launch.py:256:main] process 1059654 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:05:46,471] [INFO] [launch.py:256:main] process 1059655 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:05:46,471] [INFO] [launch.py:256:main] process 1059656 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:05:46,473] [INFO] [launch.py:139:main] 60 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-061: [2024-07-08 06:05:46,474] [INFO] [launch.py:139:main] 60 NCCL_SOCKET_IFNAME=eno1
ml-512-node-061: [2024-07-08 06:05:46,474] [INFO] [launch.py:139:main] 60 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-061: [2024-07-08 06:05:46,474] [INFO] [launch.py:139:main] 60 NCCL_P2P_LEVEL=NVL
ml-512-node-061: [2024-07-08 06:05:46,474] [INFO] [launch.py:139:main] 60 NCCL_DEBUG=WARN
ml-512-node-061: [2024-07-08 06:05:46,474] [INFO] [launch.py:139:main] 60 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-061: [2024-07-08 06:05:46,474] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-061: [2024-07-08 06:05:46,474] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=60
ml-512-node-061: [2024-07-08 06:05:46,474] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-061: [2024-07-08 06:05:46,474] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-061: [2024-07-08 06:05:46,474] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-061: [2024-07-08 06:05:46,475] [INFO] [launch.py:256:main] process 1061762 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:05:46,475] [INFO] [launch.py:256:main] process 1061763 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:05:46,476] [INFO] [launch.py:256:main] process 1061764 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:05:46,477] [INFO] [launch.py:256:main] process 1061765 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:05:46,478] [INFO] [launch.py:256:main] process 1061766 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:05:46,478] [INFO] [launch.py:256:main] process 1061767 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:05:46,479] [INFO] [launch.py:256:main] process 1061768 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:05:46,480] [INFO] [launch.py:256:main] process 1061769 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:05:46,497] [INFO] [launch.py:139:main] 52 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-053: [2024-07-08 06:05:46,497] [INFO] [launch.py:139:main] 52 NCCL_SOCKET_IFNAME=eno1
ml-512-node-053: [2024-07-08 06:05:46,497] [INFO] [launch.py:139:main] 52 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-053: [2024-07-08 06:05:46,497] [INFO] [launch.py:139:main] 52 NCCL_P2P_LEVEL=NVL
ml-512-node-053: [2024-07-08 06:05:46,497] [INFO] [launch.py:139:main] 52 NCCL_DEBUG=WARN
ml-512-node-053: [2024-07-08 06:05:46,497] [INFO] [launch.py:139:main] 52 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-053: [2024-07-08 06:05:46,497] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-053: [2024-07-08 06:05:46,497] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=52
ml-512-node-053: [2024-07-08 06:05:46,498] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-053: [2024-07-08 06:05:46,498] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-053: [2024-07-08 06:05:46,498] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-053: [2024-07-08 06:05:46,499] [INFO] [launch.py:256:main] process 1064474 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:05:46,500] [INFO] [launch.py:256:main] process 1064475 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:05:46,500] [INFO] [launch.py:256:main] process 1064476 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:05:46,501] [INFO] [launch.py:256:main] process 1064477 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:05:46,501] [INFO] [launch.py:256:main] process 1064478 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:05:46,502] [INFO] [launch.py:256:main] process 1064479 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:139:main] 38 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:139:main] 38 NCCL_SOCKET_IFNAME=eno1
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:139:main] 38 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:139:main] 38 NCCL_P2P_LEVEL=NVL
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:139:main] 38 NCCL_DEBUG=WARN
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:139:main] 38 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-053: [2024-07-08 06:05:46,503] [INFO] [launch.py:256:main] process 1064480 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=38
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-039: [2024-07-08 06:05:46,503] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-053: [2024-07-08 06:05:46,503] [INFO] [launch.py:256:main] process 1064481 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:05:46,504] [INFO] [launch.py:256:main] process 1148674 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:05:46,505] [INFO] [launch.py:256:main] process 1148675 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:05:46,506] [INFO] [launch.py:256:main] process 1148676 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:05:46,506] [INFO] [launch.py:256:main] process 1148677 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:05:46,507] [INFO] [launch.py:256:main] process 1148678 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:05:46,508] [INFO] [launch.py:256:main] process 1148679 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:05:46,508] [INFO] [launch.py:256:main] process 1148680 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:05:46,509] [INFO] [launch.py:256:main] process 1148681 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:139:main] 57 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:139:main] 57 NCCL_SOCKET_IFNAME=eno1
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:139:main] 57 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:139:main] 57 NCCL_P2P_LEVEL=NVL
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:139:main] 57 NCCL_DEBUG=WARN
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:139:main] 57 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=57
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-058: [2024-07-08 06:05:46,519] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-058: [2024-07-08 06:05:46,520] [INFO] [launch.py:256:main] process 1055272 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:05:46,521] [INFO] [launch.py:256:main] process 1055273 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:05:46,522] [INFO] [launch.py:256:main] process 1055274 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:05:46,522] [INFO] [launch.py:256:main] process 1055275 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:05:46,523] [INFO] [launch.py:256:main] process 1055276 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:05:46,524] [INFO] [launch.py:256:main] process 1055277 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:05:46,524] [INFO] [launch.py:256:main] process 1055278 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:05:46,525] [INFO] [launch.py:256:main] process 1055279 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:139:main] 48 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:139:main] 48 NCCL_SOCKET_IFNAME=eno1
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:139:main] 48 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:139:main] 48 NCCL_P2P_LEVEL=NVL
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:139:main] 48 NCCL_DEBUG=WARN
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:139:main] 48 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=48
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-049: [2024-07-08 06:05:46,525] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-049: [2024-07-08 06:05:46,526] [INFO] [launch.py:256:main] process 1066213 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:05:46,527] [INFO] [launch.py:256:main] process 1066214 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:05:46,527] [INFO] [launch.py:256:main] process 1066215 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:05:46,526] [INFO] [launch.py:139:main] 42 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-043: [2024-07-08 06:05:46,526] [INFO] [launch.py:139:main] 42 NCCL_SOCKET_IFNAME=eno1
ml-512-node-043: [2024-07-08 06:05:46,526] [INFO] [launch.py:139:main] 42 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-043: [2024-07-08 06:05:46,526] [INFO] [launch.py:139:main] 42 NCCL_P2P_LEVEL=NVL
ml-512-node-043: [2024-07-08 06:05:46,526] [INFO] [launch.py:139:main] 42 NCCL_DEBUG=WARN
ml-512-node-043: [2024-07-08 06:05:46,526] [INFO] [launch.py:139:main] 42 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-043: [2024-07-08 06:05:46,526] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-043: [2024-07-08 06:05:46,526] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=42
ml-512-node-043: [2024-07-08 06:05:46,527] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-043: [2024-07-08 06:05:46,527] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-043: [2024-07-08 06:05:46,527] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-049: [2024-07-08 06:05:46,528] [INFO] [launch.py:256:main] process 1066216 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:05:46,528] [INFO] [launch.py:256:main] process 1064754 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:05:46,529] [INFO] [launch.py:256:main] process 1066217 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:05:46,528] [INFO] [launch.py:256:main] process 1064755 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:05:46,529] [INFO] [launch.py:256:main] process 1066218 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:05:46,529] [INFO] [launch.py:256:main] process 1064756 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:05:46,530] [INFO] [launch.py:256:main] process 1066219 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:05:46,529] [INFO] [launch.py:256:main] process 1064757 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:05:46,530] [INFO] [launch.py:256:main] process 1064758 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:05:46,531] [INFO] [launch.py:256:main] process 1066220 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:05:46,531] [INFO] [launch.py:256:main] process 1064759 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:139:main] 47 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:139:main] 47 NCCL_SOCKET_IFNAME=eno1
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:139:main] 47 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:139:main] 47 NCCL_P2P_LEVEL=NVL
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:139:main] 47 NCCL_DEBUG=WARN
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:139:main] 47 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=47
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-048: [2024-07-08 06:05:46,531] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-043: [2024-07-08 06:05:46,531] [INFO] [launch.py:256:main] process 1064760 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:05:46,532] [INFO] [launch.py:256:main] process 1059123 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:05:46,532] [INFO] [launch.py:256:main] process 1064761 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:05:46,533] [INFO] [launch.py:256:main] process 1059124 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:05:46,534] [INFO] [launch.py:256:main] process 1059125 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:05:46,535] [INFO] [launch.py:256:main] process 1059126 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:139:main] 45 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:139:main] 45 NCCL_SOCKET_IFNAME=eno1
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:139:main] 45 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:139:main] 45 NCCL_P2P_LEVEL=NVL
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:139:main] 45 NCCL_DEBUG=WARN
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:139:main] 45 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=45
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-046: [2024-07-08 06:05:46,534] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-048: [2024-07-08 06:05:46,535] [INFO] [launch.py:256:main] process 1059127 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:05:46,535] [INFO] [launch.py:256:main] process 1060865 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:05:46,536] [INFO] [launch.py:256:main] process 1059128 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:05:46,536] [INFO] [launch.py:256:main] process 1060866 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:05:46,537] [INFO] [launch.py:256:main] process 1059129 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:05:46,537] [INFO] [launch.py:256:main] process 1060867 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:05:46,537] [INFO] [launch.py:256:main] process 1059130 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:05:46,537] [INFO] [launch.py:256:main] process 1060868 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:05:46,538] [INFO] [launch.py:256:main] process 1060869 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:139:main] 37 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:139:main] 37 NCCL_SOCKET_IFNAME=eno1
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:139:main] 37 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:139:main] 37 NCCL_P2P_LEVEL=NVL
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:139:main] 37 NCCL_DEBUG=WARN
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:139:main] 37 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=37
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-038: [2024-07-08 06:05:46,537] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-046: [2024-07-08 06:05:46,538] [INFO] [launch.py:256:main] process 1060870 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:05:46,538] [INFO] [launch.py:256:main] process 1061373 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:05:46,539] [INFO] [launch.py:256:main] process 1060871 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:05:46,539] [INFO] [launch.py:256:main] process 1061374 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:05:46,540] [INFO] [launch.py:256:main] process 1060872 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:05:46,540] [INFO] [launch.py:256:main] process 1061375 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:05:46,540] [INFO] [launch.py:256:main] process 1061376 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:05:46,541] [INFO] [launch.py:256:main] process 1061377 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:05:46,542] [INFO] [launch.py:256:main] process 1061378 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:05:46,542] [INFO] [launch.py:256:main] process 1061379 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:05:46,543] [INFO] [launch.py:256:main] process 1061380 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:139:main] 63 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:139:main] 63 NCCL_SOCKET_IFNAME=eno1
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:139:main] 63 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:139:main] 63 NCCL_P2P_LEVEL=NVL
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:139:main] 63 NCCL_DEBUG=WARN
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:139:main] 63 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=63
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-064: [2024-07-08 06:05:46,553] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-064: [2024-07-08 06:05:46,554] [INFO] [launch.py:256:main] process 1053719 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:05:46,555] [INFO] [launch.py:256:main] process 1053720 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:05:46,555] [INFO] [launch.py:256:main] process 1053721 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:05:46,556] [INFO] [launch.py:256:main] process 1053722 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:05:46,557] [INFO] [launch.py:256:main] process 1053723 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:05:46,557] [INFO] [launch.py:256:main] process 1053724 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:05:46,558] [INFO] [launch.py:256:main] process 1053725 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:05:46,558] [INFO] [launch.py:256:main] process 1053726 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 06:05:46,568] [INFO] [launch.py:139:main] 31 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-032: [2024-07-08 06:05:46,569] [INFO] [launch.py:139:main] 31 NCCL_SOCKET_IFNAME=eno1
ml-512-node-032: [2024-07-08 06:05:46,569] [INFO] [launch.py:139:main] 31 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-032: [2024-07-08 06:05:46,569] [INFO] [launch.py:139:main] 31 NCCL_P2P_LEVEL=NVL
ml-512-node-032: [2024-07-08 06:05:46,569] [INFO] [launch.py:139:main] 31 NCCL_DEBUG=WARN
ml-512-node-032: [2024-07-08 06:05:46,569] [INFO] [launch.py:139:main] 31 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-032: [2024-07-08 06:05:46,569] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-032: [2024-07-08 06:05:46,569] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=31
ml-512-node-032: [2024-07-08 06:05:46,569] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-032: [2024-07-08 06:05:46,569] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-032: [2024-07-08 06:05:46,569] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-032: [2024-07-08 06:05:46,570] [INFO] [launch.py:256:main] process 1060599 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 06:05:46,570] [INFO] [launch.py:256:main] process 1060600 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 06:05:46,571] [INFO] [launch.py:256:main] process 1060601 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 06:05:46,572] [INFO] [launch.py:256:main] process 1060602 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 06:05:46,573] [INFO] [launch.py:256:main] process 1060603 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 06:05:46,573] [INFO] [launch.py:256:main] process 1060604 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 06:05:46,574] [INFO] [launch.py:256:main] process 1060605 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 06:05:46,575] [INFO] [launch.py:256:main] process 1060606 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:05:46,974] [INFO] [launch.py:139:main] 39 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-040: [2024-07-08 06:05:46,974] [INFO] [launch.py:139:main] 39 NCCL_SOCKET_IFNAME=eno1
ml-512-node-040: [2024-07-08 06:05:46,974] [INFO] [launch.py:139:main] 39 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-040: [2024-07-08 06:05:46,974] [INFO] [launch.py:139:main] 39 NCCL_P2P_LEVEL=NVL
ml-512-node-040: [2024-07-08 06:05:46,974] [INFO] [launch.py:139:main] 39 NCCL_DEBUG=WARN
ml-512-node-040: [2024-07-08 06:05:46,974] [INFO] [launch.py:139:main] 39 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-040: [2024-07-08 06:05:46,975] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-040: [2024-07-08 06:05:46,975] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=39
ml-512-node-040: [2024-07-08 06:05:46,975] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-040: [2024-07-08 06:05:46,975] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-040: [2024-07-08 06:05:46,975] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-040: [2024-07-08 06:05:46,976] [INFO] [launch.py:256:main] process 1116539 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:05:46,976] [INFO] [launch.py:256:main] process 1116540 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:05:46,977] [INFO] [launch.py:256:main] process 1116541 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:05:46,978] [INFO] [launch.py:256:main] process 1116542 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:05:46,979] [INFO] [launch.py:256:main] process 1116543 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:05:46,980] [INFO] [launch.py:256:main] process 1116544 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:05:46,980] [INFO] [launch.py:256:main] process 1116545 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:05:46,981] [INFO] [launch.py:256:main] process 1116546 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:139:main] 55 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:139:main] 55 NCCL_SOCKET_IFNAME=eno1
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:139:main] 55 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:139:main] 55 NCCL_P2P_LEVEL=NVL
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:139:main] 55 NCCL_DEBUG=WARN
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:139:main] 55 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=55
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-056: [2024-07-08 06:05:47,011] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-056: [2024-07-08 06:05:47,012] [INFO] [launch.py:256:main] process 1072771 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:05:47,013] [INFO] [launch.py:256:main] process 1072772 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:05:47,013] [INFO] [launch.py:256:main] process 1072773 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:05:47,014] [INFO] [launch.py:256:main] process 1072774 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:05:47,015] [INFO] [launch.py:256:main] process 1072775 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:05:47,016] [INFO] [launch.py:256:main] process 1072776 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:05:47,016] [INFO] [launch.py:256:main] process 1072777 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:05:47,017] [INFO] [launch.py:256:main] process 1072778 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:139:main] 61 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:139:main] 61 NCCL_SOCKET_IFNAME=eno1
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:139:main] 61 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:139:main] 61 NCCL_P2P_LEVEL=NVL
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:139:main] 61 NCCL_DEBUG=WARN
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:139:main] 61 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:152:main] nnodes=64, num_local_procs=8, node_rank=61
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255], 'ml-512-node-033': [256, 257, 258, 259, 260, 261, 262, 263], 'ml-512-node-034': [264, 265, 266, 267, 268, 269, 270, 271], 'ml-512-node-035': [272, 273, 274, 275, 276, 277, 278, 279], 'ml-512-node-036': [280, 281, 282, 283, 284, 285, 286, 287], 'ml-512-node-037': [288, 289, 290, 291, 292, 293, 294, 295], 'ml-512-node-038': [296, 297, 298, 299, 300, 301, 302, 303], 'ml-512-node-039': [304, 305, 306, 307, 308, 309, 310, 311], 'ml-512-node-040': [312, 313, 314, 315, 316, 317, 318, 319], 'ml-512-node-041': [320, 321, 322, 323, 324, 325, 326, 327], 'ml-512-node-042': [328, 329, 330, 331, 332, 333, 334, 335], 'ml-512-node-043': [336, 337, 338, 339, 340, 341, 342, 343], 'ml-512-node-044': [344, 345, 346, 347, 348, 349, 350, 351], 'ml-512-node-045': [352, 353, 354, 355, 356, 357, 358, 359], 'ml-512-node-046': [360, 361, 362, 363, 364, 365, 366, 367], 'ml-512-node-047': [368, 369, 370, 371, 372, 373, 374, 375], 'ml-512-node-048': [376, 377, 378, 379, 380, 381, 382, 383], 'ml-512-node-049': [384, 385, 386, 387, 388, 389, 390, 391], 'ml-512-node-050': [392, 393, 394, 395, 396, 397, 398, 399], 'ml-512-node-051': [400, 401, 402, 403, 404, 405, 406, 407], 'ml-512-node-052': [408, 409, 410, 411, 412, 413, 414, 415], 'ml-512-node-053': [416, 417, 418, 419, 420, 421, 422, 423], 'ml-512-node-054': [424, 425, 426, 427, 428, 429, 430, 431], 'ml-512-node-055': [432, 433, 434, 435, 436, 437, 438, 439], 'ml-512-node-056': [440, 441, 442, 443, 444, 445, 446, 447], 'ml-512-node-057': [448, 449, 450, 451, 452, 453, 454, 455], 'ml-512-node-058': [456, 457, 458, 459, 460, 461, 462, 463], 'ml-512-node-059': [464, 465, 466, 467, 468, 469, 470, 471], 'ml-512-node-060': [472, 473, 474, 475, 476, 477, 478, 479], 'ml-512-node-061': [480, 481, 482, 483, 484, 485, 486, 487], 'ml-512-node-062': [488, 489, 490, 491, 492, 493, 494, 495], 'ml-512-node-063': [496, 497, 498, 499, 500, 501, 502, 503], 'ml-512-node-064': [504, 505, 506, 507, 508, 509, 510, 511]})
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:164:main] dist_world_size=512
ml-512-node-062: [2024-07-08 06:05:47,436] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-062: [2024-07-08 06:05:47,437] [INFO] [launch.py:256:main] process 1055272 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:05:47,438] [INFO] [launch.py:256:main] process 1055273 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:05:47,439] [INFO] [launch.py:256:main] process 1055274 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:05:47,440] [INFO] [launch.py:256:main] process 1055275 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:05:47,440] [INFO] [launch.py:256:main] process 1055276 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:05:47,441] [INFO] [launch.py:256:main] process 1055277 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:05:47,442] [INFO] [launch.py:256:main] process 1055278 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:05:47,443] [INFO] [launch.py:256:main] process 1055279 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 06:05:49,834] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [2024-07-08 06:05:49,940] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [2024-07-08 06:05:49,955] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:05:49,987] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:05:50,051] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [2024-07-08 06:05:50,173] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 06:05:50,215] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 06:05:50,245] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 06:05:50,333] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [2024-07-08 06:05:50,345] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [2024-07-08 06:05:50,385] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 06:05:50,392] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [2024-07-08 06:05:50,479] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [2024-07-08 06:05:50,517] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [2024-07-08 06:05:50,543] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 06:05:50,539] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [2024-07-08 06:05:50,549] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [2024-07-08 06:05:50,580] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [2024-07-08 06:05:50,594] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 06:05:50,609] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 06:05:50,617] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 06:05:50,619] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 06:05:50,623] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 06:05:50,630] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 06:05:50,638] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 06:05:50,669] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 06:05:50,669] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [2024-07-08 06:05:50,689] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 06:05:50,691] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-021: [2024-07-08 06:05:50,694] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [2024-07-08 06:05:50,724] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [2024-07-08 06:05:50,730] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [2024-07-08 06:05:50,739] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [2024-07-08 06:05:50,749] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 06:05:50,754] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 06:05:50,754] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 06:05:50,761] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [2024-07-08 06:05:50,763] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 06:05:50,767] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [2024-07-08 06:05:50,778] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [2024-07-08 06:05:50,793] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [2024-07-08 06:05:50,796] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [2024-07-08 06:05:50,799] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [2024-07-08 06:05:50,800] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [2024-07-08 06:05:50,797] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [2024-07-08 06:05:50,810] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 06:05:50,814] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [2024-07-08 06:05:50,821] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 06:05:50,830] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 06:05:50,837] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 06:05:50,843] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [2024-07-08 06:05:50,850] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 06:05:50,853] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [2024-07-08 06:05:50,854] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 06:05:50,852] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [2024-07-08 06:05:50,857] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [2024-07-08 06:05:50,863] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [2024-07-08 06:05:50,862] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 06:05:50,868] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [2024-07-08 06:05:50,874] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [2024-07-08 06:05:50,874] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 06:05:50,875] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [2024-07-08 06:05:50,881] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 06:05:50,885] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [2024-07-08 06:05:50,890] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-063: [2024-07-08 06:05:50,896] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [2024-07-08 06:05:50,906] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 06:05:50,908] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [2024-07-08 06:05:50,913] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 06:05:50,916] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 06:05:50,917] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [2024-07-08 06:05:50,918] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 06:05:50,918] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 06:05:50,924] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:05:50,924] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 06:05:50,929] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 06:05:50,930] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 06:05:50,932] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 06:05:50,937] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 06:05:50,938] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [2024-07-08 06:05:50,941] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 06:05:50,946] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 06:05:50,954] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [2024-07-08 06:05:50,955] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 06:05:50,957] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [2024-07-08 06:05:50,955] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 06:05:50,962] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [2024-07-08 06:05:50,980] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [2024-07-08 06:05:50,984] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 06:05:50,992] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [2024-07-08 06:05:50,998] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [2024-07-08 06:05:51,001] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 06:05:51,002] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [2024-07-08 06:05:51,013] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 06:05:51,014] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [2024-07-08 06:05:51,018] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [2024-07-08 06:05:51,018] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [2024-07-08 06:05:51,019] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [2024-07-08 06:05:51,022] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 06:05:51,022] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [2024-07-08 06:05:51,025] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [2024-07-08 06:05:51,027] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 06:05:51,030] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 06:05:51,031] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 06:05:51,033] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [2024-07-08 06:05:51,036] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 06:05:51,036] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 06:05:51,042] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [2024-07-08 06:05:51,061] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [2024-07-08 06:05:51,065] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 06:05:51,073] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 06:05:51,072] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [2024-07-08 06:05:51,077] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 06:05:51,077] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [2024-07-08 06:05:51,084] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [2024-07-08 06:05:51,093] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [2024-07-08 06:05:51,093] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [2024-07-08 06:05:51,094] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [2024-07-08 06:05:51,095] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [2024-07-08 06:05:51,099] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [2024-07-08 06:05:51,114] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 06:05:51,114] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 06:05:51,113] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 06:05:51,116] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 06:05:51,128] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [2024-07-08 06:05:51,150] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 06:05:51,150] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [2024-07-08 06:05:51,152] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [2024-07-08 06:05:51,156] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [2024-07-08 06:05:51,161] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [2024-07-08 06:05:51,164] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 06:05:51,165] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [2024-07-08 06:05:51,167] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [2024-07-08 06:05:51,167] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [2024-07-08 06:05:51,163] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [2024-07-08 06:05:51,169] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [2024-07-08 06:05:51,177] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 06:05:51,178] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [2024-07-08 06:05:51,185] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [2024-07-08 06:05:51,203] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 06:05:51,205] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [2024-07-08 06:05:51,211] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 06:05:51,215] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [2024-07-08 06:05:51,222] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [2024-07-08 06:05:51,223] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 06:05:51,223] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 06:05:51,224] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [2024-07-08 06:05:51,229] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [2024-07-08 06:05:51,234] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [2024-07-08 06:05:51,236] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [2024-07-08 06:05:51,242] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 06:05:51,241] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [2024-07-08 06:05:51,243] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [2024-07-08 06:05:51,255] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [2024-07-08 06:05:51,258] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 06:05:51,261] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [2024-07-08 06:05:51,267] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [2024-07-08 06:05:51,271] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [2024-07-08 06:05:51,274] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [2024-07-08 06:05:51,277] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [2024-07-08 06:05:51,284] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [2024-07-08 06:05:51,294] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-021: [2024-07-08 06:05:51,294] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 06:05:51,295] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [2024-07-08 06:05:51,292] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [2024-07-08 06:05:51,297] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [2024-07-08 06:05:51,297] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [2024-07-08 06:05:51,298] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [2024-07-08 06:05:51,304] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [2024-07-08 06:05:51,305] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [2024-07-08 06:05:51,306] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 06:05:51,308] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [2024-07-08 06:05:51,314] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 06:05:51,316] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 06:05:51,312] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [2024-07-08 06:05:51,317] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [2024-07-08 06:05:51,324] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 06:05:51,327] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [2024-07-08 06:05:51,333] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 06:05:51,334] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [2024-07-08 06:05:51,335] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [2024-07-08 06:05:51,338] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [2024-07-08 06:05:51,341] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [2024-07-08 06:05:51,345] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [2024-07-08 06:05:51,346] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [2024-07-08 06:05:51,348] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 06:05:51,349] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [2024-07-08 06:05:51,357] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 06:05:51,360] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 06:05:51,360] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 06:05:51,361] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [2024-07-08 06:05:51,362] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [2024-07-08 06:05:51,362] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [2024-07-08 06:05:51,363] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [2024-07-08 06:05:51,366] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [2024-07-08 06:05:51,366] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 06:05:51,368] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 06:05:51,369] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 06:05:51,370] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [2024-07-08 06:05:51,371] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [2024-07-08 06:05:51,377] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [2024-07-08 06:05:51,381] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 06:05:51,384] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 06:05:51,385] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [2024-07-08 06:05:51,385] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [2024-07-08 06:05:51,390] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 06:05:51,396] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [2024-07-08 06:05:51,401] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [2024-07-08 06:05:51,406] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [2024-07-08 06:05:51,409] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [2024-07-08 06:05:51,410] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 06:05:51,412] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 06:05:51,414] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [2024-07-08 06:05:51,417] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [2024-07-08 06:05:51,418] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 06:05:51,416] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 06:05:51,418] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 06:05:51,419] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: 
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [2024-07-08 06:05:51,421] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 06:05:51,421] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 06:05:51,420] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 06:05:51,424] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 06:05:51,426] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [2024-07-08 06:05:51,428] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [2024-07-08 06:05:51,432] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [2024-07-08 06:05:51,439] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 06:05:51,440] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [2024-07-08 06:05:51,441] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [2024-07-08 06:05:51,443] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [2024-07-08 06:05:51,444] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [2024-07-08 06:05:51,445] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 06:05:51,446] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 06:05:51,446] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-021: [2024-07-08 06:05:51,447] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [2024-07-08 06:05:51,450] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [2024-07-08 06:05:51,460] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:05:51,462] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 06:05:51,464] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 06:05:51,464] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [2024-07-08 06:05:51,469] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 06:05:51,474] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [2024-07-08 06:05:51,480] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [2024-07-08 06:05:51,480] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 06:05:51,482] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 06:05:51,484] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 06:05:51,488] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [2024-07-08 06:05:51,490] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [2024-07-08 06:05:51,495] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [2024-07-08 06:05:51,497] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [2024-07-08 06:05:51,507] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [2024-07-08 06:05:51,507] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [2024-07-08 06:05:51,511] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 06:05:51,513] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:05:51,516] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 06:05:51,516] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [2024-07-08 06:05:51,516] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [2024-07-08 06:05:51,518] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [2024-07-08 06:05:51,527] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [2024-07-08 06:05:51,543] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 06:05:51,542] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 06:05:51,543] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [2024-07-08 06:05:51,548] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [2024-07-08 06:05:51,549] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [2024-07-08 06:05:51,551] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [2024-07-08 06:05:51,557] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [2024-07-08 06:05:51,556] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 06:05:51,558] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [2024-07-08 06:05:51,560] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [2024-07-08 06:05:51,562] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:05:51,571] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [2024-07-08 06:05:51,574] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [2024-07-08 06:05:51,581] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [2024-07-08 06:05:51,584] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [2024-07-08 06:05:51,598] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [2024-07-08 06:05:51,603] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:05:51,605] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:05:51,606] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [2024-07-08 06:05:51,615] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [2024-07-08 06:05:51,627] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:05:51,628] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:05:51,629] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:05:51,631] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [2024-07-08 06:05:51,631] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:05:51,636] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [2024-07-08 06:05:51,640] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [2024-07-08 06:05:51,644] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:05:51,655] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [2024-07-08 06:05:51,656] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [2024-07-08 06:05:51,657] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [2024-07-08 06:05:51,667] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [2024-07-08 06:05:51,676] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:05:51,676] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 06:05:51,681] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 06:05:51,683] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [2024-07-08 06:05:51,691] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [2024-07-08 06:05:51,693] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 06:05:51,697] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 06:05:51,699] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [2024-07-08 06:05:51,700] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 06:05:51,708] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [2024-07-08 06:05:51,714] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [2024-07-08 06:05:51,714] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [2024-07-08 06:05:51,719] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 06:05:51,724] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [2024-07-08 06:05:51,743] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 06:05:51,754] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [2024-07-08 06:05:51,759] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:05:51,760] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [2024-07-08 06:05:51,762] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [2024-07-08 06:05:51,767] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [2024-07-08 06:05:51,770] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 06:05:51,781] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [2024-07-08 06:05:51,789] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 06:05:51,790] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [2024-07-08 06:05:51,797] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [2024-07-08 06:05:51,802] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [2024-07-08 06:05:51,803] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [2024-07-08 06:05:51,807] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [2024-07-08 06:05:51,810] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [2024-07-08 06:05:51,817] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [2024-07-08 06:05:51,821] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [2024-07-08 06:05:51,822] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 06:05:51,825] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [2024-07-08 06:05:51,828] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [2024-07-08 06:05:51,837] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:05:51,839] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 06:05:51,843] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 06:05:51,847] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:05:51,848] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [2024-07-08 06:05:51,864] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 06:05:51,865] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 06:05:51,866] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 06:05:51,877] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 06:05:51,881] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 06:05:51,889] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [2024-07-08 06:05:51,890] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [2024-07-08 06:05:51,898] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [2024-07-08 06:05:51,905] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 06:05:51,913] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [2024-07-08 06:05:51,914] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [2024-07-08 06:05:51,921] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [2024-07-08 06:05:51,928] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [2024-07-08 06:05:51,929] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [2024-07-08 06:05:51,931] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 06:05:51,931] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [2024-07-08 06:05:51,937] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [2024-07-08 06:05:51,938] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 06:05:51,939] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [2024-07-08 06:05:51,950] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [2024-07-08 06:05:51,956] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [2024-07-08 06:05:51,956] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 06:05:51,961] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 06:05:51,976] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 06:05:51,975] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [2024-07-08 06:05:51,977] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [2024-07-08 06:05:51,989] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [2024-07-08 06:05:51,995] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 06:05:51,998] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 06:05:52,007] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 06:05:52,006] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [2024-07-08 06:05:52,014] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [2024-07-08 06:05:52,016] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 06:05:52,018] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [2024-07-08 06:05:52,021] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [2024-07-08 06:05:52,021] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:05:52,024] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [2024-07-08 06:05:52,025] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:05:52,025] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [2024-07-08 06:05:52,026] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:05:52,028] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [2024-07-08 06:05:52,039] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [2024-07-08 06:05:52,043] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:05:52,041] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [2024-07-08 06:05:52,044] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [2024-07-08 06:05:52,053] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [2024-07-08 06:05:52,064] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [2024-07-08 06:05:52,069] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [2024-07-08 06:05:52,072] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [2024-07-08 06:05:52,073] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [2024-07-08 06:05:52,074] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [2024-07-08 06:05:52,081] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:05:52,081] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [2024-07-08 06:05:52,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [2024-07-08 06:05:52,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [2024-07-08 06:05:52,101] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [2024-07-08 06:05:52,101] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [2024-07-08 06:05:52,101] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [2024-07-08 06:05:52,108] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [2024-07-08 06:05:52,110] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 06:05:52,114] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [2024-07-08 06:05:52,112] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:05:52,115] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [2024-07-08 06:05:52,120] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:05:52,119] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [2024-07-08 06:05:52,122] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [2024-07-08 06:05:52,124] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 06:05:52,125] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [2024-07-08 06:05:52,134] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 06:05:52,134] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [2024-07-08 06:05:52,137] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [2024-07-08 06:05:52,140] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [2024-07-08 06:05:52,147] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:05:52,149] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:05:52,156] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 06:05:52,157] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:05:52,159] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [2024-07-08 06:05:52,159] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 06:05:52,162] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 06:05:52,163] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [2024-07-08 06:05:52,175] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 06:05:52,175] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 06:05:52,177] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:05:52,180] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [2024-07-08 06:05:52,189] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [2024-07-08 06:05:52,191] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:05:52,192] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [2024-07-08 06:05:52,195] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:05:52,198] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:05:52,198] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [2024-07-08 06:05:52,201] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [2024-07-08 06:05:52,202] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [2024-07-08 06:05:52,200] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 06:05:52,204] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-017: [2024-07-08 06:05:52,203] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [2024-07-08 06:05:52,208] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [2024-07-08 06:05:52,215] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:05:52,215] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [2024-07-08 06:05:52,218] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:05:52,219] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [2024-07-08 06:05:52,226] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 06:05:52,226] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:05:52,226] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 06:05:52,224] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:05:52,229] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [2024-07-08 06:05:52,232] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:05:52,236] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [2024-07-08 06:05:52,240] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 06:05:52,242] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 06:05:52,246] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 06:05:52,250] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [2024-07-08 06:05:52,252] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [2024-07-08 06:05:52,257] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:05:52,258] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 06:05:52,260] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [2024-07-08 06:05:52,262] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [2024-07-08 06:05:52,262] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 06:05:52,263] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [2024-07-08 06:05:52,265] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:05:52,264] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 06:05:52,267] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:05:52,269] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [2024-07-08 06:05:52,271] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:05:52,271] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [2024-07-08 06:05:52,271] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [2024-07-08 06:05:52,274] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [2024-07-08 06:05:52,275] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [2024-07-08 06:05:52,280] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [2024-07-08 06:05:52,283] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 06:05:52,286] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:05:52,286] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [2024-07-08 06:05:52,287] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [2024-07-08 06:05:52,289] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [2024-07-08 06:05:52,296] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [2024-07-08 06:05:52,298] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [2024-07-08 06:05:52,300] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 06:05:52,301] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [2024-07-08 06:05:52,303] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [2024-07-08 06:05:52,305] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [2024-07-08 06:05:52,307] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:05:52,308] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [2024-07-08 06:05:52,310] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:05:52,312] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:05:52,313] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 06:05:52,314] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:05:52,318] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 06:05:52,319] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:05:52,322] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 06:05:52,324] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 06:05:52,324] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [2024-07-08 06:05:52,324] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [2024-07-08 06:05:52,331] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 06:05:52,330] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [2024-07-08 06:05:52,339] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [2024-07-08 06:05:52,337] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:05:52,343] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [2024-07-08 06:05:52,344] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 06:05:52,341] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 06:05:52,345] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [2024-07-08 06:05:52,350] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [2024-07-08 06:05:52,353] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 06:05:52,355] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [2024-07-08 06:05:52,360] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [2024-07-08 06:05:52,367] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:05:52,367] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [2024-07-08 06:05:52,367] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [2024-07-08 06:05:52,375] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [2024-07-08 06:05:52,380] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:05:52,381] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:05:52,383] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [2024-07-08 06:05:52,386] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:05:52,388] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [2024-07-08 06:05:52,390] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [2024-07-08 06:05:52,392] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [2024-07-08 06:05:52,398] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:05:52,400] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [2024-07-08 06:05:52,402] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [2024-07-08 06:05:52,402] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [2024-07-08 06:05:52,415] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [2024-07-08 06:05:52,419] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [2024-07-08 06:05:52,421] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [2024-07-08 06:05:52,428] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [2024-07-08 06:05:52,428] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [2024-07-08 06:05:52,433] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 06:05:52,435] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [2024-07-08 06:05:52,439] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [2024-07-08 06:05:52,448] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 06:05:52,451] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [2024-07-08 06:05:52,456] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:05:52,456] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [2024-07-08 06:05:52,459] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [2024-07-08 06:05:52,479] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [2024-07-08 06:05:52,486] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [2024-07-08 06:05:52,494] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [2024-07-08 06:05:52,512] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [2024-07-08 06:05:52,518] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [2024-07-08 06:05:52,520] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [2024-07-08 06:05:52,526] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [2024-07-08 06:05:52,530] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [2024-07-08 06:05:52,534] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [2024-07-08 06:05:52,535] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [2024-07-08 06:05:52,572] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [2024-07-08 06:05:52,573] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [2024-07-08 06:05:52,592] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [2024-07-08 06:05:52,597] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 06:05:52,597] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [2024-07-08 06:05:52,601] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [2024-07-08 06:05:52,610] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [2024-07-08 06:05:52,617] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [2024-07-08 06:05:52,624] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-012: [2024-07-08 06:05:52,625] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [2024-07-08 06:05:52,637] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [2024-07-08 06:05:52,647] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [2024-07-08 06:05:52,653] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [2024-07-08 06:05:52,657] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [2024-07-08 06:05:52,663] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-009: [2024-07-08 06:05:52,661] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [2024-07-08 06:05:52,677] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [2024-07-08 06:05:52,680] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [2024-07-08 06:05:52,682] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [2024-07-08 06:05:52,686] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [2024-07-08 06:05:52,695] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [2024-07-08 06:05:52,697] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [2024-07-08 06:05:52,699] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [2024-07-08 06:05:52,704] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [2024-07-08 06:05:52,711] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [2024-07-08 06:05:52,720] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [2024-07-08 06:05:52,731] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [2024-07-08 06:05:52,732] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [2024-07-08 06:05:52,740] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [2024-07-08 06:05:52,743] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [2024-07-08 06:05:52,745] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [2024-07-08 06:05:52,750] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [2024-07-08 06:05:52,752] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [2024-07-08 06:05:52,752] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [2024-07-08 06:05:52,760] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [2024-07-08 06:05:52,768] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [2024-07-08 06:05:52,772] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [2024-07-08 06:05:52,774] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [2024-07-08 06:05:52,777] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [2024-07-08 06:05:52,779] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [2024-07-08 06:05:52,786] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [2024-07-08 06:05:52,794] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [2024-07-08 06:05:52,806] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [2024-07-08 06:05:52,813] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [2024-07-08 06:05:52,815] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [2024-07-08 06:05:52,819] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [2024-07-08 06:05:52,820] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [2024-07-08 06:05:52,821] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [2024-07-08 06:05:52,818] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [2024-07-08 06:05:52,823] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [2024-07-08 06:05:52,824] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 06:05:52,825] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [2024-07-08 06:05:52,828] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [2024-07-08 06:05:52,830] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [2024-07-08 06:05:52,830] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [2024-07-08 06:05:52,852] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 06:05:52,854] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [2024-07-08 06:05:52,854] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [2024-07-08 06:05:52,860] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [2024-07-08 06:05:52,861] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [2024-07-08 06:05:52,864] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-023: [2024-07-08 06:05:52,864] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [2024-07-08 06:05:52,866] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [2024-07-08 06:05:52,871] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [2024-07-08 06:05:52,877] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [2024-07-08 06:05:52,877] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [2024-07-08 06:05:52,887] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-056: [2024-07-08 06:05:52,889] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [2024-07-08 06:05:52,892] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 06:05:52,892] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [2024-07-08 06:05:52,895] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [2024-07-08 06:05:52,897] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [2024-07-08 06:05:52,902] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [2024-07-08 06:05:52,904] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [2024-07-08 06:05:52,907] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [2024-07-08 06:05:52,910] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [2024-07-08 06:05:52,913] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 06:05:52,915] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [2024-07-08 06:05:52,919] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-006: [2024-07-08 06:05:52,920] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [2024-07-08 06:05:52,923] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [2024-07-08 06:05:52,926] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [2024-07-08 06:05:52,927] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [2024-07-08 06:05:52,944] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [2024-07-08 06:05:52,946] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 06:05:52,948] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [2024-07-08 06:05:52,951] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [2024-07-08 06:05:52,955] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [2024-07-08 06:05:52,958] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-023: [2024-07-08 06:05:52,958] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [2024-07-08 06:05:52,961] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [2024-07-08 06:05:52,963] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 06:05:52,963] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 06:05:52,963] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [2024-07-08 06:05:52,964] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [2024-07-08 06:05:52,964] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [2024-07-08 06:05:52,971] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:05:52,972] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [2024-07-08 06:05:52,979] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:05:52,982] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [2024-07-08 06:05:52,984] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [2024-07-08 06:05:52,986] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 06:05:52,985] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [2024-07-08 06:05:52,994] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [2024-07-08 06:05:52,996] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [2024-07-08 06:05:52,999] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [2024-07-08 06:05:53,000] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [2024-07-08 06:05:53,006] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-023: [2024-07-08 06:05:53,010] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [2024-07-08 06:05:53,022] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 06:05:53,026] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [2024-07-08 06:05:53,028] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [2024-07-08 06:05:53,032] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [2024-07-08 06:05:53,039] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [2024-07-08 06:05:53,040] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [2024-07-08 06:05:53,048] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-007: [2024-07-08 06:05:53,054] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 06:05:53,054] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 06:05:53,055] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-008: [2024-07-08 06:05:53,055] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:05:53,057] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 06:05:53,060] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [2024-07-08 06:05:53,061] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [2024-07-08 06:05:53,064] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [2024-07-08 06:05:53,065] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [2024-07-08 06:05:53,068] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [2024-07-08 06:05:53,069] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [2024-07-08 06:05:53,069] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-009: [2024-07-08 06:05:53,068] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [2024-07-08 06:05:53,070] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [2024-07-08 06:05:53,073] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [2024-07-08 06:05:53,072] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 06:05:53,080] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 06:05:53,088] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [2024-07-08 06:05:53,095] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [2024-07-08 06:05:53,101] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [2024-07-08 06:05:53,101] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 06:05:53,101] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [2024-07-08 06:05:53,108] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [2024-07-08 06:05:53,109] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 06:05:53,111] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-011: [2024-07-08 06:05:53,112] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:05:53,108] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [2024-07-08 06:05:53,125] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [2024-07-08 06:05:53,132] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [2024-07-08 06:05:53,137] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [2024-07-08 06:05:53,139] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [2024-07-08 06:05:53,158] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [2024-07-08 06:05:53,159] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:05:53,160] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:05:53,163] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:05:53,165] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [2024-07-08 06:05:53,170] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:05:53,171] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [2024-07-08 06:05:53,174] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-005: [2024-07-08 06:05:53,176] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-005: [2024-07-08 06:05:53,177] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [2024-07-08 06:05:53,179] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-020: [2024-07-08 06:05:53,174] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:05:53,179] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [2024-07-08 06:05:53,181] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [2024-07-08 06:05:53,181] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [2024-07-08 06:05:53,192] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:05:53,197] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 06:05:53,197] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-026: [2024-07-08 06:05:53,202] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-020: [2024-07-08 06:05:53,200] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 06:05:53,207] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-009: [2024-07-08 06:05:53,206] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:05:53,209] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [2024-07-08 06:05:53,214] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-005: [2024-07-08 06:05:53,216] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [2024-07-08 06:05:53,217] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:05:53,217] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:05:53,215] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [2024-07-08 06:05:53,221] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 06:05:53,228] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:05:53,228] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [2024-07-08 06:05:53,235] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [2024-07-08 06:05:53,237] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:05:53,239] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [2024-07-08 06:05:53,240] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:05:53,241] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-011: [2024-07-08 06:05:53,242] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-016: [2024-07-08 06:05:53,241] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [2024-07-08 06:05:53,247] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:05:53,247] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [2024-07-08 06:05:53,259] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [2024-07-08 06:05:53,259] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [2024-07-08 06:05:53,262] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [2024-07-08 06:05:53,266] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [2024-07-08 06:05:53,274] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [2024-07-08 06:05:53,276] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-016: [2024-07-08 06:05:53,277] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [2024-07-08 06:05:53,286] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 06:05:53,287] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 06:05:53,299] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-012: [2024-07-08 06:05:53,301] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [2024-07-08 06:05:53,305] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-007: [2024-07-08 06:05:53,305] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:05:53,304] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [2024-07-08 06:05:53,305] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-004: [2024-07-08 06:05:53,305] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-024: [2024-07-08 06:05:53,307] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-008: [2024-07-08 06:05:53,308] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 06:05:53,309] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 06:05:53,311] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [2024-07-08 06:05:53,314] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [2024-07-08 06:05:53,319] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [2024-07-08 06:05:53,327] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-004: [2024-07-08 06:05:53,327] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-006: [2024-07-08 06:05:53,327] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:05:53,327] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [2024-07-08 06:05:53,327] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:05:53,329] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-020: [2024-07-08 06:05:53,325] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:05:53,332] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [2024-07-08 06:05:53,342] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [2024-07-08 06:05:53,346] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [2024-07-08 06:05:53,348] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-022: [2024-07-08 06:05:53,351] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [2024-07-08 06:05:53,354] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-008: [2024-07-08 06:05:53,358] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [2024-07-08 06:05:53,360] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [2024-07-08 06:05:53,363] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 06:05:53,365] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-022: [2024-07-08 06:05:53,368] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-024: [2024-07-08 06:05:53,369] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [2024-07-08 06:05:53,376] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [2024-07-08 06:05:53,377] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:05:53,378] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 06:05:53,376] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-009: [2024-07-08 06:05:53,377] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-022: [2024-07-08 06:05:53,381] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-022: [2024-07-08 06:05:53,381] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [2024-07-08 06:05:53,386] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [2024-07-08 06:05:53,388] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [2024-07-08 06:05:53,394] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 06:05:53,400] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 06:05:53,400] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 06:05:53,409] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 06:05:53,418] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [2024-07-08 06:05:53,419] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 06:05:53,423] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 06:05:53,422] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [2024-07-08 06:05:53,439] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [2024-07-08 06:05:53,442] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:05:53,442] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:05:53,442] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [2024-07-08 06:05:53,439] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [2024-07-08 06:05:53,443] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [2024-07-08 06:05:53,448] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-017: [2024-07-08 06:05:53,451] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [2024-07-08 06:05:53,458] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 06:05:53,459] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:05:53,460] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [2024-07-08 06:05:53,469] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [2024-07-08 06:05:53,470] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:05:53,471] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 06:05:53,473] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 06:05:53,477] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 06:05:53,483] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 06:05:53,484] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 06:05:53,487] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 06:05:53,492] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 06:05:53,494] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 06:05:53,496] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [2024-07-08 06:05:53,504] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:05:53,505] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [2024-07-08 06:05:53,508] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 06:05:53,517] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:05:53,520] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 06:05:53,533] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [2024-07-08 06:05:53,541] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 06:05:53,542] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [2024-07-08 06:05:53,546] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [2024-07-08 06:05:53,551] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:05:53,553] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:05:53,553] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [2024-07-08 06:05:53,561] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 06:05:53,570] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [2024-07-08 06:05:53,572] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:05:53,577] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [2024-07-08 06:05:53,577] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 06:05:53,582] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 06:05:53,593] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [2024-07-08 06:05:53,604] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [2024-07-08 06:05:53,604] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 06:05:53,604] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:05:53,605] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:05:53,606] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:05:53,606] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:05:53,606] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:05:53,609] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [2024-07-08 06:05:53,613] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:05:53,617] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:05:53,620] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:05:53,621] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:05:53,625] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [2024-07-08 06:05:53,630] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [2024-07-08 06:05:53,644] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [2024-07-08 06:05:53,650] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 06:05:53,656] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:05:53,656] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:05:53,658] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:05:53,661] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 06:05:53,667] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:05:53,668] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [2024-07-08 06:05:53,676] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:05:53,678] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [2024-07-08 06:05:53,680] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 06:05:53,696] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 06:05:53,717] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 06:05:53,724] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:05:53,725] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:05:53,730] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [2024-07-08 06:05:53,733] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:05:53,735] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:05:53,739] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [2024-07-08 06:05:53,743] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:05:53,744] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:05:53,748] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:05:53,754] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [2024-07-08 06:05:53,761] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [2024-07-08 06:05:53,773] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [2024-07-08 06:05:53,773] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:05:53,780] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:05:53,779] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [2024-07-08 06:05:53,794] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [2024-07-08 06:05:53,797] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:05:53,796] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:05:53,799] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:05:53,801] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:05:53,811] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 06:05:53,826] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:05:53,832] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:05:53,838] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [2024-07-08 06:05:53,844] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 06:05:53,847] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:05:53,855] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:05:53,855] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [2024-07-08 06:05:53,862] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [2024-07-08 06:05:53,874] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:05:53,877] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:05:53,878] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:05:53,879] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:05:53,885] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:05:53,886] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:05:53,882] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 06:05:53,887] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:05:53,888] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 06:05:53,899] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [2024-07-08 06:05:53,900] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:05:53,903] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [2024-07-08 06:05:53,906] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:05:53,908] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:05:53,909] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 06:05:53,915] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:05:53,919] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:05:53,923] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 06:05:53,933] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 06:05:53,933] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:05:53,938] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 06:05:53,943] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:05:53,947] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [2024-07-08 06:05:53,971] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [2024-07-08 06:05:53,973] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:05:53,975] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:05:53,986] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:05:54,000] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:05:54,003] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:05:54,005] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:05:54,010] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 06:05:54,011] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:05:54,015] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:05:54,016] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:05:54,024] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:05:54,025] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:05:54,026] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [2024-07-08 06:05:54,062] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:05:54,062] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [2024-07-08 06:05:54,073] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:05:54,079] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:05:54,083] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:05:54,089] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [2024-07-08 06:05:54,095] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:05:54,100] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:05:54,101] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:05:54,101] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [2024-07-08 06:05:54,112] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [2024-07-08 06:05:54,113] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:05:54,116] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:05:54,116] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:05:54,116] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:05:54,133] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:05:54,133] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:05:54,134] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:05:54,140] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:05:54,139] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:05:54,144] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:05:54,148] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:05:54,148] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:05:54,161] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [2024-07-08 06:05:54,162] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [2024-07-08 06:05:54,163] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 06:05:54,166] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:05:54,166] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:05:54,174] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:05:54,180] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:05:54,184] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:05:54,189] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:05:54,197] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:05:54,212] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:05:54,218] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:05:54,222] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:05:54,227] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:05:54,229] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:05:54,230] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:05:54,243] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:05:54,242] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:05:54,241] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [2024-07-08 06:05:54,255] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [2024-07-08 06:05:54,255] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 06:05:54,260] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:05:54,261] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:05:54,261] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:05:54,266] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:05:54,268] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [2024-07-08 06:05:54,274] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [2024-07-08 06:05:54,277] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [2024-07-08 06:05:54,275] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:05:54,279] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:05:54,280] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:05:54,288] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:05:54,289] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:05:54,295] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:05:54,306] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:05:54,308] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:05:54,309] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:05:54,309] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:05:54,315] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:05:54,318] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 06:05:54,320] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:05:54,321] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:05:54,324] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:05:54,329] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:05:54,329] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 06:05:54,335] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:05:54,337] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [2024-07-08 06:05:54,349] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:05:54,349] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:05:54,351] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:05:54,354] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:05:54,360] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [2024-07-08 06:05:54,359] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:05:54,376] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:05:54,382] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:05:54,385] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:05:54,388] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 06:05:54,395] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:05:54,399] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:05:54,402] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:05:54,407] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:05:54,407] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:05:54,409] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:05:54,414] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:05:54,419] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:05:54,419] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:05:54,431] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:05:54,435] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [2024-07-08 06:05:54,444] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:05:54,453] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [2024-07-08 06:05:54,465] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 06:05:54,466] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:05:54,505] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [2024-07-08 06:05:54,680] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:05:54,738] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:05:54,795] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:05:54,824] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:05:54,846] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:05:54,846] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:05:54,867] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:05:54,888] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:05:54,901] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:05:54,903] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:05:55,019] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:05:55,106] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:05:55,109] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:05:55,111] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:05:55,276] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:05:55,348] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:05:55,443] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:05:55,482] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:05:55,482] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:05:55,535] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: NCCL version 2.19.4+cuda12.2
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-056:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-048:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-063:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-018:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-005:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017:   warnings.warn(
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017:   warnings.warn(
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-006:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-050:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-031:   warnings.warn(
ml-512-node-018:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018:   warnings.warn(
ml-512-node-015:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-032:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-026:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-028:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-044:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-012:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-044:   warnings.warn(
ml-512-node-012:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-005:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-011:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-011:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-062:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-017:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-017:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-008:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-010:   warnings.warn(
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-019:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-029:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-020:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020:   warnings.warn(
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020:   warnings.warn(
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-049:   warnings.warn(
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-057:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-003:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-018:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-054:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-032:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032:   warnings.warn(
ml-512-node-024:   warnings.warn(
ml-512-node-027:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-024:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-012:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-035:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-005:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-061:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011:   warnings.warn(
ml-512-node-005:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-061:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-002:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-022:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-008:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-019:   warnings.warn(
ml-512-node-052:   warnings.warn(
ml-512-node-020:   warnings.warn(
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-020:   warnings.warn(
ml-512-node-045:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-042:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-049:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-042:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-031:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018:   warnings.warn(
ml-512-node-025:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025:   warnings.warn(
ml-512-node-054:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-055:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028:   warnings.warn(
ml-512-node-055:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028:   warnings.warn(
ml-512-node-032:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032:   warnings.warn(
ml-512-node-024:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-030:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-012:   warnings.warn(
ml-512-node-017:   warnings.warn(
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-064:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-013:   warnings.warn(
ml-512-node-011:   warnings.warn(
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-009:   warnings.warn(
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-010:   warnings.warn(
ml-512-node-011:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-014:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014:   warnings.warn(
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-014:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-004:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-049:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-061:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-002:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-007:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-020:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-045:   warnings.warn(
ml-512-node-036:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-063:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-058:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-064:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-009:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-022:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-059:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-007:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-020:   warnings.warn(
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-045:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025:   warnings.warn(
ml-512-node-014:   warnings.warn(
ml-512-node-055:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-026:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-021:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-017:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-035:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-027:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-015:   warnings.warn(
ml-512-node-003:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-027:   warnings.warn(
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-015:   warnings.warn(
ml-512-node-033:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-029:   warnings.warn(
ml-512-node-003:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-029:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-045:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017:   warnings.warn(
ml-512-node-025:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-028:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-021:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-025:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-001:   warnings.warn(
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Detected CUDA files, patching ldflags
ml-512-node-056: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-056: Building extension module fused_adam...
ml-512-node-056: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-056: ninja: no work to do.
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.10192751884460449 seconds
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.10163092613220215 seconds
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: ninja: no work to do.
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Time to load fused_adam op: 0.10126519203186035 seconds
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Detected CUDA files, patching ldflags
ml-512-node-056: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-056: Building extension module fused_adam...
ml-512-node-056: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: ninja: no work to do.
ml-512-node-056: Time to load fused_adam op: 0.2725684642791748 seconds
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.1014106273651123 seconds
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Detected CUDA files, patching ldflags
ml-512-node-062: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Building extension module fused_adam...
ml-512-node-062: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Detected CUDA files, patching ldflags
ml-512-node-052: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-052: Building extension module fused_adam...
ml-512-node-052: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: ninja: no work to do.
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.06322145462036133 seconds
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: ninja: no work to do.
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-052: Time to load fused_adam op: 0.06278657913208008 seconds
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-015: Detected CUDA files, patching ldflags
ml-512-node-015: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-015: Building extension module fused_adam...
ml-512-node-015: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Detected CUDA files, patching ldflags
ml-512-node-012: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-012: Building extension module fused_adam...
ml-512-node-012: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-018: Detected CUDA files, patching ldflags
ml-512-node-018: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-018: Building extension module fused_adam...
ml-512-node-018: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: 
ml-512-node-035: ninja: no work to do.
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.06432366371154785 seconds
ml-512-node-015: ninja: no work to do.
ml-512-node-012: ninja: no work to do.
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-015: Time to load fused_adam op: 0.06286263465881348 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-012: Time to load fused_adam op: 0.06367206573486328 seconds
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: ninja: no work to do.
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Detected CUDA files, patching ldflags
ml-512-node-001: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-001: Building extension module fused_adam...
ml-512-node-001: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-018: Time to load fused_adam op: 0.0625772476196289 seconds
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: ninja: no work to do.
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Time to load fused_adam op: 0.06428837776184082 seconds
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Detected CUDA files, patching ldflags
ml-512-node-053: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-053: Building extension module fused_adam...
ml-512-node-053: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Detected CUDA files, patching ldflags
ml-512-node-058: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-058: Building extension module fused_adam...
ml-512-node-058: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Detected CUDA files, patching ldflags
ml-512-node-028: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-028: Building extension module fused_adam...
ml-512-node-028: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Detected CUDA files, patching ldflags
ml-512-node-059: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: Building extension module fused_adam...
ml-512-node-059: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: ninja: no work to do.
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-001: Time to load fused_adam op: 0.10177350044250488 seconds
ml-512-node-053: ninja: no work to do.
ml-512-node-040: Time to load fused_adam op: 0.3390052318572998 seconds
ml-512-node-040: Time to load fused_adam op: 0.20196986198425293 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-053: Time to load fused_adam op: 0.0636143684387207 seconds
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: ninja: no work to do.
ml-512-node-010: Detected CUDA files, patching ldflags
ml-512-node-010: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-010: Building extension module fused_adam...
ml-512-node-010: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-058: Time to load fused_adam op: 0.0628061294555664 seconds
ml-512-node-028: ninja: no work to do.
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-028: Time to load fused_adam op: 0.06246519088745117 seconds
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: ninja: no work to do.
ml-512-node-045: ninja: no work to do.
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-059: Time to load fused_adam op: 0.06239748001098633 seconds
ml-512-node-001: Time to load fused_adam op: 0.10174846649169922 seconds
ml-512-node-045: Time to load fused_adam op: 0.06369829177856445 seconds
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Time to load fused_adam op: 0.10132765769958496 seconds
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: ninja: no work to do.
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-054: Detected CUDA files, patching ldflags
ml-512-node-054: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-054: Building extension module fused_adam...
ml-512-node-054: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: Detected CUDA files, patching ldflags
ml-512-node-055: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-055: Building extension module fused_adam...
ml-512-node-055: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Time to load fused_adam op: 0.06256675720214844 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.30176806449890137 seconds
ml-512-node-020: Detected CUDA files, patching ldflags
ml-512-node-020: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-020: Building extension module fused_adam...
ml-512-node-020: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-001: Time to load fused_adam op: 0.10143470764160156 seconds
ml-512-node-001: [2024-07-08 06:06:35,504] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.4, git-hash=unknown, git-branch=unknown
ml-512-node-001: [2024-07-08 06:06:35,504] [INFO] [comm.py:662:init_distributed] Distributed backend already initialized
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-010: ninja: no work to do.
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Detected CUDA files, patching ldflags
ml-512-node-004: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-004: Building extension module fused_adam...
ml-512-node-004: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Time to load fused_adam op: 0.06297612190246582 seconds
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Time to load fused_adam op: 0.1142282485961914 seconds
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: ninja: no work to do.
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Time to load fused_adam op: 0.06418585777282715 seconds
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Time to load fused_adam op: 0.4019582271575928 seconds
ml-512-node-024: Detected CUDA files, patching ldflags
ml-512-node-024: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-024: Building extension module fused_adam...
ml-512-node-024: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: ninja: no work to do.
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.0639195442199707 seconds
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: ninja: no work to do.
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-004: ninja: no work to do.
ml-512-node-030: Detected CUDA files, patching ldflags
ml-512-node-030: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-030: Building extension module fused_adam...
ml-512-node-030: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: Time to load fused_adam op: 0.06729984283447266 seconds
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Detected CUDA files, patching ldflags
ml-512-node-021: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-004: Time to load fused_adam op: 0.0617680549621582 seconds
ml-512-node-021: Building extension module fused_adam...
ml-512-node-021: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: ninja: no work to do.
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Time to load fused_adam op: 0.06276392936706543 seconds
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-003: Detected CUDA files, patching ldflags
ml-512-node-003: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-003: Building extension module fused_adam...
ml-512-node-003: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-005: Detected CUDA files, patching ldflags
ml-512-node-005: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-005: Building extension module fused_adam...
ml-512-node-005: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: ninja: no work to do.
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Detected CUDA files, patching ldflags
ml-512-node-011: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-031: Detected CUDA files, patching ldflags
ml-512-node-031: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-011: Building extension module fused_adam...
ml-512-node-011: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-031: Building extension module fused_adam...
ml-512-node-031: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Detected CUDA files, patching ldflags
ml-512-node-009: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-009: Building extension module fused_adam...
ml-512-node-009: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: Time to load fused_adam op: 0.0661776065826416 seconds
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Detected CUDA files, patching ldflags
ml-512-node-027: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-027: Building extension module fused_adam...
ml-512-node-027: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: ninja: no work to do.
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: ninja: no work to do.
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-030: Time to load fused_adam op: 0.06166863441467285 seconds
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-021: Time to load fused_adam op: 0.0621185302734375 seconds
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: Detected CUDA files, patching ldflags
ml-512-node-008: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-008: Building extension module fused_adam...
ml-512-node-008: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: 
ml-512-node-025: Detected CUDA files, patching ldflags
ml-512-node-025: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-025: Building extension module fused_adam...
ml-512-node-025: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: ninja: no work to do.
ml-512-node-003: ninja: no work to do.
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Time to load fused_adam op: 0.10155010223388672 seconds
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-031: ninja: no work to do.
ml-512-node-036: Time to load fused_adam op: 0.06485772132873535 seconds
ml-512-node-003: Time to load fused_adam op: 0.06462717056274414 seconds
ml-512-node-009: ninja: no work to do.
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: ninja: no work to do.
ml-512-node-011: ninja: no work to do.
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-005: ninja: no work to do.
ml-512-node-005: Time to load fused_adam op: 0.0634152889251709 seconds
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-041: ninja: no work to do.
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-016: Detected CUDA files, patching ldflags
ml-512-node-016: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-009: Time to load fused_adam op: 0.06275367736816406 seconds
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Building extension module fused_adam...
ml-512-node-016: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-011: Time to load fused_adam op: 0.06656718254089355 seconds
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Time to load fused_adam op: 0.06445527076721191 seconds
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-017: Detected CUDA files, patching ldflags
ml-512-node-017: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-017: Building extension module fused_adam...
ml-512-node-017: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.06297993659973145 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Detected CUDA files, patching ldflags
ml-512-node-006: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Building extension module fused_adam...
ml-512-node-006: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-061: Detected CUDA files, patching ldflags
ml-512-node-061: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Building extension module fused_adam...
ml-512-node-061: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-018: Detected CUDA files, patching ldflags
ml-512-node-018: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: Building extension module fused_adam...
ml-512-node-018: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: ninja: no work to do.
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Time to load fused_adam op: 0.1076352596282959 seconds
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-027: Time to load fused_adam op: 0.0649104118347168 seconds
ml-512-node-045: Time to load fused_adam op: 0.08207058906555176 seconds
ml-512-node-037: ninja: no work to do.
ml-512-node-055: Detected CUDA files, patching ldflags
ml-512-node-055: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-055: Building extension module fused_adam...
ml-512-node-055: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Detected CUDA files, patching ldflags
ml-512-node-023: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-023: Building extension module fused_adam...
ml-512-node-023: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Detected CUDA files, patching ldflags
ml-512-node-032: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-032: Building extension module fused_adam...
ml-512-node-032: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-014: Detected CUDA files, patching ldflags
ml-512-node-014: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-014: Building extension module fused_adam...
ml-512-node-014: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Time to load fused_adam op: 0.06454849243164062 seconds
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: ninja: no work to do.
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: ninja: no work to do.
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-028: Detected CUDA files, patching ldflags
ml-512-node-028: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-008: Time to load fused_adam op: 0.06327581405639648 seconds
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Building extension module fused_adam...
ml-512-node-028: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-025: Time to load fused_adam op: 0.0658731460571289 seconds
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: ninja: no work to do.
ml-512-node-016: ninja: no work to do.
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Detected CUDA files, patching ldflags
ml-512-node-015: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Time to load fused_adam op: 0.10143876075744629 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-015: Building extension module fused_adam...
ml-512-node-015: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Detected CUDA files, patching ldflags
ml-512-node-063: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-063: Building extension module fused_adam...
ml-512-node-063: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Time to load fused_adam op: 0.06271958351135254 seconds
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-006: ninja: no work to do.
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-005: Time to load fused_adam op: 0.10164141654968262 seconds
ml-512-node-061: ninja: no work to do.
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-006: Time to load fused_adam op: 0.06280922889709473 seconds
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Detected CUDA files, patching ldflags
ml-512-node-049: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-049: Building extension module fused_adam...
ml-512-node-049: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Detected CUDA files, patching ldflags
ml-512-node-046: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-046: Building extension module fused_adam...
ml-512-node-016: Time to load fused_adam op: 0.06299686431884766 seconds
ml-512-node-046: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-061: Time to load fused_adam op: 0.06453585624694824 seconds
ml-512-node-029: Detected CUDA files, patching ldflags
ml-512-node-029: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Building extension module fused_adam...
ml-512-node-029: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: Detected CUDA files, patching ldflags
ml-512-node-024: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-024: Building extension module fused_adam...
ml-512-node-024: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: Detected CUDA files, patching ldflags
ml-512-node-020: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: Building extension module fused_adam...
ml-512-node-020: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: ninja: no work to do.
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: ninja: no work to do.
ml-512-node-014: ninja: no work to do.
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: ninja: no work to do.
ml-512-node-054: Detected CUDA files, patching ldflags
ml-512-node-054: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-023: Time to load fused_adam op: 0.06329011917114258 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-054: Building extension module fused_adam...
ml-512-node-030: Time to load fused_adam op: 0.10156750679016113 seconds
ml-512-node-054: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-032: Time to load fused_adam op: 0.06168723106384277 seconds
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Detected CUDA files, patching ldflags
ml-512-node-031: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Time to load fused_adam op: 0.1014859676361084 seconds
ml-512-node-014: Time to load fused_adam op: 0.06372618675231934 seconds
ml-512-node-031: Building extension module fused_adam...
ml-512-node-031: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Time to load fused_adam op: 0.06257343292236328 seconds
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Detected CUDA files, patching ldflags
ml-512-node-062: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Building extension module fused_adam...
ml-512-node-062: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-019: Detected CUDA files, patching ldflags
ml-512-node-019: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-008: Detected CUDA files, patching ldflags
ml-512-node-008: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Detected CUDA files, patching ldflags
ml-512-node-064: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-019: Building extension module fused_adam...
ml-512-node-019: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-064: Building extension module fused_adam...
ml-512-node-064: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-008: Building extension module fused_adam...
ml-512-node-008: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Detected CUDA files, patching ldflags
ml-512-node-034: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Building extension module fused_adam...
ml-512-node-034: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-027: Detected CUDA files, patching ldflags
ml-512-node-027: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-027: Building extension module fused_adam...
ml-512-node-027: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Detected CUDA files, patching ldflags
ml-512-node-011: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-011: Building extension module fused_adam...
ml-512-node-011: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-063: ninja: no work to do.
ml-512-node-030: Time to load fused_adam op: 0.10243725776672363 seconds
ml-512-node-057: Detected CUDA files, patching ldflags
ml-512-node-057: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-057: Building extension module fused_adam...
ml-512-node-057: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: ninja: no work to do.
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: ninja: no work to do.
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: ninja: no work to do.
ml-512-node-046: Time to load fused_adam op: 0.0629415512084961 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-063: Time to load fused_adam op: 0.06514239311218262 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-060: Detected CUDA files, patching ldflags
ml-512-node-060: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Building extension module fused_adam...
ml-512-node-029: ninja: no work to do.
ml-512-node-060: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-022: Detected CUDA files, patching ldflags
ml-512-node-022: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-022: Building extension module fused_adam...
ml-512-node-022: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: ninja: no work to do.
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: Time to load fused_adam op: 0.12079882621765137 seconds
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-025: Time to load fused_adam op: 0.10165214538574219 seconds
ml-512-node-025: Time to load fused_adam op: 0.10171389579772949 seconds
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-049: Time to load fused_adam op: 0.06405520439147949 seconds
ml-512-node-029: Time to load fused_adam op: 0.06386804580688477 seconds
ml-512-node-018: Time to load fused_adam op: 0.15304875373840332 seconds
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Detected CUDA files, patching ldflags
ml-512-node-013: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-013: Building extension module fused_adam...
ml-512-node-013: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: ninja: no work to do.
ml-512-node-020: ninja: no work to do.
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Detected CUDA files, patching ldflags
ml-512-node-004: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Detected CUDA files, patching ldflags
ml-512-node-061: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: Building extension module fused_adam...
ml-512-node-061: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Time to load fused_adam op: 0.10259580612182617 seconds
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Time to load fused_adam op: 0.08215451240539551 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: ninja: no work to do.
ml-512-node-019: ninja: no work to do.
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: ninja: no work to do.
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-004: Building extension module fused_adam...
ml-512-node-004: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-034: ninja: no work to do.
ml-512-node-038: Time to load fused_adam op: 0.10161280632019043 seconds
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-016: Detected CUDA files, patching ldflags
ml-512-node-016: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-019: Time to load fused_adam op: 0.06309390068054199 seconds
ml-512-node-016: Building extension module fused_adam...
ml-512-node-016: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.06277084350585938 seconds
ml-512-node-020: Time to load fused_adam op: 0.09530520439147949 seconds
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-028: ninja: no work to do.
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.06163835525512695 seconds
ml-512-node-024: ninja: no work to do.
ml-512-node-028: Time to load fused_adam op: 0.15501642227172852 seconds
ml-512-node-010: Detected CUDA files, patching ldflags
ml-512-node-010: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Time to load fused_adam op: 0.11553764343261719 seconds
ml-512-node-035: Time to load fused_adam op: 0.1014699935913086 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Building extension module fused_adam...
ml-512-node-010: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-057: ninja: no work to do.
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-031: ninja: no work to do.
ml-512-node-024: Time to load fused_adam op: 0.10778999328613281 seconds
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Time to load fused_adam op: 0.061350345611572266 seconds
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Time to load fused_adam op: 0.10235071182250977 seconds
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-032: Detected CUDA files, patching ldflags
ml-512-node-032: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-032: Building extension module fused_adam...
ml-512-node-032: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: ninja: no work to do.
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-022: ninja: no work to do.
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: ninja: no work to do.
ml-512-node-048: ninja: no work to do.
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: ninja: no work to do.
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-015: ninja: no work to do.
ml-512-node-035: Time to load fused_adam op: 0.10187292098999023 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-022: Time to load fused_adam op: 0.06416130065917969 seconds
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Time to load fused_adam op: 0.0640568733215332 seconds
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-031: Time to load fused_adam op: 0.08863210678100586 seconds
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.06223416328430176 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-013: ninja: no work to do.
ml-512-node-048: Time to load fused_adam op: 0.06580209732055664 seconds
ml-512-node-003: Detected CUDA files, patching ldflags
ml-512-node-003: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-003: Building extension module fused_adam...
ml-512-node-003: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-023: Detected CUDA files, patching ldflags
ml-512-node-023: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-023: Building extension module fused_adam...
ml-512-node-023: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-051: Detected CUDA files, patching ldflags
ml-512-node-051: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-027: ninja: no work to do.
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-015: Time to load fused_adam op: 0.14813685417175293 seconds
ml-512-node-013: Time to load fused_adam op: 0.062143564224243164 seconds
ml-512-node-008: Time to load fused_adam op: 0.08067631721496582 seconds
ml-512-node-008: Time to load fused_adam op: 0.10138130187988281 seconds
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-062: ninja: no work to do.
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-051: Building extension module fused_adam...
ml-512-node-051: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: Time to load fused_adam op: 0.10167264938354492 seconds
ml-512-node-014: Detected CUDA files, patching ldflags
ml-512-node-014: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-014: Building extension module fused_adam...
ml-512-node-014: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.1023716926574707 seconds
ml-512-node-036: Time to load fused_adam op: 0.10230851173400879 seconds
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Time to load fused_adam op: 0.08597421646118164 seconds
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Time to load fused_adam op: 0.10232305526733398 seconds
ml-512-node-012: Detected CUDA files, patching ldflags
ml-512-node-012: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-012: Building extension module fused_adam...
ml-512-node-012: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Time to load fused_adam op: 0.10172724723815918 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.1522843837738037 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Detected CUDA files, patching ldflags
ml-512-node-002: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-002: Building extension module fused_adam...
ml-512-node-002: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Detected CUDA files, patching ldflags
ml-512-node-007: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-007: Building extension module fused_adam...
ml-512-node-007: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Detected CUDA files, patching ldflags
ml-512-node-009: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-030: Detected CUDA files, patching ldflags
ml-512-node-030: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-030: Building extension module fused_adam...
ml-512-node-030: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Building extension module fused_adam...
ml-512-node-009: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: ninja: no work to do.
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: ninja: no work to do.
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-053: Detected CUDA files, patching ldflags
ml-512-node-053: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-024: Time to load fused_adam op: 0.2110302448272705 seconds
ml-512-node-053: Building extension module fused_adam...
ml-512-node-053: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Time to load fused_adam op: 0.10153675079345703 seconds
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.1017751693725586 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Time to load fused_adam op: 0.10692262649536133 seconds
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.10161590576171875 seconds
ml-512-node-054: Time to load fused_adam op: 0.1594388484954834 seconds
ml-512-node-033: ninja: no work to do.
ml-512-node-061: ninja: no work to do.
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: ninja: no work to do.
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: ninja: no work to do.
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-057: Time to load fused_adam op: 0.10153865814208984 seconds
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Time to load fused_adam op: 0.20373916625976562 seconds
ml-512-node-036: Time to load fused_adam op: 0.20174264907836914 seconds
ml-512-node-036: Time to load fused_adam op: 0.20243597030639648 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.06464290618896484 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.10227751731872559 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-016: ninja: no work to do.
ml-512-node-051: Time to load fused_adam op: 0.06218838691711426 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Time to load fused_adam op: 0.10609579086303711 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: Time to load fused_adam op: 0.10160684585571289 seconds
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.10179281234741211 seconds
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Time to load fused_adam op: 0.1184852123260498 seconds
ml-512-node-052: Detected CUDA files, patching ldflags
ml-512-node-052: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-052: Building extension module fused_adam...
ml-512-node-052: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-024: Time to load fused_adam op: 0.20141124725341797 seconds
ml-512-node-007: ninja: no work to do.
ml-512-node-049: Time to load fused_adam op: 0.10167980194091797 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-032: ninja: no work to do.
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: ninja: no work to do.
ml-512-node-016: Time to load fused_adam op: 0.0966806411743164 seconds
ml-512-node-061: Time to load fused_adam op: 0.09665107727050781 seconds
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Detected CUDA files, patching ldflags
ml-512-node-006: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-006: Building extension module fused_adam...
ml-512-node-006: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-002: Time to load fused_adam op: 0.06403398513793945 seconds
ml-512-node-020: Detected CUDA files, patching ldflags
ml-512-node-020: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-020: Building extension module fused_adam...
ml-512-node-020: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-063: Detected CUDA files, patching ldflags
ml-512-node-063: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-063: Building extension module fused_adam...
ml-512-node-063: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-032: Time to load fused_adam op: 0.1089022159576416 seconds
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-023: ninja: no work to do.
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-007: Time to load fused_adam op: 0.06410527229309082 seconds
ml-512-node-018: Time to load fused_adam op: 0.10515117645263672 seconds
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Time to load fused_adam op: 0.10145163536071777 seconds
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Time to load fused_adam op: 0.20167112350463867 seconds
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Detected CUDA files, patching ldflags
ml-512-node-060: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-060: Building extension module fused_adam...
ml-512-node-060: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Detected CUDA files, patching ldflags
ml-512-node-013: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-013: Building extension module fused_adam...
ml-512-node-013: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-023: Time to load fused_adam op: 0.09196782112121582 seconds
ml-512-node-054: Time to load fused_adam op: 0.10445952415466309 seconds
ml-512-node-012: ninja: no work to do.
ml-512-node-049: Time to load fused_adam op: 0.10145354270935059 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Time to load fused_adam op: 0.10173916816711426 seconds
ml-512-node-034: Time to load fused_adam op: 0.11640334129333496 seconds
ml-512-node-034: Time to load fused_adam op: 0.11281418800354004 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-010: ninja: no work to do.
ml-512-node-003: ninja: no work to do.
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Time to load fused_adam op: 0.20172500610351562 seconds
ml-512-node-028: Time to load fused_adam op: 0.20262503623962402 seconds
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-012: Time to load fused_adam op: 0.1103370189666748 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Time to load fused_adam op: 0.10244202613830566 seconds
ml-512-node-004: ninja: no work to do.
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Time to load fused_adam op: 0.1287829875946045 seconds
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-014: ninja: no work to do.
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-023: Time to load fused_adam op: 0.10155439376831055 seconds
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Time to load fused_adam op: 0.10264396667480469 seconds
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: ninja: no work to do.
ml-512-node-010: Time to load fused_adam op: 0.15760421752929688 seconds
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-061: Time to load fused_adam op: 0.20168709754943848 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-024: Time to load fused_adam op: 0.10553097724914551 seconds
ml-512-node-042: ninja: no work to do.
ml-512-node-014: Time to load fused_adam op: 0.11439800262451172 seconds
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.20182132720947266 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.20188331604003906 seconds
ml-512-node-049: Time to load fused_adam op: 0.10192322731018066 seconds
ml-512-node-049: Time to load fused_adam op: 0.10815691947937012 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-012: Time to load fused_adam op: 0.10192155838012695 seconds
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Time to load fused_adam op: 0.1345195770263672 seconds
ml-512-node-042: Time to load fused_adam op: 0.06398725509643555 seconds
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: ninja: no work to do.
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Time to load fused_adam op: 0.10184741020202637 seconds
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Time to load fused_adam op: 0.10156869888305664 seconds
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-037: ninja: no work to do.
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Time to load fused_adam op: 0.2120819091796875 seconds
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.07615089416503906 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-050: Detected CUDA files, patching ldflags
ml-512-node-050: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-026: Detected CUDA files, patching ldflags
ml-512-node-026: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Building extension module fused_adam...
ml-512-node-050: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: 
ml-512-node-026: Building extension module fused_adam...
ml-512-node-026: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Detected CUDA files, patching ldflags
ml-512-node-051: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-051: Building extension module fused_adam...
ml-512-node-051: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-025: Detected CUDA files, patching ldflags
ml-512-node-025: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-025: Building extension module fused_adam...
ml-512-node-025: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Time to load fused_adam op: 0.10243105888366699 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-011: Time to load fused_adam op: 0.2017984390258789 seconds
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Detected CUDA files, patching ldflags
ml-512-node-027: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: Time to load fused_adam op: 0.2026233673095703 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-061: Time to load fused_adam op: 0.20240449905395508 seconds
ml-512-node-027: Building extension module fused_adam...
ml-512-node-027: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-064: Detected CUDA files, patching ldflags
ml-512-node-064: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-064: Building extension module fused_adam...
ml-512-node-064: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Detected CUDA files, patching ldflags
ml-512-node-021: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-021: Building extension module fused_adam...
ml-512-node-021: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: Time to load fused_adam op: 0.2025001049041748 seconds
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-030: ninja: no work to do.
ml-512-node-058: Detected CUDA files, patching ldflags
ml-512-node-058: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Building extension module fused_adam...
ml-512-node-058: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-017: Detected CUDA files, patching ldflags
ml-512-node-017: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-017: Building extension module fused_adam...
ml-512-node-017: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-053: ninja: no work to do.
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-004: Time to load fused_adam op: 0.16388416290283203 seconds
ml-512-node-014: Time to load fused_adam op: 0.2017223834991455 seconds
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-014: Time to load fused_adam op: 0.2023301124572754 seconds
ml-512-node-019: Detected CUDA files, patching ldflags
ml-512-node-019: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-019: Building extension module fused_adam...
ml-512-node-019: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-007: Detected CUDA files, patching ldflags
ml-512-node-007: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-007: Building extension module fused_adam...
ml-512-node-007: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-030: Time to load fused_adam op: 0.1360301971435547 seconds
ml-512-node-054: Time to load fused_adam op: 0.20655417442321777 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Detected CUDA files, patching ldflags
ml-512-node-059: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: Building extension module fused_adam...
ml-512-node-059: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-054: Time to load fused_adam op: 0.1023869514465332 seconds
ml-512-node-013: ninja: no work to do.
ml-512-node-063: ninja: no work to do.
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-008: Time to load fused_adam op: 0.20178008079528809 seconds
ml-512-node-008: Time to load fused_adam op: 0.20177245140075684 seconds
ml-512-node-023: Time to load fused_adam op: 0.10200905799865723 seconds
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Time to load fused_adam op: 0.20180130004882812 seconds
ml-512-node-062: Time to load fused_adam op: 0.20440936088562012 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Building extension module fused_adam...
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: ninja: no work to do.
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Time to load fused_adam op: 0.15029668807983398 seconds
ml-512-node-037: Time to load fused_adam op: 0.1026773452758789 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Time to load fused_adam op: 0.15524935722351074 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-060: Time to load fused_adam op: 0.08527112007141113 seconds
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-013: Time to load fused_adam op: 0.0949563980102539 seconds
ml-512-node-015: Detected CUDA files, patching ldflags
ml-512-node-015: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-015: Building extension module fused_adam...
ml-512-node-015: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-061: Time to load fused_adam op: 0.2025899887084961 seconds
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-063: Time to load fused_adam op: 0.11329317092895508 seconds
ml-512-node-063: Time to load fused_adam op: 0.20158743858337402 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-050: ninja: no work to do.
ml-512-node-006: ninja: no work to do.
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-052: ninja: no work to do.
ml-512-node-009: Time to load fused_adam op: 0.10271430015563965 seconds
ml-512-node-009: Time to load fused_adam op: 0.10254478454589844 seconds
ml-512-node-026: ninja: no work to do.
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-002: Detected CUDA files, patching ldflags
ml-512-node-002: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-002: Building extension module fused_adam...
ml-512-node-002: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-050: Time to load fused_adam op: 0.06319737434387207 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Time to load fused_adam op: 0.06499314308166504 seconds
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Time to load fused_adam op: 0.15896248817443848 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Time to load fused_adam op: 0.10242199897766113 seconds
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Time to load fused_adam op: 0.20500993728637695 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-006: Time to load fused_adam op: 0.1367020606994629 seconds
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.10189414024353027 seconds
ml-512-node-031: Detected CUDA files, patching ldflags
ml-512-node-031: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-031: Building extension module fused_adam...
ml-512-node-031: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: Detected CUDA files, patching ldflags
ml-512-node-055: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-055: Building extension module fused_adam...
ml-512-node-055: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Time to load fused_adam op: 0.10270237922668457 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-063: Time to load fused_adam op: 0.2058265209197998 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: ninja: no work to do.
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Time to load fused_adam op: 0.10522222518920898 seconds
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-060: Time to load fused_adam op: 0.10167384147644043 seconds
ml-512-node-033: ninja: no work to do.
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-044: ninja: no work to do.
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-029: Detected CUDA files, patching ldflags
ml-512-node-029: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-020: Time to load fused_adam op: 0.13908815383911133 seconds
ml-512-node-029: Building extension module fused_adam...
ml-512-node-029: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-020: Time to load fused_adam op: 0.20192599296569824 seconds
ml-512-node-020: Time to load fused_adam op: 0.1022806167602539 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: ninja: no work to do.
ml-512-node-033: Time to load fused_adam op: 0.0908956527709961 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.06454253196716309 seconds
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: ninja: no work to do.
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Time to load fused_adam op: 0.10398650169372559 seconds
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Time to load fused_adam op: 0.20255708694458008 seconds
ml-512-node-037: Time to load fused_adam op: 0.30199241638183594 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: ninja: no work to do.
ml-512-node-013: Time to load fused_adam op: 0.20166349411010742 seconds
ml-512-node-017: ninja: no work to do.
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-060: Time to load fused_adam op: 0.10153675079345703 seconds
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-058: ninja: no work to do.
ml-512-node-009: Time to load fused_adam op: 0.10231947898864746 seconds
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-063: Time to load fused_adam op: 0.20160961151123047 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Detected CUDA files, patching ldflags
ml-512-node-032: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-032: Building extension module fused_adam...
ml-512-node-032: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-054: Time to load fused_adam op: 0.10513949394226074 seconds
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Time to load fused_adam op: 0.13984394073486328 seconds
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Time to load fused_adam op: 0.1027529239654541 seconds
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-021: Time to load fused_adam op: 0.13716840744018555 seconds
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-006: Time to load fused_adam op: 0.10150313377380371 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.19759273529052734 seconds
ml-512-node-051: ninja: no work to do.
ml-512-node-016: Detected CUDA files, patching ldflags
ml-512-node-016: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-016: Building extension module fused_adam...
ml-512-node-016: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-053: Time to load fused_adam op: 0.2019658088684082 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-063: Time to load fused_adam op: 0.12062740325927734 seconds
ml-512-node-019: ninja: no work to do.
ml-512-node-017: Time to load fused_adam op: 0.13457274436950684 seconds
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: 
ml-512-node-058: Time to load fused_adam op: 0.13698697090148926 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: ninja: no work to do.
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-063: Time to load fused_adam op: 0.2080097198486328 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Time to load fused_adam op: 0.12243199348449707 seconds
ml-512-node-019: Time to load fused_adam op: 0.10169267654418945 seconds
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-013: Time to load fused_adam op: 0.20184898376464844 seconds
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-051: Time to load fused_adam op: 0.1252295970916748 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-009: Time to load fused_adam op: 0.10240745544433594 seconds
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-007: Time to load fused_adam op: 0.11280274391174316 seconds
ml-512-node-052: Time to load fused_adam op: 0.20167303085327148 seconds
ml-512-node-052: Time to load fused_adam op: 0.20180106163024902 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-050: Time to load fused_adam op: 0.10159444808959961 seconds
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-047: ninja: no work to do.
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.20241475105285645 seconds
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-017: Time to load fused_adam op: 0.10245752334594727 seconds
ml-512-node-017: Time to load fused_adam op: 0.10224652290344238 seconds
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-050: Time to load fused_adam op: 0.10160326957702637 seconds
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-013: Time to load fused_adam op: 0.20246458053588867 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-013: Time to load fused_adam op: 0.20673513412475586 seconds
ml-512-node-002: ninja: no work to do.
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Time to load fused_adam op: 0.20261216163635254 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-019: Time to load fused_adam op: 0.20195341110229492 seconds
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.14383339881896973 seconds
ml-512-node-058: Time to load fused_adam op: 0.10188984870910645 seconds
ml-512-node-059: ninja: no work to do.
ml-512-node-037: Time to load fused_adam op: 0.3024861812591553 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-027: ninja: no work to do.
ml-512-node-027: Time to load fused_adam op: 0.1721973419189453 seconds
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-018: Detected CUDA files, patching ldflags
ml-512-node-018: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-059: Time to load fused_adam op: 0.17480683326721191 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-018: Building extension module fused_adam...
ml-512-node-018: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: ninja: no work to do.
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Time to load fused_adam op: 0.0993201732635498 seconds
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-022: Detected CUDA files, patching ldflags
ml-512-node-022: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-022: Building extension module fused_adam...
ml-512-node-022: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-006: Time to load fused_adam op: 0.10160708427429199 seconds
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: 
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Time to load fused_adam op: 0.1044774055480957 seconds
ml-512-node-007: Time to load fused_adam op: 0.10193037986755371 seconds
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-010: Detected CUDA files, patching ldflags
ml-512-node-010: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-010: Building extension module fused_adam...
ml-512-node-010: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-013: Time to load fused_adam op: 0.2015976905822754 seconds
ml-512-node-042: Time to load fused_adam op: 0.10553431510925293 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-027: Time to load fused_adam op: 0.20183753967285156 seconds
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-057: Detected CUDA files, patching ldflags
ml-512-node-057: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-057: Building extension module fused_adam...
ml-512-node-057: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.10185480117797852 seconds
ml-512-node-053: Time to load fused_adam op: 0.20219683647155762 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-052: Time to load fused_adam op: 0.21150612831115723 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-017: Time to load fused_adam op: 0.10153818130493164 seconds
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-056: Detected CUDA files, patching ldflags
ml-512-node-056: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-056: Building extension module fused_adam...
ml-512-node-056: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-047: Time to load fused_adam op: 0.20183277130126953 seconds
ml-512-node-015: ninja: no work to do.
ml-512-node-033: Time to load fused_adam op: 0.2016892433166504 seconds
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Time to load fused_adam op: 0.10149550437927246 seconds
ml-512-node-060: Time to load fused_adam op: 0.10230541229248047 seconds
ml-512-node-021: Time to load fused_adam op: 0.1025078296661377 seconds
ml-512-node-031: ninja: no work to do.
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Time to load fused_adam op: 0.11301088333129883 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-019: Time to load fused_adam op: 0.10253071784973145 seconds
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.10247421264648438 seconds
ml-512-node-015: Time to load fused_adam op: 0.17499303817749023 seconds
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-021: Time to load fused_adam op: 0.10142254829406738 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Time to load fused_adam op: 0.20206737518310547 seconds
ml-512-node-021: Time to load fused_adam op: 0.201615571975708 seconds
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Detected CUDA files, patching ldflags
ml-512-node-030: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-030: Building extension module fused_adam...
ml-512-node-030: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-027: Time to load fused_adam op: 0.3018476963043213 seconds
ml-512-node-031: Time to load fused_adam op: 0.17638850212097168 seconds
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-029: ninja: no work to do.
ml-512-node-020: Time to load fused_adam op: 0.3020446300506592 seconds
ml-512-node-047: Time to load fused_adam op: 0.20251774787902832 seconds
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Time to load fused_adam op: 0.20278692245483398 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-051: Time to load fused_adam op: 0.2016456127166748 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.2026045322418213 seconds
ml-512-node-051: Time to load fused_adam op: 0.20194315910339355 seconds
ml-512-node-051: Time to load fused_adam op: 0.10263919830322266 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-029: Time to load fused_adam op: 0.2205674648284912 seconds
ml-512-node-051: Time to load fused_adam op: 0.20156598091125488 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-058: Time to load fused_adam op: 0.10147595405578613 seconds
ml-512-node-058: Time to load fused_adam op: 0.20173931121826172 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Detected CUDA files, patching ldflags
ml-512-node-026: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-020: Time to load fused_adam op: 0.3016951084136963 seconds
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Building extension module fused_adam...
ml-512-node-026: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: ninja: no work to do.
ml-512-node-031: Time to load fused_adam op: 0.10255074501037598 seconds
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-013: Time to load fused_adam op: 0.21265792846679688 seconds
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-022: ninja: no work to do.
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-051: Time to load fused_adam op: 0.20238780975341797 seconds
ml-512-node-045: Time to load fused_adam op: 0.2097020149230957 seconds
ml-512-node-020: Time to load fused_adam op: 0.30959296226501465 seconds
ml-512-node-039: ninja: no work to do.
ml-512-node-055: Time to load fused_adam op: 0.1919693946838379 seconds
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: ninja: no work to do.
ml-512-node-058: Time to load fused_adam op: 0.10243725776672363 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-029: Time to load fused_adam op: 0.30160093307495117 seconds
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Detected CUDA files, patching ldflags
ml-512-node-064: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-064: Building extension module fused_adam...
ml-512-node-064: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-031: Time to load fused_adam op: 0.10856246948242188 seconds
ml-512-node-039: Time to load fused_adam op: 0.18302154541015625 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-016: Time to load fused_adam op: 0.1668992042541504 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-042: Time to load fused_adam op: 0.10172319412231445 seconds
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-022: Time to load fused_adam op: 0.1322793960571289 seconds
ml-512-node-022: Time to load fused_adam op: 0.10194087028503418 seconds
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-027: Time to load fused_adam op: 0.10617232322692871 seconds
ml-512-node-021: Time to load fused_adam op: 0.2048935890197754 seconds
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-058: Time to load fused_adam op: 0.2260427474975586 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-019: Time to load fused_adam op: 0.10247254371643066 seconds
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: ninja: no work to do.
ml-512-node-032: Time to load fused_adam op: 0.17827987670898438 seconds
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-015: Time to load fused_adam op: 0.2028815746307373 seconds
ml-512-node-029: Time to load fused_adam op: 0.30275654792785645 seconds
ml-512-node-051: Time to load fused_adam op: 0.1177055835723877 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-025: ninja: no work to do.
ml-512-node-047: Time to load fused_adam op: 0.3020906448364258 seconds
ml-512-node-047: Time to load fused_adam op: 0.3060123920440674 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.10260224342346191 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-022: Time to load fused_adam op: 0.10235714912414551 seconds
ml-512-node-029: Time to load fused_adam op: 0.30176591873168945 seconds
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-005: Detected CUDA files, patching ldflags
ml-512-node-005: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-005: Building extension module fused_adam...
ml-512-node-005: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Detected CUDA files, patching ldflags
ml-512-node-007: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-007: Building extension module fused_adam...
ml-512-node-007: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-042: Time to load fused_adam op: 0.1027841567993164 seconds
ml-512-node-042: Time to load fused_adam op: 0.20169591903686523 seconds
ml-512-node-042: Time to load fused_adam op: 0.2019195556640625 seconds
ml-512-node-042: Time to load fused_adam op: 0.2028331756591797 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Time to load fused_adam op: 0.20465731620788574 seconds
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-025: Time to load fused_adam op: 0.2680089473724365 seconds
ml-512-node-025: Time to load fused_adam op: 0.10173344612121582 seconds
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-022: Time to load fused_adam op: 0.1018829345703125 seconds
ml-512-node-039: Time to load fused_adam op: 0.2017354965209961 seconds
ml-512-node-015: Time to load fused_adam op: 0.40471792221069336 seconds
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Detected CUDA files, patching ldflags
ml-512-node-003: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-003: Building extension module fused_adam...
ml-512-node-003: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-027: Time to load fused_adam op: 0.10244870185852051 seconds
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-032: Time to load fused_adam op: 0.20186638832092285 seconds
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: ninja: no work to do.
ml-512-node-002: Detected CUDA files, patching ldflags
ml-512-node-002: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-002: Building extension module fused_adam...
ml-512-node-002: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: ninja: no work to do.
ml-512-node-015: Time to load fused_adam op: 0.4081904888153076 seconds
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-015: Time to load fused_adam op: 0.4020516872406006 seconds
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-032: Time to load fused_adam op: 0.20854496955871582 seconds
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Detected CUDA files, patching ldflags
ml-512-node-055: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-055: Building extension module fused_adam...
ml-512-node-055: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-046: Detected CUDA files, patching ldflags
ml-512-node-046: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-046: Building extension module fused_adam...
ml-512-node-046: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-001: Detected CUDA files, patching ldflags
ml-512-node-001: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-001: Building extension module fused_adam...
ml-512-node-001: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-016: Time to load fused_adam op: 0.4018974304199219 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-057: Time to load fused_adam op: 0.19695734977722168 seconds
ml-512-node-015: Time to load fused_adam op: 0.303516149520874 seconds
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-059: Detected CUDA files, patching ldflags
ml-512-node-059: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: ninja: no work to do.
ml-512-node-059: Building extension module fused_adam...
ml-512-node-059: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-025: Time to load fused_adam op: 0.40262269973754883 seconds
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Time to load fused_adam op: 0.40199899673461914 seconds
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-022: Time to load fused_adam op: 0.1016693115234375 seconds
ml-512-node-057: Time to load fused_adam op: 0.202470064163208 seconds
ml-512-node-041: Time to load fused_adam op: 0.24276113510131836 seconds
ml-512-node-026: ninja: no work to do.
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-029: Time to load fused_adam op: 0.20171165466308594 seconds
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-023: Detected CUDA files, patching ldflags
ml-512-node-023: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-023: Building extension module fused_adam...
ml-512-node-023: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-026: Time to load fused_adam op: 0.15843868255615234 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.22772598266601562 seconds
ml-512-node-018: ninja: no work to do.
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Time to load fused_adam op: 0.10274815559387207 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-026: Time to load fused_adam op: 0.20194268226623535 seconds
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Time to load fused_adam op: 0.40170979499816895 seconds
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Time to load fused_adam op: 0.40599513053894043 seconds
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Time to load fused_adam op: 0.3058590888977051 seconds
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Time to load fused_adam op: 0.21271228790283203 seconds
ml-512-node-048: ninja: no work to do.
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: Time to load fused_adam op: 0.2882509231567383 seconds
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: ninja: no work to do.
ml-512-node-064: Time to load fused_adam op: 0.18523621559143066 seconds
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-057: Time to load fused_adam op: 0.10708904266357422 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.20183897018432617 seconds
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-018: Time to load fused_adam op: 0.20255827903747559 seconds
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-016: Time to load fused_adam op: 0.10159587860107422 seconds
ml-512-node-005: ninja: no work to do.
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.2689497470855713 seconds
ml-512-node-048: Time to load fused_adam op: 0.10622429847717285 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.10633325576782227 seconds
ml-512-node-008: Detected CUDA files, patching ldflags
ml-512-node-008: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-008: Building extension module fused_adam...
ml-512-node-008: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-007: ninja: no work to do.
ml-512-node-004: Detected CUDA files, patching ldflags
ml-512-node-004: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-004: Building extension module fused_adam...
ml-512-node-004: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-005: Time to load fused_adam op: 0.19081640243530273 seconds
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.20345115661621094 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-032: Time to load fused_adam op: 0.4124774932861328 seconds
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-010: ninja: no work to do.
ml-512-node-002: ninja: no work to do.
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-026: Time to load fused_adam op: 0.30185961723327637 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Time to load fused_adam op: 0.155961275100708 seconds
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-026: Time to load fused_adam op: 0.30187225341796875 seconds
ml-512-node-046: ninja: no work to do.
ml-512-node-011: Detected CUDA files, patching ldflags
ml-512-node-011: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-011: Building extension module fused_adam...
ml-512-node-011: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-005: Time to load fused_adam op: 0.10499739646911621 seconds
ml-512-node-003: ninja: no work to do.
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Time to load fused_adam op: 0.10701394081115723 seconds
ml-512-node-046: Time to load fused_adam op: 0.20106005668640137 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.2042679786682129 seconds
ml-512-node-055: ninja: no work to do.
ml-512-node-010: Time to load fused_adam op: 0.24405527114868164 seconds
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-002: Time to load fused_adam op: 0.17905473709106445 seconds
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: 
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-018: Time to load fused_adam op: 0.41031575202941895 seconds
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-028: Detected CUDA files, patching ldflags
ml-512-node-028: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-028: Building extension module fused_adam...
ml-512-node-028: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-009: Detected CUDA files, patching ldflags
ml-512-node-009: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Time to load fused_adam op: 0.30294322967529297 seconds
ml-512-node-009: Building extension module fused_adam...
ml-512-node-009: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-018: Time to load fused_adam op: 0.31044459342956543 seconds
ml-512-node-003: Time to load fused_adam op: 0.19176626205444336 seconds
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.20469188690185547 seconds
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Time to load fused_adam op: 0.20772123336791992 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: ninja: no work to do.
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Detected CUDA files, patching ldflags
ml-512-node-050: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Building extension module fused_adam...
ml-512-node-050: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-002: Time to load fused_adam op: 0.10622763633728027 seconds
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.13832688331604004 seconds
ml-512-node-055: Time to load fused_adam op: 0.2032451629638672 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-046: Time to load fused_adam op: 0.1084601879119873 seconds
ml-512-node-046: Time to load fused_adam op: 0.10245823860168457 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-030: ninja: no work to do.
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-030: Time to load fused_adam op: 0.28890061378479004 seconds
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-022: Detected CUDA files, patching ldflags
ml-512-node-022: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-022: Building extension module fused_adam...
ml-512-node-022: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Time to load fused_adam op: 0.19205784797668457 seconds
ml-512-node-064: Time to load fused_adam op: 0.40294981002807617 seconds
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-003: Time to load fused_adam op: 0.10168600082397461 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: Time to load fused_adam op: 0.3112161159515381 seconds
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-002: Time to load fused_adam op: 0.30280256271362305 seconds
ml-512-node-064: Time to load fused_adam op: 0.40560030937194824 seconds
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-062: Detected CUDA files, patching ldflags
ml-512-node-062: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Building extension module fused_adam...
ml-512-node-062: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Time to load fused_adam op: 0.4019434452056885 seconds
ml-512-node-007: Time to load fused_adam op: 0.4027724266052246 seconds
ml-512-node-007: Time to load fused_adam op: 0.30676937103271484 seconds
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-059: Time to load fused_adam op: 0.3019380569458008 seconds
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Time to load fused_adam op: 0.2035832405090332 seconds
ml-512-node-003: Time to load fused_adam op: 0.20827245712280273 seconds
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Time to load fused_adam op: 0.3027772903442383 seconds
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Detected CUDA files, patching ldflags
ml-512-node-049: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-049: Building extension module fused_adam...
ml-512-node-049: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-001: ninja: no work to do.
ml-512-node-059: Time to load fused_adam op: 0.30272984504699707 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-002: Time to load fused_adam op: 0.30204033851623535 seconds
ml-512-node-002: Time to load fused_adam op: 0.30272531509399414 seconds
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: ninja: no work to do.
ml-512-node-009: ninja: no work to do.
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-005: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-005: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-005: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-005: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-001: Time to load fused_adam op: 0.3219902515411377 seconds
ml-512-node-046: Time to load fused_adam op: 0.21065187454223633 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-003: Time to load fused_adam op: 0.20293307304382324 seconds
ml-512-node-003: Time to load fused_adam op: 0.20262432098388672 seconds
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-009: Time to load fused_adam op: 0.23682546615600586 seconds
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: ninja: no work to do.
ml-512-node-050: Time to load fused_adam op: 0.17126941680908203 seconds
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-053: Detected CUDA files, patching ldflags
ml-512-node-053: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: Time to load fused_adam op: 0.40903282165527344 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-053: Building extension module fused_adam...
ml-512-node-053: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-030: Time to load fused_adam op: 0.4077019691467285 seconds
ml-512-node-030: Time to load fused_adam op: 0.5068321228027344 seconds
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: Detected CUDA files, patching ldflags
ml-512-node-012: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-012: Building extension module fused_adam...
ml-512-node-012: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-008: Time to load fused_adam op: 0.34650206565856934 seconds
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-008: Time to load fused_adam op: 0.3028285503387451 seconds
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Detected CUDA files, patching ldflags
ml-512-node-026: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-026: Building extension module fused_adam...
ml-512-node-026: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-011: ninja: no work to do.
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-001: Time to load fused_adam op: 0.20182561874389648 seconds
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-010: Detected CUDA files, patching ldflags
ml-512-node-010: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-010: Building extension module fused_adam...
ml-512-node-010: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-011: Time to load fused_adam op: 0.2682366371154785 seconds
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-031: Detected CUDA files, patching ldflags
ml-512-node-031: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-031: Building extension module fused_adam...
ml-512-node-031: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: ninja: no work to do.
ml-512-node-021: Detected CUDA files, patching ldflags
ml-512-node-021: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-016: Detected CUDA files, patching ldflags
ml-512-node-016: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-016: Building extension module fused_adam...
ml-512-node-016: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-052: Detected CUDA files, patching ldflags
ml-512-node-052: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-052: Building extension module fused_adam...
ml-512-node-052: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: ninja: no work to do.
ml-512-node-006: Detected CUDA files, patching ldflags
ml-512-node-006: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-006: Building extension module fused_adam...
ml-512-node-006: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: ninja: no work to do.
ml-512-node-044: Time to load fused_adam op: 0.2195594310760498 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-021: Building extension module fused_adam...
ml-512-node-021: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.36608338356018066 seconds
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Time to load fused_adam op: 0.41672563552856445 seconds
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-023: ninja: no work to do.
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.10714316368103027 seconds
ml-512-node-049: ninja: no work to do.
ml-512-node-023: Time to load fused_adam op: 0.3672170639038086 seconds
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Time to load fused_adam op: 0.2027573585510254 seconds
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Time to load fused_adam op: 0.22032666206359863 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-041: ninja: no work to do.
ml-512-node-033: ninja: no work to do.
ml-512-node-042: ninja: no work to do.
ml-512-node-039: ninja: no work to do.
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.21071720123291016 seconds
ml-512-node-044: Time to load fused_adam op: 0.20586585998535156 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-023: Time to load fused_adam op: 0.3113679885864258 seconds
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-005: ninja: no work to do.
ml-512-node-026: ninja: no work to do.
ml-512-node-042: Time to load fused_adam op: 0.27573347091674805 seconds
ml-512-node-041: Time to load fused_adam op: 0.27394604682922363 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-056: ninja: no work to do.
ml-512-node-017: Detected CUDA files, patching ldflags
ml-512-node-017: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-017: Building extension module fused_adam...
ml-512-node-017: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-008: Time to load fused_adam op: 0.10846972465515137 seconds
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.30110597610473633 seconds
ml-512-node-039: Time to load fused_adam op: 0.28492140769958496 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-004: Time to load fused_adam op: 0.1017608642578125 seconds
ml-512-node-005: Time to load fused_adam op: 0.23279023170471191 seconds
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-022: ninja: no work to do.
ml-512-node-061: Detected CUDA files, patching ldflags
ml-512-node-061: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: Building extension module fused_adam...
ml-512-node-061: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-039: Time to load fused_adam op: 0.5058166980743408 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.5086917877197266 seconds
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.10166597366333008 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 1.0279741287231445 seconds
ml-512-node-022: Time to load fused_adam op: 0.2773141860961914 seconds
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Time to load fused_adam op: 0.402219295501709 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.2119143009185791 seconds
ml-512-node-005: Time to load fused_adam op: 0.3105156421661377 seconds
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: ninja: no work to do.
ml-512-node-053: ninja: no work to do.
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Time to load fused_adam op: 0.30195021629333496 seconds
ml-512-node-039: Time to load fused_adam op: 0.4055216312408447 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-026: Time to load fused_adam op: 0.1827831268310547 seconds
ml-512-node-026: Time to load fused_adam op: 0.10163474082946777 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-016: ninja: no work to do.
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-055: Detected CUDA files, patching ldflags
ml-512-node-055: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-055: Building extension module fused_adam...
ml-512-node-055: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-012: Time to load fused_adam op: 0.41936469078063965 seconds
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.3356778621673584 seconds
ml-512-node-062: ninja: no work to do.
ml-512-node-056: Time to load fused_adam op: 1.319530963897705 seconds
ml-512-node-037: ninja: no work to do.
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Time to load fused_adam op: 0.30194854736328125 seconds
ml-512-node-005: Time to load fused_adam op: 0.4028053283691406 seconds
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.3611893653869629 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-005: Time to load fused_adam op: 0.2028031349182129 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-012: Time to load fused_adam op: 0.2078399658203125 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-022: Time to load fused_adam op: 0.30188822746276855 seconds
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.3411095142364502 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.31380176544189453 seconds
ml-512-node-016: Time to load fused_adam op: 0.20195627212524414 seconds
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-016: Time to load fused_adam op: 0.2120199203491211 seconds
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-010: ninja: no work to do.
ml-512-node-050: Detected CUDA files, patching ldflags
ml-512-node-050: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-050: Building extension module fused_adam...
ml-512-node-050: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-010: Time to load fused_adam op: 0.27999305725097656 seconds
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.30313754081726074 seconds
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: ninja: no work to do.
ml-512-node-028: ninja: no work to do.
ml-512-node-028: Time to load fused_adam op: 0.47127723693847656 seconds
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.307528018951416 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.4019637107849121 seconds
ml-512-node-056: Time to load fused_adam op: 1.4096031188964844 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Time to load fused_adam op: 0.4415454864501953 seconds
ml-512-node-053: Time to load fused_adam op: 0.41203832626342773 seconds
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-035: ninja: no work to do.
ml-512-node-006: ninja: no work to do.
ml-512-node-017: ninja: no work to do.
ml-512-node-014: Detected CUDA files, patching ldflags
ml-512-node-014: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-014: Building extension module fused_adam...
ml-512-node-014: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-006: Time to load fused_adam op: 0.35622215270996094 seconds
ml-512-node-010: Time to load fused_adam op: 0.6023037433624268 seconds
ml-512-node-017: Time to load fused_adam op: 0.33942484855651855 seconds
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-021: ninja: no work to do.
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.5196964740753174 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-058: Detected CUDA files, patching ldflags
ml-512-node-058: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-058: Building extension module fused_adam...
ml-512-node-058: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-010: Time to load fused_adam op: 0.6022770404815674 seconds
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-021: Time to load fused_adam op: 0.38522887229919434 seconds
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-059: Detected CUDA files, patching ldflags
ml-512-node-059: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: Building extension module fused_adam...
ml-512-node-059: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-052: ninja: no work to do.
ml-512-node-006: Time to load fused_adam op: 0.2027132511138916 seconds
ml-512-node-035: Time to load fused_adam op: 0.20628905296325684 seconds
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-050: ninja: no work to do.
ml-512-node-052: Time to load fused_adam op: 0.3518805503845215 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-028: Time to load fused_adam op: 0.5019705295562744 seconds
ml-512-node-010: Time to load fused_adam op: 0.7056090831756592 seconds
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-050: Time to load fused_adam op: 0.22956633567810059 seconds
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Detected CUDA files, patching ldflags
ml-512-node-030: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-030: Building extension module fused_adam...
ml-512-node-030: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-050: Time to load fused_adam op: 0.1021573543548584 seconds
ml-512-node-052: Time to load fused_adam op: 0.30439019203186035 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-064: Detected CUDA files, patching ldflags
ml-512-node-064: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-064: Building extension module fused_adam...
ml-512-node-064: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: ninja: no work to do.
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-050: Time to load fused_adam op: 0.20188093185424805 seconds
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.6121828556060791 seconds
ml-512-node-052: Time to load fused_adam op: 0.4193079471588135 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-050: Time to load fused_adam op: 0.4387955665588379 seconds
ml-512-node-043: ninja: no work to do.
ml-512-node-043: Time to load fused_adam op: 0.32364749908447266 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: ninja: no work to do.
ml-512-node-061: ninja: no work to do.
ml-512-node-023: Detected CUDA files, patching ldflags
ml-512-node-023: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-023: Building extension module fused_adam...
ml-512-node-023: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-043: Time to load fused_adam op: 0.6061282157897949 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-061: Time to load fused_adam op: 0.44017744064331055 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-055: ninja: no work to do.
ml-512-node-055: Time to load fused_adam op: 0.4617142677307129 seconds
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: ninja: no work to do.
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-058: Time to load fused_adam op: 0.3723483085632324 seconds
ml-512-node-043: Time to load fused_adam op: 0.3020150661468506 seconds
ml-512-node-043: Time to load fused_adam op: 0.5141890048980713 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-059: ninja: no work to do.
ml-512-node-030: Time to load fused_adam op: 0.2480170726776123 seconds
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-014: ninja: no work to do.
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-027: Detected CUDA files, patching ldflags
ml-512-node-027: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-014: Time to load fused_adam op: 0.3645308017730713 seconds
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-059: Time to load fused_adam op: 0.3977518081665039 seconds
ml-512-node-064: ninja: no work to do.
ml-512-node-027: Building extension module fused_adam...
ml-512-node-027: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.8029224872589111 seconds
ml-512-node-064: Time to load fused_adam op: 0.28960490226745605 seconds
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Detected CUDA files, patching ldflags
ml-512-node-009: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-009: Building extension module fused_adam...
ml-512-node-009: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: ninja: no work to do.
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.4947082996368408 seconds
ml-512-node-027: ninja: no work to do.
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-027: Time to load fused_adam op: 0.3562014102935791 seconds
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-023: ninja: no work to do.
ml-512-node-045: ninja: no work to do.
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Detected CUDA files, patching ldflags
ml-512-node-012: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-012: Building extension module fused_adam...
ml-512-node-012: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-023: Time to load fused_adam op: 0.5676352977752686 seconds
ml-512-node-045: Time to load fused_adam op: 0.427645206451416 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.30230283737182617 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: ninja: no work to do.
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Time to load fused_adam op: 0.4149506092071533 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-009: ninja: no work to do.
ml-512-node-009: Time to load fused_adam op: 0.5003089904785156 seconds
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-048: ninja: no work to do.
ml-512-node-012: ninja: no work to do.
ml-512-node-048: Time to load fused_adam op: 0.4165642261505127 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-012: Time to load fused_adam op: 0.44175267219543457 seconds
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: Time to load fused_adam op: 0.20746779441833496 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: ninja: no work to do.
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.2605288028717041 seconds
ml-512-node-062: Detected CUDA files, patching ldflags
ml-512-node-062: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Building extension module fused_adam...
ml-512-node-062: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-057: Detected CUDA files, patching ldflags
ml-512-node-057: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-057: Building extension module fused_adam...
ml-512-node-057: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Detected CUDA files, patching ldflags
ml-512-node-049: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-049: Building extension module fused_adam...
ml-512-node-049: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Detected CUDA files, patching ldflags
ml-512-node-004: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-004: Building extension module fused_adam...
ml-512-node-004: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Detected CUDA files, patching ldflags
ml-512-node-031: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-031: Building extension module fused_adam...
ml-512-node-031: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Detected CUDA files, patching ldflags
ml-512-node-007: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-007: Building extension module fused_adam...
ml-512-node-007: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-031: ninja: no work to do.
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-031: Time to load fused_adam op: 0.14090347290039062 seconds
ml-512-node-062: ninja: no work to do.
ml-512-node-031: Time to load fused_adam op: 0.10860800743103027 seconds
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.43802475929260254 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-007: ninja: no work to do.
ml-512-node-049: ninja: no work to do.
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-004: ninja: no work to do.
ml-512-node-049: Time to load fused_adam op: 0.3554415702819824 seconds
ml-512-node-007: Time to load fused_adam op: 0.3464345932006836 seconds
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-004: Time to load fused_adam op: 0.3719205856323242 seconds
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-057: ninja: no work to do.
ml-512-node-004: Time to load fused_adam op: 0.20198559761047363 seconds
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Time to load fused_adam op: 0.5168130397796631 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Detected CUDA files, patching ldflags
ml-512-node-023: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-023: Building extension module fused_adam...
ml-512-node-023: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-011: Detected CUDA files, patching ldflags
ml-512-node-011: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-011: Building extension module fused_adam...
ml-512-node-011: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: ninja: no work to do.
ml-512-node-011: Time to load fused_adam op: 0.2085130214691162 seconds
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Detected CUDA files, patching ldflags
ml-512-node-059: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: Building extension module fused_adam...
ml-512-node-059: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: Detected CUDA files, patching ldflags
ml-512-node-060: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-060: Building extension module fused_adam...
ml-512-node-060: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: ninja: no work to do.
ml-512-node-038: Time to load fused_adam op: 0.2904784679412842 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-059: ninja: no work to do.
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Time to load fused_adam op: 0.23357582092285156 seconds
ml-512-node-023: ninja: no work to do.
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Time to load fused_adam op: 0.6244325637817383 seconds
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-026: Detected CUDA files, patching ldflags
ml-512-node-026: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-026: Building extension module fused_adam...
ml-512-node-026: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: ninja: no work to do.
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: ninja: no work to do.
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-026: Time to load fused_adam op: 0.2163698673248291 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-060: Time to load fused_adam op: 0.4106879234313965 seconds
ml-512-node-006: Detected CUDA files, patching ldflags
ml-512-node-006: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-006: Building extension module fused_adam...
ml-512-node-006: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Detected CUDA files, patching ldflags
ml-512-node-021: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-021: Building extension module fused_adam...
ml-512-node-021: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-006: ninja: no work to do.
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-006: Time to load fused_adam op: 0.2682621479034424 seconds
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Detected CUDA files, patching ldflags
ml-512-node-011: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-011: Building extension module fused_adam...
ml-512-node-011: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Detected CUDA files, patching ldflags
ml-512-node-046: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-046: Building extension module fused_adam...
ml-512-node-046: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-021: ninja: no work to do.
ml-512-node-021: Time to load fused_adam op: 0.4954519271850586 seconds
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: ninja: no work to do.
ml-512-node-011: ninja: no work to do.
ml-512-node-046: Time to load fused_adam op: 0.20591068267822266 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-011: Time to load fused_adam op: 0.3607289791107178 seconds
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-040: ninja: no work to do.
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 1.0638236999511719 seconds
ml-512-node-040: Time to load fused_adam op: 0.2050788402557373 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-017: Detected CUDA files, patching ldflags
ml-512-node-017: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-017: Building extension module fused_adam...
ml-512-node-017: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: ninja: no work to do.
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-017: Time to load fused_adam op: 0.4615166187286377 seconds
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Detected CUDA files, patching ldflags
ml-512-node-019: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-019: Building extension module fused_adam...
ml-512-node-019: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-019: ninja: no work to do.
ml-512-node-019: Time to load fused_adam op: 0.5499286651611328 seconds
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-056: Detected CUDA files, patching ldflags
ml-512-node-056: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-056: Building extension module fused_adam...
ml-512-node-056: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Detected CUDA files, patching ldflags
ml-512-node-028: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-028: Building extension module fused_adam...
ml-512-node-028: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-001: Detected CUDA files, patching ldflags
ml-512-node-001: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-001: Building extension module fused_adam...
ml-512-node-001: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-001: ninja: no work to do.
ml-512-node-001: Time to load fused_adam op: 0.35819244384765625 seconds
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-056: ninja: no work to do.
ml-512-node-056: Time to load fused_adam op: 1.0322816371917725 seconds
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-028: ninja: no work to do.
ml-512-node-028: Time to load fused_adam op: 0.5039694309234619 seconds
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-001: [2024-07-08 06:07:01,182] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
ml-512-node-001: [2024-07-08 06:07:01,183] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
ml-512-node-001: [2024-07-08 06:07:01,183] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
ml-512-node-001: [2024-07-08 06:07:01,193] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
ml-512-node-001: [2024-07-08 06:07:01,193] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale
ml-512-node-001: [2024-07-08 06:07:01,423] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FP16_Optimizer
ml-512-node-001: [2024-07-08 06:07:01,423] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
ml-512-node-001: [2024-07-08 06:07:01,423] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7e3bc43278b0>
ml-512-node-001: [2024-07-08 06:07:01,423] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 06:07:01,423] [INFO] [config.py:997:print] DeepSpeedEngine configuration:
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   activation_checkpointing_config  {
ml-512-node-001:     "partition_activations": false, 
ml-512-node-001:     "contiguous_memory_optimization": false, 
ml-512-node-001:     "cpu_checkpointing": false, 
ml-512-node-001:     "number_checkpoints": null, 
ml-512-node-001:     "synchronize_checkpoint_boundary": false, 
ml-512-node-001:     "profile": false
ml-512-node-001: }
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   amp_enabled .................. False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   amp_params ................... False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   autotuning_config ............ {
ml-512-node-001:     "enabled": false, 
ml-512-node-001:     "start_step": null, 
ml-512-node-001:     "end_step": null, 
ml-512-node-001:     "metric_path": null, 
ml-512-node-001:     "arg_mappings": null, 
ml-512-node-001:     "metric": "throughput", 
ml-512-node-001:     "model_info": null, 
ml-512-node-001:     "results_dir": "autotuning_results", 
ml-512-node-001:     "exps_dir": "autotuning_exps", 
ml-512-node-001:     "overwrite": true, 
ml-512-node-001:     "fast": true, 
ml-512-node-001:     "start_profile_step": 3, 
ml-512-node-001:     "end_profile_step": 5, 
ml-512-node-001:     "tuner_type": "gridsearch", 
ml-512-node-001:     "tuner_early_stopping": 5, 
ml-512-node-001:     "tuner_num_trials": 50, 
ml-512-node-001:     "model_info_path": null, 
ml-512-node-001:     "mp_size": 1, 
ml-512-node-001:     "max_train_batch_size": null, 
ml-512-node-001:     "min_train_batch_size": 1, 
ml-512-node-001:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
ml-512-node-001:     "min_train_micro_batch_size_per_gpu": 1, 
ml-512-node-001:     "num_tuning_micro_batch_sizes": 3
ml-512-node-001: }
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   bfloat16_enabled ............. False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   bfloat16_immediate_grad_update  False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   checkpoint_parallel_write_pipeline  False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   checkpoint_tag_validation_enabled  True
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   checkpoint_tag_validation_fail  False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7e3bc4324310>
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   communication_data_type ...... None
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   curriculum_enabled_legacy .... False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   curriculum_params_legacy ..... False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   data_efficiency_enabled ...... False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   dataloader_drop_last ......... False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   disable_allgather ............ False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   dump_state ................... False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   eigenvalue_enabled ........... False
ml-512-node-001: [2024-07-08 06:07:01,424] [INFO] [config.py:1001:print]   eigenvalue_gas_boundary_resolution  1
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   eigenvalue_layer_name ........ bert.encoder.layer
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   eigenvalue_layer_num ......... 0
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   eigenvalue_max_iter .......... 100
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   eigenvalue_stability ......... 1e-06
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   eigenvalue_tol ............... 0.01
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   eigenvalue_verbose ........... False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   elasticity_enabled ........... False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   flops_profiler_config ........ {
ml-512-node-001:     "enabled": false, 
ml-512-node-001:     "recompute_fwd_factor": 0.0, 
ml-512-node-001:     "profile_step": 1, 
ml-512-node-001:     "module_depth": -1, 
ml-512-node-001:     "top_modules": 1, 
ml-512-node-001:     "detailed": true, 
ml-512-node-001:     "output_file": null
ml-512-node-001: }
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   fp16_auto_cast ............... False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   fp16_enabled ................. True
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   fp16_master_weights_and_gradients  False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   global_rank .................. 0
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   grad_accum_dtype ............. None
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   gradient_accumulation_steps .. 1
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   gradient_clipping ............ 1.0
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   gradient_predivide_factor .... 1.0
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   graph_harvesting ............. False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   initial_dynamic_scale ........ 65536
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   load_universal_checkpoint .... False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   loss_scale ................... 0
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   memory_breakdown ............. False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   mics_hierarchial_params_gather  False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   mics_shard_size .............. -1
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step1_tensorboard/ds_tensorboard_logs/', job_name='step1_model_tensorboard') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   nebula_config ................ {
ml-512-node-001:     "enabled": false, 
ml-512-node-001:     "persistent_storage_path": null, 
ml-512-node-001:     "persistent_time_interval": 100, 
ml-512-node-001:     "num_of_version_in_retention": 2, 
ml-512-node-001:     "enable_nebula_load": true, 
ml-512-node-001:     "load_path": null
ml-512-node-001: }
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   optimizer_legacy_fusion ...... False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   optimizer_name ............... None
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   optimizer_params ............. None
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   pld_enabled .................. False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   pld_params ................... False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   prescale_gradients ........... False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   scheduler_name ............... None
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   scheduler_params ............. None
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   seq_parallel_communication_data_type  torch.float32
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   sparse_attention ............. None
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   sparse_gradients_enabled ..... False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   steps_per_print .............. 10
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   timers_config ................ enabled=True synchronized=True
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   train_batch_size ............. 12288
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   train_micro_batch_size_per_gpu  24
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   use_data_before_expert_parallel_  False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   use_node_local_storage ....... False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   wall_clock_breakdown ......... False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   weight_quantization_config ... None
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   world_size ................... 512
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   zero_allow_untested_optimizer  False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   zero_enabled ................. False
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   zero_force_ds_cpu_optimizer .. True
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:1001:print]   zero_optimization_stage ...... 0
ml-512-node-001: [2024-07-08 06:07:01,425] [INFO] [config.py:987:print_user_config]   json = {
ml-512-node-001:     "train_batch_size": 1.228800e+04, 
ml-512-node-001:     "train_micro_batch_size_per_gpu": 24, 
ml-512-node-001:     "steps_per_print": 10, 
ml-512-node-001:     "zero_optimization": {
ml-512-node-001:         "stage": 0, 
ml-512-node-001:         "offload_param": {
ml-512-node-001:             "device": "none"
ml-512-node-001:         }, 
ml-512-node-001:         "offload_optimizer": {
ml-512-node-001:             "device": "none"
ml-512-node-001:         }, 
ml-512-node-001:         "stage3_param_persistence_threshold": 1.000000e+04, 
ml-512-node-001:         "stage3_max_live_parameters": 3.000000e+07, 
ml-512-node-001:         "stage3_prefetch_bucket_size": 3.000000e+07, 
ml-512-node-001:         "memory_efficient_linear": false
ml-512-node-001:     }, 
ml-512-node-001:     "fp16": {
ml-512-node-001:         "enabled": true, 
ml-512-node-001:         "loss_scale_window": 100
ml-512-node-001:     }, 
ml-512-node-001:     "gradient_clipping": 1.0, 
ml-512-node-001:     "prescale_gradients": false, 
ml-512-node-001:     "wall_clock_breakdown": false, 
ml-512-node-001:     "hybrid_engine": {
ml-512-node-001:         "enabled": false, 
ml-512-node-001:         "max_out_tokens": 512, 
ml-512-node-001:         "inference_tp_size": 1, 
ml-512-node-001:         "release_inference_cache": false, 
ml-512-node-001:         "pin_parameters": true, 
ml-512-node-001:         "tp_gather_partition_size": 8
ml-512-node-001:     }, 
ml-512-node-001:     "tensorboard": {
ml-512-node-001:         "enabled": false, 
ml-512-node-001:         "output_path": "step1_tensorboard/ds_tensorboard_logs/", 
ml-512-node-001:         "job_name": "step1_model_tensorboard"
ml-512-node-001:     }
ml-512-node-001: }
ml-512-node-001: ***** Running training *****
ml-512-node-001: Beginning of Epoch 1/100, Total Micro Batches 1
ml-512-node-064: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 06:07:03,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-022: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-019: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-029: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-029: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-016: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-029: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-019: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-022: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 06:07:03,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-016: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-016: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536, reducing to 32768.0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-016: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-009: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-009: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-009: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-001: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-001: Beginning of Epoch 2/100, Total Micro Batches 1
ml-512-node-052: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:07:03,730] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-004: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-022: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:03,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-022: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-022: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:03,732] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-017: [2024-07-08 06:07:03,729] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:07:03,731] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 06:07:03,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-001: [2024-07-08 06:07:03,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 06:07:03,918] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:03,918] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 06:07:03,918] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 06:07:03,918] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 06:07:03,918] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 06:07:03,918] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 06:07:03,918] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-001: Beginning of Epoch 3/100, Total Micro Batches 1
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:03,918] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:03,920] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-008: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 06:07:03,919] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 06:07:03,917] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:07:03,921] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 06:07:03,922] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-014: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,103] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-011: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-014: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-014: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-025: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: Beginning of Epoch 4/100, Total Micro Batches 1
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-014: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-014: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-010: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-005: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 06:07:04,109] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 06:07:04,105] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-018: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 06:07:04,104] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 06:07:04,106] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-028: [2024-07-08 06:07:04,107] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-028: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:07:04,108] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-027: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-027: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-001: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-001: Beginning of Epoch 5/100, Total Micro Batches 1
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-011: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-011: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 06:07:04,291] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-014: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,290] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-029: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 06:07:04,295] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,292] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,293] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:07:04,294] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 06:07:04,477] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 06:07:04,482] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 06:07:04,482] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 06:07:04,480] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0
ml-512-node-019: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: Beginning of Epoch 6/100, Total Micro Batches 1
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:07:04,475] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 06:07:04,480] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 06:07:04,478] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 06:07:04,479] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-025: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 2048.0, reducing to 1024.0
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-001: Beginning of Epoch 7/100, Total Micro Batches 1
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 06:07:04,666] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:07:04,660] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:07:04,661] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 06:07:04,666] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 06:07:04,666] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-020: [2024-07-08 06:07:04,661] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,661] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 06:07:04,662] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 06:07:04,661] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:07:04,663] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-010: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: [2024-07-08 06:07:04,664] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 06:07:04,665] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-027: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-025: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-016: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-016: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:07:04,846] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-006: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 06:07:04,847] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-016: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 1024.0, reducing to 512.0
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Beginning of Epoch 8/100, Total Micro Batches 1
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:07:04,851] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-017: [2024-07-08 06:07:04,848] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:07:04,849] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-014: [2024-07-08 06:07:04,850] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-007: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,031] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:07:05,031] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,036] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 512.0, reducing to 256.0
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:07:05,031] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: Beginning of Epoch 9/100, Total Micro Batches 1
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:07:05,031] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 06:07:05,031] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 06:07:05,031] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,031] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 06:07:05,031] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 06:07:05,031] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-021: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 06:07:05,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-006: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 06:07:05,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 06:07:05,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 06:07:05,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-013: [2024-07-08 06:07:05,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:07:05,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,222] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 256.0, reducing to 128.0
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Beginning of Epoch 10/100, Total Micro Batches 1
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-010: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 06:07:05,217] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: [2024-07-08 06:07:05,219] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,222] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:07:05,220] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:07:05,221] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 128.0, reducing to 64.0
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-006: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 06:07:05,403] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-025: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-029: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 06:07:05,404] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-010: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:07:05,401] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:07:05,405] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=10, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-044: [2024-07-08 06:07:05,406] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 06:07:05,406] [INFO] [timer.py:258:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=66887.5602362496, CurrSamplesPerSec=67240.10477742365, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-001: Beginning of Epoch 11/100, Total Micro Batches 1
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 06:07:05,588] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: [2024-07-08 06:07:05,586] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-014: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 64.0, reducing to 32.0
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Beginning of Epoch 12/100, Total Micro Batches 1
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-008: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,590] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 06:07:05,589] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 06:07:05,591] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:07:05,587] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 06:07:05,592] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 06:07:05,773] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,775] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:07:05,772] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32.0, reducing to 16.0
ml-512-node-057: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 06:07:05,774] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-023: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-003: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: Beginning of Epoch 13/100, Total Micro Batches 1
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:07:05,776] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:07:05,777] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 06:07:05,959] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-027: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-003: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-048: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 06:07:05,962] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16.0, reducing to 8.0
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-001: Beginning of Epoch 14/100, Total Micro Batches 1
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: [2024-07-08 06:07:05,958] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-048: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 06:07:05,957] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: [2024-07-08 06:07:05,960] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 06:07:05,962] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:07:05,961] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 13
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 13
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 13
ml-512-node-064: Grad overflow on iteration 13
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 13
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 13
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 13
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 13
ml-512-node-039: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: Grad overflow on iteration 13
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 13
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 13
ml-512-node-003: Grad overflow on iteration 13
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 13
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: Grad overflow on iteration 13
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 13
ml-512-node-003: Grad overflow on iteration 13
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 13
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 13
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 13
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 13
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 13
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 13
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 13
ml-512-node-018: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 13
ml-512-node-018: Grad overflow on iteration 13
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 13
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 13
ml-512-node-009: Grad overflow on iteration 13
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 13
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 13
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 13
ml-512-node-030: Grad overflow on iteration 13
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 13
ml-512-node-008: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 13
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 13
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 13
ml-512-node-008: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 13
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 13
ml-512-node-028: Grad overflow on iteration 13
ml-512-node-017: Grad overflow on iteration 13
ml-512-node-026: Grad overflow on iteration 13
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 13
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 13
ml-512-node-060: Grad overflow on iteration 13
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 13
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 13
ml-512-node-007: Grad overflow on iteration 13
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 13
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: Grad overflow on iteration 13
ml-512-node-018: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: Grad overflow on iteration 13
ml-512-node-013: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 13
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 13
ml-512-node-018: Grad overflow on iteration 13
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 13
ml-512-node-045: Grad overflow on iteration 13
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 13
ml-512-node-045: Grad overflow on iteration 13
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 13
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 13
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 13
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 13
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 13
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: Grad overflow on iteration 13
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 13
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: Grad overflow on iteration 13
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 13
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: Grad overflow on iteration 13
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 13
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 13
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 13
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 13
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 13
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 13
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 13
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 13
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 13
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 13
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 13
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: Grad overflow on iteration 13
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 13
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 13
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 13
ml-512-node-063: Grad overflow on iteration 13
ml-512-node-049: Grad overflow on iteration 13
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: Grad overflow on iteration 13
ml-512-node-031: Grad overflow on iteration 13
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 13
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 13
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: Grad overflow on iteration 13
ml-512-node-043: Grad overflow on iteration 13
ml-512-node-019: Grad overflow on iteration 13
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 13
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 13
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: Grad overflow on iteration 13
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 13
ml-512-node-019: Grad overflow on iteration 13
ml-512-node-020: Grad overflow on iteration 13
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 13
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 13
ml-512-node-011: Grad overflow on iteration 13
ml-512-node-007: Grad overflow on iteration 13
ml-512-node-023: Grad overflow on iteration 13
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: Grad overflow on iteration 13
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 13
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 13
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: Grad overflow on iteration 13
ml-512-node-012: Grad overflow on iteration 13
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 13
ml-512-node-053: Grad overflow on iteration 13
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 13
ml-512-node-058: Grad overflow on iteration 13
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 13
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 13
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 13
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-030: Grad overflow on iteration 13
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 13
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 13
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 06:07:06,142] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-008: Grad overflow on iteration 13
ml-512-node-008: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 13
ml-512-node-008: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 13
ml-512-node-008: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 13
ml-512-node-008: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 13
ml-512-node-055: Grad overflow on iteration 13
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 13
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 13
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: Grad overflow on iteration 13
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 13
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 13
ml-512-node-049: Grad overflow on iteration 13
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 13
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 13
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 13
ml-512-node-046: Grad overflow on iteration 13
ml-512-node-063: Grad overflow on iteration 13
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: Grad overflow on iteration 13
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: Grad overflow on iteration 13
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 13
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 13
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 13
ml-512-node-063: Grad overflow on iteration 13
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: Grad overflow on iteration 13
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 13
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: Grad overflow on iteration 13
ml-512-node-038: Grad overflow on iteration 13
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: Grad overflow on iteration 13
ml-512-node-022: Grad overflow on iteration 13
ml-512-node-021: Grad overflow on iteration 13
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 13
ml-512-node-029: Grad overflow on iteration 13
ml-512-node-047: Grad overflow on iteration 13
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 13
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 13
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 13
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 13
ml-512-node-044: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: Grad overflow on iteration 13
ml-512-node-033: Grad overflow on iteration 13
ml-512-node-047: Grad overflow on iteration 13
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 13
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: Grad overflow on iteration 13
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 13
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 13
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 13
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 13
ml-512-node-028: Grad overflow on iteration 13
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 13
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: Grad overflow on iteration 13
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 13
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 13
ml-512-node-062: Grad overflow on iteration 13
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: Grad overflow on iteration 13
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 13
ml-512-node-002: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 13
ml-512-node-017: Grad overflow on iteration 13
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-023: Grad overflow on iteration 13
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 13
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: Grad overflow on iteration 13
ml-512-node-019: Grad overflow on iteration 13
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 13
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 13
ml-512-node-021: Grad overflow on iteration 13
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 13
ml-512-node-012: Grad overflow on iteration 13
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 13
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 13
ml-512-node-010: Grad overflow on iteration 13
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-030: Grad overflow on iteration 13
ml-512-node-056: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: Grad overflow on iteration 13
ml-512-node-008: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-047: Grad overflow on iteration 13
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 13
ml-512-node-039: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 13
ml-512-node-060: Grad overflow on iteration 13
ml-512-node-059: Grad overflow on iteration 13
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 13
ml-512-node-041: Grad overflow on iteration 13
ml-512-node-007: Grad overflow on iteration 13
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: Grad overflow on iteration 13
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 13
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 13
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 13
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: Grad overflow on iteration 13
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 13
ml-512-node-006: Grad overflow on iteration 13
ml-512-node-034: Grad overflow on iteration 13
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 13
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: Grad overflow on iteration 13
ml-512-node-044: Grad overflow on iteration 13
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: Grad overflow on iteration 13
ml-512-node-034: Grad overflow on iteration 13
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 13
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 13
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 13
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 13
ml-512-node-015: Grad overflow on iteration 13
ml-512-node-014: Grad overflow on iteration 13
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 13
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 13
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: Grad overflow on iteration 13
ml-512-node-050: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 13
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 13
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 13
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-008: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 13
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 13
ml-512-node-049: Grad overflow on iteration 13
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: Grad overflow on iteration 13
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 13
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: Grad overflow on iteration 13
ml-512-node-011: Grad overflow on iteration 13
ml-512-node-023: Grad overflow on iteration 13
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: Grad overflow on iteration 13
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: Grad overflow on iteration 13
ml-512-node-009: Grad overflow on iteration 13
ml-512-node-005: Grad overflow on iteration 13
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 13
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 13
ml-512-node-021: Grad overflow on iteration 13
ml-512-node-009: Grad overflow on iteration 13
ml-512-node-044: Grad overflow on iteration 13
ml-512-node-009: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 13
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 13
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 13
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: Grad overflow on iteration 13
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 13
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 13
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: Grad overflow on iteration 13
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 13
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: Grad overflow on iteration 13
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 13
ml-512-node-008: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 13
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: Grad overflow on iteration 13
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: Grad overflow on iteration 13
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: Grad overflow on iteration 13
ml-512-node-049: Grad overflow on iteration 13
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 13
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 13
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 13
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 13
ml-512-node-036: Grad overflow on iteration 13
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 13
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 13
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 13
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 13
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 13
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 13
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: Grad overflow on iteration 13
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: Grad overflow on iteration 13
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: Grad overflow on iteration 13
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: Grad overflow on iteration 13
ml-512-node-038: Grad overflow on iteration 13
ml-512-node-058: Grad overflow on iteration 13
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 13
ml-512-node-024: Grad overflow on iteration 13
ml-512-node-010: Grad overflow on iteration 13
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 13
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 13
ml-512-node-016: Grad overflow on iteration 13
ml-512-node-028: Grad overflow on iteration 13
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: Grad overflow on iteration 13
ml-512-node-026: Grad overflow on iteration 13
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 13
ml-512-node-062: Grad overflow on iteration 13
ml-512-node-013: Grad overflow on iteration 13
ml-512-node-003: Grad overflow on iteration 13
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: Grad overflow on iteration 13
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 13
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 13
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 13
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 13
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 13
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 13
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: Grad overflow on iteration 13
ml-512-node-049: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 13
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 13
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 13
ml-512-node-063: Grad overflow on iteration 13
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 13
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 13
ml-512-node-002: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 13
ml-512-node-063: Grad overflow on iteration 13
ml-512-node-002: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: Grad overflow on iteration 13
ml-512-node-011: Grad overflow on iteration 13
ml-512-node-002: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 13
ml-512-node-022: Grad overflow on iteration 13
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 13
ml-512-node-061: Grad overflow on iteration 13
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: Grad overflow on iteration 13
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 13
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: Grad overflow on iteration 13
ml-512-node-041: Grad overflow on iteration 13
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 13
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 13
ml-512-node-001: Grad overflow on iteration 13
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: Grad overflow on iteration 13
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 13
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: Grad overflow on iteration 13
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: Grad overflow on iteration 13
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 13
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: Grad overflow on iteration 13
ml-512-node-050: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: Grad overflow on iteration 13
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 13
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 13
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: Grad overflow on iteration 13
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 13
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 13
ml-512-node-023: Grad overflow on iteration 13
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: Grad overflow on iteration 13
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: Grad overflow on iteration 13
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: Grad overflow on iteration 13
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: Grad overflow on iteration 13
ml-512-node-034: Grad overflow on iteration 13
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: Grad overflow on iteration 13
ml-512-node-021: Grad overflow on iteration 13
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 13
ml-512-node-042: Grad overflow on iteration 13
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 13
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 13
ml-512-node-001: Grad overflow on iteration 13
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: Grad overflow on iteration 13
ml-512-node-039: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 13
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: Grad overflow on iteration 13
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 13
ml-512-node-050: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: Grad overflow on iteration 13
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 13
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 13
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 13
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 13
ml-512-node-006: Grad overflow on iteration 13
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 13
ml-512-node-060: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: Grad overflow on iteration 13
ml-512-node-019: Grad overflow on iteration 13
ml-512-node-051: Grad overflow on iteration 13
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 13
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 13
ml-512-node-023: Grad overflow on iteration 13
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: Grad overflow on iteration 13
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 13
ml-512-node-015: Grad overflow on iteration 13
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: Grad overflow on iteration 13
ml-512-node-052: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 13
ml-512-node-042: Grad overflow on iteration 13
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: Grad overflow on iteration 13
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 13
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 13
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 13
ml-512-node-030: Grad overflow on iteration 13
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: Grad overflow on iteration 13
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 13
ml-512-node-046: Grad overflow on iteration 13
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: Grad overflow on iteration 13
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 13
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 13
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: Grad overflow on iteration 13
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: Grad overflow on iteration 13
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: Grad overflow on iteration 13
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 13
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 13
ml-512-node-021: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 13
ml-512-node-057: Grad overflow on iteration 13
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: Grad overflow on iteration 13
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: Grad overflow on iteration 13
ml-512-node-038: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: Grad overflow on iteration 13
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-008: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 13
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: Grad overflow on iteration 13
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-030: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: Grad overflow on iteration 13
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: Grad overflow on iteration 13
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 13
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: Grad overflow on iteration 13
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: Grad overflow on iteration 13
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 13
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 13
ml-512-node-019: Grad overflow on iteration 13
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 13
ml-512-node-036: Grad overflow on iteration 13
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: Grad overflow on iteration 13
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 13
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 13
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 13
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 13
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: Grad overflow on iteration 13
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 13
ml-512-node-042: Grad overflow on iteration 13
ml-512-node-058: Grad overflow on iteration 13
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 06:07:06,146] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8.0, reducing to 4.0
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 13
ml-512-node-047: Grad overflow on iteration 13
ml-512-node-001: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: Grad overflow on iteration 13
ml-512-node-039: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: Grad overflow on iteration 13
ml-512-node-003: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 13
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: Grad overflow on iteration 13
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 13
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: Grad overflow on iteration 13
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 13
ml-512-node-005: Grad overflow on iteration 13
ml-512-node-017: Grad overflow on iteration 13
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 13
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: Grad overflow on iteration 13
ml-512-node-029: Grad overflow on iteration 13
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: Grad overflow on iteration 13
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 13
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: Grad overflow on iteration 13
ml-512-node-027: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: Grad overflow on iteration 13
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 13
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: Grad overflow on iteration 13
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: Grad overflow on iteration 13
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: Grad overflow on iteration 13
ml-512-node-033: Grad overflow on iteration 13
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: Grad overflow on iteration 13
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 13
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: Grad overflow on iteration 13
ml-512-node-002: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: Grad overflow on iteration 13
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 13
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: Grad overflow on iteration 13
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: Grad overflow on iteration 13
ml-512-node-011: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: Grad overflow on iteration 13
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: Grad overflow on iteration 13
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 13
ml-512-node-005: Grad overflow on iteration 13
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: Grad overflow on iteration 13
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 13
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 13
ml-512-node-042: Grad overflow on iteration 13
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: Grad overflow on iteration 13
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: Grad overflow on iteration 13
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-008: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-057: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: Beginning of Epoch 15/100, Total Micro Batches 1
ml-512-node-015: Grad overflow on iteration 13
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: Grad overflow on iteration 13
ml-512-node-013: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: Grad overflow on iteration 13
ml-512-node-002: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 13
ml-512-node-002: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 13
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 13
ml-512-node-050: Grad overflow on iteration 13
ml-512-node-050: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 13
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 13
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 13
ml-512-node-029: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 13
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: Grad overflow on iteration 13
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: Grad overflow on iteration 13
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 13
ml-512-node-048: Grad overflow on iteration 13
ml-512-node-052: Grad overflow on iteration 13
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: Grad overflow on iteration 13
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 06:07:06,144] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 13
ml-512-node-002: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 13
ml-512-node-050: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 13
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-017: [2024-07-08 06:07:06,143] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 13
ml-512-node-034: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 13
ml-512-node-029: Grad overflow on iteration 13
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 13
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 13
ml-512-node-048: Grad overflow on iteration 13
ml-512-node-048: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 13
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 13
ml-512-node-048: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 13
ml-512-node-052: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: Grad overflow on iteration 13
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: Grad overflow on iteration 13
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 13
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 13
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 13
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 13
ml-512-node-039: Grad overflow on iteration 13
ml-512-node-020: Grad overflow on iteration 13
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 13
ml-512-node-059: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-023: Grad overflow on iteration 13
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: Grad overflow on iteration 13
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: Grad overflow on iteration 13
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: Grad overflow on iteration 13
ml-512-node-035: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 06:07:06,146] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: Grad overflow on iteration 13
ml-512-node-005: Grad overflow on iteration 13
ml-512-node-047: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: Grad overflow on iteration 13
ml-512-node-056: Grad overflow on iteration 13
ml-512-node-024: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: Grad overflow on iteration 13
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 13
ml-512-node-061: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: Grad overflow on iteration 13
ml-512-node-054: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: Grad overflow on iteration 13
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: Grad overflow on iteration 13
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 13
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 13
ml-512-node-040: Grad overflow on iteration 13
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: Grad overflow on iteration 13
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: Grad overflow on iteration 13
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 13
ml-512-node-010: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 13
ml-512-node-033: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 13
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: Grad overflow on iteration 13
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: Grad overflow on iteration 13
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 06:07:06,141] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 06:07:06,145] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: Beginning of Epoch 16/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 17/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 18/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 19/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 20/100, Total Micro Batches 1
ml-512-node-001: [2024-07-08 06:07:07,429] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=14, lr=[6e-11, 6e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 06:07:07,433] [INFO] [timer.py:258:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=63558.91209213194, CurrSamplesPerSec=58823.551458444854, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-001: Beginning of Epoch 21/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 22/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 23/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 24/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 25/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 26/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 27/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 28/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 29/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 30/100, Total Micro Batches 1
ml-512-node-001: [2024-07-08 06:07:09,512] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=14, lr=[9.890738003669029e-11, 9.890738003669029e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 06:07:09,516] [INFO] [timer.py:258:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=62010.29368125456, CurrSamplesPerSec=59490.30886024519, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-001: Beginning of Epoch 31/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 32/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 33/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 34/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 35/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 36/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 37/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 38/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 39/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 40/100, Total Micro Batches 1
ml-512-node-001: [2024-07-08 06:07:11,604] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=14, lr=[9.24024048078213e-11, 9.24024048078213e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 06:07:11,608] [INFO] [timer.py:258:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=61219.41911114948, CurrSamplesPerSec=58210.140378538206, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-001: Beginning of Epoch 41/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 42/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 43/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 44/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 45/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 46/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 47/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 48/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 49/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 50/100, Total Micro Batches 1
ml-512-node-001: [2024-07-08 06:07:13,684] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=14, lr=[8.078307376628292e-11, 8.078307376628292e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 06:07:13,687] [INFO] [timer.py:258:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=60851.74352489075, CurrSamplesPerSec=59292.9970134693, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-001: Beginning of Epoch 51/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 52/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 53/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 54/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 55/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 56/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 57/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 58/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 59/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 60/100, Total Micro Batches 1
ml-512-node-001: [2024-07-08 06:07:15,772] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=14, lr=[6.545084971874738e-11, 6.545084971874738e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 06:07:15,776] [INFO] [timer.py:258:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=60567.59501234421, CurrSamplesPerSec=58977.69787488714, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-001: Beginning of Epoch 61/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 62/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 63/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 64/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 65/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 66/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 67/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 68/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 69/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 70/100, Total Micro Batches 1
ml-512-node-001: [2024-07-08 06:07:17,845] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=14, lr=[4.8255025164874965e-11, 4.8255025164874965e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 06:07:17,850] [INFO] [timer.py:258:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=60429.70909861555, CurrSamplesPerSec=59528.581273186755, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-001: Beginning of Epoch 71/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 72/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 73/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 74/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 75/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 76/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 77/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 78/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 79/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 80/100, Total Micro Batches 1
ml-512-node-001: [2024-07-08 06:07:19,925] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=14, lr=[3.12696703292044e-11, 3.12696703292044e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 06:07:19,929] [INFO] [timer.py:258:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=60305.80195753981, CurrSamplesPerSec=59484.335386177925, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-001: Beginning of Epoch 81/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 82/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 83/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 84/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 85/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 86/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 87/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 88/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 89/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 90/100, Total Micro Batches 1
ml-512-node-001: [2024-07-08 06:07:21,998] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=14, lr=[1.6543469682057107e-11, 1.6543469682057107e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 06:07:22,002] [INFO] [timer.py:258:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=60233.62013565311, CurrSamplesPerSec=59794.26573033904, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-001: Beginning of Epoch 91/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 92/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 93/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 94/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 95/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 96/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 97/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 98/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 99/100, Total Micro Batches 1
ml-512-node-001: Beginning of Epoch 100/100, Total Micro Batches 1
ml-512-node-001: [2024-07-08 06:07:24,074] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=14, lr=[5.852620357053651e-12, 5.852620357053651e-12], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 06:07:24,078] [INFO] [timer.py:258:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=60166.38330978022, CurrSamplesPerSec=59607.617842173924, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-001: ======================================================================
ml-512-node-001: Execution time: 18.6705 seconds for 90 steps
ml-512-node-001: Throughput: 59233.4026 samples/sec
ml-512-node-042: [2024-07-08 06:07:27,490] [INFO] [launch.py:351:main] Process 1060932 exits successfully.
ml-512-node-055: [2024-07-08 06:07:27,493] [INFO] [launch.py:351:main] Process 1080554 exits successfully.
ml-512-node-036: [2024-07-08 06:07:27,500] [INFO] [launch.py:351:main] Process 1061831 exits successfully.
ml-512-node-036: [2024-07-08 06:07:27,500] [INFO] [launch.py:351:main] Process 1061837 exits successfully.
ml-512-node-037: [2024-07-08 06:07:27,506] [INFO] [launch.py:351:main] Process 1065881 exits successfully.
ml-512-node-034: [2024-07-08 06:07:27,514] [INFO] [launch.py:351:main] Process 1062496 exits successfully.
ml-512-node-051: [2024-07-08 06:07:27,527] [INFO] [launch.py:351:main] Process 1062704 exits successfully.
ml-512-node-035: [2024-07-08 06:07:27,538] [INFO] [launch.py:351:main] Process 1069331 exits successfully.
ml-512-node-035: [2024-07-08 06:07:27,538] [INFO] [launch.py:351:main] Process 1069328 exits successfully.
ml-512-node-044: [2024-07-08 06:07:27,553] [INFO] [launch.py:351:main] Process 1059263 exits successfully.
ml-512-node-062: [2024-07-08 06:07:27,574] [INFO] [launch.py:351:main] Process 1055279 exits successfully.
ml-512-node-052: [2024-07-08 06:07:27,584] [INFO] [launch.py:351:main] Process 1058137 exits successfully.
ml-512-node-007: [2024-07-08 06:07:27,594] [INFO] [launch.py:351:main] Process 1076135 exits successfully.
ml-512-node-050: [2024-07-08 06:07:27,599] [INFO] [launch.py:351:main] Process 1058652 exits successfully.
ml-512-node-010: [2024-07-08 06:07:27,632] [INFO] [launch.py:351:main] Process 1067581 exits successfully.
ml-512-node-039: [2024-07-08 06:07:27,639] [INFO] [launch.py:351:main] Process 1148680 exits successfully.
ml-512-node-039: [2024-07-08 06:07:27,639] [INFO] [launch.py:351:main] Process 1148674 exits successfully.
ml-512-node-058: [2024-07-08 06:07:27,644] [INFO] [launch.py:351:main] Process 1055277 exits successfully.
ml-512-node-058: [2024-07-08 06:07:27,644] [INFO] [launch.py:351:main] Process 1055276 exits successfully.
ml-512-node-018: [2024-07-08 06:07:27,650] [INFO] [launch.py:351:main] Process 1066672 exits successfully.
ml-512-node-049: [2024-07-08 06:07:27,658] [INFO] [launch.py:351:main] Process 1066215 exits successfully.
ml-512-node-006: [2024-07-08 06:07:27,658] [INFO] [launch.py:351:main] Process 1070995 exits successfully.
ml-512-node-023: [2024-07-08 06:07:27,661] [INFO] [launch.py:351:main] Process 1069919 exits successfully.
ml-512-node-026: [2024-07-08 06:07:27,665] [INFO] [launch.py:351:main] Process 1064749 exits successfully.
ml-512-node-022: [2024-07-08 06:07:27,669] [INFO] [launch.py:351:main] Process 1065743 exits successfully.
ml-512-node-038: [2024-07-08 06:07:27,672] [INFO] [launch.py:351:main] Process 1061376 exits successfully.
ml-512-node-009: [2024-07-08 06:07:27,671] [INFO] [launch.py:351:main] Process 1072942 exits successfully.
ml-512-node-012: [2024-07-08 06:07:27,673] [INFO] [launch.py:351:main] Process 1067898 exits successfully.
ml-512-node-016: [2024-07-08 06:07:27,673] [INFO] [launch.py:351:main] Process 1066676 exits successfully.
ml-512-node-004: [2024-07-08 06:07:27,676] [INFO] [launch.py:351:main] Process 1071434 exits successfully.
ml-512-node-029: [2024-07-08 06:07:27,677] [INFO] [launch.py:351:main] Process 1069232 exits successfully.
ml-512-node-029: [2024-07-08 06:07:27,677] [INFO] [launch.py:351:main] Process 1069230 exits successfully.
ml-512-node-029: [2024-07-08 06:07:27,678] [INFO] [launch.py:351:main] Process 1069227 exits successfully.
ml-512-node-020: [2024-07-08 06:07:27,675] [INFO] [launch.py:351:main] Process 1065700 exits successfully.
ml-512-node-064: [2024-07-08 06:07:27,682] [INFO] [launch.py:351:main] Process 1053725 exits successfully.
ml-512-node-046: [2024-07-08 06:07:27,683] [INFO] [launch.py:351:main] Process 1060865 exits successfully.
ml-512-node-046: [2024-07-08 06:07:27,683] [INFO] [launch.py:351:main] Process 1060871 exits successfully.
ml-512-node-002: [2024-07-08 06:07:27,685] [INFO] [launch.py:351:main] Process 1083143 exits successfully.
ml-512-node-002: [2024-07-08 06:07:27,686] [INFO] [launch.py:351:main] Process 1083144 exits successfully.
ml-512-node-032: [2024-07-08 06:07:27,692] [INFO] [launch.py:351:main] Process 1060602 exits successfully.
ml-512-node-005: [2024-07-08 06:07:27,705] [INFO] [launch.py:351:main] Process 1089308 exits successfully.
ml-512-node-028: [2024-07-08 06:07:27,707] [INFO] [launch.py:351:main] Process 1064967 exits successfully.
ml-512-node-028: [2024-07-08 06:07:27,707] [INFO] [launch.py:351:main] Process 1064966 exits successfully.
ml-512-node-024: [2024-07-08 06:07:27,720] [INFO] [launch.py:351:main] Process 1066069 exits successfully.
ml-512-node-024: [2024-07-08 06:07:27,721] [INFO] [launch.py:351:main] Process 1066070 exits successfully.
ml-512-node-024: [2024-07-08 06:07:27,721] [INFO] [launch.py:351:main] Process 1066063 exits successfully.
ml-512-node-013: [2024-07-08 06:07:27,747] [INFO] [launch.py:351:main] Process 1072364 exits successfully.
ml-512-node-013: [2024-07-08 06:07:27,747] [INFO] [launch.py:351:main] Process 1072366 exits successfully.
ml-512-node-013: [2024-07-08 06:07:27,747] [INFO] [launch.py:351:main] Process 1072369 exits successfully.
ml-512-node-003: [2024-07-08 06:07:27,751] [INFO] [launch.py:351:main] Process 1075243 exits successfully.
ml-512-node-030: [2024-07-08 06:07:27,754] [INFO] [launch.py:351:main] Process 1070036 exits successfully.
ml-512-node-030: [2024-07-08 06:07:27,754] [INFO] [launch.py:351:main] Process 1070033 exits successfully.
ml-512-node-014: [2024-07-08 06:07:27,766] [INFO] [launch.py:351:main] Process 1065803 exits successfully.
ml-512-node-014: [2024-07-08 06:07:27,766] [INFO] [launch.py:351:main] Process 1065804 exits successfully.
ml-512-node-031: [2024-07-08 06:07:27,770] [INFO] [launch.py:351:main] Process 1067931 exits successfully.
ml-512-node-015: [2024-07-08 06:07:27,862] [INFO] [launch.py:351:main] Process 1071247 exits successfully.
ml-512-node-015: [2024-07-08 06:07:27,862] [INFO] [launch.py:351:main] Process 1071243 exits successfully.
ml-512-node-040: [2024-07-08 06:07:28,108] [INFO] [launch.py:351:main] Process 1116540 exits successfully.
ml-512-node-040: [2024-07-08 06:07:28,108] [INFO] [launch.py:351:main] Process 1116546 exits successfully.
ml-512-node-056: [2024-07-08 06:07:28,126] [INFO] [launch.py:351:main] Process 1072773 exits successfully.
ml-512-node-056: [2024-07-08 06:07:28,126] [INFO] [launch.py:351:main] Process 1072771 exits successfully.
ml-512-node-056: [2024-07-08 06:07:28,126] [INFO] [launch.py:351:main] Process 1072777 exits successfully.
ml-512-node-056: [2024-07-08 06:07:28,126] [INFO] [launch.py:351:main] Process 1072776 exits successfully.
ml-512-node-056: [2024-07-08 06:07:28,126] [INFO] [launch.py:351:main] Process 1072774 exits successfully.
ml-512-node-056: [2024-07-08 06:07:28,127] [INFO] [launch.py:351:main] Process 1072772 exits successfully.
ml-512-node-056: [2024-07-08 06:07:28,127] [INFO] [launch.py:351:main] Process 1072778 exits successfully.
ml-512-node-041: [2024-07-08 06:07:28,482] [INFO] [launch.py:351:main] Process 1067399 exits successfully.
ml-512-node-041: [2024-07-08 06:07:28,483] [INFO] [launch.py:351:main] Process 1067398 exits successfully.
ml-512-node-041: [2024-07-08 06:07:28,483] [INFO] [launch.py:351:main] Process 1067396 exits successfully.
ml-512-node-041: [2024-07-08 06:07:28,483] [INFO] [launch.py:351:main] Process 1067394 exits successfully.
ml-512-node-041: [2024-07-08 06:07:28,483] [INFO] [launch.py:351:main] Process 1067400 exits successfully.
ml-512-node-041: [2024-07-08 06:07:28,483] [INFO] [launch.py:351:main] Process 1067395 exits successfully.
ml-512-node-041: [2024-07-08 06:07:28,483] [INFO] [launch.py:351:main] Process 1067393 exits successfully.
ml-512-node-041: [2024-07-08 06:07:28,483] [INFO] [launch.py:351:main] Process 1067397 exits successfully.
ml-512-node-042: [2024-07-08 06:07:28,491] [INFO] [launch.py:351:main] Process 1060928 exits successfully.
ml-512-node-042: [2024-07-08 06:07:28,491] [INFO] [launch.py:351:main] Process 1060926 exits successfully.
ml-512-node-042: [2024-07-08 06:07:28,491] [INFO] [launch.py:351:main] Process 1060930 exits successfully.
ml-512-node-042: [2024-07-08 06:07:28,491] [INFO] [launch.py:351:main] Process 1060931 exits successfully.
ml-512-node-042: [2024-07-08 06:07:28,492] [INFO] [launch.py:351:main] Process 1060929 exits successfully.
ml-512-node-042: [2024-07-08 06:07:28,492] [INFO] [launch.py:351:main] Process 1060927 exits successfully.
ml-512-node-042: [2024-07-08 06:07:28,492] [INFO] [launch.py:351:main] Process 1060933 exits successfully.
ml-512-node-055: [2024-07-08 06:07:28,495] [INFO] [launch.py:351:main] Process 1080549 exits successfully.
ml-512-node-055: [2024-07-08 06:07:28,495] [INFO] [launch.py:351:main] Process 1080547 exits successfully.
ml-512-node-055: [2024-07-08 06:07:28,495] [INFO] [launch.py:351:main] Process 1080551 exits successfully.
ml-512-node-055: [2024-07-08 06:07:28,495] [INFO] [launch.py:351:main] Process 1080553 exits successfully.
ml-512-node-055: [2024-07-08 06:07:28,495] [INFO] [launch.py:351:main] Process 1080552 exits successfully.
ml-512-node-055: [2024-07-08 06:07:28,495] [INFO] [launch.py:351:main] Process 1080550 exits successfully.
ml-512-node-055: [2024-07-08 06:07:28,495] [INFO] [launch.py:351:main] Process 1080548 exits successfully.
ml-512-node-036: [2024-07-08 06:07:28,501] [INFO] [launch.py:351:main] Process 1061835 exits successfully.
ml-512-node-036: [2024-07-08 06:07:28,502] [INFO] [launch.py:351:main] Process 1061833 exits successfully.
ml-512-node-036: [2024-07-08 06:07:28,502] [INFO] [launch.py:351:main] Process 1061832 exits successfully.
ml-512-node-036: [2024-07-08 06:07:28,502] [INFO] [launch.py:351:main] Process 1061830 exits successfully.
ml-512-node-036: [2024-07-08 06:07:28,502] [INFO] [launch.py:351:main] Process 1061834 exits successfully.
ml-512-node-036: [2024-07-08 06:07:28,502] [INFO] [launch.py:351:main] Process 1061836 exits successfully.
ml-512-node-037: [2024-07-08 06:07:28,508] [INFO] [launch.py:351:main] Process 1065883 exits successfully.
ml-512-node-037: [2024-07-08 06:07:28,508] [INFO] [launch.py:351:main] Process 1065885 exits successfully.
ml-512-node-037: [2024-07-08 06:07:28,508] [INFO] [launch.py:351:main] Process 1065887 exits successfully.
ml-512-node-037: [2024-07-08 06:07:28,508] [INFO] [launch.py:351:main] Process 1065886 exits successfully.
ml-512-node-037: [2024-07-08 06:07:28,508] [INFO] [launch.py:351:main] Process 1065884 exits successfully.
ml-512-node-037: [2024-07-08 06:07:28,508] [INFO] [launch.py:351:main] Process 1065882 exits successfully.
ml-512-node-037: [2024-07-08 06:07:28,508] [INFO] [launch.py:351:main] Process 1065888 exits successfully.
ml-512-node-034: [2024-07-08 06:07:28,516] [INFO] [launch.py:351:main] Process 1062491 exits successfully.
ml-512-node-034: [2024-07-08 06:07:28,516] [INFO] [launch.py:351:main] Process 1062489 exits successfully.
ml-512-node-034: [2024-07-08 06:07:28,516] [INFO] [launch.py:351:main] Process 1062493 exits successfully.
ml-512-node-034: [2024-07-08 06:07:28,516] [INFO] [launch.py:351:main] Process 1062495 exits successfully.
ml-512-node-034: [2024-07-08 06:07:28,516] [INFO] [launch.py:351:main] Process 1062494 exits successfully.
ml-512-node-034: [2024-07-08 06:07:28,516] [INFO] [launch.py:351:main] Process 1062492 exits successfully.
ml-512-node-034: [2024-07-08 06:07:28,516] [INFO] [launch.py:351:main] Process 1062490 exits successfully.
ml-512-node-051: [2024-07-08 06:07:28,528] [INFO] [launch.py:351:main] Process 1062703 exits successfully.
ml-512-node-051: [2024-07-08 06:07:28,528] [INFO] [launch.py:351:main] Process 1062701 exits successfully.
ml-512-node-051: [2024-07-08 06:07:28,528] [INFO] [launch.py:351:main] Process 1062699 exits successfully.
ml-512-node-051: [2024-07-08 06:07:28,528] [INFO] [launch.py:351:main] Process 1062705 exits successfully.
ml-512-node-051: [2024-07-08 06:07:28,528] [INFO] [launch.py:351:main] Process 1062700 exits successfully.
ml-512-node-051: [2024-07-08 06:07:28,529] [INFO] [launch.py:351:main] Process 1062698 exits successfully.
ml-512-node-051: [2024-07-08 06:07:28,529] [INFO] [launch.py:351:main] Process 1062702 exits successfully.
ml-512-node-047: [2024-07-08 06:07:28,531] [INFO] [launch.py:351:main] Process 1062892 exits successfully.
ml-512-node-047: [2024-07-08 06:07:28,532] [INFO] [launch.py:351:main] Process 1062894 exits successfully.
ml-512-node-047: [2024-07-08 06:07:28,532] [INFO] [launch.py:351:main] Process 1062893 exits successfully.
ml-512-node-047: [2024-07-08 06:07:28,532] [INFO] [launch.py:351:main] Process 1062891 exits successfully.
ml-512-node-047: [2024-07-08 06:07:28,532] [INFO] [launch.py:351:main] Process 1062889 exits successfully.
ml-512-node-047: [2024-07-08 06:07:28,532] [INFO] [launch.py:351:main] Process 1062895 exits successfully.
ml-512-node-047: [2024-07-08 06:07:28,532] [INFO] [launch.py:351:main] Process 1062890 exits successfully.
ml-512-node-047: [2024-07-08 06:07:28,532] [INFO] [launch.py:351:main] Process 1062888 exits successfully.
ml-512-node-057: [2024-07-08 06:07:28,532] [INFO] [launch.py:351:main] Process 1062198 exits successfully.
ml-512-node-057: [2024-07-08 06:07:28,533] [INFO] [launch.py:351:main] Process 1062196 exits successfully.
ml-512-node-057: [2024-07-08 06:07:28,533] [INFO] [launch.py:351:main] Process 1062200 exits successfully.
ml-512-node-057: [2024-07-08 06:07:28,533] [INFO] [launch.py:351:main] Process 1062202 exits successfully.
ml-512-node-057: [2024-07-08 06:07:28,533] [INFO] [launch.py:351:main] Process 1062201 exits successfully.
ml-512-node-057: [2024-07-08 06:07:28,533] [INFO] [launch.py:351:main] Process 1062199 exits successfully.
ml-512-node-057: [2024-07-08 06:07:28,533] [INFO] [launch.py:351:main] Process 1062197 exits successfully.
ml-512-node-057: [2024-07-08 06:07:28,533] [INFO] [launch.py:351:main] Process 1062203 exits successfully.
ml-512-node-063: [2024-07-08 06:07:28,539] [INFO] [launch.py:351:main] Process 1059529 exits successfully.
ml-512-node-063: [2024-07-08 06:07:28,539] [INFO] [launch.py:351:main] Process 1059528 exits successfully.
ml-512-node-063: [2024-07-08 06:07:28,539] [INFO] [launch.py:351:main] Process 1059526 exits successfully.
ml-512-node-063: [2024-07-08 06:07:28,539] [INFO] [launch.py:351:main] Process 1059524 exits successfully.
ml-512-node-063: [2024-07-08 06:07:28,539] [INFO] [launch.py:351:main] Process 1059530 exits successfully.
ml-512-node-063: [2024-07-08 06:07:28,540] [INFO] [launch.py:351:main] Process 1059525 exits successfully.
ml-512-node-063: [2024-07-08 06:07:28,540] [INFO] [launch.py:351:main] Process 1059523 exits successfully.
ml-512-node-035: [2024-07-08 06:07:28,539] [INFO] [launch.py:351:main] Process 1069333 exits successfully.
ml-512-node-035: [2024-07-08 06:07:28,539] [INFO] [launch.py:351:main] Process 1069332 exits successfully.
ml-512-node-063: [2024-07-08 06:07:28,540] [INFO] [launch.py:351:main] Process 1059527 exits successfully.
ml-512-node-035: [2024-07-08 06:07:28,539] [INFO] [launch.py:351:main] Process 1069330 exits successfully.
ml-512-node-035: [2024-07-08 06:07:28,539] [INFO] [launch.py:351:main] Process 1069334 exits successfully.
ml-512-node-035: [2024-07-08 06:07:28,540] [INFO] [launch.py:351:main] Process 1069329 exits successfully.
ml-512-node-035: [2024-07-08 06:07:28,540] [INFO] [launch.py:351:main] Process 1069327 exits successfully.
ml-512-node-044: [2024-07-08 06:07:28,554] [INFO] [launch.py:351:main] Process 1059261 exits successfully.
ml-512-node-044: [2024-07-08 06:07:28,555] [INFO] [launch.py:351:main] Process 1059259 exits successfully.
ml-512-node-044: [2024-07-08 06:07:28,555] [INFO] [launch.py:351:main] Process 1059257 exits successfully.
ml-512-node-044: [2024-07-08 06:07:28,555] [INFO] [launch.py:351:main] Process 1059258 exits successfully.
ml-512-node-044: [2024-07-08 06:07:28,555] [INFO] [launch.py:351:main] Process 1059256 exits successfully.
ml-512-node-044: [2024-07-08 06:07:28,555] [INFO] [launch.py:351:main] Process 1059260 exits successfully.
ml-512-node-044: [2024-07-08 06:07:28,555] [INFO] [launch.py:351:main] Process 1059262 exits successfully.
ml-512-node-062: [2024-07-08 06:07:28,576] [INFO] [launch.py:351:main] Process 1055274 exits successfully.
ml-512-node-062: [2024-07-08 06:07:28,576] [INFO] [launch.py:351:main] Process 1055272 exits successfully.
ml-512-node-062: [2024-07-08 06:07:28,576] [INFO] [launch.py:351:main] Process 1055276 exits successfully.
ml-512-node-062: [2024-07-08 06:07:28,576] [INFO] [launch.py:351:main] Process 1055278 exits successfully.
ml-512-node-062: [2024-07-08 06:07:28,576] [INFO] [launch.py:351:main] Process 1055277 exits successfully.
ml-512-node-062: [2024-07-08 06:07:28,576] [INFO] [launch.py:351:main] Process 1055275 exits successfully.
ml-512-node-062: [2024-07-08 06:07:28,576] [INFO] [launch.py:351:main] Process 1055273 exits successfully.
ml-512-node-033: [2024-07-08 06:07:28,574] [INFO] [launch.py:351:main] Process 1072283 exits successfully.
ml-512-node-033: [2024-07-08 06:07:28,575] [INFO] [launch.py:351:main] Process 1072281 exits successfully.
ml-512-node-033: [2024-07-08 06:07:28,575] [INFO] [launch.py:351:main] Process 1072285 exits successfully.
ml-512-node-033: [2024-07-08 06:07:28,575] [INFO] [launch.py:351:main] Process 1072287 exits successfully.
ml-512-node-033: [2024-07-08 06:07:28,575] [INFO] [launch.py:351:main] Process 1072286 exits successfully.
ml-512-node-033: [2024-07-08 06:07:28,575] [INFO] [launch.py:351:main] Process 1072284 exits successfully.
ml-512-node-033: [2024-07-08 06:07:28,575] [INFO] [launch.py:351:main] Process 1072282 exits successfully.
ml-512-node-033: [2024-07-08 06:07:28,575] [INFO] [launch.py:351:main] Process 1072288 exits successfully.
ml-512-node-045: [2024-07-08 06:07:28,583] [INFO] [launch.py:351:main] Process 1064738 exits successfully.
ml-512-node-045: [2024-07-08 06:07:28,583] [INFO] [launch.py:351:main] Process 1064737 exits successfully.
ml-512-node-045: [2024-07-08 06:07:28,583] [INFO] [launch.py:351:main] Process 1064735 exits successfully.
ml-512-node-045: [2024-07-08 06:07:28,583] [INFO] [launch.py:351:main] Process 1064733 exits successfully.
ml-512-node-045: [2024-07-08 06:07:28,583] [INFO] [launch.py:351:main] Process 1064739 exits successfully.
ml-512-node-045: [2024-07-08 06:07:28,584] [INFO] [launch.py:351:main] Process 1064734 exits successfully.
ml-512-node-045: [2024-07-08 06:07:28,584] [INFO] [launch.py:351:main] Process 1064732 exits successfully.
ml-512-node-045: [2024-07-08 06:07:28,584] [INFO] [launch.py:351:main] Process 1064736 exits successfully.
ml-512-node-052: [2024-07-08 06:07:28,586] [INFO] [launch.py:351:main] Process 1058141 exits successfully.
ml-512-node-052: [2024-07-08 06:07:28,586] [INFO] [launch.py:351:main] Process 1058143 exits successfully.
ml-512-node-052: [2024-07-08 06:07:28,586] [INFO] [launch.py:351:main] Process 1058142 exits successfully.
ml-512-node-052: [2024-07-08 06:07:28,586] [INFO] [launch.py:351:main] Process 1058140 exits successfully.
ml-512-node-052: [2024-07-08 06:07:28,586] [INFO] [launch.py:351:main] Process 1058138 exits successfully.
ml-512-node-052: [2024-07-08 06:07:28,586] [INFO] [launch.py:351:main] Process 1058144 exits successfully.
ml-512-node-052: [2024-07-08 06:07:28,586] [INFO] [launch.py:351:main] Process 1058139 exits successfully.
ml-512-node-054: [2024-07-08 06:07:28,594] [INFO] [launch.py:351:main] Process 1056116 exits successfully.
ml-512-node-054: [2024-07-08 06:07:28,594] [INFO] [launch.py:351:main] Process 1056114 exits successfully.
ml-512-node-054: [2024-07-08 06:07:28,594] [INFO] [launch.py:351:main] Process 1056118 exits successfully.
ml-512-node-054: [2024-07-08 06:07:28,595] [INFO] [launch.py:351:main] Process 1056120 exits successfully.
ml-512-node-054: [2024-07-08 06:07:28,595] [INFO] [launch.py:351:main] Process 1056119 exits successfully.
ml-512-node-054: [2024-07-08 06:07:28,595] [INFO] [launch.py:351:main] Process 1056117 exits successfully.
ml-512-node-054: [2024-07-08 06:07:28,595] [INFO] [launch.py:351:main] Process 1056115 exits successfully.
ml-512-node-054: [2024-07-08 06:07:28,595] [INFO] [launch.py:351:main] Process 1056121 exits successfully.
ml-512-node-007: [2024-07-08 06:07:28,596] [INFO] [launch.py:351:main] Process 1076137 exits successfully.
ml-512-node-007: [2024-07-08 06:07:28,596] [INFO] [launch.py:351:main] Process 1076136 exits successfully.
ml-512-node-007: [2024-07-08 06:07:28,596] [INFO] [launch.py:351:main] Process 1076134 exits successfully.
ml-512-node-007: [2024-07-08 06:07:28,596] [INFO] [launch.py:351:main] Process 1076132 exits successfully.
ml-512-node-007: [2024-07-08 06:07:28,596] [INFO] [launch.py:351:main] Process 1076138 exits successfully.
ml-512-node-007: [2024-07-08 06:07:28,596] [INFO] [launch.py:351:main] Process 1076133 exits successfully.
ml-512-node-007: [2024-07-08 06:07:28,596] [INFO] [launch.py:351:main] Process 1076131 exits successfully.
ml-512-node-050: [2024-07-08 06:07:28,600] [INFO] [launch.py:351:main] Process 1058655 exits successfully.
ml-512-node-050: [2024-07-08 06:07:28,600] [INFO] [launch.py:351:main] Process 1058654 exits successfully.
ml-512-node-050: [2024-07-08 06:07:28,600] [INFO] [launch.py:351:main] Process 1058650 exits successfully.
ml-512-node-050: [2024-07-08 06:07:28,600] [INFO] [launch.py:351:main] Process 1058656 exits successfully.
ml-512-node-050: [2024-07-08 06:07:28,600] [INFO] [launch.py:351:main] Process 1058651 exits successfully.
ml-512-node-050: [2024-07-08 06:07:28,601] [INFO] [launch.py:351:main] Process 1058649 exits successfully.
ml-512-node-050: [2024-07-08 06:07:28,601] [INFO] [launch.py:351:main] Process 1058653 exits successfully.
ml-512-node-059: [2024-07-08 06:07:28,604] [INFO] [launch.py:351:main] Process 1059651 exits successfully.
ml-512-node-059: [2024-07-08 06:07:28,604] [INFO] [launch.py:351:main] Process 1059649 exits successfully.
ml-512-node-059: [2024-07-08 06:07:28,604] [INFO] [launch.py:351:main] Process 1059653 exits successfully.
ml-512-node-059: [2024-07-08 06:07:28,604] [INFO] [launch.py:351:main] Process 1059655 exits successfully.
ml-512-node-059: [2024-07-08 06:07:28,604] [INFO] [launch.py:351:main] Process 1059654 exits successfully.
ml-512-node-059: [2024-07-08 06:07:28,604] [INFO] [launch.py:351:main] Process 1059652 exits successfully.
ml-512-node-059: [2024-07-08 06:07:28,604] [INFO] [launch.py:351:main] Process 1059650 exits successfully.
ml-512-node-059: [2024-07-08 06:07:28,604] [INFO] [launch.py:351:main] Process 1059656 exits successfully.
ml-512-node-053: [2024-07-08 06:07:28,616] [INFO] [launch.py:351:main] Process 1064476 exits successfully.
ml-512-node-053: [2024-07-08 06:07:28,616] [INFO] [launch.py:351:main] Process 1064474 exits successfully.
ml-512-node-053: [2024-07-08 06:07:28,616] [INFO] [launch.py:351:main] Process 1064478 exits successfully.
ml-512-node-053: [2024-07-08 06:07:28,616] [INFO] [launch.py:351:main] Process 1064480 exits successfully.
ml-512-node-053: [2024-07-08 06:07:28,616] [INFO] [launch.py:351:main] Process 1064479 exits successfully.
ml-512-node-053: [2024-07-08 06:07:28,616] [INFO] [launch.py:351:main] Process 1064477 exits successfully.
ml-512-node-053: [2024-07-08 06:07:28,617] [INFO] [launch.py:351:main] Process 1064475 exits successfully.
ml-512-node-053: [2024-07-08 06:07:28,617] [INFO] [launch.py:351:main] Process 1064481 exits successfully.
ml-512-node-061: [2024-07-08 06:07:28,632] [INFO] [launch.py:351:main] Process 1061764 exits successfully.
ml-512-node-061: [2024-07-08 06:07:28,632] [INFO] [launch.py:351:main] Process 1061762 exits successfully.
ml-512-node-061: [2024-07-08 06:07:28,632] [INFO] [launch.py:351:main] Process 1061766 exits successfully.
ml-512-node-061: [2024-07-08 06:07:28,632] [INFO] [launch.py:351:main] Process 1061768 exits successfully.
ml-512-node-061: [2024-07-08 06:07:28,632] [INFO] [launch.py:351:main] Process 1061767 exits successfully.
ml-512-node-061: [2024-07-08 06:07:28,632] [INFO] [launch.py:351:main] Process 1061765 exits successfully.
ml-512-node-061: [2024-07-08 06:07:28,632] [INFO] [launch.py:351:main] Process 1061763 exits successfully.
ml-512-node-061: [2024-07-08 06:07:28,633] [INFO] [launch.py:351:main] Process 1061769 exits successfully.
ml-512-node-010: [2024-07-08 06:07:28,633] [INFO] [launch.py:351:main] Process 1067583 exits successfully.
ml-512-node-010: [2024-07-08 06:07:28,633] [INFO] [launch.py:351:main] Process 1067585 exits successfully.
ml-512-node-010: [2024-07-08 06:07:28,633] [INFO] [launch.py:351:main] Process 1067584 exits successfully.
ml-512-node-010: [2024-07-08 06:07:28,633] [INFO] [launch.py:351:main] Process 1067582 exits successfully.
ml-512-node-010: [2024-07-08 06:07:28,633] [INFO] [launch.py:351:main] Process 1067580 exits successfully.
ml-512-node-010: [2024-07-08 06:07:28,634] [INFO] [launch.py:351:main] Process 1067586 exits successfully.
ml-512-node-010: [2024-07-08 06:07:28,634] [INFO] [launch.py:351:main] Process 1067579 exits successfully.
ml-512-node-008: [2024-07-08 06:07:28,638] [INFO] [launch.py:351:main] Process 1069905 exits successfully.
ml-512-node-008: [2024-07-08 06:07:28,638] [INFO] [launch.py:351:main] Process 1069907 exits successfully.
ml-512-node-008: [2024-07-08 06:07:28,638] [INFO] [launch.py:351:main] Process 1069906 exits successfully.
ml-512-node-008: [2024-07-08 06:07:28,638] [INFO] [launch.py:351:main] Process 1069904 exits successfully.
ml-512-node-008: [2024-07-08 06:07:28,638] [INFO] [launch.py:351:main] Process 1069902 exits successfully.
ml-512-node-008: [2024-07-08 06:07:28,639] [INFO] [launch.py:351:main] Process 1069908 exits successfully.
ml-512-node-008: [2024-07-08 06:07:28,639] [INFO] [launch.py:351:main] Process 1069903 exits successfully.
ml-512-node-008: [2024-07-08 06:07:28,639] [INFO] [launch.py:351:main] Process 1069901 exits successfully.
ml-512-node-039: [2024-07-08 06:07:28,641] [INFO] [launch.py:351:main] Process 1148678 exits successfully.
ml-512-node-039: [2024-07-08 06:07:28,641] [INFO] [launch.py:351:main] Process 1148679 exits successfully.
ml-512-node-039: [2024-07-08 06:07:28,641] [INFO] [launch.py:351:main] Process 1148677 exits successfully.
ml-512-node-039: [2024-07-08 06:07:28,641] [INFO] [launch.py:351:main] Process 1148675 exits successfully.
ml-512-node-039: [2024-07-08 06:07:28,641] [INFO] [launch.py:351:main] Process 1148681 exits successfully.
ml-512-node-039: [2024-07-08 06:07:28,641] [INFO] [launch.py:351:main] Process 1148676 exits successfully.
ml-512-node-058: [2024-07-08 06:07:28,645] [INFO] [launch.py:351:main] Process 1055278 exits successfully.
ml-512-node-058: [2024-07-08 06:07:28,645] [INFO] [launch.py:351:main] Process 1055275 exits successfully.
ml-512-node-058: [2024-07-08 06:07:28,645] [INFO] [launch.py:351:main] Process 1055273 exits successfully.
ml-512-node-058: [2024-07-08 06:07:28,645] [INFO] [launch.py:351:main] Process 1055279 exits successfully.
ml-512-node-058: [2024-07-08 06:07:28,645] [INFO] [launch.py:351:main] Process 1055274 exits successfully.
ml-512-node-058: [2024-07-08 06:07:28,645] [INFO] [launch.py:351:main] Process 1055272 exits successfully.
ml-512-node-018: [2024-07-08 06:07:28,651] [INFO] [launch.py:351:main] Process 1066673 exits successfully.
ml-512-node-018: [2024-07-08 06:07:28,651] [INFO] [launch.py:351:main] Process 1066671 exits successfully.
ml-512-node-018: [2024-07-08 06:07:28,651] [INFO] [launch.py:351:main] Process 1066675 exits successfully.
ml-512-node-018: [2024-07-08 06:07:28,651] [INFO] [launch.py:351:main] Process 1066677 exits successfully.
ml-512-node-018: [2024-07-08 06:07:28,651] [INFO] [launch.py:351:main] Process 1066676 exits successfully.
ml-512-node-018: [2024-07-08 06:07:28,651] [INFO] [launch.py:351:main] Process 1066674 exits successfully.
ml-512-node-018: [2024-07-08 06:07:28,652] [INFO] [launch.py:351:main] Process 1066678 exits successfully.
ml-512-node-043: [2024-07-08 06:07:28,656] [INFO] [launch.py:351:main] Process 1064754 exits successfully.
ml-512-node-043: [2024-07-08 06:07:28,656] [INFO] [launch.py:351:main] Process 1064761 exits successfully.
ml-512-node-049: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1066217 exits successfully.
ml-512-node-049: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1066219 exits successfully.
ml-512-node-049: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1066218 exits successfully.
ml-512-node-049: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1066216 exits successfully.
ml-512-node-049: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1066214 exits successfully.
ml-512-node-049: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1066220 exits successfully.
ml-512-node-049: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1066213 exits successfully.
ml-512-node-006: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1070991 exits successfully.
ml-512-node-006: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1070989 exits successfully.
ml-512-node-006: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1070993 exits successfully.
ml-512-node-006: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1070994 exits successfully.
ml-512-node-006: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1070992 exits successfully.
ml-512-node-006: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1070990 exits successfully.
ml-512-node-006: [2024-07-08 06:07:28,660] [INFO] [launch.py:351:main] Process 1070996 exits successfully.
ml-512-node-023: [2024-07-08 06:07:28,663] [INFO] [launch.py:351:main] Process 1069914 exits successfully.
ml-512-node-023: [2024-07-08 06:07:28,663] [INFO] [launch.py:351:main] Process 1069912 exits successfully.
ml-512-node-023: [2024-07-08 06:07:28,663] [INFO] [launch.py:351:main] Process 1069916 exits successfully.
ml-512-node-023: [2024-07-08 06:07:28,663] [INFO] [launch.py:351:main] Process 1069918 exits successfully.
ml-512-node-023: [2024-07-08 06:07:28,663] [INFO] [launch.py:351:main] Process 1069917 exits successfully.
ml-512-node-023: [2024-07-08 06:07:28,663] [INFO] [launch.py:351:main] Process 1069915 exits successfully.
ml-512-node-023: [2024-07-08 06:07:28,663] [INFO] [launch.py:351:main] Process 1069913 exits successfully.
ml-512-node-026: [2024-07-08 06:07:28,667] [INFO] [launch.py:351:main] Process 1064745 exits successfully.
ml-512-node-026: [2024-07-08 06:07:28,667] [INFO] [launch.py:351:main] Process 1064743 exits successfully.
ml-512-node-026: [2024-07-08 06:07:28,667] [INFO] [launch.py:351:main] Process 1064747 exits successfully.
ml-512-node-026: [2024-07-08 06:07:28,667] [INFO] [launch.py:351:main] Process 1064748 exits successfully.
ml-512-node-026: [2024-07-08 06:07:28,667] [INFO] [launch.py:351:main] Process 1064746 exits successfully.
ml-512-node-026: [2024-07-08 06:07:28,667] [INFO] [launch.py:351:main] Process 1064744 exits successfully.
ml-512-node-026: [2024-07-08 06:07:28,667] [INFO] [launch.py:351:main] Process 1064750 exits successfully.
ml-512-node-019: [2024-07-08 06:07:28,667] [INFO] [launch.py:351:main] Process 1071643 exits successfully.
ml-512-node-019: [2024-07-08 06:07:28,668] [INFO] [launch.py:351:main] Process 1071641 exits successfully.
ml-512-node-019: [2024-07-08 06:07:28,668] [INFO] [launch.py:351:main] Process 1071648 exits successfully.
ml-512-node-022: [2024-07-08 06:07:28,670] [INFO] [launch.py:351:main] Process 1065740 exits successfully.
ml-512-node-022: [2024-07-08 06:07:28,671] [INFO] [launch.py:351:main] Process 1065742 exits successfully.
ml-512-node-022: [2024-07-08 06:07:28,671] [INFO] [launch.py:351:main] Process 1065741 exits successfully.
ml-512-node-022: [2024-07-08 06:07:28,671] [INFO] [launch.py:351:main] Process 1065739 exits successfully.
ml-512-node-022: [2024-07-08 06:07:28,671] [INFO] [launch.py:351:main] Process 1065737 exits successfully.
ml-512-node-022: [2024-07-08 06:07:28,671] [INFO] [launch.py:351:main] Process 1065738 exits successfully.
ml-512-node-022: [2024-07-08 06:07:28,671] [INFO] [launch.py:351:main] Process 1065736 exits successfully.
ml-512-node-027: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1075132 exits successfully.
ml-512-node-027: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1075131 exits successfully.
ml-512-node-038: [2024-07-08 06:07:28,673] [INFO] [launch.py:351:main] Process 1061378 exits successfully.
ml-512-node-038: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1061374 exits successfully.
ml-512-node-038: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1061380 exits successfully.
ml-512-node-038: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1061375 exits successfully.
ml-512-node-038: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1061373 exits successfully.
ml-512-node-038: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1061377 exits successfully.
ml-512-node-038: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1061379 exits successfully.
ml-512-node-012: [2024-07-08 06:07:28,675] [INFO] [launch.py:351:main] Process 1067904 exits successfully.
ml-512-node-012: [2024-07-08 06:07:28,675] [INFO] [launch.py:351:main] Process 1067903 exits successfully.
ml-512-node-012: [2024-07-08 06:07:28,675] [INFO] [launch.py:351:main] Process 1067901 exits successfully.
ml-512-node-009: [2024-07-08 06:07:28,673] [INFO] [launch.py:351:main] Process 1072945 exits successfully.
ml-512-node-009: [2024-07-08 06:07:28,673] [INFO] [launch.py:351:main] Process 1072947 exits successfully.
ml-512-node-012: [2024-07-08 06:07:28,675] [INFO] [launch.py:351:main] Process 1067899 exits successfully.
ml-512-node-009: [2024-07-08 06:07:28,673] [INFO] [launch.py:351:main] Process 1072946 exits successfully.
ml-512-node-009: [2024-07-08 06:07:28,673] [INFO] [launch.py:351:main] Process 1072944 exits successfully.
ml-512-node-012: [2024-07-08 06:07:28,675] [INFO] [launch.py:351:main] Process 1067905 exits successfully.
ml-512-node-009: [2024-07-08 06:07:28,673] [INFO] [launch.py:351:main] Process 1072948 exits successfully.
ml-512-node-012: [2024-07-08 06:07:28,675] [INFO] [launch.py:351:main] Process 1067900 exits successfully.
ml-512-node-009: [2024-07-08 06:07:28,673] [INFO] [launch.py:351:main] Process 1072943 exits successfully.
ml-512-node-012: [2024-07-08 06:07:28,675] [INFO] [launch.py:351:main] Process 1067902 exits successfully.
ml-512-node-009: [2024-07-08 06:07:28,673] [INFO] [launch.py:351:main] Process 1072941 exits successfully.
ml-512-node-016: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1066674 exits successfully.
ml-512-node-016: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1066672 exits successfully.
ml-512-node-016: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1066670 exits successfully.
ml-512-node-016: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1066671 exits successfully.
ml-512-node-016: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1066669 exits successfully.
ml-512-node-016: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1066673 exits successfully.
ml-512-node-016: [2024-07-08 06:07:28,674] [INFO] [launch.py:351:main] Process 1066675 exits successfully.
ml-512-node-004: [2024-07-08 06:07:28,678] [INFO] [launch.py:351:main] Process 1071430 exits successfully.
ml-512-node-004: [2024-07-08 06:07:28,678] [INFO] [launch.py:351:main] Process 1071428 exits successfully.
ml-512-node-004: [2024-07-08 06:07:28,678] [INFO] [launch.py:351:main] Process 1071432 exits successfully.
ml-512-node-004: [2024-07-08 06:07:28,678] [INFO] [launch.py:351:main] Process 1071433 exits successfully.
ml-512-node-004: [2024-07-08 06:07:28,678] [INFO] [launch.py:351:main] Process 1071431 exits successfully.
ml-512-node-004: [2024-07-08 06:07:28,678] [INFO] [launch.py:351:main] Process 1071429 exits successfully.
ml-512-node-004: [2024-07-08 06:07:28,678] [INFO] [launch.py:351:main] Process 1071435 exits successfully.
ml-512-node-029: [2024-07-08 06:07:28,679] [INFO] [launch.py:351:main] Process 1069233 exits successfully.
ml-512-node-029: [2024-07-08 06:07:28,679] [INFO] [launch.py:351:main] Process 1069228 exits successfully.
ml-512-node-029: [2024-07-08 06:07:28,679] [INFO] [launch.py:351:main] Process 1069234 exits successfully.
ml-512-node-029: [2024-07-08 06:07:28,679] [INFO] [launch.py:351:main] Process 1069229 exits successfully.
ml-512-node-029: [2024-07-08 06:07:28,679] [INFO] [launch.py:351:main] Process 1069231 exits successfully.
ml-512-node-020: [2024-07-08 06:07:28,677] [INFO] [launch.py:351:main] Process 1065695 exits successfully.
ml-512-node-020: [2024-07-08 06:07:28,677] [INFO] [launch.py:351:main] Process 1065693 exits successfully.
ml-512-node-020: [2024-07-08 06:07:28,677] [INFO] [launch.py:351:main] Process 1065697 exits successfully.
ml-512-node-020: [2024-07-08 06:07:28,677] [INFO] [launch.py:351:main] Process 1065699 exits successfully.
ml-512-node-020: [2024-07-08 06:07:28,677] [INFO] [launch.py:351:main] Process 1065698 exits successfully.
ml-512-node-020: [2024-07-08 06:07:28,677] [INFO] [launch.py:351:main] Process 1065696 exits successfully.
ml-512-node-020: [2024-07-08 06:07:28,677] [INFO] [launch.py:351:main] Process 1065694 exits successfully.
ml-512-node-048: [2024-07-08 06:07:28,683] [INFO] [launch.py:351:main] Process 1059128 exits successfully.
ml-512-node-048: [2024-07-08 06:07:28,683] [INFO] [launch.py:351:main] Process 1059130 exits successfully.
ml-512-node-064: [2024-07-08 06:07:28,683] [INFO] [launch.py:351:main] Process 1053724 exits successfully.
ml-512-node-064: [2024-07-08 06:07:28,683] [INFO] [launch.py:351:main] Process 1053722 exits successfully.
ml-512-node-064: [2024-07-08 06:07:28,684] [INFO] [launch.py:351:main] Process 1053720 exits successfully.
ml-512-node-064: [2024-07-08 06:07:28,684] [INFO] [launch.py:351:main] Process 1053726 exits successfully.
ml-512-node-064: [2024-07-08 06:07:28,684] [INFO] [launch.py:351:main] Process 1053721 exits successfully.
ml-512-node-064: [2024-07-08 06:07:28,684] [INFO] [launch.py:351:main] Process 1053719 exits successfully.
ml-512-node-064: [2024-07-08 06:07:28,684] [INFO] [launch.py:351:main] Process 1053723 exits successfully.
ml-512-node-046: [2024-07-08 06:07:28,684] [INFO] [launch.py:351:main] Process 1060867 exits successfully.
ml-512-node-046: [2024-07-08 06:07:28,685] [INFO] [launch.py:351:main] Process 1060869 exits successfully.
ml-512-node-046: [2024-07-08 06:07:28,685] [INFO] [launch.py:351:main] Process 1060870 exits successfully.
ml-512-node-046: [2024-07-08 06:07:28,685] [INFO] [launch.py:351:main] Process 1060868 exits successfully.
ml-512-node-046: [2024-07-08 06:07:28,685] [INFO] [launch.py:351:main] Process 1060866 exits successfully.
ml-512-node-046: [2024-07-08 06:07:28,685] [INFO] [launch.py:351:main] Process 1060872 exits successfully.
ml-512-node-002: [2024-07-08 06:07:28,687] [INFO] [launch.py:351:main] Process 1083145 exits successfully.
ml-512-node-002: [2024-07-08 06:07:28,687] [INFO] [launch.py:351:main] Process 1083147 exits successfully.
ml-512-node-002: [2024-07-08 06:07:28,687] [INFO] [launch.py:351:main] Process 1083149 exits successfully.
ml-512-node-002: [2024-07-08 06:07:28,687] [INFO] [launch.py:351:main] Process 1083148 exits successfully.
ml-512-node-002: [2024-07-08 06:07:28,687] [INFO] [launch.py:351:main] Process 1083146 exits successfully.
ml-512-node-002: [2024-07-08 06:07:28,687] [INFO] [launch.py:351:main] Process 1083150 exits successfully.
ml-512-node-032: [2024-07-08 06:07:28,693] [INFO] [launch.py:351:main] Process 1060603 exits successfully.
ml-512-node-032: [2024-07-08 06:07:28,693] [INFO] [launch.py:351:main] Process 1060605 exits successfully.
ml-512-node-032: [2024-07-08 06:07:28,694] [INFO] [launch.py:351:main] Process 1060604 exits successfully.
ml-512-node-032: [2024-07-08 06:07:28,694] [INFO] [launch.py:351:main] Process 1060600 exits successfully.
ml-512-node-032: [2024-07-08 06:07:28,694] [INFO] [launch.py:351:main] Process 1060606 exits successfully.
ml-512-node-032: [2024-07-08 06:07:28,694] [INFO] [launch.py:351:main] Process 1060601 exits successfully.
ml-512-node-032: [2024-07-08 06:07:28,694] [INFO] [launch.py:351:main] Process 1060599 exits successfully.
ml-512-node-025: [2024-07-08 06:07:28,702] [INFO] [launch.py:351:main] Process 1071756 exits successfully.
ml-512-node-025: [2024-07-08 06:07:28,702] [INFO] [launch.py:351:main] Process 1071758 exits successfully.
ml-512-node-025: [2024-07-08 06:07:28,702] [INFO] [launch.py:351:main] Process 1071757 exits successfully.
ml-512-node-025: [2024-07-08 06:07:28,702] [INFO] [launch.py:351:main] Process 1071755 exits successfully.
ml-512-node-025: [2024-07-08 06:07:28,702] [INFO] [launch.py:351:main] Process 1071753 exits successfully.
ml-512-node-025: [2024-07-08 06:07:28,703] [INFO] [launch.py:351:main] Process 1071759 exits successfully.
ml-512-node-025: [2024-07-08 06:07:28,703] [INFO] [launch.py:351:main] Process 1071754 exits successfully.
ml-512-node-025: [2024-07-08 06:07:28,703] [INFO] [launch.py:351:main] Process 1071752 exits successfully.
ml-512-node-005: [2024-07-08 06:07:28,706] [INFO] [launch.py:351:main] Process 1089312 exits successfully.
ml-512-node-005: [2024-07-08 06:07:28,706] [INFO] [launch.py:351:main] Process 1089311 exits successfully.
ml-512-node-005: [2024-07-08 06:07:28,707] [INFO] [launch.py:351:main] Process 1089309 exits successfully.
ml-512-node-005: [2024-07-08 06:07:28,707] [INFO] [launch.py:351:main] Process 1089307 exits successfully.
ml-512-node-005: [2024-07-08 06:07:28,707] [INFO] [launch.py:351:main] Process 1089313 exits successfully.
ml-512-node-005: [2024-07-08 06:07:28,707] [INFO] [launch.py:351:main] Process 1089306 exits successfully.
ml-512-node-005: [2024-07-08 06:07:28,707] [INFO] [launch.py:351:main] Process 1089310 exits successfully.
ml-512-node-028: [2024-07-08 06:07:28,708] [INFO] [launch.py:351:main] Process 1064965 exits successfully.
ml-512-node-028: [2024-07-08 06:07:28,709] [INFO] [launch.py:351:main] Process 1064963 exits successfully.
ml-512-node-028: [2024-07-08 06:07:28,709] [INFO] [launch.py:351:main] Process 1064969 exits successfully.
ml-512-node-028: [2024-07-08 06:07:28,709] [INFO] [launch.py:351:main] Process 1064968 exits successfully.
ml-512-node-028: [2024-07-08 06:07:28,709] [INFO] [launch.py:351:main] Process 1064964 exits successfully.
ml-512-node-028: [2024-07-08 06:07:28,709] [INFO] [launch.py:351:main] Process 1064970 exits successfully.
ml-512-node-017: [2024-07-08 06:07:28,719] [INFO] [launch.py:351:main] Process 1074920 exits successfully.
ml-512-node-017: [2024-07-08 06:07:28,719] [INFO] [launch.py:351:main] Process 1074917 exits successfully.
ml-512-node-024: [2024-07-08 06:07:28,722] [INFO] [launch.py:351:main] Process 1066068 exits successfully.
ml-512-node-024: [2024-07-08 06:07:28,722] [INFO] [launch.py:351:main] Process 1066066 exits successfully.
ml-512-node-024: [2024-07-08 06:07:28,722] [INFO] [launch.py:351:main] Process 1066064 exits successfully.
ml-512-node-024: [2024-07-08 06:07:28,722] [INFO] [launch.py:351:main] Process 1066065 exits successfully.
ml-512-node-024: [2024-07-08 06:07:28,722] [INFO] [launch.py:351:main] Process 1066067 exits successfully.
ml-512-node-011: [2024-07-08 06:07:28,723] [INFO] [launch.py:351:main] Process 1073326 exits successfully.
ml-512-node-011: [2024-07-08 06:07:28,723] [INFO] [launch.py:351:main] Process 1073324 exits successfully.
ml-512-node-011: [2024-07-08 06:07:28,723] [INFO] [launch.py:351:main] Process 1073328 exits successfully.
ml-512-node-011: [2024-07-08 06:07:28,723] [INFO] [launch.py:351:main] Process 1073330 exits successfully.
ml-512-node-011: [2024-07-08 06:07:28,723] [INFO] [launch.py:351:main] Process 1073329 exits successfully.
ml-512-node-011: [2024-07-08 06:07:28,723] [INFO] [launch.py:351:main] Process 1073327 exits successfully.
ml-512-node-011: [2024-07-08 06:07:28,723] [INFO] [launch.py:351:main] Process 1073325 exits successfully.
ml-512-node-011: [2024-07-08 06:07:28,724] [INFO] [launch.py:351:main] Process 1073331 exits successfully.
ml-512-node-013: [2024-07-08 06:07:28,748] [INFO] [launch.py:351:main] Process 1072362 exits successfully.
ml-512-node-013: [2024-07-08 06:07:28,748] [INFO] [launch.py:351:main] Process 1072368 exits successfully.
ml-512-node-013: [2024-07-08 06:07:28,748] [INFO] [launch.py:351:main] Process 1072367 exits successfully.
ml-512-node-013: [2024-07-08 06:07:28,748] [INFO] [launch.py:351:main] Process 1072365 exits successfully.
ml-512-node-013: [2024-07-08 06:07:28,748] [INFO] [launch.py:351:main] Process 1072363 exits successfully.
ml-512-node-003: [2024-07-08 06:07:28,752] [INFO] [launch.py:351:main] Process 1075245 exits successfully.
ml-512-node-003: [2024-07-08 06:07:28,752] [INFO] [launch.py:351:main] Process 1075247 exits successfully.
ml-512-node-003: [2024-07-08 06:07:28,752] [INFO] [launch.py:351:main] Process 1075246 exits successfully.
ml-512-node-003: [2024-07-08 06:07:28,752] [INFO] [launch.py:351:main] Process 1075244 exits successfully.
ml-512-node-003: [2024-07-08 06:07:28,752] [INFO] [launch.py:351:main] Process 1075242 exits successfully.
ml-512-node-003: [2024-07-08 06:07:28,752] [INFO] [launch.py:351:main] Process 1075248 exits successfully.
ml-512-node-003: [2024-07-08 06:07:28,752] [INFO] [launch.py:351:main] Process 1075241 exits successfully.
ml-512-node-030: [2024-07-08 06:07:28,755] [INFO] [launch.py:351:main] Process 1070034 exits successfully.
ml-512-node-030: [2024-07-08 06:07:28,756] [INFO] [launch.py:351:main] Process 1070032 exits successfully.
ml-512-node-030: [2024-07-08 06:07:28,756] [INFO] [launch.py:351:main] Process 1070038 exits successfully.
ml-512-node-030: [2024-07-08 06:07:28,756] [INFO] [launch.py:351:main] Process 1070037 exits successfully.
ml-512-node-030: [2024-07-08 06:07:28,756] [INFO] [launch.py:351:main] Process 1070035 exits successfully.
ml-512-node-030: [2024-07-08 06:07:28,756] [INFO] [launch.py:351:main] Process 1070039 exits successfully.
ml-512-node-060: [2024-07-08 06:07:28,763] [INFO] [launch.py:351:main] Process 1056133 exits successfully.
ml-512-node-060: [2024-07-08 06:07:28,763] [INFO] [launch.py:351:main] Process 1056132 exits successfully.
ml-512-node-060: [2024-07-08 06:07:28,764] [INFO] [launch.py:351:main] Process 1056130 exits successfully.
ml-512-node-060: [2024-07-08 06:07:28,764] [INFO] [launch.py:351:main] Process 1056128 exits successfully.
ml-512-node-060: [2024-07-08 06:07:28,764] [INFO] [launch.py:351:main] Process 1056134 exits successfully.
ml-512-node-060: [2024-07-08 06:07:28,764] [INFO] [launch.py:351:main] Process 1056129 exits successfully.
ml-512-node-060: [2024-07-08 06:07:28,764] [INFO] [launch.py:351:main] Process 1056127 exits successfully.
ml-512-node-060: [2024-07-08 06:07:28,764] [INFO] [launch.py:351:main] Process 1056131 exits successfully.
ml-512-node-014: [2024-07-08 06:07:28,767] [INFO] [launch.py:351:main] Process 1065801 exits successfully.
ml-512-node-014: [2024-07-08 06:07:28,767] [INFO] [launch.py:351:main] Process 1065805 exits successfully.
ml-512-node-014: [2024-07-08 06:07:28,767] [INFO] [launch.py:351:main] Process 1065807 exits successfully.
ml-512-node-014: [2024-07-08 06:07:28,767] [INFO] [launch.py:351:main] Process 1065806 exits successfully.
ml-512-node-014: [2024-07-08 06:07:28,767] [INFO] [launch.py:351:main] Process 1065802 exits successfully.
ml-512-node-014: [2024-07-08 06:07:28,768] [INFO] [launch.py:351:main] Process 1065808 exits successfully.
ml-512-node-031: [2024-07-08 06:07:28,772] [INFO] [launch.py:351:main] Process 1067935 exits successfully.
ml-512-node-031: [2024-07-08 06:07:28,772] [INFO] [launch.py:351:main] Process 1067937 exits successfully.
ml-512-node-031: [2024-07-08 06:07:28,772] [INFO] [launch.py:351:main] Process 1067936 exits successfully.
ml-512-node-031: [2024-07-08 06:07:28,772] [INFO] [launch.py:351:main] Process 1067934 exits successfully.
ml-512-node-031: [2024-07-08 06:07:28,772] [INFO] [launch.py:351:main] Process 1067932 exits successfully.
ml-512-node-031: [2024-07-08 06:07:28,772] [INFO] [launch.py:351:main] Process 1067938 exits successfully.
ml-512-node-031: [2024-07-08 06:07:28,772] [INFO] [launch.py:351:main] Process 1067933 exits successfully.
ml-512-node-015: [2024-07-08 06:07:28,864] [INFO] [launch.py:351:main] Process 1071244 exits successfully.
ml-512-node-015: [2024-07-08 06:07:28,864] [INFO] [launch.py:351:main] Process 1071242 exits successfully.
ml-512-node-015: [2024-07-08 06:07:28,864] [INFO] [launch.py:351:main] Process 1071246 exits successfully.
ml-512-node-015: [2024-07-08 06:07:28,864] [INFO] [launch.py:351:main] Process 1071248 exits successfully.
ml-512-node-015: [2024-07-08 06:07:28,864] [INFO] [launch.py:351:main] Process 1071245 exits successfully.
ml-512-node-015: [2024-07-08 06:07:28,864] [INFO] [launch.py:351:main] Process 1071249 exits successfully.
ml-512-node-040: [2024-07-08 06:07:29,109] [INFO] [launch.py:351:main] Process 1116541 exits successfully.
ml-512-node-040: [2024-07-08 06:07:29,109] [INFO] [launch.py:351:main] Process 1116539 exits successfully.
ml-512-node-040: [2024-07-08 06:07:29,109] [INFO] [launch.py:351:main] Process 1116543 exits successfully.
ml-512-node-040: [2024-07-08 06:07:29,109] [INFO] [launch.py:351:main] Process 1116545 exits successfully.
ml-512-node-040: [2024-07-08 06:07:29,110] [INFO] [launch.py:351:main] Process 1116544 exits successfully.
ml-512-node-040: [2024-07-08 06:07:29,110] [INFO] [launch.py:351:main] Process 1116542 exits successfully.
ml-512-node-056: [2024-07-08 06:07:29,128] [INFO] [launch.py:351:main] Process 1072775 exits successfully.
ml-512-node-001: [2024-07-08 06:07:29,551] [INFO] [launch.py:351:main] Process 1992109 exits successfully.
ml-512-node-001: [2024-07-08 06:07:29,551] [INFO] [launch.py:351:main] Process 1992111 exits successfully.
ml-512-node-001: [2024-07-08 06:07:29,551] [INFO] [launch.py:351:main] Process 1992104 exits successfully.
ml-512-node-043: [2024-07-08 06:07:29,658] [INFO] [launch.py:351:main] Process 1064756 exits successfully.
ml-512-node-043: [2024-07-08 06:07:29,658] [INFO] [launch.py:351:main] Process 1064758 exits successfully.
ml-512-node-043: [2024-07-08 06:07:29,658] [INFO] [launch.py:351:main] Process 1064760 exits successfully.
ml-512-node-043: [2024-07-08 06:07:29,658] [INFO] [launch.py:351:main] Process 1064759 exits successfully.
ml-512-node-043: [2024-07-08 06:07:29,658] [INFO] [launch.py:351:main] Process 1064757 exits successfully.
ml-512-node-043: [2024-07-08 06:07:29,658] [INFO] [launch.py:351:main] Process 1064755 exits successfully.
ml-512-node-019: [2024-07-08 06:07:29,669] [INFO] [launch.py:351:main] Process 1071645 exits successfully.
ml-512-node-019: [2024-07-08 06:07:29,669] [INFO] [launch.py:351:main] Process 1071647 exits successfully.
ml-512-node-019: [2024-07-08 06:07:29,669] [INFO] [launch.py:351:main] Process 1071646 exits successfully.
ml-512-node-019: [2024-07-08 06:07:29,669] [INFO] [launch.py:351:main] Process 1071644 exits successfully.
ml-512-node-019: [2024-07-08 06:07:29,669] [INFO] [launch.py:351:main] Process 1071642 exits successfully.
ml-512-node-027: [2024-07-08 06:07:29,675] [INFO] [launch.py:351:main] Process 1075130 exits successfully.
ml-512-node-027: [2024-07-08 06:07:29,675] [INFO] [launch.py:351:main] Process 1075128 exits successfully.
ml-512-node-027: [2024-07-08 06:07:29,675] [INFO] [launch.py:351:main] Process 1075134 exits successfully.
ml-512-node-027: [2024-07-08 06:07:29,676] [INFO] [launch.py:351:main] Process 1075133 exits successfully.
ml-512-node-027: [2024-07-08 06:07:29,676] [INFO] [launch.py:351:main] Process 1075129 exits successfully.
ml-512-node-027: [2024-07-08 06:07:29,676] [INFO] [launch.py:351:main] Process 1075135 exits successfully.
ml-512-node-048: [2024-07-08 06:07:29,685] [INFO] [launch.py:351:main] Process 1059127 exits successfully.
ml-512-node-048: [2024-07-08 06:07:29,685] [INFO] [launch.py:351:main] Process 1059129 exits successfully.
ml-512-node-048: [2024-07-08 06:07:29,685] [INFO] [launch.py:351:main] Process 1059126 exits successfully.
ml-512-node-048: [2024-07-08 06:07:29,685] [INFO] [launch.py:351:main] Process 1059124 exits successfully.
ml-512-node-048: [2024-07-08 06:07:29,685] [INFO] [launch.py:351:main] Process 1059125 exits successfully.
ml-512-node-048: [2024-07-08 06:07:29,685] [INFO] [launch.py:351:main] Process 1059123 exits successfully.
ml-512-node-021: [2024-07-08 06:07:29,708] [INFO] [launch.py:351:main] Process 1071504 exits successfully.
ml-512-node-021: [2024-07-08 06:07:29,709] [INFO] [launch.py:351:main] Process 1071503 exits successfully.
ml-512-node-021: [2024-07-08 06:07:29,709] [INFO] [launch.py:351:main] Process 1071501 exits successfully.
ml-512-node-021: [2024-07-08 06:07:29,709] [INFO] [launch.py:351:main] Process 1071499 exits successfully.
ml-512-node-021: [2024-07-08 06:07:29,709] [INFO] [launch.py:351:main] Process 1071505 exits successfully.
ml-512-node-021: [2024-07-08 06:07:29,709] [INFO] [launch.py:351:main] Process 1071500 exits successfully.
ml-512-node-021: [2024-07-08 06:07:29,709] [INFO] [launch.py:351:main] Process 1071498 exits successfully.
ml-512-node-021: [2024-07-08 06:07:29,709] [INFO] [launch.py:351:main] Process 1071502 exits successfully.
ml-512-node-017: [2024-07-08 06:07:29,720] [INFO] [launch.py:351:main] Process 1074921 exits successfully.
ml-512-node-017: [2024-07-08 06:07:29,720] [INFO] [launch.py:351:main] Process 1074923 exits successfully.
ml-512-node-017: [2024-07-08 06:07:29,720] [INFO] [launch.py:351:main] Process 1074922 exits successfully.
ml-512-node-017: [2024-07-08 06:07:29,720] [INFO] [launch.py:351:main] Process 1074918 exits successfully.
ml-512-node-017: [2024-07-08 06:07:29,720] [INFO] [launch.py:351:main] Process 1074924 exits successfully.
ml-512-node-017: [2024-07-08 06:07:29,721] [INFO] [launch.py:351:main] Process 1074919 exits successfully.
ml-512-node-001: [2024-07-08 06:07:30,552] [INFO] [launch.py:351:main] Process 1992110 exits successfully.
ml-512-node-001: [2024-07-08 06:07:30,552] [INFO] [launch.py:351:main] Process 1992107 exits successfully.
ml-512-node-001: [2024-07-08 06:07:30,553] [INFO] [launch.py:351:main] Process 1992105 exits successfully.
ml-512-node-001: [2024-07-08 06:07:30,553] [INFO] [launch.py:351:main] Process 1992106 exits successfully.
ml-512-node-001: [2024-07-08 06:07:30,553] [INFO] [launch.py:351:main] Process 1992108 exits successfully.
