ml-512-node-033 slots=8
ml-512-node-034 slots=8
ml-512-node-035 slots=8
ml-512-node-036 slots=8
ml-512-node-037 slots=8
ml-512-node-038 slots=8
ml-512-node-039 slots=8
ml-512-node-040 slots=8
ml-512-node-041 slots=8
ml-512-node-042 slots=8
ml-512-node-043 slots=8
ml-512-node-044 slots=8
ml-512-node-045 slots=8
ml-512-node-046 slots=8
ml-512-node-047 slots=8
ml-512-node-048 slots=8
ml-512-node-049 slots=8
ml-512-node-050 slots=8
ml-512-node-051 slots=8
ml-512-node-052 slots=8
ml-512-node-053 slots=8
ml-512-node-054 slots=8
ml-512-node-055 slots=8
ml-512-node-056 slots=8
ml-512-node-057 slots=8
ml-512-node-058 slots=8
ml-512-node-059 slots=8
ml-512-node-060 slots=8
ml-512-node-061 slots=8
ml-512-node-062 slots=8
ml-512-node-063 slots=8
ml-512-node-064 slots=8
[2024-07-08 07:19:13,787] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-07-08 07:19:15.123793: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-07-08 07:19:15.161298: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[2024-07-08 07:19:16,627] [INFO] [runner.py:557:main] deepspeed_env file = ./.deepspeed_env
[2024-07-08 07:19:16,628] [INFO] [multinode_runner.py:81:get_cmd] Running on the following workers: ml-512-node-033,ml-512-node-034,ml-512-node-035,ml-512-node-036,ml-512-node-037,ml-512-node-038,ml-512-node-039,ml-512-node-040,ml-512-node-041,ml-512-node-042,ml-512-node-043,ml-512-node-044,ml-512-node-045,ml-512-node-046,ml-512-node-047,ml-512-node-048,ml-512-node-049,ml-512-node-050,ml-512-node-051,ml-512-node-052,ml-512-node-053,ml-512-node-054,ml-512-node-055,ml-512-node-056,ml-512-node-057,ml-512-node-058,ml-512-node-059,ml-512-node-060,ml-512-node-061,ml-512-node-062,ml-512-node-063,ml-512-node-064
[2024-07-08 07:19:16,628] [INFO] [runner.py:568:main] cmd = pdsh -S -f 1024 -w ml-512-node-033,ml-512-node-034,ml-512-node-035,ml-512-node-036,ml-512-node-037,ml-512-node-038,ml-512-node-039,ml-512-node-040,ml-512-node-041,ml-512-node-042,ml-512-node-043,ml-512-node-044,ml-512-node-045,ml-512-node-046,ml-512-node-047,ml-512-node-048,ml-512-node-049,ml-512-node-050,ml-512-node-051,ml-512-node-052,ml-512-node-053,ml-512-node-054,ml-512-node-055,ml-512-node-056,ml-512-node-057,ml-512-node-058,ml-512-node-059,ml-512-node-060,ml-512-node-061,ml-512-node-062,ml-512-node-063,ml-512-node-064 export PYTHONPATH=/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training; export PROJECT_PATH=/home/ubuntu/ml-1cc/benchmark; export OMPI_MCA_btl_tcp_if_include=eno1; export UCX_TLS=self,shm,tcp; export NCCL_P2P_LEVEL=NVL; export NCCL_NET_GDR_LEVEL=PIX; export NCCL_IB_HCA='=mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8'; export NCCL_IB_PCI_RELAXED_ORDERING=1; export NCCL_SOCKET_IFNAME=eno1; export NCCL_DEBUG=WARN;  cd /home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training; /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJtbC01MTItbm9kZS0wMzMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --node_rank=%n --master_addr=ml-512-node-033 --master_port=29500 /home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py --data_path Dahoas/full-hh-rlhf --data_split 2,4,4 --data_output_path /home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1 --model_name_or_path facebook/opt-13b --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --max_seq_len 512 --learning_rate 1e-10 --weight_decay 0.1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --seed 1234 --gradient_checkpointing --zero_stage 0 --lora_dim 128 --lora_module_name decoder.layers. --deepspeed --num_warmup_steps 10 --num_train_epochs 100 --max_steps 100
ml-512-node-033: [2024-07-08 07:19:18,051] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: 2024-07-08 07:19:19.458033: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-033: 2024-07-08 07:19:19.496233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-033: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-044: [2024-07-08 07:19:20,253] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 07:19:20,265] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [2024-07-08 07:19:20,279] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 07:19:20,419] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 07:19:20,436] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 07:19:20,452] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 07:19:20,453] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 07:19:20,456] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 07:19:20,458] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 07:19:20,459] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 07:19:20,458] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 07:19:20,461] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 07:19:20,461] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 07:19:20,460] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 07:19:20,474] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 07:19:20,472] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 07:19:20,477] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 07:19:20,474] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 07:19:20,482] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [2024-07-08 07:19:20,478] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 07:19:20,485] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 07:19:20,489] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 07:19:20,489] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [2024-07-08 07:19:20,495] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 07:19:20,540] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-040: [2024-07-08 07:19:20,582] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-056: [2024-07-08 07:19:20,706] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:139:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:139:main] 0 NCCL_SOCKET_IFNAME=eno1
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:139:main] 0 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:139:main] 0 NCCL_P2P_LEVEL=NVL
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:139:main] 0 NCCL_DEBUG=WARN
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:139:main] 0 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=0
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-033: [2024-07-08 07:19:20,778] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-033: [2024-07-08 07:19:20,779] [INFO] [launch.py:256:main] process 1096581 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 07:19:20,780] [INFO] [launch.py:256:main] process 1096582 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 07:19:20,781] [INFO] [launch.py:256:main] process 1096583 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 07:19:20,781] [INFO] [launch.py:256:main] process 1096584 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 07:19:20,782] [INFO] [launch.py:256:main] process 1096585 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 07:19:20,783] [INFO] [launch.py:256:main] process 1096586 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 07:19:20,783] [INFO] [launch.py:256:main] process 1096587 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 07:19:20,784] [INFO] [launch.py:256:main] process 1096588 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 07:19:21,465] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-063: [2024-07-08 07:19:21,481] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [2024-07-08 07:19:21,483] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [2024-07-08 07:19:21,513] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: 2024-07-08 07:19:21.605078: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-034: 2024-07-08 07:19:21.614346: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: 2024-07-08 07:19:21.644319: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-044: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-061: 2024-07-08 07:19:21.651237: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-034: 2024-07-08 07:19:21.653051: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-034: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-061: 2024-07-08 07:19:21.690685: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-061: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: 2024-07-08 07:19:21.776823: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-048: 2024-07-08 07:19:21.797233: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-038: 2024-07-08 07:19:21.810562: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-050: 2024-07-08 07:19:21.814352: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-050: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-036: 2024-07-08 07:19:21.812587: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-047: 2024-07-08 07:19:21.828108: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-064: 2024-07-08 07:19:21.830543: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-048: 2024-07-08 07:19:21.834654: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-048: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-039: 2024-07-08 07:19:21.836451: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-058: 2024-07-08 07:19:21.836919: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-035: 2024-07-08 07:19:21.833438: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-041: 2024-07-08 07:19:21.840420: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-055: 2024-07-08 07:19:21.838932: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-054: 2024-07-08 07:19:21.846665: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-046: 2024-07-08 07:19:21.847070: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-042: 2024-07-08 07:19:21.847152: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-038: 2024-07-08 07:19:21.849440: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-038: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-036: 2024-07-08 07:19:21.850792: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-036: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-047: 2024-07-08 07:19:21.866213: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-047: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-057: 2024-07-08 07:19:21.868442: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-064: 2024-07-08 07:19:21.869867: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-064: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-058: 2024-07-08 07:19:21.874528: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-058: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-039: 2024-07-08 07:19:21.874614: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-039: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-035: 2024-07-08 07:19:21.872680: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-035: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-062: 2024-07-08 07:19:21.878366: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-045: 2024-07-08 07:19:21.878481: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-055: 2024-07-08 07:19:21.876510: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-055: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-041: 2024-07-08 07:19:21.880086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-041: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-054: 2024-07-08 07:19:21.885715: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-054: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-046: 2024-07-08 07:19:21.885981: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-046: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-042: 2024-07-08 07:19:21.886095: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-042: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-057: 2024-07-08 07:19:21.907542: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-057: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-052: 2024-07-08 07:19:21.906768: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-062: 2024-07-08 07:19:21.917627: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-062: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-045: 2024-07-08 07:19:21.918337: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-045: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-051: 2024-07-08 07:19:21.920515: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-043: 2024-07-08 07:19:21.923244: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-060: 2024-07-08 07:19:21.927808: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-037: 2024-07-08 07:19:21.936924: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-052: 2024-07-08 07:19:21.945949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-052: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-051: 2024-07-08 07:19:21.958121: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-051: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-043: 2024-07-08 07:19:21.962799: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-043: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-060: 2024-07-08 07:19:21.967763: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-060: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-037: 2024-07-08 07:19:21.976808: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-037: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: 2024-07-08 07:19:22.218978: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-040: 2024-07-08 07:19:22.254975: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-040: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: 2024-07-08 07:19:22.396062: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: 2024-07-08 07:19:22.432290: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-056: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-059: 2024-07-08 07:19:22.833550: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-049: 2024-07-08 07:19:22.867163: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-059: 2024-07-08 07:19:22.872606: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-059: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-053: 2024-07-08 07:19:22.880711: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-063: 2024-07-08 07:19:22.886085: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:139:main] 1 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:139:main] 1 NCCL_SOCKET_IFNAME=eno1
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:139:main] 1 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:139:main] 1 NCCL_P2P_LEVEL=NVL
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:139:main] 1 NCCL_DEBUG=WARN
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:139:main] 1 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=1
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-034: [2024-07-08 07:19:22,903] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-034: [2024-07-08 07:19:22,905] [INFO] [launch.py:256:main] process 1085706 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 07:19:22,905] [INFO] [launch.py:256:main] process 1085707 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 07:19:22,906] [INFO] [launch.py:256:main] process 1085708 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 07:19:22,906] [INFO] [launch.py:256:main] process 1085709 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: 2024-07-08 07:19:22.906276: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-049: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-034: [2024-07-08 07:19:22,907] [INFO] [launch.py:256:main] process 1085710 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 07:19:22,908] [INFO] [launch.py:256:main] process 1085711 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 07:19:22,908] [INFO] [launch.py:256:main] process 1085712 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 07:19:22,909] [INFO] [launch.py:256:main] process 1085713 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: 2024-07-08 07:19:22.919705: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-053: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:139:main] 11 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:139:main] 11 NCCL_SOCKET_IFNAME=eno1
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:139:main] 11 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:139:main] 11 NCCL_P2P_LEVEL=NVL
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:139:main] 11 NCCL_DEBUG=WARN
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:139:main] 11 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=11
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-044: [2024-07-08 07:19:22,922] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-044: [2024-07-08 07:19:22,924] [INFO] [launch.py:256:main] process 1082487 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: 2024-07-08 07:19:22.924213: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-044: [2024-07-08 07:19:22,924] [INFO] [launch.py:256:main] process 1082488 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-044: [2024-07-08 07:19:22,925] [INFO] [launch.py:256:main] process 1082489 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 07:19:22,925] [INFO] [launch.py:256:main] process 1082490 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 07:19:22,926] [INFO] [launch.py:256:main] process 1082491 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 07:19:22,927] [INFO] [launch.py:256:main] process 1082492 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 07:19:22,927] [INFO] [launch.py:256:main] process 1082493 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 07:19:22,928] [INFO] [launch.py:256:main] process 1082494 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 07:19:22,960] [INFO] [launch.py:139:main] 28 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-061: [2024-07-08 07:19:22,960] [INFO] [launch.py:139:main] 28 NCCL_SOCKET_IFNAME=eno1
ml-512-node-061: [2024-07-08 07:19:22,960] [INFO] [launch.py:139:main] 28 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-061: [2024-07-08 07:19:22,960] [INFO] [launch.py:139:main] 28 NCCL_P2P_LEVEL=NVL
ml-512-node-061: [2024-07-08 07:19:22,960] [INFO] [launch.py:139:main] 28 NCCL_DEBUG=WARN
ml-512-node-061: [2024-07-08 07:19:22,960] [INFO] [launch.py:139:main] 28 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-061: [2024-07-08 07:19:22,961] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-061: [2024-07-08 07:19:22,961] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=28
ml-512-node-061: [2024-07-08 07:19:22,961] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-061: [2024-07-08 07:19:22,961] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-061: [2024-07-08 07:19:22,961] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-061: [2024-07-08 07:19:22,962] [INFO] [launch.py:256:main] process 1085392 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 07:19:22,962] [INFO] [launch.py:256:main] process 1085393 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 07:19:22,963] [INFO] [launch.py:256:main] process 1085394 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 07:19:22,964] [INFO] [launch.py:256:main] process 1085395 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 07:19:22,965] [INFO] [launch.py:256:main] process 1085396 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 07:19:22,965] [INFO] [launch.py:256:main] process 1085397 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 07:19:22,966] [INFO] [launch.py:256:main] process 1085398 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 07:19:22,967] [INFO] [launch.py:256:main] process 1085399 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:139:main] 17 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:139:main] 17 NCCL_SOCKET_IFNAME=eno1
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:139:main] 17 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:139:main] 17 NCCL_P2P_LEVEL=NVL
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:139:main] 17 NCCL_DEBUG=WARN
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:139:main] 17 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=17
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-050: [2024-07-08 07:19:23,102] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-050: [2024-07-08 07:19:23,103] [INFO] [launch.py:256:main] process 1081869 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 07:19:23,104] [INFO] [launch.py:256:main] process 1081870 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 07:19:23,104] [INFO] [launch.py:256:main] process 1081871 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 07:19:23,105] [INFO] [launch.py:256:main] process 1081872 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 07:19:23,105] [INFO] [launch.py:256:main] process 1081873 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 07:19:23,106] [INFO] [launch.py:256:main] process 1081874 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 07:19:23,107] [INFO] [launch.py:256:main] process 1081875 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 07:19:23,107] [INFO] [launch.py:256:main] process 1081876 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:139:main] 15 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:139:main] 15 NCCL_SOCKET_IFNAME=eno1
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:139:main] 15 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:139:main] 15 NCCL_P2P_LEVEL=NVL
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:139:main] 15 NCCL_DEBUG=WARN
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:139:main] 15 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=15
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-048: [2024-07-08 07:19:23,117] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-048: [2024-07-08 07:19:23,118] [INFO] [launch.py:256:main] process 1082335 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 07:19:23,118] [INFO] [launch.py:256:main] process 1082336 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:139:main] 14 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:139:main] 14 NCCL_SOCKET_IFNAME=eno1
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:139:main] 14 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:139:main] 14 NCCL_P2P_LEVEL=NVL
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:139:main] 14 NCCL_DEBUG=WARN
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:139:main] 14 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=14
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-047: [2024-07-08 07:19:23,118] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-047: [2024-07-08 07:19:23,119] [INFO] [launch.py:256:main] process 1086333 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 07:19:23,119] [INFO] [launch.py:256:main] process 1082337 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 07:19:23,120] [INFO] [launch.py:256:main] process 1086334 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 07:19:23,120] [INFO] [launch.py:256:main] process 1082338 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 07:19:23,120] [INFO] [launch.py:256:main] process 1086335 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 07:19:23,121] [INFO] [launch.py:256:main] process 1082339 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 07:19:23,121] [INFO] [launch.py:256:main] process 1086336 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 07:19:23,121] [INFO] [launch.py:256:main] process 1082340 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 07:19:23,122] [INFO] [launch.py:256:main] process 1086337 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 07:19:23,122] [INFO] [launch.py:256:main] process 1082341 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 07:19:23,122] [INFO] [launch.py:256:main] process 1086338 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 07:19:23,122] [INFO] [launch.py:256:main] process 1082342 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 07:19:23,123] [INFO] [launch.py:256:main] process 1086339 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 07:19:23,124] [INFO] [launch.py:256:main] process 1086340 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 07:19:23,136] [INFO] [launch.py:139:main] 2 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-035: [2024-07-08 07:19:23,136] [INFO] [launch.py:139:main] 2 NCCL_SOCKET_IFNAME=eno1
ml-512-node-035: [2024-07-08 07:19:23,136] [INFO] [launch.py:139:main] 2 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-035: [2024-07-08 07:19:23,136] [INFO] [launch.py:139:main] 2 NCCL_P2P_LEVEL=NVL
ml-512-node-035: [2024-07-08 07:19:23,136] [INFO] [launch.py:139:main] 2 NCCL_DEBUG=WARN
ml-512-node-035: [2024-07-08 07:19:23,136] [INFO] [launch.py:139:main] 2 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-035: [2024-07-08 07:19:23,136] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-035: [2024-07-08 07:19:23,136] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=2
ml-512-node-035: [2024-07-08 07:19:23,137] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-035: [2024-07-08 07:19:23,137] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-035: [2024-07-08 07:19:23,137] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-035: [2024-07-08 07:19:23,137] [INFO] [launch.py:256:main] process 1092770 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 07:19:23,138] [INFO] [launch.py:256:main] process 1092771 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 07:19:23,136] [INFO] [launch.py:139:main] 3 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:139:main] 3 NCCL_SOCKET_IFNAME=eno1
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:139:main] 3 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:139:main] 3 NCCL_P2P_LEVEL=NVL
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:139:main] 3 NCCL_DEBUG=WARN
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:139:main] 3 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=3
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-035: [2024-07-08 07:19:23,139] [INFO] [launch.py:256:main] process 1092772 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 07:19:23,137] [INFO] [launch.py:256:main] process 1085054 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 07:19:23,140] [INFO] [launch.py:256:main] process 1092773 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 07:19:23,138] [INFO] [launch.py:256:main] process 1085055 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 07:19:23,139] [INFO] [launch.py:139:main] 8 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-041: [2024-07-08 07:19:23,139] [INFO] [launch.py:139:main] 8 NCCL_SOCKET_IFNAME=eno1
ml-512-node-041: [2024-07-08 07:19:23,139] [INFO] [launch.py:139:main] 8 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-041: [2024-07-08 07:19:23,140] [INFO] [launch.py:139:main] 8 NCCL_P2P_LEVEL=NVL
ml-512-node-041: [2024-07-08 07:19:23,140] [INFO] [launch.py:139:main] 8 NCCL_DEBUG=WARN
ml-512-node-041: [2024-07-08 07:19:23,140] [INFO] [launch.py:139:main] 8 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-041: [2024-07-08 07:19:23,140] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-041: [2024-07-08 07:19:23,140] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=8
ml-512-node-041: [2024-07-08 07:19:23,140] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-041: [2024-07-08 07:19:23,140] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-041: [2024-07-08 07:19:23,140] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-035: [2024-07-08 07:19:23,140] [INFO] [launch.py:256:main] process 1092774 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 07:19:23,139] [INFO] [launch.py:256:main] process 1085056 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 07:19:23,141] [INFO] [launch.py:256:main] process 1092775 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 07:19:23,141] [INFO] [launch.py:256:main] process 1091249 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 07:19:23,141] [INFO] [launch.py:256:main] process 1092776 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 07:19:23,140] [INFO] [launch.py:256:main] process 1085057 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 07:19:23,142] [INFO] [launch.py:256:main] process 1091250 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 07:19:23,142] [INFO] [launch.py:256:main] process 1091251 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 07:19:23,142] [INFO] [launch.py:256:main] process 1092777 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 07:19:23,141] [INFO] [launch.py:256:main] process 1085058 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:139:main] 25 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:139:main] 25 NCCL_SOCKET_IFNAME=eno1
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:139:main] 25 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:139:main] 25 NCCL_P2P_LEVEL=NVL
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:139:main] 25 NCCL_DEBUG=WARN
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:139:main] 25 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-041: [2024-07-08 07:19:23,142] [INFO] [launch.py:256:main] process 1091252 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=25
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-058: [2024-07-08 07:19:23,146] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-036: [2024-07-08 07:19:23,141] [INFO] [launch.py:256:main] process 1085059 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 07:19:23,143] [INFO] [launch.py:256:main] process 1091253 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 07:19:23,147] [INFO] [launch.py:256:main] process 1079327 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 07:19:23,143] [INFO] [launch.py:256:main] process 1091254 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 07:19:23,142] [INFO] [launch.py:256:main] process 1085060 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 07:19:23,144] [INFO] [launch.py:256:main] process 1091255 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 9 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 9 NCCL_SOCKET_IFNAME=eno1
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 9 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 9 NCCL_P2P_LEVEL=NVL
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 9 NCCL_DEBUG=WARN
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 9 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=9
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-058: [2024-07-08 07:19:23,147] [INFO] [launch.py:256:main] process 1079328 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-042: [2024-07-08 07:19:23,147] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 21 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 21 NCCL_SOCKET_IFNAME=eno1
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 21 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 21 NCCL_P2P_LEVEL=NVL
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 21 NCCL_DEBUG=WARN
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:139:main] 21 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=21
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-054: [2024-07-08 07:19:23,147] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-041: [2024-07-08 07:19:23,144] [INFO] [launch.py:256:main] process 1091256 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 07:19:23,143] [INFO] [launch.py:256:main] process 1085061 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 07:19:23,148] [INFO] [launch.py:256:main] process 1084131 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 07:19:23,148] [INFO] [launch.py:256:main] process 1079329 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 07:19:23,148] [INFO] [launch.py:256:main] process 1079364 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 07:19:23,149] [INFO] [launch.py:256:main] process 1079330 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 07:19:23,149] [INFO] [launch.py:256:main] process 1084132 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 07:19:23,149] [INFO] [launch.py:256:main] process 1079365 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 07:19:23,150] [INFO] [launch.py:256:main] process 1079331 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 07:19:23,150] [INFO] [launch.py:256:main] process 1084133 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 07:19:23,150] [INFO] [launch.py:256:main] process 1079366 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:139:main] 6 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:139:main] 6 NCCL_SOCKET_IFNAME=eno1
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:139:main] 6 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:139:main] 6 NCCL_P2P_LEVEL=NVL
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:139:main] 6 NCCL_DEBUG=WARN
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:139:main] 6 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=6
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-039: [2024-07-08 07:19:23,149] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-058: [2024-07-08 07:19:23,150] [INFO] [launch.py:256:main] process 1079332 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 07:19:23,150] [INFO] [launch.py:256:main] process 1084134 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 07:19:23,150] [INFO] [launch.py:256:main] process 1079367 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 07:19:23,150] [INFO] [launch.py:256:main] process 1172102 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 07:19:23,151] [INFO] [launch.py:256:main] process 1079333 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 07:19:23,151] [INFO] [launch.py:256:main] process 1084135 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 07:19:23,151] [INFO] [launch.py:256:main] process 1079368 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 07:19:23,151] [INFO] [launch.py:256:main] process 1172103 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 07:19:23,152] [INFO] [launch.py:256:main] process 1084136 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 07:19:23,152] [INFO] [launch.py:256:main] process 1079334 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 07:19:23,152] [INFO] [launch.py:256:main] process 1079369 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 07:19:23,152] [INFO] [launch.py:256:main] process 1172104 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 07:19:23,152] [INFO] [launch.py:256:main] process 1084137 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 07:19:23,152] [INFO] [launch.py:256:main] process 1079370 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 07:19:23,152] [INFO] [launch.py:256:main] process 1172105 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 07:19:23,153] [INFO] [launch.py:256:main] process 1084138 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 07:19:23,153] [INFO] [launch.py:256:main] process 1079371 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 07:19:23,153] [INFO] [launch.py:256:main] process 1172106 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 07:19:23,154] [INFO] [launch.py:256:main] process 1172107 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 07:19:23,154] [INFO] [launch.py:256:main] process 1172108 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 07:19:23,155] [INFO] [launch.py:256:main] process 1172109 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:139:main] 5 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:139:main] 5 NCCL_SOCKET_IFNAME=eno1
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:139:main] 5 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:139:main] 5 NCCL_P2P_LEVEL=NVL
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:139:main] 5 NCCL_DEBUG=WARN
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:139:main] 5 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=5
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-038: [2024-07-08 07:19:23,152] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-038: [2024-07-08 07:19:23,153] [INFO] [launch.py:256:main] process 1084644 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 07:19:23,154] [INFO] [launch.py:256:main] process 1084645 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 07:19:23,155] [INFO] [launch.py:256:main] process 1084646 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 07:19:23,156] [INFO] [launch.py:256:main] process 1084647 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 07:19:23,156] [INFO] [launch.py:256:main] process 1084648 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 07:19:23,157] [INFO] [launch.py:256:main] process 1084649 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 07:19:23,157] [INFO] [launch.py:256:main] process 1084650 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 07:19:23,158] [INFO] [launch.py:256:main] process 1084651 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:139:main] 31 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:139:main] 31 NCCL_SOCKET_IFNAME=eno1
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:139:main] 31 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:139:main] 31 NCCL_P2P_LEVEL=NVL
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:139:main] 31 NCCL_DEBUG=WARN
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:139:main] 31 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=31
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-064: [2024-07-08 07:19:23,162] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-064: [2024-07-08 07:19:23,163] [INFO] [launch.py:256:main] process 1076954 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 07:19:23,164] [INFO] [launch.py:256:main] process 1076955 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 07:19:23,164] [INFO] [launch.py:256:main] process 1076956 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 07:19:23,165] [INFO] [launch.py:256:main] process 1076957 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 07:19:23,166] [INFO] [launch.py:256:main] process 1076958 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 07:19:23,166] [INFO] [launch.py:256:main] process 1076959 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 07:19:23,167] [INFO] [launch.py:256:main] process 1076960 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 07:19:23,167] [INFO] [launch.py:256:main] process 1076961 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 07:19:23,179] [INFO] [launch.py:139:main] 24 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-057: [2024-07-08 07:19:23,179] [INFO] [launch.py:139:main] 24 NCCL_SOCKET_IFNAME=eno1
ml-512-node-057: [2024-07-08 07:19:23,179] [INFO] [launch.py:139:main] 24 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-057: [2024-07-08 07:19:23,179] [INFO] [launch.py:139:main] 24 NCCL_P2P_LEVEL=NVL
ml-512-node-057: [2024-07-08 07:19:23,179] [INFO] [launch.py:139:main] 24 NCCL_DEBUG=WARN
ml-512-node-057: [2024-07-08 07:19:23,179] [INFO] [launch.py:139:main] 24 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-057: [2024-07-08 07:19:23,179] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-057: [2024-07-08 07:19:23,179] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=24
ml-512-node-057: [2024-07-08 07:19:23,179] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-057: [2024-07-08 07:19:23,179] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-057: [2024-07-08 07:19:23,180] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-057: [2024-07-08 07:19:23,180] [INFO] [launch.py:256:main] process 1086884 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:139:main] 22 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:139:main] 22 NCCL_SOCKET_IFNAME=eno1
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:139:main] 22 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:139:main] 22 NCCL_P2P_LEVEL=NVL
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:139:main] 22 NCCL_DEBUG=WARN
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:139:main] 22 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=22
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-055: [2024-07-08 07:19:23,175] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-057: [2024-07-08 07:19:23,181] [INFO] [launch.py:256:main] process 1086885 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 07:19:23,176] [INFO] [launch.py:256:main] process 1103975 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 07:19:23,182] [INFO] [launch.py:256:main] process 1086886 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 07:19:23,177] [INFO] [launch.py:256:main] process 1103976 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 07:19:23,183] [INFO] [launch.py:256:main] process 1086887 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 07:19:23,178] [INFO] [launch.py:256:main] process 1103977 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 07:19:23,183] [INFO] [launch.py:256:main] process 1086888 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 07:19:23,178] [INFO] [launch.py:256:main] process 1103978 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 07:19:23,184] [INFO] [launch.py:256:main] process 1086889 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 07:19:23,179] [INFO] [launch.py:256:main] process 1103979 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 07:19:23,185] [INFO] [launch.py:256:main] process 1086890 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 07:19:23,180] [INFO] [launch.py:256:main] process 1103980 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 07:19:23,185] [INFO] [launch.py:256:main] process 1086891 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 07:19:23,180] [INFO] [launch.py:256:main] process 1103981 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 07:19:23,181] [INFO] [launch.py:256:main] process 1103982 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:139:main] 13 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:139:main] 13 NCCL_SOCKET_IFNAME=eno1
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:139:main] 13 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:139:main] 13 NCCL_P2P_LEVEL=NVL
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:139:main] 13 NCCL_DEBUG=WARN
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:139:main] 13 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=13
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-046: [2024-07-08 07:19:23,190] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-046: [2024-07-08 07:19:23,191] [INFO] [launch.py:256:main] process 1084067 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 07:19:23,192] [INFO] [launch.py:256:main] process 1084068 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 07:19:23,193] [INFO] [launch.py:256:main] process 1084069 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 07:19:23,193] [INFO] [launch.py:256:main] process 1084070 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 07:19:23,194] [INFO] [launch.py:256:main] process 1084071 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 07:19:23,195] [INFO] [launch.py:256:main] process 1084072 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:139:main] 12 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:139:main] 12 NCCL_SOCKET_IFNAME=eno1
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:139:main] 12 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:139:main] 12 NCCL_P2P_LEVEL=NVL
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:139:main] 12 NCCL_DEBUG=WARN
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:139:main] 12 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-046: [2024-07-08 07:19:23,195] [INFO] [launch.py:256:main] process 1084073 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=12
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-045: [2024-07-08 07:19:23,194] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-046: [2024-07-08 07:19:23,196] [INFO] [launch.py:256:main] process 1084074 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 07:19:23,195] [INFO] [launch.py:256:main] process 1088380 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 07:19:23,196] [INFO] [launch.py:256:main] process 1088381 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 07:19:23,196] [INFO] [launch.py:256:main] process 1088382 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 07:19:23,197] [INFO] [launch.py:256:main] process 1088383 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 07:19:23,198] [INFO] [launch.py:256:main] process 1088384 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 07:19:23,198] [INFO] [launch.py:256:main] process 1088385 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 07:19:23,199] [INFO] [launch.py:256:main] process 1088386 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 07:19:23,200] [INFO] [launch.py:256:main] process 1088387 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 07:19:23,210] [INFO] [launch.py:139:main] 29 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-062: [2024-07-08 07:19:23,210] [INFO] [launch.py:139:main] 29 NCCL_SOCKET_IFNAME=eno1
ml-512-node-062: [2024-07-08 07:19:23,210] [INFO] [launch.py:139:main] 29 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-062: [2024-07-08 07:19:23,210] [INFO] [launch.py:139:main] 29 NCCL_P2P_LEVEL=NVL
ml-512-node-062: [2024-07-08 07:19:23,210] [INFO] [launch.py:139:main] 29 NCCL_DEBUG=WARN
ml-512-node-062: [2024-07-08 07:19:23,210] [INFO] [launch.py:139:main] 29 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-062: [2024-07-08 07:19:23,210] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-062: [2024-07-08 07:19:23,211] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=29
ml-512-node-062: [2024-07-08 07:19:23,211] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-062: [2024-07-08 07:19:23,211] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-062: [2024-07-08 07:19:23,211] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-062: [2024-07-08 07:19:23,211] [INFO] [launch.py:256:main] process 1078495 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 07:19:23,212] [INFO] [launch.py:256:main] process 1078496 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 07:19:23,213] [INFO] [launch.py:256:main] process 1078497 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 07:19:23,214] [INFO] [launch.py:256:main] process 1078498 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:139:main] 19 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:139:main] 19 NCCL_SOCKET_IFNAME=eno1
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:139:main] 19 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:139:main] 19 NCCL_P2P_LEVEL=NVL
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:139:main] 19 NCCL_DEBUG=WARN
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:139:main] 19 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=19
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-052: [2024-07-08 07:19:23,212] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-062: [2024-07-08 07:19:23,214] [INFO] [launch.py:256:main] process 1078499 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 07:19:23,213] [INFO] [launch.py:256:main] process 1081362 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 07:19:23,215] [INFO] [launch.py:256:main] process 1078500 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 07:19:23,215] [INFO] [launch.py:256:main] process 1078501 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 07:19:23,214] [INFO] [launch.py:256:main] process 1081363 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 07:19:23,216] [INFO] [launch.py:256:main] process 1078502 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 07:19:23,215] [INFO] [launch.py:256:main] process 1081364 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 07:19:23,216] [INFO] [launch.py:256:main] process 1081365 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 07:19:23,216] [INFO] [launch.py:256:main] process 1081366 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 07:19:23,217] [INFO] [launch.py:256:main] process 1081367 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 07:19:23,217] [INFO] [launch.py:256:main] process 1081368 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 07:19:23,218] [INFO] [launch.py:256:main] process 1081369 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:139:main] 10 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:139:main] 10 NCCL_SOCKET_IFNAME=eno1
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:139:main] 10 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:139:main] 10 NCCL_P2P_LEVEL=NVL
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:139:main] 10 NCCL_DEBUG=WARN
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:139:main] 10 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=10
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-043: [2024-07-08 07:19:23,226] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-043: [2024-07-08 07:19:23,227] [INFO] [launch.py:256:main] process 1088171 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 07:19:23,228] [INFO] [launch.py:256:main] process 1088172 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 07:19:23,229] [INFO] [launch.py:256:main] process 1088173 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 07:19:23,229] [INFO] [launch.py:256:main] process 1088174 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 07:19:23,230] [INFO] [launch.py:256:main] process 1088175 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 07:19:23,230] [INFO] [launch.py:256:main] process 1088176 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 07:19:23,231] [INFO] [launch.py:256:main] process 1088177 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 07:19:23,232] [INFO] [launch.py:256:main] process 1088178 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:139:main] 27 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:139:main] 27 NCCL_SOCKET_IFNAME=eno1
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:139:main] 27 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:139:main] 27 NCCL_P2P_LEVEL=NVL
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:139:main] 27 NCCL_DEBUG=WARN
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:139:main] 27 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=27
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-060: [2024-07-08 07:19:23,241] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-060: [2024-07-08 07:19:23,242] [INFO] [launch.py:256:main] process 1079369 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 07:19:23,242] [INFO] [launch.py:256:main] process 1079370 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 07:19:23,243] [INFO] [launch.py:256:main] process 1079371 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 07:19:23,244] [INFO] [launch.py:256:main] process 1079372 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 07:19:23,245] [INFO] [launch.py:256:main] process 1079373 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 07:19:23,245] [INFO] [launch.py:256:main] process 1079374 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 07:19:23,246] [INFO] [launch.py:256:main] process 1079375 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 07:19:23,246] [INFO] [launch.py:256:main] process 1079376 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:139:main] 18 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:139:main] 18 NCCL_SOCKET_IFNAME=eno1
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:139:main] 18 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:139:main] 18 NCCL_P2P_LEVEL=NVL
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:139:main] 18 NCCL_DEBUG=WARN
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:139:main] 18 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=18
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-051: [2024-07-08 07:19:23,247] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-051: [2024-07-08 07:19:23,248] [INFO] [launch.py:256:main] process 1086122 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 07:19:23,249] [INFO] [launch.py:256:main] process 1086123 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 07:19:23,249] [INFO] [launch.py:256:main] process 1086124 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 07:19:23,250] [INFO] [launch.py:256:main] process 1086125 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 07:19:23,250] [INFO] [launch.py:256:main] process 1086126 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 07:19:23,251] [INFO] [launch.py:256:main] process 1086127 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 07:19:23,251] [INFO] [launch.py:256:main] process 1086128 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 07:19:23,252] [INFO] [launch.py:256:main] process 1086129 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:139:main] 4 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:139:main] 4 NCCL_SOCKET_IFNAME=eno1
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:139:main] 4 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:139:main] 4 NCCL_P2P_LEVEL=NVL
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:139:main] 4 NCCL_DEBUG=WARN
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:139:main] 4 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=4
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-037: [2024-07-08 07:19:23,290] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-037: [2024-07-08 07:19:23,291] [INFO] [launch.py:256:main] process 1089501 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 07:19:23,292] [INFO] [launch.py:256:main] process 1089502 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 07:19:23,292] [INFO] [launch.py:256:main] process 1089503 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 07:19:23,293] [INFO] [launch.py:256:main] process 1089504 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 07:19:23,294] [INFO] [launch.py:256:main] process 1089505 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 07:19:23,295] [INFO] [launch.py:256:main] process 1089506 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 07:19:23,295] [INFO] [launch.py:256:main] process 1089507 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 07:19:23,296] [INFO] [launch.py:256:main] process 1089508 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:139:main] 7 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:139:main] 7 NCCL_SOCKET_IFNAME=eno1
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:139:main] 7 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:139:main] 7 NCCL_P2P_LEVEL=NVL
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:139:main] 7 NCCL_DEBUG=WARN
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:139:main] 7 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=7
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-040: [2024-07-08 07:19:23,609] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-040: [2024-07-08 07:19:23,610] [INFO] [launch.py:256:main] process 1139782 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 07:19:23,611] [INFO] [launch.py:256:main] process 1139783 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 07:19:23,611] [INFO] [launch.py:256:main] process 1139784 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 07:19:23,612] [INFO] [launch.py:256:main] process 1139785 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 07:19:23,613] [INFO] [launch.py:256:main] process 1139786 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 07:19:23,613] [INFO] [launch.py:256:main] process 1139787 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 07:19:23,614] [INFO] [launch.py:256:main] process 1139788 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 07:19:23,614] [INFO] [launch.py:256:main] process 1139789 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:139:main] 23 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:139:main] 23 NCCL_SOCKET_IFNAME=eno1
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:139:main] 23 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:139:main] 23 NCCL_P2P_LEVEL=NVL
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:139:main] 23 NCCL_DEBUG=WARN
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:139:main] 23 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=23
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-056: [2024-07-08 07:19:23,796] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-056: [2024-07-08 07:19:23,797] [INFO] [launch.py:256:main] process 1095951 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 07:19:23,798] [INFO] [launch.py:256:main] process 1095952 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 07:19:23,798] [INFO] [launch.py:256:main] process 1095953 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 07:19:23,799] [INFO] [launch.py:256:main] process 1095954 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 07:19:23,800] [INFO] [launch.py:256:main] process 1095955 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 07:19:23,800] [INFO] [launch.py:256:main] process 1095956 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 07:19:23,801] [INFO] [launch.py:256:main] process 1095957 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 07:19:23,802] [INFO] [launch.py:256:main] process 1095958 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 07:19:24,126] [INFO] [launch.py:139:main] 26 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-059: [2024-07-08 07:19:24,126] [INFO] [launch.py:139:main] 26 NCCL_SOCKET_IFNAME=eno1
ml-512-node-059: [2024-07-08 07:19:24,126] [INFO] [launch.py:139:main] 26 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-059: [2024-07-08 07:19:24,126] [INFO] [launch.py:139:main] 26 NCCL_P2P_LEVEL=NVL
ml-512-node-059: [2024-07-08 07:19:24,126] [INFO] [launch.py:139:main] 26 NCCL_DEBUG=WARN
ml-512-node-059: [2024-07-08 07:19:24,126] [INFO] [launch.py:139:main] 26 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-059: [2024-07-08 07:19:24,126] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-059: [2024-07-08 07:19:24,126] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=26
ml-512-node-059: [2024-07-08 07:19:24,127] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-059: [2024-07-08 07:19:24,127] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-059: [2024-07-08 07:19:24,127] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-059: [2024-07-08 07:19:24,127] [INFO] [launch.py:256:main] process 1083089 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 07:19:24,128] [INFO] [launch.py:256:main] process 1083090 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 07:19:24,129] [INFO] [launch.py:256:main] process 1083091 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 07:19:24,130] [INFO] [launch.py:256:main] process 1083092 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 07:19:24,130] [INFO] [launch.py:256:main] process 1083093 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 07:19:24,131] [INFO] [launch.py:256:main] process 1083094 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 07:19:24,131] [INFO] [launch.py:256:main] process 1083095 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 07:19:24,131] [INFO] [launch.py:256:main] process 1083096 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:139:main] 20 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:139:main] 20 NCCL_SOCKET_IFNAME=eno1
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:139:main] 20 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:139:main] 20 NCCL_P2P_LEVEL=NVL
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:139:main] 20 NCCL_DEBUG=WARN
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:139:main] 20 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=20
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-053: [2024-07-08 07:19:24,197] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-053: [2024-07-08 07:19:24,198] [INFO] [launch.py:256:main] process 1088091 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 07:19:24,199] [INFO] [launch.py:256:main] process 1088092 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 07:19:24,200] [INFO] [launch.py:256:main] process 1088093 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 07:19:24,200] [INFO] [launch.py:256:main] process 1088094 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 07:19:24,201] [INFO] [launch.py:256:main] process 1088095 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 07:19:24,201] [INFO] [launch.py:256:main] process 1088096 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 07:19:24,202] [INFO] [launch.py:256:main] process 1088097 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 07:19:24,202] [INFO] [launch.py:256:main] process 1088098 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 07:19:24,229] [INFO] [launch.py:139:main] 16 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-049: [2024-07-08 07:19:24,229] [INFO] [launch.py:139:main] 16 NCCL_SOCKET_IFNAME=eno1
ml-512-node-049: [2024-07-08 07:19:24,229] [INFO] [launch.py:139:main] 16 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-049: [2024-07-08 07:19:24,229] [INFO] [launch.py:139:main] 16 NCCL_P2P_LEVEL=NVL
ml-512-node-049: [2024-07-08 07:19:24,229] [INFO] [launch.py:139:main] 16 NCCL_DEBUG=WARN
ml-512-node-049: [2024-07-08 07:19:24,229] [INFO] [launch.py:139:main] 16 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-049: [2024-07-08 07:19:24,229] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-049: [2024-07-08 07:19:24,230] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=16
ml-512-node-049: [2024-07-08 07:19:24,230] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-049: [2024-07-08 07:19:24,230] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-049: [2024-07-08 07:19:24,230] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-049: [2024-07-08 07:19:24,230] [INFO] [launch.py:256:main] process 1090303 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 07:19:24,231] [INFO] [launch.py:256:main] process 1090304 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 07:19:24,232] [INFO] [launch.py:256:main] process 1090305 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:139:main] 30 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:139:main] 30 NCCL_SOCKET_IFNAME=eno1
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:139:main] 30 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:139:main] 30 NCCL_P2P_LEVEL=NVL
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:139:main] 30 NCCL_DEBUG=WARN
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:139:main] 30 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=30
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-063: [2024-07-08 07:19:24,231] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-049: [2024-07-08 07:19:24,232] [INFO] [launch.py:256:main] process 1090306 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 07:19:24,232] [INFO] [launch.py:256:main] process 1082938 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 07:19:24,233] [INFO] [launch.py:256:main] process 1090307 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 07:19:24,233] [INFO] [launch.py:256:main] process 1082939 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 07:19:24,233] [INFO] [launch.py:256:main] process 1090308 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 07:19:24,234] [INFO] [launch.py:256:main] process 1082940 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 07:19:24,234] [INFO] [launch.py:256:main] process 1090309 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 07:19:24,234] [INFO] [launch.py:256:main] process 1082941 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 07:19:24,235] [INFO] [launch.py:256:main] process 1090310 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 07:19:24,235] [INFO] [launch.py:256:main] process 1082942 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 07:19:24,235] [INFO] [launch.py:256:main] process 1082943 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 07:19:24,236] [INFO] [launch.py:256:main] process 1082944 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 07:19:24,237] [INFO] [launch.py:256:main] process 1082945 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 07:19:25,855] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 07:19:26,011] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 07:19:26,157] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 07:19:26,392] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 07:19:26,596] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 07:19:26,620] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 07:19:26,620] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 07:19:26,635] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 07:19:26,667] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [2024-07-08 07:19:26,850] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 07:19:27,179] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 07:19:27,180] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 07:19:27,332] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 07:19:27,351] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 07:19:27,620] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [2024-07-08 07:19:27,643] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 07:19:27,836] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 07:19:27,850] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [2024-07-08 07:19:27,925] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 07:19:28,026] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 07:19:28,060] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 07:19:28,068] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 07:19:28,085] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 07:19:28,137] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [2024-07-08 07:19:28,160] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 07:19:28,198] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 07:19:28,201] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 07:19:28,202] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 07:19:28,213] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 07:19:28,235] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 07:19:28,246] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 07:19:28,285] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 07:19:28,297] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 07:19:28,297] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 07:19:28,313] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 07:19:28,315] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 07:19:28,321] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 07:19:28,343] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [2024-07-08 07:19:28,356] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 07:19:28,368] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 07:19:28,368] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 07:19:28,384] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 07:19:28,386] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 07:19:28,382] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [2024-07-08 07:19:28,405] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 07:19:28,405] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 07:19:28,409] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [2024-07-08 07:19:28,419] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 07:19:28,424] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [2024-07-08 07:19:28,439] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 07:19:28,445] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 07:19:28,451] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 07:19:28,453] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 07:19:28,460] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 07:19:28,462] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 07:19:28,485] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 07:19:28,493] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-063: [2024-07-08 07:19:28,498] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 07:19:28,517] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 07:19:28,519] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [2024-07-08 07:19:28,515] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [2024-07-08 07:19:28,524] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 07:19:28,532] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 07:19:28,534] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [2024-07-08 07:19:28,538] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 07:19:28,542] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 07:19:28,542] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 07:19:28,541] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 07:19:28,546] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [2024-07-08 07:19:28,548] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 07:19:28,564] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [2024-07-08 07:19:28,564] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 07:19:28,566] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 07:19:28,577] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 07:19:28,577] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 07:19:28,584] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 07:19:28,589] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [2024-07-08 07:19:28,595] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 07:19:28,599] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 07:19:28,603] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 07:19:28,604] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 07:19:28,607] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 07:19:28,611] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 07:19:28,611] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 07:19:28,611] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [2024-07-08 07:19:28,624] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 07:19:28,626] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 07:19:28,626] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 07:19:28,628] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [2024-07-08 07:19:28,651] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [2024-07-08 07:19:28,673] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [2024-07-08 07:19:28,679] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 07:19:28,683] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 07:19:28,683] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [2024-07-08 07:19:28,686] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 07:19:28,689] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 07:19:28,691] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 07:19:28,693] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 07:19:28,699] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 07:19:28,699] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [2024-07-08 07:19:28,705] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 07:19:28,708] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [2024-07-08 07:19:28,709] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [2024-07-08 07:19:28,713] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 07:19:28,719] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [2024-07-08 07:19:28,724] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 07:19:28,746] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 07:19:28,749] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 07:19:28,753] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 07:19:28,753] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 07:19:28,760] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 07:19:28,770] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [2024-07-08 07:19:28,773] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 07:19:28,774] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 07:19:28,779] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 07:19:28,774] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 07:19:28,781] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 07:19:28,786] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 07:19:28,785] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [2024-07-08 07:19:28,794] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 07:19:28,800] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 07:19:28,803] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [2024-07-08 07:19:28,814] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 07:19:28,811] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [2024-07-08 07:19:28,814] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 07:19:28,817] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 07:19:28,818] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 07:19:28,820] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 07:19:28,820] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [2024-07-08 07:19:28,824] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [2024-07-08 07:19:28,828] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 07:19:28,829] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 07:19:28,814] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [2024-07-08 07:19:28,837] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [2024-07-08 07:19:28,849] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [2024-07-08 07:19:28,862] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 07:19:28,866] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [2024-07-08 07:19:28,868] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [2024-07-08 07:19:28,868] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 07:19:28,872] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 07:19:28,876] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 07:19:28,881] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [2024-07-08 07:19:28,893] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [2024-07-08 07:19:28,899] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 07:19:28,902] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 07:19:28,900] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [2024-07-08 07:19:28,910] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [2024-07-08 07:19:28,904] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [2024-07-08 07:19:28,910] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 07:19:28,915] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [2024-07-08 07:19:28,918] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 07:19:28,918] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [2024-07-08 07:19:28,927] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 07:19:28,928] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [2024-07-08 07:19:28,929] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [2024-07-08 07:19:28,931] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [2024-07-08 07:19:28,935] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [2024-07-08 07:19:28,941] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 07:19:28,944] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 07:19:28,947] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 07:19:28,947] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 07:19:28,952] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [2024-07-08 07:19:28,955] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 07:19:28,954] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [2024-07-08 07:19:28,955] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [2024-07-08 07:19:28,967] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 07:19:28,968] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [2024-07-08 07:19:28,972] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 07:19:28,973] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [2024-07-08 07:19:28,980] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [2024-07-08 07:19:28,990] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 07:19:28,992] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 07:19:29,001] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [2024-07-08 07:19:29,009] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 07:19:29,014] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [2024-07-08 07:19:29,023] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 07:19:29,025] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [2024-07-08 07:19:29,024] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 07:19:29,022] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [2024-07-08 07:19:29,029] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [2024-07-08 07:19:29,031] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 07:19:29,030] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 07:19:29,030] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 07:19:29,033] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 07:19:29,032] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [2024-07-08 07:19:29,041] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [2024-07-08 07:19:29,046] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 07:19:29,049] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [2024-07-08 07:19:29,056] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [2024-07-08 07:19:29,058] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [2024-07-08 07:19:29,060] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [2024-07-08 07:19:29,068] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [2024-07-08 07:19:29,071] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 07:19:29,076] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 07:19:29,077] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 07:19:29,080] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [2024-07-08 07:19:29,079] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 07:19:29,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [2024-07-08 07:19:29,086] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [2024-07-08 07:19:29,095] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 07:19:29,101] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [2024-07-08 07:19:29,103] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 07:19:29,104] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [2024-07-08 07:19:29,107] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 07:19:29,114] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [2024-07-08 07:19:29,111] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 07:19:29,116] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [2024-07-08 07:19:29,123] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 07:19:29,130] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [2024-07-08 07:19:29,141] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 07:19:29,143] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [2024-07-08 07:19:29,152] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [2024-07-08 07:19:29,155] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 07:19:29,175] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [2024-07-08 07:19:29,188] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [2024-07-08 07:19:29,208] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [2024-07-08 07:19:29,230] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [2024-07-08 07:19:29,236] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 07:19:29,244] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [2024-07-08 07:19:29,280] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [2024-07-08 07:19:29,306] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [2024-07-08 07:19:29,308] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 07:19:29,316] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [2024-07-08 07:19:29,341] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [2024-07-08 07:19:29,361] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 07:19:29,391] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [2024-07-08 07:19:29,412] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [2024-07-08 07:19:29,458] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [2024-07-08 07:19:29,463] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 07:19:29,464] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [2024-07-08 07:19:29,506] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [2024-07-08 07:19:29,517] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 07:19:29,534] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [2024-07-08 07:19:29,536] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [2024-07-08 07:19:29,548] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [2024-07-08 07:19:29,597] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [2024-07-08 07:19:29,607] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [2024-07-08 07:19:29,642] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [2024-07-08 07:19:29,657] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 07:19:29,718] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [2024-07-08 07:19:29,720] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 07:19:29,729] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [2024-07-08 07:19:29,734] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 07:19:29,738] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [2024-07-08 07:19:29,773] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 07:19:29,773] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [2024-07-08 07:19:29,781] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 07:19:29,788] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [2024-07-08 07:19:29,793] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [2024-07-08 07:19:29,809] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [2024-07-08 07:19:29,812] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:29,817] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 07:19:29,822] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [2024-07-08 07:19:29,834] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 07:19:29,845] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [2024-07-08 07:19:29,861] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 07:19:29,892] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 07:19:29,905] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 07:19:29,906] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:29,912] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 07:19:29,929] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 07:19:29,928] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [2024-07-08 07:19:29,928] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 07:19:29,936] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 07:19:29,941] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [2024-07-08 07:19:29,941] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 07:19:29,947] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 07:19:29,953] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [2024-07-08 07:19:29,968] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 07:19:29,970] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 07:19:29,971] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [2024-07-08 07:19:29,970] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 07:19:29,983] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [2024-07-08 07:19:29,993] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [2024-07-08 07:19:29,998] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 07:19:30,004] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [2024-07-08 07:19:30,024] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 07:19:30,021] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:30,028] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [2024-07-08 07:19:30,036] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 07:19:30,040] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [2024-07-08 07:19:30,043] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [2024-07-08 07:19:30,046] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [2024-07-08 07:19:30,054] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [2024-07-08 07:19:30,060] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [2024-07-08 07:19:30,067] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [2024-07-08 07:19:30,095] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 07:19:30,097] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 07:19:30,099] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [2024-07-08 07:19:30,105] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 07:19:30,107] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 07:19:30,111] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [2024-07-08 07:19:30,115] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 07:19:30,123] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 07:19:30,126] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 07:19:30,128] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 07:19:30,129] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [2024-07-08 07:19:30,136] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 07:19:30,141] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:30,142] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [2024-07-08 07:19:30,145] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 07:19:30,146] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 07:19:30,157] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 07:19:30,153] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 07:19:30,162] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 07:19:30,168] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [2024-07-08 07:19:30,203] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [2024-07-08 07:19:30,216] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 07:19:30,220] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 07:19:30,219] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 07:19:30,224] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [2024-07-08 07:19:30,269] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 07:19:30,269] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [2024-07-08 07:19:30,288] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 07:19:30,288] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 07:19:30,288] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [2024-07-08 07:19:30,294] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [2024-07-08 07:19:30,301] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 07:19:30,305] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 07:19:30,306] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 07:19:30,309] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [2024-07-08 07:19:30,326] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 07:19:30,327] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 07:19:30,339] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 07:19:30,347] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [2024-07-08 07:19:30,365] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 07:19:30,373] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 07:19:30,389] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [2024-07-08 07:19:30,396] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 07:19:30,402] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 07:19:30,398] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [2024-07-08 07:19:30,425] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 07:19:30,426] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [2024-07-08 07:19:30,453] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 07:19:30,456] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 07:19:30,460] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 07:19:30,468] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [2024-07-08 07:19:30,481] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [2024-07-08 07:19:30,505] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [2024-07-08 07:19:30,523] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [2024-07-08 07:19:30,529] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 07:19:30,532] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [2024-07-08 07:19:30,549] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 07:19:30,548] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 07:19:30,552] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 07:19:30,555] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 07:19:30,555] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [2024-07-08 07:19:30,565] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 07:19:30,566] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 07:19:30,567] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 07:19:30,570] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 07:19:30,568] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 07:19:30,587] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 07:19:30,596] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 07:19:30,612] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 07:19:30,629] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 07:19:30,636] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 07:19:30,637] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [2024-07-08 07:19:30,639] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 07:19:30,649] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [2024-07-08 07:19:30,650] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 07:19:30,663] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 07:19:30,662] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [2024-07-08 07:19:30,675] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [2024-07-08 07:19:30,688] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 07:19:30,695] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [2024-07-08 07:19:30,702] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [2024-07-08 07:19:30,701] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 07:19:30,706] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [2024-07-08 07:19:30,713] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 07:19:30,716] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 07:19:30,721] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 07:19:30,725] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 07:19:30,725] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [2024-07-08 07:19:30,734] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 07:19:30,736] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [2024-07-08 07:19:30,736] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 07:19:30,735] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 07:19:30,739] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 07:19:30,737] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 07:19:30,757] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 07:19:30,760] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 07:19:30,761] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [2024-07-08 07:19:30,770] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 07:19:30,773] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 07:19:30,774] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 07:19:30,779] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 07:19:30,776] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 07:19:30,784] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 07:19:30,795] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 07:19:30,802] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [2024-07-08 07:19:30,806] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 07:19:30,807] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 07:19:30,821] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 07:19:30,822] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 07:19:30,826] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 07:19:30,828] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 07:19:30,826] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [2024-07-08 07:19:30,831] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 07:19:30,834] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 07:19:30,844] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 07:19:30,846] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 07:19:30,851] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 07:19:30,851] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 07:19:30,850] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 07:19:30,850] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 07:19:30,861] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 07:19:30,861] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [2024-07-08 07:19:30,864] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 07:19:30,867] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 07:19:30,870] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 07:19:30,872] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 07:19:30,872] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 07:19:30,875] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 07:19:30,878] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 07:19:30,887] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 07:19:30,888] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [2024-07-08 07:19:30,889] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [2024-07-08 07:19:30,910] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 07:19:30,908] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 07:19:30,911] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 07:19:30,911] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 07:19:30,913] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 07:19:30,910] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [2024-07-08 07:19:30,920] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [2024-07-08 07:19:30,924] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 07:19:30,924] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 07:19:30,934] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 07:19:30,934] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 07:19:30,936] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 07:19:30,935] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 07:19:30,938] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 07:19:30,941] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 07:19:30,946] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 07:19:30,947] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [2024-07-08 07:19:30,953] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 07:19:30,955] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 07:19:30,951] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [2024-07-08 07:19:30,957] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 07:19:30,956] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 07:19:30,957] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 07:19:30,966] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 07:19:30,985] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 07:19:30,985] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 07:19:30,985] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [2024-07-08 07:19:30,996] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 07:19:30,995] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 07:19:31,002] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 07:19:31,002] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [2024-07-08 07:19:31,015] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 07:19:31,023] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [2024-07-08 07:19:31,031] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 07:19:31,032] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:31,035] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 07:19:31,038] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [2024-07-08 07:19:31,055] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 07:19:31,055] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 07:19:31,058] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 07:19:31,058] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [2024-07-08 07:19:31,059] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 07:19:31,067] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 07:19:31,075] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 07:19:31,082] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [2024-07-08 07:19:31,106] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 07:19:31,114] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 07:19:31,115] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 07:19:31,119] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 07:19:31,119] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 07:19:31,120] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 07:19:31,143] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 07:19:31,187] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 07:19:31,218] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 07:19:31,299] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 07:19:31,331] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:31,346] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 07:19:31,355] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:31,422] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 07:19:31,424] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:31,427] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 07:19:31,439] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [2024-07-08 07:19:31,456] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 07:19:31,547] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 07:19:31,568] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 07:19:31,721] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 07:19:31,761] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 07:19:31,778] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 07:19:31,795] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 07:19:31,848] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 07:19:31,872] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 07:19:31,883] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 07:19:31,897] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 07:19:31,905] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 07:19:31,905] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:31,924] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 07:19:31,930] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 07:19:31,938] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 07:19:31,947] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 07:19:31,950] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 07:19:31,961] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 07:19:31,964] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 07:19:31,971] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 07:19:31,981] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 07:19:32,024] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:32,024] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 07:19:32,026] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 07:19:32,027] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 07:19:32,033] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 07:19:32,095] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 07:19:32,134] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 07:19:32,195] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 07:19:32,229] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 07:19:32,316] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 07:19:32,374] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: NCCL version 2.19.4+cuda12.2
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-049:   warnings.warn(
ml-512-node-064:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-063:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-055:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-033:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-063:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-063:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-049:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-056:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-042:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-037:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-050:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-050:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-063:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-062:   warnings.warn(
ml-512-node-052:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-048:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-044:   warnings.warn(
ml-512-node-035:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-064:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-055:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-059:   warnings.warn(
ml-512-node-037:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-059:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-037:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-042:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-058:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-058:   warnings.warn(
ml-512-node-054:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-037:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-049:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-052:   warnings.warn(
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-035:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-056:   warnings.warn(
ml-512-node-064:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-060:   warnings.warn(
ml-512-node-056:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-037:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-036:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-060:   warnings.warn(
ml-512-node-061:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-060:   warnings.warn(
ml-512-node-056:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-052:   warnings.warn(
ml-512-node-061:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-035:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-061:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-056: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:12,  6.34s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:09<00:19,  9.77s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:10<00:20, 10.08s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:13<00:26, 13.41s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:13<00:27, 13.55s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:13<00:27, 13.70s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:13<00:27, 13.55s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:13<00:26, 13.40s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:18<00:09,  9.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:21<00:10, 10.98s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:21<00:10, 10.96s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:27<00:13, 13.68s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:27<00:13, 13.69s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:27<00:13, 13.79s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:27<00:13, 13.87s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:27<00:13, 13.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:29<00:00, 10.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:29<00:00,  9.69s/it]
ml-512-node-040: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:09<00:19,  9.67s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:09<00:19,  9.90s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:10<00:20, 10.06s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:12<00:25, 12.76s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:28, 14.24s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:28, 14.29s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:29, 14.50s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:14<00:28, 14.44s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.83s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:12, 12.03s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:23<00:11, 11.93s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:24<00:11, 11.88s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:28<00:14, 14.02s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:28<00:14, 14.10s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:28<00:14, 14.16s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:28<00:14, 14.19s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:31<00:00, 10.28s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:31<00:00, 10.52s/it]
ml-512-node-056: Loading checkpoint shards: 100%|██████████| 3/3 [00:32<00:00, 10.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:32<00:00, 10.86s/it]
ml-512-node-040: Loading checkpoint shards: 100%|██████████| 3/3 [00:32<00:00, 10.86s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:32<00:00, 10.94s/it]
ml-512-node-040: Loading checkpoint shards: 100%|██████████| 3/3 [00:33<00:00, 11.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:33<00:00, 11.04s/it]
ml-512-node-056: Loading checkpoint shards: 100%|██████████| 3/3 [00:33<00:00, 11.19s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:33<00:00, 11.01s/it]
ml-512-node-040: Loading checkpoint shards: 100%|██████████| 3/3 [00:34<00:00, 11.21s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:34<00:00, 11.48s/it]
ml-512-node-056: Loading checkpoint shards: 100%|██████████| 3/3 [00:40<00:00, 13.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:40<00:00, 13.50s/it]
ml-512-node-056: Loading checkpoint shards: 100%|██████████| 3/3 [00:40<00:00, 13.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:40<00:00, 13.46s/it]
ml-512-node-056: Loading checkpoint shards: 100%|██████████| 3/3 [00:40<00:00, 13.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:40<00:00, 13.59s/it]
ml-512-node-056: Loading checkpoint shards: 100%|██████████| 3/3 [00:41<00:00, 13.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:41<00:00, 13.76s/it]
ml-512-node-056: Loading checkpoint shards: 100%|██████████| 3/3 [00:41<00:00, 13.78s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:41<00:00, 13.76s/it]
ml-512-node-040: Loading checkpoint shards: 100%|██████████| 3/3 [00:41<00:00, 13.78s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:41<00:00, 13.87s/it]
ml-512-node-040: Loading checkpoint shards: 100%|██████████| 3/3 [00:41<00:00, 13.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:41<00:00, 13.89s/it]
ml-512-node-040: Loading checkpoint shards: 100%|██████████| 3/3 [00:42<00:00, 14.06s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:42<00:00, 14.09s/it]
ml-512-node-040: Loading checkpoint shards: 100%|██████████| 3/3 [00:42<00:00, 14.31s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:42<00:00, 14.30s/it]
ml-512-node-050: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:19<00:39, 19.74s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.66s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.00s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.93s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.05s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.91s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.16s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:42<00:21, 21.67s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:42<00:21, 21.28s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:42<00:21, 21.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.23s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:42<00:21, 21.16s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:42<00:21, 21.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:41<00:20, 20.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:56<00:00, 18.20s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:56<00:00, 18.95s/it]
ml-512-node-050: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.14s/it]
ml-512-node-050: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.09s/it]
ml-512-node-042: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:20<00:41, 20.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.44s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.03s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.52s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.74s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.80s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.81s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.73s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.89s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.68s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.78s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.94s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.23s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.13s/it]
ml-512-node-050: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.02s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.08s/it]
ml-512-node-039: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.03s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.77s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.73s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.64s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.80s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.61s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:22, 22.09s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.73s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.94s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.91s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.98s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.97s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.08s/it]
ml-512-node-050: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.97s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.01s/it]
ml-512-node-050: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.97s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.00s/it]
ml-512-node-050: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.01s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.05s/it]
ml-512-node-050: Loading checkpoint shards: 100%|██████████| 3/3 [00:55<00:00, 17.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:55<00:00, 18.65s/it]
ml-512-node-042: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.10s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.14s/it]
ml-512-node-039: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.91s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.07s/it]
ml-512-node-039: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.91s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.05s/it]
ml-512-node-042: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.19s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.29s/it]
ml-512-node-039: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.16s/it]
ml-512-node-039: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.20s/it]
ml-512-node-039: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.22s/it]
ml-512-node-039: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.99s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.27s/it]
ml-512-node-039: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.97s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.23s/it]
ml-512-node-042: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.45s/it]
ml-512-node-042: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.23s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.42s/it]
ml-512-node-042: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.20s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.36s/it]
ml-512-node-042: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.44s/it]
ml-512-node-042: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.47s/it]
ml-512-node-046: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:20<00:41, 20.66s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.26s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.37s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.48s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.53s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.59s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.45s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.48s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.83s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.88s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.91s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.48s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.53s/it]
ml-512-node-046: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.29s/it]
ml-512-node-034: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.41s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.61s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.13s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.30s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.01s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.13s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.00s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.10s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.93s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.44s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.71s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.14s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.06s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.02s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.03s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.07s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.35s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.35s/it]
ml-512-node-036: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.27s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.20s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.58s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.09s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.15s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.08s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.03s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.27s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.36s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.03s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.16s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.77s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.22s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.16s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.14s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.39s/it]
ml-512-node-063: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.65s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.16s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.90s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.82s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.90s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.05s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.02s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.91s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.99s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.11s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.28s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.23s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.25s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.31s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.26s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.36s/it]
ml-512-node-046: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.57s/it]
ml-512-node-034: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.11s/it]
ml-512-node-034: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.15s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.34s/it]
ml-512-node-044: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.92s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.45s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.61s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.92s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.18s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.34s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.05s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.99s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.93s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.23s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.94s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.89s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.91s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.00s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.06s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.55s/it]
ml-512-node-063: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.31s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.39s/it]
ml-512-node-044: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.56s/it]
ml-512-node-044: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.56s/it]
ml-512-node-061: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.44s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.67s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.87s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.42s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.27s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.24s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:22, 22.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.64s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.66s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.72s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.77s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.71s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.63s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.49s/it]
ml-512-node-063: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.44s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.39s/it]
ml-512-node-046: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.44s/it]
ml-512-node-046: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.36s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.45s/it]
ml-512-node-046: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.47s/it]
ml-512-node-046: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.50s/it]
ml-512-node-046: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.36s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.46s/it]
ml-512-node-036: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.29s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.42s/it]
ml-512-node-036: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.32s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.48s/it]
ml-512-node-052: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.67s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.16s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.30s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.97s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.94s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.45s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.50s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.02s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.03s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.23s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.21s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.02s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.32s/it]
ml-512-node-061: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.41s/it]
ml-512-node-061: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.45s/it]
ml-512-node-052: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.28s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.39s/it]
ml-512-node-044: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.62s/it]
ml-512-node-034: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.34s/it]
ml-512-node-033: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.82s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.23s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.60s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.01s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.16s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.22s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.01s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.18s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.67s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.39s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.00s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.58s/it]
ml-512-node-044: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.50s/it]
ml-512-node-044: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.58s/it]
ml-512-node-034: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.35s/it]
ml-512-node-033: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.61s/it]
ml-512-node-035: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.69s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.56s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.52s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.08s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.36s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.94s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.50s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.54s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.67s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.08s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.20s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.44s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.28s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.39s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.47s/it]
ml-512-node-044: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.51s/it]
ml-512-node-034: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.39s/it]
ml-512-node-034: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.17s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.46s/it]
ml-512-node-044: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.36s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.53s/it]
ml-512-node-034: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.38s/it]
ml-512-node-052: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.29s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.42s/it]
ml-512-node-033: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.20s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.19s/it]
ml-512-node-035: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.16s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.20s/it]
ml-512-node-035: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.36s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.51s/it]
ml-512-node-063: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.60s/it]
ml-512-node-061: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.47s/it]
ml-512-node-061: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.45s/it]
ml-512-node-063: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.64s/it]
ml-512-node-061: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.46s/it]
ml-512-node-061: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.44s/it]
ml-512-node-061: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.51s/it]
ml-512-node-036: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.61s/it]
ml-512-node-063: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.44s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.66s/it]
ml-512-node-063: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.40s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.61s/it]
ml-512-node-036: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.35s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.57s/it]
ml-512-node-036: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.56s/it]
ml-512-node-036: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.55s/it]
ml-512-node-036: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.14s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.26s/it]
ml-512-node-052: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.23s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.40s/it]
ml-512-node-052: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.57s/it]
ml-512-node-052: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.56s/it]
ml-512-node-052: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.23s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.39s/it]
ml-512-node-063: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.61s/it]
ml-512-node-033: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.54s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.75s/it]
ml-512-node-052: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.58s/it]
ml-512-node-057: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.21s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.26s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.79s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.76s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.86s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.86s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.88s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.89s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.79s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.95s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.95s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.95s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.95s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.60s/it]
ml-512-node-033: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.35s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.46s/it]
ml-512-node-035: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.62s/it]
ml-512-node-041: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.85s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.31s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.09s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.72s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.72s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.76s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.74s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.73s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.13s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.99s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.71s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.12s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.12s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.14s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.45s/it]
ml-512-node-035: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.72s/it]
ml-512-node-033: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.56s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.76s/it]
ml-512-node-057: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.67s/it]
ml-512-node-033: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.57s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.78s/it]
ml-512-node-035: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.78s/it]
ml-512-node-057: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.56s/it]
ml-512-node-035: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.59s/it]
ml-512-node-035: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.77s/it]
ml-512-node-033: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.56s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.74s/it]
ml-512-node-041: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.59s/it]
ml-512-node-041: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.62s/it]
ml-512-node-057: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.58s/it]
ml-512-node-057: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.56s/it]
ml-512-node-041: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.69s/it]
ml-512-node-057: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.35s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.58s/it]
ml-512-node-041: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.68s/it]
ml-512-node-041: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.21s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.35s/it]
ml-512-node-041: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.69s/it]
ml-512-node-041: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.44s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.70s/it]
ml-512-node-057: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.35s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.58s/it]
ml-512-node-057: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.36s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.59s/it]
ml-512-node-064: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.30s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.16s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.13s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.27s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.37s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.32s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.67s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.90s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.64s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.89s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.87s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.89s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.53s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.70s/it]
ml-512-node-043: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.64s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.63s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.75s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.58s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.77s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.63s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.54s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.76s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.75s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.41s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.93s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.26s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.58s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.63s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.86s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.80s/it]
ml-512-node-043: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.67s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.80s/it]
ml-512-node-064: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.71s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.78s/it]
ml-512-node-064: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.55s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.72s/it]
ml-512-node-043: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.48s/it]
ml-512-node-054: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.82s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.42s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.32s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.47s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.61s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.59s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.59s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.73s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.81s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.81s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.40s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.82s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.86s/it]
ml-512-node-047: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.35s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.49s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.46s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.30s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.43s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.34s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.41s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.91s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.08s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.88s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.29s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.34s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.13s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.63s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.87s/it]
ml-512-node-047: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.89s/it]
ml-512-node-047: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.67s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.90s/it]
ml-512-node-054: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.85s/it]
ml-512-node-054: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.67s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.77s/it]
ml-512-node-064: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.64s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.94s/it]
ml-512-node-064: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.63s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.92s/it]
ml-512-node-064: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.63s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.92s/it]
ml-512-node-064: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.87s/it]
ml-512-node-064: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.64s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.92s/it]
ml-512-node-043: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.03s/it]
ml-512-node-043: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.76s/it]
ml-512-node-054: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.76s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.02s/it]
ml-512-node-051: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.38s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.94s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.06s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.64s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.55s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.59s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.61s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.73s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.68s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.25s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.68s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.67s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.72s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.87s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.02s/it]
ml-512-node-051: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.01s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.01s/it]
ml-512-node-054: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.05s/it]
ml-512-node-051: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.68s/it]
ml-512-node-047: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.67s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.03s/it]
ml-512-node-047: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.03s/it]
ml-512-node-045: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.23s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.41s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.46s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.09s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.22s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.38s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.40s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.80s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.94s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.04s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.00s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.07s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.99s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.98s/it]
ml-512-node-054: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.57s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.72s/it]
ml-512-node-047: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.70s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.06s/it]
ml-512-node-054: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.06s/it]
ml-512-node-047: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.49s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.73s/it]
ml-512-node-043: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.05s/it]
ml-512-node-054: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.80s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.06s/it]
ml-512-node-045: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.05s/it]
ml-512-node-047: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.90s/it]
ml-512-node-045: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.86s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.86s/it]
ml-512-node-051: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.72s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.98s/it]
ml-512-node-043: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.09s/it]
ml-512-node-051: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.02s/it]
ml-512-node-051: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.76s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.03s/it]
ml-512-node-051: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 20.00s/it]
ml-512-node-051: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 20.00s/it]
ml-512-node-045: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.20s/it]
ml-512-node-045: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.91s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.12s/it]
ml-512-node-045: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.20s/it]
ml-512-node-045: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.17s/it]
ml-512-node-045: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.17s/it]
ml-512-node-060: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.30s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.44s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.06s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.68s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.26s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.53s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.69s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.57s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.63s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.08s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.02s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.10s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.51s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.05s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.87s/it]
ml-512-node-055: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.68s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.24s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.61s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.77s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.56s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.95s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.91s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.66s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.96s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.72s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.41s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.77s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.99s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.04s/it]
ml-512-node-060: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.92s/it]
ml-512-node-037: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.90s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.81s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.96s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.43s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.73s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.57s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.36s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.49s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.98s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.00s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.02s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.96s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.03s/it]
ml-512-node-037: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.10s/it]
ml-512-node-060: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 20.00s/it]
ml-512-node-037: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.08s/it]
ml-512-node-059: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.19s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.97s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.13s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.91s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.02s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.07s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.20s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.22s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.11s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.55s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.57s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.55s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.52s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.93s/it]
ml-512-node-062: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.27s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.76s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.79s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.02s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.01s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.96s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.94s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.13s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.41s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.55s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.49s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.32s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.02s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.25s/it]
ml-512-node-060: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.19s/it]
ml-512-node-060: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.19s/it]
ml-512-node-043: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.25s/it]
ml-512-node-060: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.72s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.72s/it]
ml-512-node-060: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.01s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.14s/it]
ml-512-node-062: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.26s/it]
ml-512-node-060: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.02s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.16s/it]
ml-512-node-055: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.08s/it]
ml-512-node-059: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.86s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.03s/it]
ml-512-node-055: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.12s/it]
ml-512-node-037: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.06s/it]
ml-512-node-037: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.83s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.14s/it]
ml-512-node-037: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.02s/it]
ml-512-node-037: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.06s/it]
ml-512-node-037: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.80s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.09s/it]
ml-512-node-059: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.85s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.02s/it]
ml-512-node-062: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.32s/it]
ml-512-node-048: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.63s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.95s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.03s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.01s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.07s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.87s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.24s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.89s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:23, 23.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.93s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.04s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.91s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.07s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.02s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.12s/it]
ml-512-node-055: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.83s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.98s/it]
ml-512-node-055: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.09s/it]
ml-512-node-055: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.65s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.70s/it]
ml-512-node-055: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.83s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.97s/it]
ml-512-node-055: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.91s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.08s/it]
ml-512-node-048: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.12s/it]
ml-512-node-048: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.09s/it]
ml-512-node-059: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.71s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.88s/it]
ml-512-node-059: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.25s/it]
ml-512-node-059: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.24s/it]
ml-512-node-059: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.21s/it]
ml-512-node-059: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.24s/it]
ml-512-node-038: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.67s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.61s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.93s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.64s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.74s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.62s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.23s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.72s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.42s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.76s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.02s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.84s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.06s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.00s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.13s/it]
ml-512-node-038: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.27s/it]
ml-512-node-038: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.99s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.24s/it]
ml-512-node-038: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.89s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.10s/it]
ml-512-node-038: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.13s/it]
ml-512-node-038: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.02s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.30s/it]
ml-512-node-038: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.99s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.24s/it]
ml-512-node-038: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.77s/it]
ml-512-node-062: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.06s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.29s/it]
ml-512-node-053: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.53s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.93s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.03s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.09s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.29s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.22s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.41s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.36s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.36s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.50s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.28s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.21s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.38s/it]
ml-512-node-053: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.20s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.39s/it]
ml-512-node-053: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.17s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.36s/it]
ml-512-node-048: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.26s/it]
ml-512-node-048: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.25s/it]
ml-512-node-048: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.18s/it]
ml-512-node-048: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.26s/it]
ml-512-node-048: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.13s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.31s/it]
ml-512-node-053: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.28s/it]
ml-512-node-053: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.31s/it]
ml-512-node-053: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.99s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.23s/it]
ml-512-node-053: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.30s/it]
ml-512-node-053: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.27s/it]
ml-512-node-062: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.16s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.37s/it]
ml-512-node-062: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.13s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.33s/it]
ml-512-node-062: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.17s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.37s/it]
ml-512-node-062: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.21s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.39s/it]
ml-512-node-058: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.78s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.09s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.09s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.20s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.36s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.47s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.58s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.64s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.40s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.34s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.49s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.36s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.45s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.35s/it]
ml-512-node-058: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.20s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.29s/it]
ml-512-node-058: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.49s/it]
ml-512-node-058: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.20s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.41s/it]
ml-512-node-058: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.30s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.36s/it]
ml-512-node-058: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.21s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.43s/it]
ml-512-node-058: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.22s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.47s/it]
ml-512-node-058: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.23s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.47s/it]
ml-512-node-049: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.51s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.48s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.37s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.43s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.24s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.39s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.48s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.89s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:24, 24.04s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:24, 24.03s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.28s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.35s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.40s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.56s/it]
ml-512-node-049: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.67s/it]
ml-512-node-049: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.68s/it]
ml-512-node-049: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.89s/it]
ml-512-node-049: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.86s/it]
ml-512-node-049: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.64s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.92s/it]
ml-512-node-049: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.66s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.93s/it]
ml-512-node-049: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.66s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.93s/it]
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Detected CUDA files, patching ldflags
ml-512-node-056: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-056: Building extension module fused_adam...
ml-512-node-056: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: ninja: no work to do.
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.10552477836608887 seconds
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: ninja: no work to do.
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.10286664962768555 seconds
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.10681796073913574 seconds
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.10142707824707031 seconds
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Detected CUDA files, patching ldflags
ml-512-node-056: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-056: Building extension module fused_adam...
ml-512-node-056: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: ninja: no work to do.
ml-512-node-056: ninja: no work to do.
ml-512-node-040: Time to load fused_adam op: 0.2947702407836914 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.2477869987487793 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.406933069229126 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.4028024673461914 seconds
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.40229368209838867 seconds
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Time to load fused_adam op: 0.20188570022583008 seconds
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Detected CUDA files, patching ldflags
ml-512-node-063: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-063: Building extension module fused_adam...
ml-512-node-063: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: 
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.3019421100616455 seconds
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: ninja: no work to do.
ml-512-node-056: Time to load fused_adam op: 0.4022641181945801 seconds
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Detected CUDA files, patching ldflags
ml-512-node-034: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Time to load fused_adam op: 0.20292115211486816 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-034: Building extension module fused_adam...
ml-512-node-034: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-052: Detected CUDA files, patching ldflags
ml-512-node-052: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-052: Building extension module fused_adam...
ml-512-node-052: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Time to load fused_adam op: 0.0669097900390625 seconds
ml-512-node-040: Time to load fused_adam op: 0.3136904239654541 seconds
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Detected CUDA files, patching ldflags
ml-512-node-061: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: Building extension module fused_adam...
ml-512-node-061: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: 
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Time to load fused_adam op: 0.4033694267272949 seconds
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Detected CUDA files, patching ldflags
ml-512-node-051: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-051: Building extension module fused_adam...
ml-512-node-051: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Detected CUDA files, patching ldflags
ml-512-node-059: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Building extension module fused_adam...
ml-512-node-059: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Detected CUDA files, patching ldflags
ml-512-node-058: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-058: Building extension module fused_adam...
ml-512-node-058: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: ninja: no work to do.
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Detected CUDA files, patching ldflags
ml-512-node-063: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: ninja: no work to do.
ml-512-node-063: Building extension module fused_adam...
ml-512-node-063: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-052: ninja: no work to do.
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-060: Detected CUDA files, patching ldflags
ml-512-node-060: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: ninja: no work to do.
ml-512-node-060: Building extension module fused_adam...
ml-512-node-060: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Time to load fused_adam op: 0.06601977348327637 seconds
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Detected CUDA files, patching ldflags
ml-512-node-050: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Building extension module fused_adam...
ml-512-node-050: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Time to load fused_adam op: 0.0672910213470459 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-037: ninja: no work to do.
ml-512-node-052: Time to load fused_adam op: 0.06790041923522949 seconds
ml-512-node-061: Time to load fused_adam op: 0.06504130363464355 seconds
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Detected CUDA files, patching ldflags
ml-512-node-049: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-049: Building extension module fused_adam...
ml-512-node-049: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Time to load fused_adam op: 0.0674893856048584 seconds
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: ninja: no work to do.
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Time to load fused_adam op: 0.0663762092590332 seconds
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Detected CUDA files, patching ldflags
ml-512-node-046: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: ninja: no work to do.
ml-512-node-046: Building extension module fused_adam...
ml-512-node-046: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-055: Detected CUDA files, patching ldflags
ml-512-node-055: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: Time to load fused_adam op: 0.06835627555847168 seconds
ml-512-node-055: Building extension module fused_adam...
ml-512-node-055: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-058: ninja: no work to do.
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: ninja: no work to do.
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-058: Time to load fused_adam op: 0.06653618812561035 seconds
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: ninja: no work to do.
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-060: ninja: no work to do.
ml-512-node-038: Time to load fused_adam op: 0.06703615188598633 seconds
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: ninja: no work to do.
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-063: Time to load fused_adam op: 0.06327104568481445 seconds
ml-512-node-057: Detected CUDA files, patching ldflags
ml-512-node-057: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-057: Building extension module fused_adam...
ml-512-node-057: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-060: Time to load fused_adam op: 0.0671689510345459 seconds
ml-512-node-050: Time to load fused_adam op: 0.06565165519714355 seconds
ml-512-node-049: ninja: no work to do.
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-052: Time to load fused_adam op: 0.10148978233337402 secondsTime to load fused_adam op: 0.10141706466674805 seconds
ml-512-node-052: 
ml-512-node-062: Detected CUDA files, patching ldflags
ml-512-node-062: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Building extension module fused_adam...
ml-512-node-062: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-039: ninja: no work to do.
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Time to load fused_adam op: 0.10146188735961914 seconds
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: [2024-07-08 07:22:51,530] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.4, git-hash=unknown, git-branch=unknown
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-049: Time to load fused_adam op: 0.06653451919555664 seconds
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: [2024-07-08 07:22:51,530] [INFO] [comm.py:662:init_distributed] Distributed backend already initialized
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.10135221481323242 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.06738877296447754 seconds
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: 
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: ninja: no work to do.
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: ninja: no work to do.
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: ninja: no work to do.
ml-512-node-046: Time to load fused_adam op: 0.06714725494384766 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.06749629974365234 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.10567927360534668 seconds
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-052: Time to load fused_adam op: 0.11547422409057617 seconds
ml-512-node-055: Time to load fused_adam op: 0.06710314750671387 seconds
ml-512-node-061: Detected CUDA files, patching ldflags
ml-512-node-061: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-061: Building extension module fused_adam...
ml-512-node-061: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Time to load fused_adam op: 0.10152244567871094 seconds
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.1125326156616211 seconds
ml-512-node-057: ninja: no work to do.
ml-512-node-063: Time to load fused_adam op: 0.1056218147277832 seconds
ml-512-node-033: Time to load fused_adam op: 0.11061406135559082 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-058: Time to load fused_adam op: 0.10136699676513672 seconds
ml-512-node-052: Time to load fused_adam op: 0.12141013145446777 seconds
ml-512-node-034: Detected CUDA files, patching ldflags
ml-512-node-034: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Building extension module fused_adam...
ml-512-node-034: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Time to load fused_adam op: 0.06696486473083496 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: ninja: no work to do.
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.06886005401611328 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-051: Time to load fused_adam op: 0.10136055946350098 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-062: ninja: no work to do.
ml-512-node-062: Time to load fused_adam op: 0.0684807300567627 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-035: ninja: no work to do.
ml-512-node-035: Time to load fused_adam op: 0.06661128997802734 seconds
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-059: Time to load fused_adam op: 0.10149407386779785 seconds
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.10138726234436035 seconds
ml-512-node-039: Time to load fused_adam op: 0.10122156143188477 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-060: Time to load fused_adam op: 0.10146927833557129 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Detected CUDA files, patching ldflags
ml-512-node-041: ninja: no work to do.
ml-512-node-041: Time to load fused_adam op: 0.06563782691955566 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-049: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Time to load fused_adam op: 0.1014251708984375 seconds
ml-512-node-042: ninja: no work to do.
ml-512-node-042: Time to load fused_adam op: 0.0653233528137207 seconds
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Time to load fused_adam op: 0.101348876953125 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Building extension module fused_adam...
ml-512-node-049: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.10445117950439453 seconds
ml-512-node-046: Time to load fused_adam op: 0.10167527198791504 seconds
ml-512-node-061: ninja: no work to do.
ml-512-node-052: Time to load fused_adam op: 0.10303068161010742 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.10403203964233398 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-037: ninja: no work to do.
ml-512-node-037: Time to load fused_adam op: 0.06821489334106445 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.10160613059997559 seconds
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.1014242172241211 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.10139846801757812 seconds
ml-512-node-033: Time to load fused_adam op: 0.11601734161376953 seconds
ml-512-node-061: Time to load fused_adam op: 0.08110451698303223 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-034: ninja: no work to do.
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-046: Time to load fused_adam op: 0.10212326049804688 seconds
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Time to load fused_adam op: 0.10187435150146484 seconds
ml-512-node-050: Time to load fused_adam op: 0.1017460823059082 seconds
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Detected CUDA files, patching ldflags
ml-512-node-060: Time to load fused_adam op: 0.10745549201965332 seconds
ml-512-node-057: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Time to load fused_adam op: 0.09794092178344727 seconds
ml-512-node-052: Time to load fused_adam op: 0.10234570503234863 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-046: Time to load fused_adam op: 0.10185718536376953 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: 
ml-512-node-054: 
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Building extension module fused_adam...
ml-512-node-057: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-050: Time to load fused_adam op: 0.10164380073547363 seconds
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Time to load fused_adam op: 0.10180234909057617 seconds
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: ninja: no work to do.
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Time to load fused_adam op: 0.10781383514404297 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Time to load fused_adam op: 0.10210585594177246 seconds
ml-512-node-049: Time to load fused_adam op: 0.06323480606079102 seconds
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.10127568244934082 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-046: Time to load fused_adam op: 0.1062171459197998 seconds
ml-512-node-037: Time to load fused_adam op: 0.10390353202819824 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-046: Time to load fused_adam op: 0.10517168045043945 seconds
ml-512-node-035: Time to load fused_adam op: 0.10166645050048828 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.10152792930603027 seconds
ml-512-node-062: Time to load fused_adam op: 0.10155510902404785 seconds
ml-512-node-062: Time to load fused_adam op: 0.10143375396728516 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.10118794441223145 seconds
ml-512-node-060: Time to load fused_adam op: 0.10520172119140625 seconds
ml-512-node-060: Time to load fused_adam op: 0.10476326942443848 seconds
ml-512-node-039: Time to load fused_adam op: 0.11281108856201172 seconds
ml-512-node-039: Time to load fused_adam op: 0.10430788993835449 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.10114479064941406 seconds
ml-512-node-035: Time to load fused_adam op: 0.10115504264831543 seconds
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Time to load fused_adam op: 0.10172152519226074 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-050: Time to load fused_adam op: 0.11096334457397461 seconds
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Time to load fused_adam op: 0.2018587589263916 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Time to load fused_adam op: 0.10521578788757324 seconds
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Detected CUDA files, patching ldflags
ml-512-node-054: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-054: Building extension module fused_adam...
ml-512-node-054: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-057: ninja: no work to do.
ml-512-node-053: Detected CUDA files, patching ldflags
ml-512-node-053: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-053: Building extension module fused_adam...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-045: ninja: no work to do.
ml-512-node-058: Detected CUDA files, patching ldflags
ml-512-node-058: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-058: Building extension module fused_adam...
ml-512-node-058: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-057: Time to load fused_adam op: 0.07016563415527344 seconds
ml-512-node-051: Detected CUDA files, patching ldflags
ml-512-node-051: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-051: Building extension module fused_adam...
ml-512-node-051: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-060: Time to load fused_adam op: 0.10820698738098145 seconds
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-057: Time to load fused_adam op: 0.10126829147338867 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-063: Time to load fused_adam op: 0.20805907249450684 seconds
ml-512-node-063: Time to load fused_adam op: 0.20261311531066895 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-061: Time to load fused_adam op: 0.10172319412231445 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-061: Time to load fused_adam op: 0.20148372650146484 seconds
ml-512-node-061: Time to load fused_adam op: 0.20175814628601074 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-046: Time to load fused_adam op: 0.13509106636047363 seconds
ml-512-node-057: Time to load fused_adam op: 0.10173439979553223 seconds
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.10370707511901855 seconds
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Time to load fused_adam op: 0.21774601936340332 seconds
ml-512-node-045: Time to load fused_adam op: 0.06299972534179688 seconds
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-034: Time to load fused_adam op: 0.20211267471313477 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.1044168472290039 secondsTime to load fused_adam op: 0.10452079772949219 seconds
ml-512-node-041: 
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: ninja: no work to do.
ml-512-node-055: Time to load fused_adam op: 0.10186338424682617 seconds
ml-512-node-055: Time to load fused_adam op: 0.1015925407409668 seconds
ml-512-node-055: Time to load fused_adam op: 0.1048440933227539 seconds
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-049: Time to load fused_adam op: 0.10161781311035156 seconds
ml-512-node-049: Time to load fused_adam op: 0.10159111022949219 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.10138559341430664 seconds
ml-512-node-034: Time to load fused_adam op: 0.10284042358398438 seconds
ml-512-node-061: Time to load fused_adam op: 0.20163226127624512 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.10230541229248047 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.2062225341796875 seconds
ml-512-node-057: Time to load fused_adam op: 0.11044168472290039 seconds
ml-512-node-054: ninja: no work to do.
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-059: Detected CUDA files, patching ldflags
ml-512-node-059: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: Building extension module fused_adam...
ml-512-node-059: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-053: ninja: no work to do.
ml-512-node-038: Time to load fused_adam op: 0.0962834358215332 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-054: Time to load fused_adam op: 0.06530427932739258 seconds
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.06641125679016113 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.2100832462310791 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-042: ninja: no work to do.
ml-512-node-062: Detected CUDA files, patching ldflags
ml-512-node-062: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Building extension module fused_adam...
ml-512-node-062: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-043: ninja: no work to do.
ml-512-node-058: ninja: no work to do.
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Time to load fused_adam op: 0.1040201187133789 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-042: Time to load fused_adam op: 0.08214879035949707 seconds
ml-512-node-042: Time to load fused_adam op: 0.10144972801208496 seconds
ml-512-node-051: ninja: no work to do.
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.06876301765441895 seconds
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.13051724433898926 seconds
ml-512-node-058: Time to load fused_adam op: 0.07822966575622559 seconds
ml-512-node-051: Time to load fused_adam op: 0.089691162109375 seconds
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Time to load fused_adam op: 0.10450363159179688 seconds
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Time to load fused_adam op: 0.10219120979309082 seconds
ml-512-node-045: Time to load fused_adam op: 0.20169329643249512 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.20183444023132324 seconds
ml-512-node-038: Time to load fused_adam op: 0.1047675609588623 seconds
ml-512-node-038: Time to load fused_adam op: 0.20237112045288086 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.20163440704345703 seconds
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Time to load fused_adam op: 0.10173726081848145 seconds
ml-512-node-049: Time to load fused_adam op: 0.20171666145324707 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-061: Time to load fused_adam op: 0.20243406295776367 seconds
ml-512-node-061: Time to load fused_adam op: 0.20467376708984375 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.10515856742858887 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.10156726837158203 seconds
ml-512-node-053: Time to load fused_adam op: 0.10156655311584473 seconds
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Time to load fused_adam op: 0.10155892372131348 seconds
ml-512-node-053: Time to load fused_adam op: 0.1023099422454834 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.10201907157897949 seconds
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: ninja: no work to do.
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Time to load fused_adam op: 0.10182857513427734 seconds
ml-512-node-059: ninja: no work to do.
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Time to load fused_adam op: 0.10381937026977539 seconds
ml-512-node-057: Time to load fused_adam op: 0.203016996383667 seconds
ml-512-node-057: Time to load fused_adam op: 0.20166397094726562 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-064: Detected CUDA files, patching ldflags
ml-512-node-064: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-058: Time to load fused_adam op: 0.1018214225769043 seconds
ml-512-node-064: Building extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.20380258560180664 seconds
ml-512-node-045: Time to load fused_adam op: 0.21875834465026855 seconds
ml-512-node-045: Time to load fused_adam op: 0.2098557949066162 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-045: Loading extension module fused_adam...Loading extension module fused_adam...
ml-512-node-045: 
ml-512-node-064: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Time to load fused_adam op: 0.11512303352355957 seconds
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-050: Detected CUDA files, patching ldflags
ml-512-node-054: Detected CUDA files, patching ldflags
ml-512-node-054: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Building extension module fused_adam...
ml-512-node-050: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-054: Building extension module fused_adam...
ml-512-node-054: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-051: Time to load fused_adam op: 0.10190916061401367 seconds
ml-512-node-042: Time to load fused_adam op: 0.2016451358795166 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-042: Time to load fused_adam op: 0.2019047737121582 seconds
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Time to load fused_adam op: 0.10937047004699707 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.2018735408782959 seconds
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-058: Time to load fused_adam op: 0.10438728332519531 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Time to load fused_adam op: 0.10663986206054688 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-042: Time to load fused_adam op: 0.20508790016174316 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.22291040420532227 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: ninja: no work to do.
ml-512-node-042: Time to load fused_adam op: 0.21522235870361328 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Time to load fused_adam op: 0.21741151809692383 seconds
ml-512-node-043: Time to load fused_adam op: 0.20175385475158691 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-064: ninja: no work to do.
ml-512-node-048: Time to load fused_adam op: 0.06507611274719238 seconds
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.20461726188659668 seconds
ml-512-node-038: Time to load fused_adam op: 0.10195684432983398 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.06749439239501953 seconds
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: ninja: no work to do.
ml-512-node-054: Time to load fused_adam op: 0.07815361022949219 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: ninja: no work to do.
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-041: ninja: no work to do.
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.11208391189575195 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Time to load fused_adam op: 0.06664562225341797 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-050: ninja: no work to do.
ml-512-node-062: Time to load fused_adam op: 0.20355987548828125 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-036: ninja: no work to do.
ml-512-node-036: Time to load fused_adam op: 0.06755399703979492 seconds
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-050: Time to load fused_adam op: 0.0807952880859375 seconds
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-042: Time to load fused_adam op: 0.20198941230773926 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.20569634437561035 seconds
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Time to load fused_adam op: 0.20391106605529785 seconds
ml-512-node-043: Time to load fused_adam op: 0.2232835292816162 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.1013648509979248 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.10189032554626465 seconds
ml-512-node-047: ninja: no work to do.
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.10150694847106934 seconds
ml-512-node-047: Time to load fused_adam op: 0.06660652160644531 seconds
ml-512-node-062: Time to load fused_adam op: 0.2075502872467041 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-054: Loading extension module fused_adam...Loading extension module fused_adam...
ml-512-node-054: 
ml-512-node-054: Time to load fused_adam op: 0.2018144130706787 seconds
ml-512-node-054: Time to load fused_adam op: 0.20182156562805176 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.10425925254821777 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Time to load fused_adam op: 0.31472158432006836 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-059: Time to load fused_adam op: 0.3023982048034668 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.101409912109375 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.1144859790802002 seconds
ml-512-node-064: Detected CUDA files, patching ldflags
ml-512-node-064: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-064: Building extension module fused_adam...
ml-512-node-064: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Time to load fused_adam op: 0.10144948959350586 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-058: Detected CUDA files, patching ldflags
ml-512-node-058: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.10668325424194336 seconds
ml-512-node-048: Time to load fused_adam op: 0.10209250450134277 seconds
ml-512-node-058: Building extension module fused_adam...
ml-512-node-058: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Time to load fused_adam op: 0.10123419761657715 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.11721611022949219 seconds
ml-512-node-059: Time to load fused_adam op: 0.302814245223999 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.3021690845489502 seconds
ml-512-node-054: Time to load fused_adam op: 0.21393489837646484 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-054: Time to load fused_adam op: 0.11618661880493164 seconds
ml-512-node-044: Time to load fused_adam op: 0.11686086654663086 seconds
ml-512-node-044: Time to load fused_adam op: 0.10343408584594727 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-054: Time to load fused_adam op: 0.11124491691589355 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.10150623321533203 seconds
ml-512-node-047: Time to load fused_adam op: 0.10150527954101562 seconds
ml-512-node-047: Time to load fused_adam op: 0.10133767127990723 seconds
ml-512-node-064: ninja: no work to do.
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.061360836029052734 seconds
ml-512-node-044: Time to load fused_adam op: 0.10304903984069824 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-054: Time to load fused_adam op: 0.2017993927001953 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.10348820686340332 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.10143136978149414 seconds
ml-512-node-036: Time to load fused_adam op: 0.10145807266235352 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-051: Detected CUDA files, patching ldflags
ml-512-node-051: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-051: Building extension module fused_adam...
ml-512-node-051: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: Time to load fused_adam op: 0.10800600051879883 seconds
ml-512-node-048: Time to load fused_adam op: 0.1209096908569336 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.10168862342834473 seconds
ml-512-node-041: Time to load fused_adam op: 0.3070487976074219 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.11795425415039062 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.13176321983337402 seconds
ml-512-node-060: Detected CUDA files, patching ldflags
ml-512-node-060: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-060: Building extension module fused_adam...
ml-512-node-060: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-064: Time to load fused_adam op: 0.2018909454345703 seconds
ml-512-node-064: Time to load fused_adam op: 0.201615571975708 seconds
ml-512-node-064: Time to load fused_adam op: 0.20233392715454102 seconds
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.10703325271606445 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.20280146598815918 seconds
ml-512-node-064: Time to load fused_adam op: 0.20485424995422363 seconds
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-058: ninja: no work to do.
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Time to load fused_adam op: 0.21351027488708496 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-035: ninja: no work to do.
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-051: ninja: no work to do.
ml-512-node-035: Time to load fused_adam op: 0.21866226196289062 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-058: Time to load fused_adam op: 0.20807361602783203 seconds
ml-512-node-051: Time to load fused_adam op: 0.2233109474182129 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-060: ninja: no work to do.
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-060: Time to load fused_adam op: 0.19353365898132324 seconds
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-051: Time to load fused_adam op: 0.10252141952514648 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: ninja: no work to do.
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.3518385887145996 seconds
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-052: Detected CUDA files, patching ldflags
ml-512-node-052: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-052: Building extension module fused_adam...
ml-512-node-052: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: ninja: no work to do.
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.23821353912353516 seconds
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: ninja: no work to do.
ml-512-node-052: Time to load fused_adam op: 0.2030198574066162 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Detected CUDA files, patching ldflags
ml-512-node-051: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-051: Building extension module fused_adam...
ml-512-node-051: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: ninja: no work to do.
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.40007472038269043 seconds
ml-512-node-045: ninja: no work to do.
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Detected CUDA files, patching ldflags
ml-512-node-034: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Building extension module fused_adam...
ml-512-node-034: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Time to load fused_adam op: 0.45255589485168457 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-057: Detected CUDA files, patching ldflags
ml-512-node-057: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-064: Detected CUDA files, patching ldflags
ml-512-node-064: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-064: Building extension module fused_adam...
ml-512-node-064: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-057: Building extension module fused_adam...
ml-512-node-057: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-051: ninja: no work to do.
ml-512-node-051: Time to load fused_adam op: 0.3196406364440918 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-040: ninja: no work to do.
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Detected CUDA files, patching ldflags
ml-512-node-059: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-060: Detected CUDA files, patching ldflags
ml-512-node-060: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-060: Building extension module fused_adam...
ml-512-node-060: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 1.0222325325012207 seconds
ml-512-node-059: Building extension module fused_adam...
ml-512-node-059: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: ninja: no work to do.
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-064: ninja: no work to do.
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.27469396591186523 seconds
ml-512-node-057: ninja: no work to do.
ml-512-node-034: ninja: no work to do.
ml-512-node-057: Time to load fused_adam op: 0.4141697883605957 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.4586958885192871 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.4189455509185791 seconds
ml-512-node-060: ninja: no work to do.
ml-512-node-059: ninja: no work to do.
ml-512-node-060: Time to load fused_adam op: 0.3340871334075928 seconds
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-059: Time to load fused_adam op: 0.3252236843109131 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-048: ninja: no work to do.
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.40743398666381836 seconds
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: ninja: no work to do.
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.48302364349365234 seconds
ml-512-node-050: Detected CUDA files, patching ldflags
ml-512-node-050: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Building extension module fused_adam...
ml-512-node-050: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-050: ninja: no work to do.
ml-512-node-050: Time to load fused_adam op: 0.4561617374420166 seconds
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-033: [2024-07-08 07:24:10,763] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
ml-512-node-033: [2024-07-08 07:24:10,767] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
ml-512-node-033: [2024-07-08 07:24:10,767] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
ml-512-node-033: [2024-07-08 07:24:10,813] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
ml-512-node-033: [2024-07-08 07:24:10,813] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale
ml-512-node-033: [2024-07-08 07:24:11,431] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FP16_Optimizer
ml-512-node-033: [2024-07-08 07:24:11,431] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
ml-512-node-033: [2024-07-08 07:24:11,431] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x714b56463760>
ml-512-node-033: [2024-07-08 07:24:11,431] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:24:11,433] [INFO] [config.py:997:print] DeepSpeedEngine configuration:
ml-512-node-033: [2024-07-08 07:24:11,434] [INFO] [config.py:1001:print]   activation_checkpointing_config  {
ml-512-node-033:     "partition_activations": false, 
ml-512-node-033:     "contiguous_memory_optimization": false, 
ml-512-node-033:     "cpu_checkpointing": false, 
ml-512-node-033:     "number_checkpoints": null, 
ml-512-node-033:     "synchronize_checkpoint_boundary": false, 
ml-512-node-033:     "profile": false
ml-512-node-033: }
ml-512-node-033: [2024-07-08 07:24:11,434] [INFO] [config.py:1001:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
ml-512-node-033: [2024-07-08 07:24:11,434] [INFO] [config.py:1001:print]   amp_enabled .................. False
ml-512-node-033: [2024-07-08 07:24:11,434] [INFO] [config.py:1001:print]   amp_params ................... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   autotuning_config ............ {
ml-512-node-033:     "enabled": false, 
ml-512-node-033:     "start_step": null, 
ml-512-node-033:     "end_step": null, 
ml-512-node-033:     "metric_path": null, 
ml-512-node-033:     "arg_mappings": null, 
ml-512-node-033:     "metric": "throughput", 
ml-512-node-033:     "model_info": null, 
ml-512-node-033:     "results_dir": "autotuning_results", 
ml-512-node-033:     "exps_dir": "autotuning_exps", 
ml-512-node-033:     "overwrite": true, 
ml-512-node-033:     "fast": true, 
ml-512-node-033:     "start_profile_step": 3, 
ml-512-node-033:     "end_profile_step": 5, 
ml-512-node-033:     "tuner_type": "gridsearch", 
ml-512-node-033:     "tuner_early_stopping": 5, 
ml-512-node-033:     "tuner_num_trials": 50, 
ml-512-node-033:     "model_info_path": null, 
ml-512-node-033:     "mp_size": 1, 
ml-512-node-033:     "max_train_batch_size": null, 
ml-512-node-033:     "min_train_batch_size": 1, 
ml-512-node-033:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
ml-512-node-033:     "min_train_micro_batch_size_per_gpu": 1, 
ml-512-node-033:     "num_tuning_micro_batch_sizes": 3
ml-512-node-033: }
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   bfloat16_enabled ............. False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   bfloat16_immediate_grad_update  False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   checkpoint_parallel_write_pipeline  False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   checkpoint_tag_validation_enabled  True
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   checkpoint_tag_validation_fail  False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x714b564600a0>
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   communication_data_type ...... None
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   curriculum_enabled_legacy .... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   curriculum_params_legacy ..... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   data_efficiency_enabled ...... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   dataloader_drop_last ......... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   disable_allgather ............ False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   dump_state ................... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   eigenvalue_enabled ........... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   eigenvalue_gas_boundary_resolution  1
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   eigenvalue_layer_name ........ bert.encoder.layer
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   eigenvalue_layer_num ......... 0
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   eigenvalue_max_iter .......... 100
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   eigenvalue_stability ......... 1e-06
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   eigenvalue_tol ............... 0.01
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   eigenvalue_verbose ........... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   elasticity_enabled ........... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   flops_profiler_config ........ {
ml-512-node-033:     "enabled": false, 
ml-512-node-033:     "recompute_fwd_factor": 0.0, 
ml-512-node-033:     "profile_step": 1, 
ml-512-node-033:     "module_depth": -1, 
ml-512-node-033:     "top_modules": 1, 
ml-512-node-033:     "detailed": true, 
ml-512-node-033:     "output_file": null
ml-512-node-033: }
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   fp16_auto_cast ............... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   fp16_enabled ................. True
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   fp16_master_weights_and_gradients  False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   global_rank .................. 0
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   grad_accum_dtype ............. None
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   gradient_accumulation_steps .. 1
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   gradient_clipping ............ 1.0
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   gradient_predivide_factor .... 1.0
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   graph_harvesting ............. False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   initial_dynamic_scale ........ 65536
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   load_universal_checkpoint .... False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   loss_scale ................... 0
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   memory_breakdown ............. False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   mics_hierarchial_params_gather  False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   mics_shard_size .............. -1
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step1_tensorboard/ds_tensorboard_logs/', job_name='step1_model_tensorboard') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
ml-512-node-033: [2024-07-08 07:24:11,435] [INFO] [config.py:1001:print]   nebula_config ................ {
ml-512-node-033:     "enabled": false, 
ml-512-node-033:     "persistent_storage_path": null, 
ml-512-node-033:     "persistent_time_interval": 100, 
ml-512-node-033:     "num_of_version_in_retention": 2, 
ml-512-node-033:     "enable_nebula_load": true, 
ml-512-node-033:     "load_path": null
ml-512-node-033: }
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   optimizer_legacy_fusion ...... False
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   optimizer_name ............... None
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   optimizer_params ............. None
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   pld_enabled .................. False
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   pld_params ................... False
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   prescale_gradients ........... False
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   scheduler_name ............... None
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   scheduler_params ............. None
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   seq_parallel_communication_data_type  torch.float32
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   sparse_attention ............. None
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   sparse_gradients_enabled ..... False
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   steps_per_print .............. 10
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   timers_config ................ enabled=True synchronized=True
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   train_batch_size ............. 4096
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   train_micro_batch_size_per_gpu  16
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   use_data_before_expert_parallel_  False
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   use_node_local_storage ....... False
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   wall_clock_breakdown ......... False
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   weight_quantization_config ... None
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   world_size ................... 256
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   zero_allow_untested_optimizer  False
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   zero_enabled ................. False
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   zero_force_ds_cpu_optimizer .. True
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:1001:print]   zero_optimization_stage ...... 0
ml-512-node-033: [2024-07-08 07:24:11,436] [INFO] [config.py:987:print_user_config]   json = {
ml-512-node-033:     "train_batch_size": 4.096000e+03, 
ml-512-node-033:     "train_micro_batch_size_per_gpu": 16, 
ml-512-node-033:     "steps_per_print": 10, 
ml-512-node-033:     "zero_optimization": {
ml-512-node-033:         "stage": 0, 
ml-512-node-033:         "offload_param": {
ml-512-node-033:             "device": "none"
ml-512-node-033:         }, 
ml-512-node-033:         "offload_optimizer": {
ml-512-node-033:             "device": "none"
ml-512-node-033:         }, 
ml-512-node-033:         "stage3_param_persistence_threshold": 1.000000e+04, 
ml-512-node-033:         "stage3_max_live_parameters": 3.000000e+07, 
ml-512-node-033:         "stage3_prefetch_bucket_size": 3.000000e+07, 
ml-512-node-033:         "memory_efficient_linear": false
ml-512-node-033:     }, 
ml-512-node-033:     "fp16": {
ml-512-node-033:         "enabled": true, 
ml-512-node-033:         "loss_scale_window": 100
ml-512-node-033:     }, 
ml-512-node-033:     "gradient_clipping": 1.0, 
ml-512-node-033:     "prescale_gradients": false, 
ml-512-node-033:     "wall_clock_breakdown": false, 
ml-512-node-033:     "hybrid_engine": {
ml-512-node-033:         "enabled": false, 
ml-512-node-033:         "max_out_tokens": 512, 
ml-512-node-033:         "inference_tp_size": 1, 
ml-512-node-033:         "release_inference_cache": false, 
ml-512-node-033:         "pin_parameters": true, 
ml-512-node-033:         "tp_gather_partition_size": 8
ml-512-node-033:     }, 
ml-512-node-033:     "tensorboard": {
ml-512-node-033:         "enabled": false, 
ml-512-node-033:         "output_path": "step1_tensorboard/ds_tensorboard_logs/", 
ml-512-node-033:         "job_name": "step1_model_tensorboard"
ml-512-node-033:     }
ml-512-node-033: }
ml-512-node-033: ***** Running training *****
ml-512-node-033: Beginning of Epoch 1/100, Total Micro Batches 5
ml-512-node-061: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-061:   warnings.warn(
ml-512-node-039: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-039:   warnings.warn(
ml-512-node-034: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-034:   warnings.warn(
ml-512-node-043: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-043:   warnings.warn(
ml-512-node-033: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-033:   warnings.warn(
ml-512-node-045: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-045:   warnings.warn(
ml-512-node-054: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-054:   warnings.warn(
ml-512-node-039: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-039:   warnings.warn(
ml-512-node-053: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-053:   warnings.warn(
ml-512-node-042: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-042:   warnings.warn(
ml-512-node-044: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-044:   warnings.warn(
ml-512-node-040: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-040:   warnings.warn(
ml-512-node-037: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-037:   warnings.warn(
ml-512-node-044: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-044:   warnings.warn(
ml-512-node-037: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-037:   warnings.warn(
ml-512-node-057: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-057:   warnings.warn(
ml-512-node-054: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-054:   warnings.warn(
ml-512-node-049: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-049:   warnings.warn(
ml-512-node-049: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-049:   warnings.warn(
ml-512-node-038: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-038:   warnings.warn(
ml-512-node-050: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-050:   warnings.warn(
ml-512-node-040: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-040:   warnings.warn(
ml-512-node-060: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-060:   warnings.warn(
ml-512-node-037: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-037:   warnings.warn(
ml-512-node-033: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-033:   warnings.warn(
ml-512-node-062: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-062:   warnings.warn(
ml-512-node-035: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-035:   warnings.warn(
ml-512-node-055: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-055:   warnings.warn(
ml-512-node-055: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-055:   warnings.warn(
ml-512-node-047: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-047:   warnings.warn(
ml-512-node-038: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-038:   warnings.warn(
ml-512-node-054: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-054:   warnings.warn(
ml-512-node-054: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-054:   warnings.warn(
ml-512-node-059: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-059:   warnings.warn(
ml-512-node-058: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-058:   warnings.warn(
ml-512-node-058: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-058:   warnings.warn(
ml-512-node-035: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-035:   warnings.warn(
ml-512-node-058: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-058:   warnings.warn(
ml-512-node-060: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-060:   warnings.warn(
ml-512-node-040: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-040:   warnings.warn(
ml-512-node-044: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-044:   warnings.warn(
ml-512-node-051: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-051:   warnings.warn(
ml-512-node-041: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-041:   warnings.warn(
ml-512-node-043: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-043:   warnings.warn(
ml-512-node-052: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-052:   warnings.warn(
ml-512-node-043: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-043:   warnings.warn(
ml-512-node-061: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-061:   warnings.warn(
ml-512-node-037: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-037:   warnings.warn(
ml-512-node-056: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-056:   warnings.warn(
ml-512-node-063: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-063:   warnings.warn(
ml-512-node-051: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-051:   warnings.warn(
ml-512-node-048: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-048:   warnings.warn(
ml-512-node-061: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-061:   warnings.warn(
ml-512-node-041: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-041:   warnings.warn(
ml-512-node-057: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-057:   warnings.warn(
ml-512-node-036: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-036:   warnings.warn(
ml-512-node-036: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-036:   warnings.warn(
ml-512-node-036: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-036:   warnings.warn(
ml-512-node-052: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-052:   warnings.warn(
ml-512-node-050: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-050:   warnings.warn(
ml-512-node-052: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-052:   warnings.warn(
ml-512-node-037: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-037:   warnings.warn(
ml-512-node-056: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-056:   warnings.warn(
ml-512-node-057: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-057:   warnings.warn(
ml-512-node-063: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-063:   warnings.warn(
ml-512-node-060: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-060:   warnings.warn(
ml-512-node-048: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-048:   warnings.warn(
ml-512-node-035: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-035:   warnings.warn(
ml-512-node-038: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-038:   warnings.warn(
ml-512-node-062: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-062:   warnings.warn(
ml-512-node-037: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-037:   warnings.warn(
ml-512-node-045: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-045:   warnings.warn(
ml-512-node-057: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-057:   warnings.warn(
ml-512-node-043: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-043:   warnings.warn(
ml-512-node-034: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-034:   warnings.warn(
ml-512-node-038: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-038:   warnings.warn(
ml-512-node-048: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-048:   warnings.warn(
ml-512-node-044: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-044:   warnings.warn(
ml-512-node-058: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-058:   warnings.warn(
ml-512-node-064: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-064:   warnings.warn(
ml-512-node-051: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-051:   warnings.warn(
ml-512-node-063: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-063:   warnings.warn(
ml-512-node-049: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-049:   warnings.warn(
ml-512-node-057: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-057:   warnings.warn(
ml-512-node-047: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-047:   warnings.warn(
ml-512-node-055: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-055:   warnings.warn(
ml-512-node-064: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-064:   warnings.warn(
ml-512-node-046: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-046:   warnings.warn(
ml-512-node-039: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-039:   warnings.warn(
ml-512-node-045: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-045:   warnings.warn(
ml-512-node-038: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-038:   warnings.warn(
ml-512-node-055: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-055:   warnings.warn(
ml-512-node-053: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-053:   warnings.warn(
ml-512-node-064: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-064:   warnings.warn(
ml-512-node-064: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-064:   warnings.warn(
ml-512-node-064: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-064:   warnings.warn(
ml-512-node-055: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-055:   warnings.warn(
ml-512-node-042: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-042:   warnings.warn(
ml-512-node-057: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-057:   warnings.warn(
ml-512-node-062: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-062:   warnings.warn(
ml-512-node-055: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-055:   warnings.warn(
ml-512-node-059: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-059:   warnings.warn(
ml-512-node-053: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-053:   warnings.warn(
ml-512-node-059: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-059:   warnings.warn(
ml-512-node-039: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-039:   warnings.warn(
ml-512-node-054: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-054:   warnings.warn(
ml-512-node-044: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-044:   warnings.warn(
ml-512-node-064: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-064:   warnings.warn(
ml-512-node-040: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-040:   warnings.warn(
ml-512-node-048: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-048:   warnings.warn(
ml-512-node-033: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-033:   warnings.warn(
ml-512-node-050: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-050:   warnings.warn(
ml-512-node-047: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-047:   warnings.warn(
ml-512-node-047: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-047:   warnings.warn(
ml-512-node-033: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-033:   warnings.warn(
ml-512-node-035: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-035:   warnings.warn(
ml-512-node-063: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-055: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-063:   warnings.warn(
ml-512-node-055:   warnings.warn(
ml-512-node-039: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-039:   warnings.warn(
ml-512-node-048: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-048:   warnings.warn(
ml-512-node-039: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-039:   warnings.warn(
ml-512-node-059: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-059:   warnings.warn(
ml-512-node-035: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-035:   warnings.warn(
ml-512-node-058: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-058:   warnings.warn(
ml-512-node-038: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-038:   warnings.warn(
ml-512-node-045: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-045:   warnings.warn(
ml-512-node-043: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-043:   warnings.warn(
ml-512-node-034: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-034:   warnings.warn(
ml-512-node-046: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-046:   warnings.warn(
ml-512-node-036: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-036:   warnings.warn(
ml-512-node-045: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-045:   warnings.warn(
ml-512-node-049: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-049:   warnings.warn(
ml-512-node-058: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-058:   warnings.warn(
ml-512-node-035: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-035:   warnings.warn(
ml-512-node-059: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-059:   warnings.warn(
ml-512-node-033: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-033:   warnings.warn(
ml-512-node-058: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-058:   warnings.warn(
ml-512-node-056: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-056:   warnings.warn(
ml-512-node-036: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-036:   warnings.warn(
ml-512-node-041: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-041:   warnings.warn(
ml-512-node-063: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-063:   warnings.warn(
ml-512-node-050: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-050:   warnings.warn(
ml-512-node-044: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-044:   warnings.warn(
ml-512-node-049: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-049:   warnings.warn(
ml-512-node-036: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-036:   warnings.warn(
ml-512-node-052: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-052:   warnings.warn(
ml-512-node-042: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-042:   warnings.warn(
ml-512-node-060: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-060:   warnings.warn(
ml-512-node-062: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-062:   warnings.warn(
ml-512-node-037: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-037:   warnings.warn(
ml-512-node-039: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-039:   warnings.warn(
ml-512-node-038: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-038:   warnings.warn(
ml-512-node-059: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-059:   warnings.warn(
ml-512-node-056: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-056:   warnings.warn(
ml-512-node-054: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-054:   warnings.warn(
ml-512-node-034: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-034:   warnings.warn(
ml-512-node-034: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-034:   warnings.warn(
ml-512-node-049: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-049:   warnings.warn(
ml-512-node-044: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-044:   warnings.warn(
ml-512-node-035: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-035:   warnings.warn(
ml-512-node-056: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-056:   warnings.warn(
ml-512-node-061: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-061:   warnings.warn(
ml-512-node-050: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-050:   warnings.warn(
ml-512-node-041: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-041:   warnings.warn(
ml-512-node-035: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-035:   warnings.warn(
ml-512-node-042: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-042:   warnings.warn(
ml-512-node-062: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-062:   warnings.warn(
ml-512-node-063: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-063:   warnings.warn(
ml-512-node-060: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-060:   warnings.warn(
ml-512-node-043: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-043:   warnings.warn(
ml-512-node-064: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-064:   warnings.warn(
ml-512-node-051: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-051:   warnings.warn(
ml-512-node-054: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-054:   warnings.warn(
ml-512-node-034: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-034:   warnings.warn(
ml-512-node-041: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-041:   warnings.warn(
ml-512-node-047: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-047:   warnings.warn(
ml-512-node-048: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-048:   warnings.warn(
ml-512-node-046: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-046:   warnings.warn(
ml-512-node-046: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-046:   warnings.warn(
ml-512-node-042: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-042:   warnings.warn(
ml-512-node-046: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-046:   warnings.warn(
ml-512-node-033: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-033:   warnings.warn(
ml-512-node-060: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-060:   warnings.warn(
ml-512-node-045: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-045:   warnings.warn(
ml-512-node-061: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-061:   warnings.warn(
ml-512-node-041: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-041:   warnings.warn(
ml-512-node-051: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-051:   warnings.warn(
ml-512-node-037: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-037:   warnings.warn(
ml-512-node-055: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-055:   warnings.warn(
ml-512-node-040: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-040:   warnings.warn(
ml-512-node-063: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-063:   warnings.warn(
ml-512-node-062: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-062:   warnings.warn(
ml-512-node-049: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-049:   warnings.warn(
ml-512-node-048: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-048:   warnings.warn(
ml-512-node-058: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-058:   warnings.warn(
ml-512-node-038: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-038:   warnings.warn(
ml-512-node-052: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-052:   warnings.warn(
ml-512-node-057: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-057:   warnings.warn(
ml-512-node-040: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-040:   warnings.warn(
ml-512-node-052: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-052:   warnings.warn(
ml-512-node-036: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-036:   warnings.warn(
ml-512-node-039: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-039:   warnings.warn(
ml-512-node-059: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-059:   warnings.warn(
ml-512-node-060: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-060:   warnings.warn(
ml-512-node-061: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-061:   warnings.warn(
ml-512-node-056: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-056:   warnings.warn(
ml-512-node-044: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-044:   warnings.warn(
ml-512-node-053: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-053:   warnings.warn(
ml-512-node-033: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-033:   warnings.warn(
ml-512-node-041: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-041:   warnings.warn(
ml-512-node-040: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-040:   warnings.warn(
ml-512-node-047: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-047:   warnings.warn(
ml-512-node-048: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-048:   warnings.warn(
ml-512-node-041: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-041:   warnings.warn(
ml-512-node-034: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-034:   warnings.warn(
ml-512-node-059: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-059:   warnings.warn(
ml-512-node-063: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-063:   warnings.warn(
ml-512-node-042: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-042:   warnings.warn(
ml-512-node-046: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-046:   warnings.warn(
ml-512-node-054: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-054:   warnings.warn(
ml-512-node-051: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-051:   warnings.warn(
ml-512-node-050: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-050:   warnings.warn(
ml-512-node-052: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-052:   warnings.warn(
ml-512-node-040: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-040:   warnings.warn(
ml-512-node-056: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-056:   warnings.warn(
ml-512-node-043: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-043:   warnings.warn(
ml-512-node-033: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-033:   warnings.warn(
ml-512-node-056: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-056:   warnings.warn(
ml-512-node-051: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-051:   warnings.warn(
ml-512-node-046: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-046:   warnings.warn(
ml-512-node-036: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-036:   warnings.warn(
ml-512-node-050: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-050:   warnings.warn(
ml-512-node-060: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-060:   warnings.warn(
ml-512-node-053: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-053:   warnings.warn(
ml-512-node-042: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-042:   warnings.warn(
ml-512-node-057: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-057:   warnings.warn(
ml-512-node-053: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-053:   warnings.warn(
ml-512-node-047: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-047:   warnings.warn(
ml-512-node-053: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-053:   warnings.warn(
ml-512-node-042: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-042:   warnings.warn(
ml-512-node-053: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-053:   warnings.warn(
ml-512-node-062: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-062:   warnings.warn(
ml-512-node-046: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-046:   warnings.warn(
ml-512-node-049: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-049:   warnings.warn(
ml-512-node-061: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-061:   warnings.warn(
ml-512-node-052: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-052:   warnings.warn(
ml-512-node-047: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-047:   warnings.warn(
ml-512-node-043: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-043:   warnings.warn(
ml-512-node-061: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-061:   warnings.warn(
ml-512-node-034: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-034:   warnings.warn(
ml-512-node-051: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-051:   warnings.warn(
ml-512-node-050: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-050:   warnings.warn(
ml-512-node-045: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-045:   warnings.warn(
ml-512-node-062: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-062:   warnings.warn(
ml-512-node-064: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-064:   warnings.warn(
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:14,074] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 07:24:14,076] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536, reducing to 32768.0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 07:24:14,075] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:14,077] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 07:24:14,080] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 07:24:14,078] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 07:24:14,079] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 07:24:15,807] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:15,808] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 07:24:15,806] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 07:24:15,804] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 07:24:15,805] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 07:24:15,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 07:24:15,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 07:24:17,549] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:17,548] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 07:24:17,551] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 07:24:17,551] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 07:24:17,547] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 07:24:17,545] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 07:24:17,550] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 07:24:17,546] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 07:24:19,283] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 07:24:19,284] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 07:24:19,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 07:24:19,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 07:24:19,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 07:24:19,285] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 07:24:21,019] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: Beginning of Epoch 2/100, Total Micro Batches 5
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 07:24:21,017] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 07:24:21,020] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 07:24:21,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 07:24:21,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 07:24:21,018] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 07:24:22,765] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 2048.0, reducing to 1024.0
ml-512-node-033: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 07:24:22,760] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 07:24:22,759] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 07:24:22,760] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 07:24:22,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 07:24:22,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 07:24:22,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 07:24:22,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 07:24:24,496] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 1024.0, reducing to 512.0
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:24,499] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 07:24:24,498] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 07:24:24,502] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 07:24:24,497] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 07:24:24,500] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 07:24:24,501] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,243] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 07:24:26,245] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 512.0, reducing to 256.0
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 07:24:26,242] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:26,241] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 07:24:26,240] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 07:24:26,244] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 07:24:26,245] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 07:24:26,246] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 256.0, reducing to 128.0
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 07:24:27,982] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:27,980] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 07:24:27,984] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 07:24:27,983] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 07:24:27,985] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 07:24:27,981] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 07:24:29,722] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 07:24:29,722] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 07:24:29,722] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 128.0, reducing to 64.0
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 07:24:29,720] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 07:24:29,721] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 07:24:29,722] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 07:24:29,722] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 07:24:29,722] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 07:24:29,722] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 07:24:29,722] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:29,726] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=10, lr=[0.0, 0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-064: [2024-07-08 07:24:29,723] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 07:24:29,726] [INFO] [timer.py:258:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=2356.030524472948, CurrSamplesPerSec=2354.710537533248, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-033: Beginning of Epoch 3/100, Total Micro Batches 5
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 07:24:29,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:29,722] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 07:24:29,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 07:24:31,467] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 64.0, reducing to 32.0
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 07:24:31,469] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 07:24:31,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 07:24:31,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 07:24:31,470] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 07:24:31,471] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 07:24:31,468] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32.0, reducing to 16.0
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 07:24:33,204] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 07:24:33,202] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 07:24:33,203] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 07:24:33,205] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:33,201] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 07:24:33,207] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 07:24:33,206] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16.0, reducing to 8.0
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:34,936] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 07:24:34,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 07:24:34,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 07:24:34,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:34,937] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 07:24:34,934] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 07:24:34,935] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 07:24:34,938] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: Beginning of Epoch 4/100, Total Micro Batches 5
ml-512-node-033: [2024-07-08 07:24:47,498] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=13, lr=[7e-11, 0.00035, 7e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:24:47,507] [INFO] [timer.py:258:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=2327.32672137918, CurrSamplesPerSec=2279.062168593249, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-033: Beginning of Epoch 5/100, Total Micro Batches 5
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 21
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 21
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 21
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 21
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 21
ml-512-node-033: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 21
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 21
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 21
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 21
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8.0, reducing to 4.0
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 21
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 21
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 21
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 21
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 21
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 21
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 21
ml-512-node-038: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 21
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 21
ml-512-node-049: Grad overflow on iteration 21
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 21
ml-512-node-049: Grad overflow on iteration 21
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 21
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 21
ml-512-node-059: Grad overflow on iteration 21
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 21
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 21
ml-512-node-047: Grad overflow on iteration 21
ml-512-node-054: Grad overflow on iteration 21
ml-512-node-062: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 21
ml-512-node-054: Grad overflow on iteration 21
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 21
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: Grad overflow on iteration 21
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 21
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 21
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 21
ml-512-node-057: Grad overflow on iteration 21
ml-512-node-041: Grad overflow on iteration 21
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 21
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: Grad overflow on iteration 21
ml-512-node-039: Grad overflow on iteration 21
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: Grad overflow on iteration 21
ml-512-node-048: Grad overflow on iteration 21
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: Grad overflow on iteration 21
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 21
ml-512-node-057: Grad overflow on iteration 21
ml-512-node-063: Grad overflow on iteration 21
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:51,031] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 21
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 21
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 21
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 21
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 21
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 21
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 21
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 21
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-034: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 21
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 21
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 21
ml-512-node-035: Grad overflow on iteration 21
ml-512-node-062: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 21
ml-512-node-051: Grad overflow on iteration 21
ml-512-node-062: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 21
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 21
ml-512-node-062: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: Grad overflow on iteration 21
ml-512-node-054: Grad overflow on iteration 21
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 21
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 21
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: Grad overflow on iteration 21
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-049: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 21
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 21
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 21
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-054: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 21
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 21
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 21
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 21
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 21
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 21
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 21
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 21
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 21
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-050: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: Grad overflow on iteration 21
ml-512-node-043: Grad overflow on iteration 21
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: Grad overflow on iteration 21
ml-512-node-045: Grad overflow on iteration 21
ml-512-node-064: Grad overflow on iteration 21
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 21
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 21
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 21
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 21
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: Grad overflow on iteration 21
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 21
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 21
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 21
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 21
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 21
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 21
ml-512-node-063: Grad overflow on iteration 21
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 21
ml-512-node-047: Grad overflow on iteration 21
ml-512-node-052: Grad overflow on iteration 21
ml-512-node-062: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 21
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 21
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 21
ml-512-node-041: Grad overflow on iteration 21
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: Grad overflow on iteration 21
ml-512-node-062: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: Grad overflow on iteration 21
ml-512-node-063: Grad overflow on iteration 21
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: Grad overflow on iteration 21
ml-512-node-041: Grad overflow on iteration 21
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 21
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 21
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 21
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: Grad overflow on iteration 21
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 21
ml-512-node-035: Grad overflow on iteration 21
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 21
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 21
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: Grad overflow on iteration 21
ml-512-node-046: Grad overflow on iteration 21
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 21
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 21
ml-512-node-046: Grad overflow on iteration 21
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 21
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 21
ml-512-node-040: Grad overflow on iteration 21
ml-512-node-052: Grad overflow on iteration 21
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: Grad overflow on iteration 21
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: Grad overflow on iteration 21
ml-512-node-061: Grad overflow on iteration 21
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 21
ml-512-node-052: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: Grad overflow on iteration 21
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 21
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 21
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: Grad overflow on iteration 21
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: Grad overflow on iteration 21
ml-512-node-051: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: Grad overflow on iteration 21
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 21
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-041: [2024-07-08 07:24:51,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: Grad overflow on iteration 21
ml-512-node-056: Grad overflow on iteration 21
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-064: [2024-07-08 07:24:51,035] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 21
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 21
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 21
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 21
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 21
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: Grad overflow on iteration 21
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: Grad overflow on iteration 21
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 21
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 21
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: Grad overflow on iteration 21
ml-512-node-051: Grad overflow on iteration 21
ml-512-node-039: Grad overflow on iteration 21
ml-512-node-060: Grad overflow on iteration 21
ml-512-node-041: Grad overflow on iteration 21
ml-512-node-042: Grad overflow on iteration 21
ml-512-node-061: Grad overflow on iteration 21
ml-512-node-041: [2024-07-08 07:24:51,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 21
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 21
ml-512-node-061: Grad overflow on iteration 21
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: Grad overflow on iteration 21
ml-512-node-053: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 21
ml-512-node-056: Grad overflow on iteration 21
ml-512-node-044: Grad overflow on iteration 21
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 21
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 21
ml-512-node-051: Grad overflow on iteration 21
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 21
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 21
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 21
ml-512-node-062: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: Grad overflow on iteration 21
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 21
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 21
ml-512-node-046: Grad overflow on iteration 21
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: Grad overflow on iteration 21
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 21
ml-512-node-060: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 21
ml-512-node-037: Grad overflow on iteration 21
ml-512-node-060: Grad overflow on iteration 21
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 21
ml-512-node-041: [2024-07-08 07:24:51,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 21
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: Grad overflow on iteration 21
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 21
ml-512-node-044: Grad overflow on iteration 21
ml-512-node-036: Grad overflow on iteration 21
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 21
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: Grad overflow on iteration 21
ml-512-node-042: Grad overflow on iteration 21
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: Grad overflow on iteration 21
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 21
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: Grad overflow on iteration 21
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: Grad overflow on iteration 21
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 21
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 21
ml-512-node-045: Grad overflow on iteration 21
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 21
ml-512-node-036: Grad overflow on iteration 21
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 21
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 21
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 21
ml-512-node-060: Grad overflow on iteration 21
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: Grad overflow on iteration 21
ml-512-node-060: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: Grad overflow on iteration 21
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-057: Grad overflow on iteration 21
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 21
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-057: Grad overflow on iteration 21
ml-512-node-046: Grad overflow on iteration 21
ml-512-node-047: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 21
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-063: Grad overflow on iteration 21
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: Grad overflow on iteration 21
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 21
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 21
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 21
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: Grad overflow on iteration 21
ml-512-node-062: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-062: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: Grad overflow on iteration 21
ml-512-node-062: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: Grad overflow on iteration 21
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 07:24:51,032] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: Grad overflow on iteration 21
ml-512-node-056: Grad overflow on iteration 21
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 21
ml-512-node-040: Grad overflow on iteration 21
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 07:24:51,034] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: Grad overflow on iteration 21
ml-512-node-059: Grad overflow on iteration 21
ml-512-node-040: Grad overflow on iteration 21
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-043: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 21
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: Grad overflow on iteration 21
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 21
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: Grad overflow on iteration 21
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 21
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: Grad overflow on iteration 21
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: Grad overflow on iteration 21
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 21
ml-512-node-044: Grad overflow on iteration 21
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 21
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 21
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 21
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: Grad overflow on iteration 21
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 21
ml-512-node-057: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: Grad overflow on iteration 21
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 21
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-044: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-042: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: Grad overflow on iteration 21
ml-512-node-060: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-058: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-051: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: Grad overflow on iteration 21
ml-512-node-061: Grad overflow on iteration 21
ml-512-node-037: Grad overflow on iteration 21
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-040: Grad overflow on iteration 21
ml-512-node-060: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 21
ml-512-node-053: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-055: [2024-07-08 07:24:51,033] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: Grad overflow on iteration 21
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: Grad overflow on iteration 21
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 21
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-056: Grad overflow on iteration 21
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-045: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: Grad overflow on iteration 21
ml-512-node-037: Grad overflow on iteration 21
ml-512-node-048: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-060: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: Grad overflow on iteration 21
ml-512-node-053: [2024-07-08 07:24:51,036] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 21
ml-512-node-039: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: Grad overflow on iteration 21
ml-512-node-053: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 21
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: Grad overflow on iteration 21
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 21
ml-512-node-061: Grad overflow on iteration 21
ml-512-node-037: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: Grad overflow on iteration 21
ml-512-node-061: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-053: [2024-07-08 07:24:51,037] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-033: Beginning of Epoch 6/100, Total Micro Batches 5
ml-512-node-033: [2024-07-08 07:25:05,354] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=14, lr=[9.996300896035338e-11, 0.0004998150448017669, 9.996300896035338e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:25:05,362] [INFO] [timer.py:258:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=2315.749701714494, CurrSamplesPerSec=2291.7278644482003, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-033: Beginning of Epoch 7/100, Total Micro Batches 5
ml-512-node-033: Beginning of Epoch 8/100, Total Micro Batches 5
ml-512-node-033: [2024-07-08 07:25:23,148] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=14, lr=[9.973715078832288e-11, 0.0004986857539416143, 9.973715078832288e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:25:23,157] [INFO] [timer.py:258:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=2312.4012774594785, CurrSamplesPerSec=2311.890255698624, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-033: Beginning of Epoch 9/100, Total Micro Batches 5
ml-512-node-033: Beginning of Epoch 10/100, Total Micro Batches 5
ml-512-node-033: [2024-07-08 07:25:40,942] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=14, lr=[9.930691199511774e-11, 0.0004965345599755888, 9.930691199511774e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:25:40,950] [INFO] [timer.py:258:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=2310.484515889821, CurrSamplesPerSec=2309.2730498255664, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-033: Beginning of Epoch 11/100, Total Micro Batches 5
ml-512-node-033: Beginning of Epoch 12/100, Total Micro Batches 5
ml-512-node-033: [2024-07-08 07:25:58,677] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=14, lr=[9.867406052422525e-11, 0.0004933703026211262, 9.867406052422525e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:25:58,686] [INFO] [timer.py:258:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=2310.5389761182378, CurrSamplesPerSec=2309.756143285563, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-033: Beginning of Epoch 13/100, Total Micro Batches 5
ml-512-node-033: Beginning of Epoch 14/100, Total Micro Batches 5
ml-512-node-033: [2024-07-08 07:26:16,442] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=14, lr=[9.784119689808544e-11, 0.0004892059844904272, 9.784119689808544e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:26:16,450] [INFO] [timer.py:258:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=2310.0139172002955, CurrSamplesPerSec=2297.366724836756, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-033: Beginning of Epoch 15/100, Total Micro Batches 5
ml-512-node-033: Beginning of Epoch 16/100, Total Micro Batches 5
ml-512-node-033: [2024-07-08 07:26:34,326] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=14, lr=[9.681174353198687e-11, 0.0004840587176599343, 9.681174353198687e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:26:34,334] [INFO] [timer.py:258:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=2307.6413502989853, CurrSamplesPerSec=2290.3362119177045, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-033: Beginning of Epoch 17/100, Total Micro Batches 5
ml-512-node-033: Beginning of Epoch 18/100, Total Micro Batches 5
ml-512-node-033: [2024-07-08 07:26:52,220] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=14, lr=[9.558993067062784e-11, 0.00047794965335313925, 9.558993067062784e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:26:52,229] [INFO] [timer.py:258:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=2305.6383611756924, CurrSamplesPerSec=2291.121195499606, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-033: Beginning of Epoch 19/100, Total Micro Batches 5
ml-512-node-033: Beginning of Epoch 20/100, Total Micro Batches 5
ml-512-node-033: [2024-07-08 07:27:10,134] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=14, lr=[9.418077900513376e-11, 0.0004709038950256688, 9.418077900513376e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:27:10,143] [INFO] [timer.py:258:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=2303.7970507213195, CurrSamplesPerSec=2287.570764303451, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-033: Beginning of Epoch 21/100, Total Micro Batches 5
ml-512-node-033: Beginning of Epoch 22/100, Total Micro Batches 5
ml-512-node-033: [2024-07-08 07:27:28,079] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=14, lr=[9.259007904196022e-11, 0.0004629503952098011, 9.259007904196022e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 07:27:28,088] [INFO] [timer.py:258:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=2301.921166954189, CurrSamplesPerSec=2285.8358637604842, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-033: ======================================================================
ml-512-node-033: Execution time: 178.3595 seconds for 100 steps
ml-512-node-033: Throughput: 2296.4848 samples/sec
ml-512-node-048: [2024-07-08 07:27:31,798] [INFO] [launch.py:351:main] Process 1082340 exits successfully.
ml-512-node-058: [2024-07-08 07:27:31,816] [INFO] [launch.py:351:main] Process 1079331 exits successfully.
ml-512-node-055: [2024-07-08 07:27:31,817] [INFO] [launch.py:351:main] Process 1103982 exits successfully.
ml-512-node-035: [2024-07-08 07:27:31,830] [INFO] [launch.py:351:main] Process 1092775 exits successfully.
ml-512-node-035: [2024-07-08 07:27:31,831] [INFO] [launch.py:351:main] Process 1092776 exits successfully.
ml-512-node-037: [2024-07-08 07:27:32,018] [INFO] [launch.py:351:main] Process 1089502 exits successfully.
ml-512-node-037: [2024-07-08 07:27:32,019] [INFO] [launch.py:351:main] Process 1089505 exits successfully.
ml-512-node-044: [2024-07-08 07:27:32,578] [INFO] [launch.py:351:main] Process 1082492 exits successfully.
ml-512-node-034: [2024-07-08 07:27:32,627] [INFO] [launch.py:351:main] Process 1085710 exits successfully.
ml-512-node-047: [2024-07-08 07:27:32,774] [INFO] [launch.py:351:main] Process 1086340 exits successfully.
ml-512-node-036: [2024-07-08 07:27:32,769] [INFO] [launch.py:351:main] Process 1085059 exits successfully.
ml-512-node-042: [2024-07-08 07:27:32,798] [INFO] [launch.py:351:main] Process 1084135 exits successfully.
ml-512-node-042: [2024-07-08 07:27:32,798] [INFO] [launch.py:351:main] Process 1084137 exits successfully.
ml-512-node-042: [2024-07-08 07:27:32,798] [INFO] [launch.py:351:main] Process 1084136 exits successfully.
ml-512-node-042: [2024-07-08 07:27:32,798] [INFO] [launch.py:351:main] Process 1084134 exits successfully.
ml-512-node-042: [2024-07-08 07:27:32,798] [INFO] [launch.py:351:main] Process 1084132 exits successfully.
ml-512-node-042: [2024-07-08 07:27:32,798] [INFO] [launch.py:351:main] Process 1084138 exits successfully.
ml-512-node-042: [2024-07-08 07:27:32,798] [INFO] [launch.py:351:main] Process 1084133 exits successfully.
ml-512-node-042: [2024-07-08 07:27:32,798] [INFO] [launch.py:351:main] Process 1084131 exits successfully.
ml-512-node-048: [2024-07-08 07:27:32,799] [INFO] [launch.py:351:main] Process 1082341 exits successfully.
ml-512-node-048: [2024-07-08 07:27:32,799] [INFO] [launch.py:351:main] Process 1082338 exits successfully.
ml-512-node-048: [2024-07-08 07:27:32,799] [INFO] [launch.py:351:main] Process 1082336 exits successfully.
ml-512-node-048: [2024-07-08 07:27:32,800] [INFO] [launch.py:351:main] Process 1082342 exits successfully.
ml-512-node-048: [2024-07-08 07:27:32,800] [INFO] [launch.py:351:main] Process 1082337 exits successfully.
ml-512-node-048: [2024-07-08 07:27:32,800] [INFO] [launch.py:351:main] Process 1082335 exits successfully.
ml-512-node-048: [2024-07-08 07:27:32,800] [INFO] [launch.py:351:main] Process 1082339 exits successfully.
ml-512-node-064: [2024-07-08 07:27:32,809] [INFO] [launch.py:351:main] Process 1076956 exits successfully.
ml-512-node-064: [2024-07-08 07:27:32,809] [INFO] [launch.py:351:main] Process 1076954 exits successfully.
ml-512-node-064: [2024-07-08 07:27:32,809] [INFO] [launch.py:351:main] Process 1076958 exits successfully.
ml-512-node-064: [2024-07-08 07:27:32,809] [INFO] [launch.py:351:main] Process 1076960 exits successfully.
ml-512-node-064: [2024-07-08 07:27:32,809] [INFO] [launch.py:351:main] Process 1076959 exits successfully.
ml-512-node-064: [2024-07-08 07:27:32,809] [INFO] [launch.py:351:main] Process 1076957 exits successfully.
ml-512-node-057: [2024-07-08 07:27:32,813] [INFO] [launch.py:351:main] Process 1086889 exits successfully.
ml-512-node-057: [2024-07-08 07:27:32,813] [INFO] [launch.py:351:main] Process 1086886 exits successfully.
ml-512-node-058: [2024-07-08 07:27:32,817] [INFO] [launch.py:351:main] Process 1079333 exits successfully.
ml-512-node-058: [2024-07-08 07:27:32,817] [INFO] [launch.py:351:main] Process 1079332 exits successfully.
ml-512-node-058: [2024-07-08 07:27:32,818] [INFO] [launch.py:351:main] Process 1079330 exits successfully.
ml-512-node-058: [2024-07-08 07:27:32,818] [INFO] [launch.py:351:main] Process 1079328 exits successfully.
ml-512-node-058: [2024-07-08 07:27:32,818] [INFO] [launch.py:351:main] Process 1079334 exits successfully.
ml-512-node-058: [2024-07-08 07:27:32,818] [INFO] [launch.py:351:main] Process 1079329 exits successfully.
ml-512-node-058: [2024-07-08 07:27:32,818] [INFO] [launch.py:351:main] Process 1079327 exits successfully.
ml-512-node-055: [2024-07-08 07:27:32,819] [INFO] [launch.py:351:main] Process 1103979 exits successfully.
ml-512-node-055: [2024-07-08 07:27:32,819] [INFO] [launch.py:351:main] Process 1103981 exits successfully.
ml-512-node-055: [2024-07-08 07:27:32,819] [INFO] [launch.py:351:main] Process 1103980 exits successfully.
ml-512-node-055: [2024-07-08 07:27:32,819] [INFO] [launch.py:351:main] Process 1103978 exits successfully.
ml-512-node-055: [2024-07-08 07:27:32,819] [INFO] [launch.py:351:main] Process 1103976 exits successfully.
ml-512-node-055: [2024-07-08 07:27:32,819] [INFO] [launch.py:351:main] Process 1103977 exits successfully.
ml-512-node-055: [2024-07-08 07:27:32,819] [INFO] [launch.py:351:main] Process 1103975 exits successfully.
ml-512-node-054: [2024-07-08 07:27:32,832] [INFO] [launch.py:351:main] Process 1079364 exits successfully.
ml-512-node-035: [2024-07-08 07:27:32,832] [INFO] [launch.py:351:main] Process 1092773 exits successfully.
ml-512-node-035: [2024-07-08 07:27:32,832] [INFO] [launch.py:351:main] Process 1092771 exits successfully.
ml-512-node-035: [2024-07-08 07:27:32,832] [INFO] [launch.py:351:main] Process 1092777 exits successfully.
ml-512-node-035: [2024-07-08 07:27:32,832] [INFO] [launch.py:351:main] Process 1092772 exits successfully.
ml-512-node-035: [2024-07-08 07:27:32,832] [INFO] [launch.py:351:main] Process 1092770 exits successfully.
ml-512-node-035: [2024-07-08 07:27:32,832] [INFO] [launch.py:351:main] Process 1092774 exits successfully.
ml-512-node-039: [2024-07-08 07:27:32,845] [INFO] [launch.py:351:main] Process 1172108 exits successfully.
ml-512-node-039: [2024-07-08 07:27:32,845] [INFO] [launch.py:351:main] Process 1172109 exits successfully.
ml-512-node-041: [2024-07-08 07:27:32,843] [INFO] [launch.py:351:main] Process 1091253 exits successfully.
ml-512-node-063: [2024-07-08 07:27:32,864] [INFO] [launch.py:351:main] Process 1082938 exits successfully.
ml-512-node-063: [2024-07-08 07:27:32,864] [INFO] [launch.py:351:main] Process 1082942 exits successfully.
ml-512-node-063: [2024-07-08 07:27:32,865] [INFO] [launch.py:351:main] Process 1082939 exits successfully.
ml-512-node-038: [2024-07-08 07:27:32,861] [INFO] [launch.py:351:main] Process 1084646 exits successfully.
ml-512-node-038: [2024-07-08 07:27:32,861] [INFO] [launch.py:351:main] Process 1084644 exits successfully.
ml-512-node-038: [2024-07-08 07:27:32,861] [INFO] [launch.py:351:main] Process 1084648 exits successfully.
ml-512-node-038: [2024-07-08 07:27:32,861] [INFO] [launch.py:351:main] Process 1084649 exits successfully.
ml-512-node-038: [2024-07-08 07:27:32,861] [INFO] [launch.py:351:main] Process 1084647 exits successfully.
ml-512-node-038: [2024-07-08 07:27:32,861] [INFO] [launch.py:351:main] Process 1084645 exits successfully.
ml-512-node-038: [2024-07-08 07:27:32,861] [INFO] [launch.py:351:main] Process 1084651 exits successfully.
ml-512-node-046: [2024-07-08 07:27:32,868] [INFO] [launch.py:351:main] Process 1084068 exits successfully.
ml-512-node-062: [2024-07-08 07:27:32,875] [INFO] [launch.py:351:main] Process 1078496 exits successfully.
ml-512-node-052: [2024-07-08 07:27:32,878] [INFO] [launch.py:351:main] Process 1081368 exits successfully.
ml-512-node-045: [2024-07-08 07:27:32,893] [INFO] [launch.py:351:main] Process 1088387 exits successfully.
ml-512-node-049: [2024-07-08 07:27:32,905] [INFO] [launch.py:351:main] Process 1090310 exits successfully.
ml-512-node-051: [2024-07-08 07:27:32,940] [INFO] [launch.py:351:main] Process 1086125 exits successfully.
ml-512-node-051: [2024-07-08 07:27:32,940] [INFO] [launch.py:351:main] Process 1086124 exits successfully.
ml-512-node-051: [2024-07-08 07:27:32,940] [INFO] [launch.py:351:main] Process 1086122 exits successfully.
ml-512-node-037: [2024-07-08 07:27:33,020] [INFO] [launch.py:351:main] Process 1089507 exits successfully.
ml-512-node-037: [2024-07-08 07:27:33,020] [INFO] [launch.py:351:main] Process 1089506 exits successfully.
ml-512-node-037: [2024-07-08 07:27:33,020] [INFO] [launch.py:351:main] Process 1089504 exits successfully.
ml-512-node-037: [2024-07-08 07:27:33,020] [INFO] [launch.py:351:main] Process 1089508 exits successfully.
ml-512-node-037: [2024-07-08 07:27:33,020] [INFO] [launch.py:351:main] Process 1089503 exits successfully.
ml-512-node-037: [2024-07-08 07:27:33,020] [INFO] [launch.py:351:main] Process 1089501 exits successfully.
ml-512-node-056: [2024-07-08 07:27:33,437] [INFO] [launch.py:351:main] Process 1095953 exits successfully.
ml-512-node-056: [2024-07-08 07:27:33,437] [INFO] [launch.py:351:main] Process 1095955 exits successfully.
ml-512-node-056: [2024-07-08 07:27:33,437] [INFO] [launch.py:351:main] Process 1095952 exits successfully.
ml-512-node-033: [2024-07-08 07:27:33,482] [INFO] [launch.py:351:main] Process 1096585 exits successfully.
ml-512-node-033: [2024-07-08 07:27:33,483] [INFO] [launch.py:351:main] Process 1096587 exits successfully.
ml-512-node-033: [2024-07-08 07:27:33,483] [INFO] [launch.py:351:main] Process 1096586 exits successfully.
ml-512-node-033: [2024-07-08 07:27:33,483] [INFO] [launch.py:351:main] Process 1096584 exits successfully.
ml-512-node-033: [2024-07-08 07:27:33,483] [INFO] [launch.py:351:main] Process 1096582 exits successfully.
ml-512-node-033: [2024-07-08 07:27:33,483] [INFO] [launch.py:351:main] Process 1096588 exits successfully.
ml-512-node-033: [2024-07-08 07:27:33,483] [INFO] [launch.py:351:main] Process 1096583 exits successfully.
ml-512-node-033: [2024-07-08 07:27:33,483] [INFO] [launch.py:351:main] Process 1096581 exits successfully.
ml-512-node-044: [2024-07-08 07:27:33,579] [INFO] [launch.py:351:main] Process 1082489 exits successfully.
ml-512-node-044: [2024-07-08 07:27:33,579] [INFO] [launch.py:351:main] Process 1082487 exits successfully.
ml-512-node-044: [2024-07-08 07:27:33,579] [INFO] [launch.py:351:main] Process 1082491 exits successfully.
ml-512-node-044: [2024-07-08 07:27:33,579] [INFO] [launch.py:351:main] Process 1082493 exits successfully.
ml-512-node-044: [2024-07-08 07:27:33,580] [INFO] [launch.py:351:main] Process 1082490 exits successfully.
ml-512-node-044: [2024-07-08 07:27:33,580] [INFO] [launch.py:351:main] Process 1082488 exits successfully.
ml-512-node-044: [2024-07-08 07:27:33,580] [INFO] [launch.py:351:main] Process 1082494 exits successfully.
ml-512-node-061: [2024-07-08 07:27:33,625] [INFO] [launch.py:351:main] Process 1085394 exits successfully.
ml-512-node-061: [2024-07-08 07:27:33,625] [INFO] [launch.py:351:main] Process 1085392 exits successfully.
ml-512-node-061: [2024-07-08 07:27:33,625] [INFO] [launch.py:351:main] Process 1085396 exits successfully.
ml-512-node-061: [2024-07-08 07:27:33,625] [INFO] [launch.py:351:main] Process 1085398 exits successfully.
ml-512-node-061: [2024-07-08 07:27:33,626] [INFO] [launch.py:351:main] Process 1085397 exits successfully.
ml-512-node-061: [2024-07-08 07:27:33,626] [INFO] [launch.py:351:main] Process 1085395 exits successfully.
ml-512-node-061: [2024-07-08 07:27:33,626] [INFO] [launch.py:351:main] Process 1085399 exits successfully.
ml-512-node-034: [2024-07-08 07:27:33,628] [INFO] [launch.py:351:main] Process 1085712 exits successfully.
ml-512-node-034: [2024-07-08 07:27:33,628] [INFO] [launch.py:351:main] Process 1085711 exits successfully.
ml-512-node-034: [2024-07-08 07:27:33,628] [INFO] [launch.py:351:main] Process 1085709 exits successfully.
ml-512-node-034: [2024-07-08 07:27:33,628] [INFO] [launch.py:351:main] Process 1085707 exits successfully.
ml-512-node-034: [2024-07-08 07:27:33,628] [INFO] [launch.py:351:main] Process 1085713 exits successfully.
ml-512-node-034: [2024-07-08 07:27:33,629] [INFO] [launch.py:351:main] Process 1085708 exits successfully.
ml-512-node-034: [2024-07-08 07:27:33,629] [INFO] [launch.py:351:main] Process 1085706 exits successfully.
ml-512-node-050: [2024-07-08 07:27:33,723] [INFO] [launch.py:351:main] Process 1081875 exits successfully.
ml-512-node-050: [2024-07-08 07:27:33,723] [INFO] [launch.py:351:main] Process 1081874 exits successfully.
ml-512-node-050: [2024-07-08 07:27:33,723] [INFO] [launch.py:351:main] Process 1081872 exits successfully.
ml-512-node-050: [2024-07-08 07:27:33,724] [INFO] [launch.py:351:main] Process 1081870 exits successfully.
ml-512-node-050: [2024-07-08 07:27:33,724] [INFO] [launch.py:351:main] Process 1081876 exits successfully.
ml-512-node-050: [2024-07-08 07:27:33,724] [INFO] [launch.py:351:main] Process 1081871 exits successfully.
ml-512-node-050: [2024-07-08 07:27:33,724] [INFO] [launch.py:351:main] Process 1081869 exits successfully.
ml-512-node-050: [2024-07-08 07:27:33,724] [INFO] [launch.py:351:main] Process 1081873 exits successfully.
ml-512-node-047: [2024-07-08 07:27:33,775] [INFO] [launch.py:351:main] Process 1086337 exits successfully.
ml-512-node-047: [2024-07-08 07:27:33,775] [INFO] [launch.py:351:main] Process 1086339 exits successfully.
ml-512-node-047: [2024-07-08 07:27:33,775] [INFO] [launch.py:351:main] Process 1086338 exits successfully.
ml-512-node-047: [2024-07-08 07:27:33,775] [INFO] [launch.py:351:main] Process 1086336 exits successfully.
ml-512-node-047: [2024-07-08 07:27:33,776] [INFO] [launch.py:351:main] Process 1086334 exits successfully.
ml-512-node-047: [2024-07-08 07:27:33,776] [INFO] [launch.py:351:main] Process 1086335 exits successfully.
ml-512-node-047: [2024-07-08 07:27:33,776] [INFO] [launch.py:351:main] Process 1086333 exits successfully.
ml-512-node-036: [2024-07-08 07:27:33,771] [INFO] [launch.py:351:main] Process 1085058 exits successfully.
ml-512-node-036: [2024-07-08 07:27:33,771] [INFO] [launch.py:351:main] Process 1085060 exits successfully.
ml-512-node-036: [2024-07-08 07:27:33,771] [INFO] [launch.py:351:main] Process 1085057 exits successfully.
ml-512-node-036: [2024-07-08 07:27:33,771] [INFO] [launch.py:351:main] Process 1085055 exits successfully.
ml-512-node-036: [2024-07-08 07:27:33,771] [INFO] [launch.py:351:main] Process 1085061 exits successfully.
ml-512-node-036: [2024-07-08 07:27:33,771] [INFO] [launch.py:351:main] Process 1085056 exits successfully.
ml-512-node-036: [2024-07-08 07:27:33,771] [INFO] [launch.py:351:main] Process 1085054 exits successfully.
ml-512-node-059: [2024-07-08 07:27:33,804] [INFO] [launch.py:351:main] Process 1083093 exits successfully.
ml-512-node-059: [2024-07-08 07:27:33,805] [INFO] [launch.py:351:main] Process 1083095 exits successfully.
ml-512-node-059: [2024-07-08 07:27:33,805] [INFO] [launch.py:351:main] Process 1083090 exits successfully.
ml-512-node-059: [2024-07-08 07:27:33,805] [INFO] [launch.py:351:main] Process 1083091 exits successfully.
ml-512-node-059: [2024-07-08 07:27:33,805] [INFO] [launch.py:351:main] Process 1083089 exits successfully.
ml-512-node-064: [2024-07-08 07:27:33,810] [INFO] [launch.py:351:main] Process 1076961 exits successfully.
ml-512-node-064: [2024-07-08 07:27:33,811] [INFO] [launch.py:351:main] Process 1076955 exits successfully.
ml-512-node-057: [2024-07-08 07:27:33,815] [INFO] [launch.py:351:main] Process 1086887 exits successfully.
ml-512-node-057: [2024-07-08 07:27:33,815] [INFO] [launch.py:351:main] Process 1086885 exits successfully.
ml-512-node-057: [2024-07-08 07:27:33,815] [INFO] [launch.py:351:main] Process 1086891 exits successfully.
ml-512-node-057: [2024-07-08 07:27:33,815] [INFO] [launch.py:351:main] Process 1086884 exits successfully.
ml-512-node-057: [2024-07-08 07:27:33,815] [INFO] [launch.py:351:main] Process 1086888 exits successfully.
ml-512-node-057: [2024-07-08 07:27:33,815] [INFO] [launch.py:351:main] Process 1086890 exits successfully.
ml-512-node-054: [2024-07-08 07:27:33,834] [INFO] [launch.py:351:main] Process 1079366 exits successfully.
ml-512-node-054: [2024-07-08 07:27:33,834] [INFO] [launch.py:351:main] Process 1079368 exits successfully.
ml-512-node-054: [2024-07-08 07:27:33,834] [INFO] [launch.py:351:main] Process 1079370 exits successfully.
ml-512-node-054: [2024-07-08 07:27:33,834] [INFO] [launch.py:351:main] Process 1079369 exits successfully.
ml-512-node-054: [2024-07-08 07:27:33,834] [INFO] [launch.py:351:main] Process 1079367 exits successfully.
ml-512-node-054: [2024-07-08 07:27:33,834] [INFO] [launch.py:351:main] Process 1079365 exits successfully.
ml-512-node-054: [2024-07-08 07:27:33,834] [INFO] [launch.py:351:main] Process 1079371 exits successfully.
ml-512-node-060: [2024-07-08 07:27:33,839] [INFO] [launch.py:351:main] Process 1079375 exits successfully.
ml-512-node-060: [2024-07-08 07:27:33,840] [INFO] [launch.py:351:main] Process 1079374 exits successfully.
ml-512-node-060: [2024-07-08 07:27:33,840] [INFO] [launch.py:351:main] Process 1079372 exits successfully.
ml-512-node-060: [2024-07-08 07:27:33,840] [INFO] [launch.py:351:main] Process 1079370 exits successfully.
ml-512-node-043: [2024-07-08 07:27:33,842] [INFO] [launch.py:351:main] Process 1088173 exits successfully.
ml-512-node-043: [2024-07-08 07:27:33,843] [INFO] [launch.py:351:main] Process 1088171 exits successfully.
ml-512-node-043: [2024-07-08 07:27:33,843] [INFO] [launch.py:351:main] Process 1088175 exits successfully.
ml-512-node-043: [2024-07-08 07:27:33,843] [INFO] [launch.py:351:main] Process 1088177 exits successfully.
ml-512-node-043: [2024-07-08 07:27:33,843] [INFO] [launch.py:351:main] Process 1088176 exits successfully.
ml-512-node-043: [2024-07-08 07:27:33,843] [INFO] [launch.py:351:main] Process 1088174 exits successfully.
ml-512-node-043: [2024-07-08 07:27:33,843] [INFO] [launch.py:351:main] Process 1088172 exits successfully.
ml-512-node-043: [2024-07-08 07:27:33,843] [INFO] [launch.py:351:main] Process 1088178 exits successfully.
ml-512-node-039: [2024-07-08 07:27:33,847] [INFO] [launch.py:351:main] Process 1172104 exits successfully.
ml-512-node-039: [2024-07-08 07:27:33,847] [INFO] [launch.py:351:main] Process 1172102 exits successfully.
ml-512-node-039: [2024-07-08 07:27:33,847] [INFO] [launch.py:351:main] Process 1172106 exits successfully.
ml-512-node-039: [2024-07-08 07:27:33,847] [INFO] [launch.py:351:main] Process 1172107 exits successfully.
ml-512-node-039: [2024-07-08 07:27:33,847] [INFO] [launch.py:351:main] Process 1172105 exits successfully.
ml-512-node-039: [2024-07-08 07:27:33,847] [INFO] [launch.py:351:main] Process 1172103 exits successfully.
ml-512-node-041: [2024-07-08 07:27:33,844] [INFO] [launch.py:351:main] Process 1091251 exits successfully.
ml-512-node-041: [2024-07-08 07:27:33,844] [INFO] [launch.py:351:main] Process 1091249 exits successfully.
ml-512-node-041: [2024-07-08 07:27:33,844] [INFO] [launch.py:351:main] Process 1091255 exits successfully.
ml-512-node-041: [2024-07-08 07:27:33,844] [INFO] [launch.py:351:main] Process 1091254 exits successfully.
ml-512-node-041: [2024-07-08 07:27:33,844] [INFO] [launch.py:351:main] Process 1091252 exits successfully.
ml-512-node-041: [2024-07-08 07:27:33,844] [INFO] [launch.py:351:main] Process 1091250 exits successfully.
ml-512-node-041: [2024-07-08 07:27:33,844] [INFO] [launch.py:351:main] Process 1091256 exits successfully.
ml-512-node-053: [2024-07-08 07:27:33,862] [INFO] [launch.py:351:main] Process 1088097 exits successfully.
ml-512-node-053: [2024-07-08 07:27:33,863] [INFO] [launch.py:351:main] Process 1088096 exits successfully.
ml-512-node-053: [2024-07-08 07:27:33,863] [INFO] [launch.py:351:main] Process 1088094 exits successfully.
ml-512-node-053: [2024-07-08 07:27:33,863] [INFO] [launch.py:351:main] Process 1088098 exits successfully.
ml-512-node-053: [2024-07-08 07:27:33,863] [INFO] [launch.py:351:main] Process 1088091 exits successfully.
ml-512-node-053: [2024-07-08 07:27:33,863] [INFO] [launch.py:351:main] Process 1088095 exits successfully.
ml-512-node-063: [2024-07-08 07:27:33,866] [INFO] [launch.py:351:main] Process 1082940 exits successfully.
ml-512-node-063: [2024-07-08 07:27:33,866] [INFO] [launch.py:351:main] Process 1082944 exits successfully.
ml-512-node-063: [2024-07-08 07:27:33,866] [INFO] [launch.py:351:main] Process 1082943 exits successfully.
ml-512-node-063: [2024-07-08 07:27:33,866] [INFO] [launch.py:351:main] Process 1082941 exits successfully.
ml-512-node-063: [2024-07-08 07:27:33,866] [INFO] [launch.py:351:main] Process 1082945 exits successfully.
ml-512-node-038: [2024-07-08 07:27:33,863] [INFO] [launch.py:351:main] Process 1084650 exits successfully.
ml-512-node-046: [2024-07-08 07:27:33,869] [INFO] [launch.py:351:main] Process 1084069 exits successfully.
ml-512-node-046: [2024-07-08 07:27:33,870] [INFO] [launch.py:351:main] Process 1084067 exits successfully.
ml-512-node-046: [2024-07-08 07:27:33,870] [INFO] [launch.py:351:main] Process 1084071 exits successfully.
ml-512-node-046: [2024-07-08 07:27:33,870] [INFO] [launch.py:351:main] Process 1084073 exits successfully.
ml-512-node-046: [2024-07-08 07:27:33,870] [INFO] [launch.py:351:main] Process 1084072 exits successfully.
ml-512-node-046: [2024-07-08 07:27:33,870] [INFO] [launch.py:351:main] Process 1084070 exits successfully.
ml-512-node-046: [2024-07-08 07:27:33,870] [INFO] [launch.py:351:main] Process 1084074 exits successfully.
ml-512-node-062: [2024-07-08 07:27:33,876] [INFO] [launch.py:351:main] Process 1078499 exits successfully.
ml-512-node-062: [2024-07-08 07:27:33,876] [INFO] [launch.py:351:main] Process 1078501 exits successfully.
ml-512-node-062: [2024-07-08 07:27:33,876] [INFO] [launch.py:351:main] Process 1078500 exits successfully.
ml-512-node-062: [2024-07-08 07:27:33,876] [INFO] [launch.py:351:main] Process 1078498 exits successfully.
ml-512-node-062: [2024-07-08 07:27:33,876] [INFO] [launch.py:351:main] Process 1078502 exits successfully.
ml-512-node-062: [2024-07-08 07:27:33,877] [INFO] [launch.py:351:main] Process 1078497 exits successfully.
ml-512-node-062: [2024-07-08 07:27:33,877] [INFO] [launch.py:351:main] Process 1078495 exits successfully.
ml-512-node-052: [2024-07-08 07:27:33,880] [INFO] [launch.py:351:main] Process 1081366 exits successfully.
ml-512-node-052: [2024-07-08 07:27:33,880] [INFO] [launch.py:351:main] Process 1081367 exits successfully.
ml-512-node-052: [2024-07-08 07:27:33,880] [INFO] [launch.py:351:main] Process 1081365 exits successfully.
ml-512-node-052: [2024-07-08 07:27:33,880] [INFO] [launch.py:351:main] Process 1081363 exits successfully.
ml-512-node-052: [2024-07-08 07:27:33,880] [INFO] [launch.py:351:main] Process 1081369 exits successfully.
ml-512-node-052: [2024-07-08 07:27:33,880] [INFO] [launch.py:351:main] Process 1081364 exits successfully.
ml-512-node-052: [2024-07-08 07:27:33,880] [INFO] [launch.py:351:main] Process 1081362 exits successfully.
ml-512-node-045: [2024-07-08 07:27:33,894] [INFO] [launch.py:351:main] Process 1088384 exits successfully.
ml-512-node-045: [2024-07-08 07:27:33,894] [INFO] [launch.py:351:main] Process 1088386 exits successfully.
ml-512-node-045: [2024-07-08 07:27:33,894] [INFO] [launch.py:351:main] Process 1088385 exits successfully.
ml-512-node-045: [2024-07-08 07:27:33,894] [INFO] [launch.py:351:main] Process 1088383 exits successfully.
ml-512-node-045: [2024-07-08 07:27:33,895] [INFO] [launch.py:351:main] Process 1088381 exits successfully.
ml-512-node-045: [2024-07-08 07:27:33,895] [INFO] [launch.py:351:main] Process 1088382 exits successfully.
ml-512-node-045: [2024-07-08 07:27:33,895] [INFO] [launch.py:351:main] Process 1088380 exits successfully.
ml-512-node-049: [2024-07-08 07:27:33,907] [INFO] [launch.py:351:main] Process 1090309 exits successfully.
ml-512-node-049: [2024-07-08 07:27:33,907] [INFO] [launch.py:351:main] Process 1090308 exits successfully.
ml-512-node-049: [2024-07-08 07:27:33,907] [INFO] [launch.py:351:main] Process 1090306 exits successfully.
ml-512-node-049: [2024-07-08 07:27:33,907] [INFO] [launch.py:351:main] Process 1090304 exits successfully.
ml-512-node-049: [2024-07-08 07:27:33,907] [INFO] [launch.py:351:main] Process 1090305 exits successfully.
ml-512-node-049: [2024-07-08 07:27:33,907] [INFO] [launch.py:351:main] Process 1090303 exits successfully.
ml-512-node-049: [2024-07-08 07:27:33,907] [INFO] [launch.py:351:main] Process 1090307 exits successfully.
ml-512-node-051: [2024-07-08 07:27:33,942] [INFO] [launch.py:351:main] Process 1086128 exits successfully.
ml-512-node-051: [2024-07-08 07:27:33,942] [INFO] [launch.py:351:main] Process 1086127 exits successfully.
ml-512-node-051: [2024-07-08 07:27:33,942] [INFO] [launch.py:351:main] Process 1086123 exits successfully.
ml-512-node-051: [2024-07-08 07:27:33,942] [INFO] [launch.py:351:main] Process 1086129 exits successfully.
ml-512-node-051: [2024-07-08 07:27:33,942] [INFO] [launch.py:351:main] Process 1086126 exits successfully.
ml-512-node-040: [2024-07-08 07:27:34,259] [INFO] [launch.py:351:main] Process 1139788 exits successfully.
ml-512-node-040: [2024-07-08 07:27:34,259] [INFO] [launch.py:351:main] Process 1139787 exits successfully.
ml-512-node-040: [2024-07-08 07:27:34,260] [INFO] [launch.py:351:main] Process 1139785 exits successfully.
ml-512-node-040: [2024-07-08 07:27:34,260] [INFO] [launch.py:351:main] Process 1139783 exits successfully.
ml-512-node-040: [2024-07-08 07:27:34,260] [INFO] [launch.py:351:main] Process 1139789 exits successfully.
ml-512-node-040: [2024-07-08 07:27:34,260] [INFO] [launch.py:351:main] Process 1139784 exits successfully.
ml-512-node-040: [2024-07-08 07:27:34,260] [INFO] [launch.py:351:main] Process 1139782 exits successfully.
ml-512-node-056: [2024-07-08 07:27:34,439] [INFO] [launch.py:351:main] Process 1095951 exits successfully.
ml-512-node-056: [2024-07-08 07:27:34,439] [INFO] [launch.py:351:main] Process 1095957 exits successfully.
ml-512-node-056: [2024-07-08 07:27:34,439] [INFO] [launch.py:351:main] Process 1095956 exits successfully.
ml-512-node-056: [2024-07-08 07:27:34,439] [INFO] [launch.py:351:main] Process 1095954 exits successfully.
ml-512-node-056: [2024-07-08 07:27:34,439] [INFO] [launch.py:351:main] Process 1095958 exits successfully.
ml-512-node-061: [2024-07-08 07:27:34,627] [INFO] [launch.py:351:main] Process 1085393 exits successfully.
ml-512-node-059: [2024-07-08 07:27:34,806] [INFO] [launch.py:351:main] Process 1083094 exits successfully.
ml-512-node-059: [2024-07-08 07:27:34,806] [INFO] [launch.py:351:main] Process 1083092 exits successfully.
ml-512-node-059: [2024-07-08 07:27:34,806] [INFO] [launch.py:351:main] Process 1083096 exits successfully.
ml-512-node-060: [2024-07-08 07:27:34,841] [INFO] [launch.py:351:main] Process 1079373 exits successfully.
ml-512-node-060: [2024-07-08 07:27:34,841] [INFO] [launch.py:351:main] Process 1079371 exits successfully.
ml-512-node-060: [2024-07-08 07:27:34,841] [INFO] [launch.py:351:main] Process 1079369 exits successfully.
ml-512-node-060: [2024-07-08 07:27:34,841] [INFO] [launch.py:351:main] Process 1079376 exits successfully.
ml-512-node-053: [2024-07-08 07:27:34,864] [INFO] [launch.py:351:main] Process 1088093 exits successfully.
ml-512-node-053: [2024-07-08 07:27:34,864] [INFO] [launch.py:351:main] Process 1088092 exits successfully.
ml-512-node-040: [2024-07-08 07:27:35,261] [INFO] [launch.py:351:main] Process 1139786 exits successfully.
