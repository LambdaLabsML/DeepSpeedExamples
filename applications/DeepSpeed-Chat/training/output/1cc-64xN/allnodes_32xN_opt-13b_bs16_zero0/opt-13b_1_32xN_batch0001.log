ml-512-node-001 slots=8
ml-512-node-002 slots=8
ml-512-node-003 slots=8
ml-512-node-004 slots=8
ml-512-node-005 slots=8
ml-512-node-006 slots=8
ml-512-node-007 slots=8
ml-512-node-008 slots=8
ml-512-node-009 slots=8
ml-512-node-010 slots=8
ml-512-node-011 slots=8
ml-512-node-012 slots=8
ml-512-node-013 slots=8
ml-512-node-014 slots=8
ml-512-node-015 slots=8
ml-512-node-016 slots=8
ml-512-node-017 slots=8
ml-512-node-018 slots=8
ml-512-node-019 slots=8
ml-512-node-020 slots=8
ml-512-node-021 slots=8
ml-512-node-022 slots=8
ml-512-node-023 slots=8
ml-512-node-024 slots=8
ml-512-node-025 slots=8
ml-512-node-026 slots=8
ml-512-node-027 slots=8
ml-512-node-028 slots=8
ml-512-node-029 slots=8
ml-512-node-030 slots=8
ml-512-node-031 slots=8
ml-512-node-032 slots=8
[2024-07-08 07:19:15,942] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-07-08 07:19:17.346883: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-07-08 07:19:17.388445: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[2024-07-08 07:19:18,897] [INFO] [runner.py:557:main] deepspeed_env file = ./.deepspeed_env
[2024-07-08 07:19:18,898] [INFO] [multinode_runner.py:81:get_cmd] Running on the following workers: ml-512-node-001,ml-512-node-002,ml-512-node-003,ml-512-node-004,ml-512-node-005,ml-512-node-006,ml-512-node-007,ml-512-node-008,ml-512-node-009,ml-512-node-010,ml-512-node-011,ml-512-node-012,ml-512-node-013,ml-512-node-014,ml-512-node-015,ml-512-node-016,ml-512-node-017,ml-512-node-018,ml-512-node-019,ml-512-node-020,ml-512-node-021,ml-512-node-022,ml-512-node-023,ml-512-node-024,ml-512-node-025,ml-512-node-026,ml-512-node-027,ml-512-node-028,ml-512-node-029,ml-512-node-030,ml-512-node-031,ml-512-node-032
[2024-07-08 07:19:18,898] [INFO] [runner.py:568:main] cmd = pdsh -S -f 1024 -w ml-512-node-001,ml-512-node-002,ml-512-node-003,ml-512-node-004,ml-512-node-005,ml-512-node-006,ml-512-node-007,ml-512-node-008,ml-512-node-009,ml-512-node-010,ml-512-node-011,ml-512-node-012,ml-512-node-013,ml-512-node-014,ml-512-node-015,ml-512-node-016,ml-512-node-017,ml-512-node-018,ml-512-node-019,ml-512-node-020,ml-512-node-021,ml-512-node-022,ml-512-node-023,ml-512-node-024,ml-512-node-025,ml-512-node-026,ml-512-node-027,ml-512-node-028,ml-512-node-029,ml-512-node-030,ml-512-node-031,ml-512-node-032 export PYTHONPATH=/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training; export PROJECT_PATH=/home/ubuntu/ml-1cc/benchmark; export OMPI_MCA_btl_tcp_if_include=eno1; export UCX_TLS=self,shm,tcp; export NCCL_P2P_LEVEL=NVL; export NCCL_NET_GDR_LEVEL=PIX; export NCCL_IB_HCA='=mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8'; export NCCL_IB_PCI_RELAXED_ORDERING=1; export NCCL_SOCKET_IFNAME=eno1; export NCCL_DEBUG=WARN;  cd /home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training; /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJtbC01MTItbm9kZS0wMDEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMDkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMTkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMjkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --node_rank=%n --master_addr=ml-512-node-001 --master_port=29500 /home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py --data_path Dahoas/full-hh-rlhf --data_split 2,4,4 --data_output_path /home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1 --model_name_or_path facebook/opt-13b --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --max_seq_len 512 --learning_rate 1e-10 --weight_decay 0.1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --seed 1234 --gradient_checkpointing --zero_stage 0 --lora_dim 128 --lora_module_name decoder.layers. --deepspeed --num_warmup_steps 10 --num_train_epochs 100 --max_steps 100
ml-512-node-001: [2024-07-08 07:19:21,179] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [2024-07-08 07:19:22,508] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 07:19:22,510] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [2024-07-08 07:19:22,692] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [2024-07-08 07:19:22,705] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 07:19:22,710] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 07:19:22,712] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [2024-07-08 07:19:22,713] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 07:19:22,726] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [2024-07-08 07:19:22,728] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [2024-07-08 07:19:22,729] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 07:19:22,730] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 07:19:22,731] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 07:19:22,732] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [2024-07-08 07:19:22,733] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 07:19:22,736] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 07:19:22,745] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 07:19:22,745] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 07:19:22,747] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 07:19:22,748] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 07:19:22,748] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 07:19:22,750] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 07:19:22,754] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 07:19:22,756] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 07:19:22,770] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 07:19:22,769] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [2024-07-08 07:19:22,776] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 07:19:22,777] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: 2024-07-08 07:19:22.798838: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-001: 2024-07-08 07:19:22.836711: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-001: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [2024-07-08 07:19:23,718] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [2024-07-08 07:19:23,725] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [2024-07-08 07:19:23,728] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [2024-07-08 07:19:23,744] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: 2024-07-08 07:19:23.858572: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-005: 2024-07-08 07:19:23.875439: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-009: 2024-07-08 07:19:23.896188: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-009: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-005: 2024-07-08 07:19:23.914751: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-005: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-016: 2024-07-08 07:19:24.044690: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-006: 2024-07-08 07:19:24.046219: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-004: 2024-07-08 07:19:24.070561: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-020: 2024-07-08 07:19:24.073105: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-008: 2024-07-08 07:19:24.073862: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-007: 2024-07-08 07:19:24.076058: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-016: 2024-07-08 07:19:24.082291: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-016: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-013: 2024-07-08 07:19:24.082558: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-006: 2024-07-08 07:19:24.083726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-006: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-026: 2024-07-08 07:19:24.086086: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-011: 2024-07-08 07:19:24.087627: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-012: 2024-07-08 07:19:24.093970: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-029: 2024-07-08 07:19:24.099238: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-004: 2024-07-08 07:19:24.107830: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-004: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-020: 2024-07-08 07:19:24.110855: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-020: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-003: 2024-07-08 07:19:24.108901: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-008: 2024-07-08 07:19:24.112975: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-008: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-007: 2024-07-08 07:19:24.113596: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-007: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-022: 2024-07-08 07:19:24.113511: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-028: 2024-07-08 07:19:24.114725: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-002: 2024-07-08 07:19:24.119590: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-013: 2024-07-08 07:19:24.120329: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-013: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-026: 2024-07-08 07:19:24.123382: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-026: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-023: 2024-07-08 07:19:24.123943: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-011: 2024-07-08 07:19:24.127288: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-011: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-012: 2024-07-08 07:19:24.133178: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-012: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-030: 2024-07-08 07:19:24.132714: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:139:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:139:main] 0 NCCL_SOCKET_IFNAME=eno1
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:139:main] 0 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:139:main] 0 NCCL_P2P_LEVEL=NVL
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:139:main] 0 NCCL_DEBUG=WARN
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:139:main] 0 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=0
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-001: [2024-07-08 07:19:24,131] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-001: [2024-07-08 07:19:24,132] [INFO] [launch.py:256:main] process 2031564 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 07:19:24,133] [INFO] [launch.py:256:main] process 2031565 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 07:19:24,133] [INFO] [launch.py:256:main] process 2031566 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: 2024-07-08 07:19:24.136465: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-029: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-001: [2024-07-08 07:19:24,134] [INFO] [launch.py:256:main] process 2031567 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 07:19:24,135] [INFO] [launch.py:256:main] process 2031568 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 07:19:24,136] [INFO] [launch.py:256:main] process 2031569 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 07:19:24,136] [INFO] [launch.py:256:main] process 2031570 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-001: [2024-07-08 07:19:24,137] [INFO] [launch.py:256:main] process 2031571 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: 2024-07-08 07:19:24.141985: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-018: 2024-07-08 07:19:24.144770: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-024: 2024-07-08 07:19:24.143996: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-003: 2024-07-08 07:19:24.146480: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-003: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-031: 2024-07-08 07:19:24.147883: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-022: 2024-07-08 07:19:24.151552: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-022: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-028: 2024-07-08 07:19:24.152866: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-028: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-002: 2024-07-08 07:19:24.157775: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-002: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-023: 2024-07-08 07:19:24.161992: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-023: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-025: 2024-07-08 07:19:24.164409: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-010: 2024-07-08 07:19:24.167025: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-030: 2024-07-08 07:19:24.172434: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-030: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-027: 2024-07-08 07:19:24.179027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-027: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-024: 2024-07-08 07:19:24.182328: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-024: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-018: 2024-07-08 07:19:24.183802: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-018: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-031: 2024-07-08 07:19:24.186786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-031: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-025: 2024-07-08 07:19:24.202362: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-025: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-010: 2024-07-08 07:19:24.205516: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-010: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-017: 2024-07-08 07:19:24.212909: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-032: 2024-07-08 07:19:24.220312: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: 2024-07-08 07:19:24.252086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-017: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: 2024-07-08 07:19:24.259525: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-032: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: 2024-07-08 07:19:25.062188: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-021: 2024-07-08 07:19:25.095105: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-015: 2024-07-08 07:19:25.099585: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-015: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-014: 2024-07-08 07:19:25.129484: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-021: 2024-07-08 07:19:25.135161: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-021: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-009: [2024-07-08 07:19:25,146] [INFO] [launch.py:139:main] 8 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-009: [2024-07-08 07:19:25,146] [INFO] [launch.py:139:main] 8 NCCL_SOCKET_IFNAME=eno1
ml-512-node-009: [2024-07-08 07:19:25,146] [INFO] [launch.py:139:main] 8 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-009: [2024-07-08 07:19:25,146] [INFO] [launch.py:139:main] 8 NCCL_P2P_LEVEL=NVL
ml-512-node-009: [2024-07-08 07:19:25,147] [INFO] [launch.py:139:main] 8 NCCL_DEBUG=WARN
ml-512-node-009: [2024-07-08 07:19:25,147] [INFO] [launch.py:139:main] 8 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-009: [2024-07-08 07:19:25,147] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-009: [2024-07-08 07:19:25,147] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=8
ml-512-node-009: [2024-07-08 07:19:25,147] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-009: [2024-07-08 07:19:25,147] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-009: [2024-07-08 07:19:25,147] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-009: [2024-07-08 07:19:25,148] [INFO] [launch.py:256:main] process 1096802 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 07:19:25,148] [INFO] [launch.py:256:main] process 1096803 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: 2024-07-08 07:19:25.147419: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-009: [2024-07-08 07:19:25,149] [INFO] [launch.py:256:main] process 1096804 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 07:19:25,150] [INFO] [launch.py:256:main] process 1096805 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 07:19:25,150] [INFO] [launch.py:256:main] process 1096806 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 07:19:25,151] [INFO] [launch.py:256:main] process 1096807 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 07:19:25,152] [INFO] [launch.py:256:main] process 1096808 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-009: [2024-07-08 07:19:25,152] [INFO] [launch.py:256:main] process 1096809 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: 2024-07-08 07:19:25.167017: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-014: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-019: 2024-07-08 07:19:25.186266: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-019: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-005: [2024-07-08 07:19:25,193] [INFO] [launch.py:139:main] 4 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-005: [2024-07-08 07:19:25,193] [INFO] [launch.py:139:main] 4 NCCL_SOCKET_IFNAME=eno1
ml-512-node-005: [2024-07-08 07:19:25,193] [INFO] [launch.py:139:main] 4 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-005: [2024-07-08 07:19:25,194] [INFO] [launch.py:139:main] 4 NCCL_P2P_LEVEL=NVL
ml-512-node-005: [2024-07-08 07:19:25,194] [INFO] [launch.py:139:main] 4 NCCL_DEBUG=WARN
ml-512-node-005: [2024-07-08 07:19:25,194] [INFO] [launch.py:139:main] 4 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-005: [2024-07-08 07:19:25,194] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-005: [2024-07-08 07:19:25,194] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=4
ml-512-node-005: [2024-07-08 07:19:25,194] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-005: [2024-07-08 07:19:25,194] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-005: [2024-07-08 07:19:25,194] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-005: [2024-07-08 07:19:25,194] [INFO] [launch.py:256:main] process 1112893 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 07:19:25,195] [INFO] [launch.py:256:main] process 1112894 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 07:19:25,196] [INFO] [launch.py:256:main] process 1112895 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 07:19:25,196] [INFO] [launch.py:256:main] process 1112896 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 07:19:25,197] [INFO] [launch.py:256:main] process 1112897 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 07:19:25,198] [INFO] [launch.py:256:main] process 1112898 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 07:19:25,198] [INFO] [launch.py:256:main] process 1112899 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-005: [2024-07-08 07:19:25,199] [INFO] [launch.py:256:main] process 1112900 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 07:19:25,351] [INFO] [launch.py:139:main] 3 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-004: [2024-07-08 07:19:25,351] [INFO] [launch.py:139:main] 3 NCCL_SOCKET_IFNAME=eno1
ml-512-node-004: [2024-07-08 07:19:25,351] [INFO] [launch.py:139:main] 3 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-004: [2024-07-08 07:19:25,351] [INFO] [launch.py:139:main] 3 NCCL_P2P_LEVEL=NVL
ml-512-node-004: [2024-07-08 07:19:25,351] [INFO] [launch.py:139:main] 3 NCCL_DEBUG=WARN
ml-512-node-004: [2024-07-08 07:19:25,351] [INFO] [launch.py:139:main] 3 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-004: [2024-07-08 07:19:25,351] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-004: [2024-07-08 07:19:25,352] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=3
ml-512-node-004: [2024-07-08 07:19:25,352] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-004: [2024-07-08 07:19:25,352] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-004: [2024-07-08 07:19:25,352] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-004: [2024-07-08 07:19:25,352] [INFO] [launch.py:256:main] process 1094645 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 07:19:25,353] [INFO] [launch.py:256:main] process 1094646 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 07:19:25,354] [INFO] [launch.py:256:main] process 1094647 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 07:19:25,354] [INFO] [launch.py:256:main] process 1094648 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 07:19:25,355] [INFO] [launch.py:256:main] process 1094649 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 07:19:25,356] [INFO] [launch.py:256:main] process 1094650 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 07:19:25,356] [INFO] [launch.py:256:main] process 1094651 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-004: [2024-07-08 07:19:25,357] [INFO] [launch.py:256:main] process 1094652 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:139:main] 19 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:139:main] 19 NCCL_SOCKET_IFNAME=eno1
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:139:main] 19 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:139:main] 19 NCCL_P2P_LEVEL=NVL
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:139:main] 19 NCCL_DEBUG=WARN
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:139:main] 19 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=19
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-020: [2024-07-08 07:19:25,358] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-020: [2024-07-08 07:19:25,359] [INFO] [launch.py:256:main] process 1088927 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 07:19:25,360] [INFO] [launch.py:256:main] process 1088928 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 07:19:25,360] [INFO] [launch.py:256:main] process 1088929 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 07:19:25,361] [INFO] [launch.py:256:main] process 1088930 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 07:19:25,362] [INFO] [launch.py:256:main] process 1088931 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-020: [2024-07-08 07:19:25,362] [INFO] [launch.py:256:main] process 1088932 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:139:main] 15 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:139:main] 15 NCCL_SOCKET_IFNAME=eno1
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:139:main] 15 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:139:main] 15 NCCL_P2P_LEVEL=NVL
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:139:main] 15 NCCL_DEBUG=WARN
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:139:main] 15 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=15
ml-512-node-020: [2024-07-08 07:19:25,363] [INFO] [launch.py:256:main] process 1088933 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-016: [2024-07-08 07:19:25,361] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-020: [2024-07-08 07:19:25,363] [INFO] [launch.py:256:main] process 1088934 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 07:19:25,362] [INFO] [launch.py:256:main] process 1089894 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 07:19:25,363] [INFO] [launch.py:256:main] process 1089895 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 07:19:25,363] [INFO] [launch.py:256:main] process 1089896 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 07:19:25,364] [INFO] [launch.py:256:main] process 1089897 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:139:main] 5 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:139:main] 5 NCCL_SOCKET_IFNAME=eno1
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:139:main] 5 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:139:main] 5 NCCL_P2P_LEVEL=NVL
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:139:main] 5 NCCL_DEBUG=WARN
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:139:main] 5 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=5
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-006: [2024-07-08 07:19:25,364] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-016: [2024-07-08 07:19:25,365] [INFO] [launch.py:256:main] process 1089898 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 07:19:25,365] [INFO] [launch.py:256:main] process 1089899 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 07:19:25,365] [INFO] [launch.py:256:main] process 1094221 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 07:19:25,366] [INFO] [launch.py:256:main] process 1089900 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 07:19:25,366] [INFO] [launch.py:256:main] process 1094222 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-016: [2024-07-08 07:19:25,367] [INFO] [launch.py:256:main] process 1089901 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 07:19:25,366] [INFO] [launch.py:256:main] process 1094223 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 07:19:25,367] [INFO] [launch.py:256:main] process 1094224 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:139:main] 7 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:139:main] 7 NCCL_SOCKET_IFNAME=eno1
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:139:main] 7 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:139:main] 7 NCCL_P2P_LEVEL=NVL
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:139:main] 7 NCCL_DEBUG=WARN
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:139:main] 7 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-006: [2024-07-08 07:19:25,367] [INFO] [launch.py:256:main] process 1094225 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=7
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-008: [2024-07-08 07:19:25,367] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-006: [2024-07-08 07:19:25,368] [INFO] [launch.py:256:main] process 1094226 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 07:19:25,368] [INFO] [launch.py:256:main] process 1093123 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 07:19:25,369] [INFO] [launch.py:256:main] process 1094227 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 07:19:25,369] [INFO] [launch.py:256:main] process 1093124 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 07:19:25,369] [INFO] [launch.py:256:main] process 1094228 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 07:19:25,370] [INFO] [launch.py:256:main] process 1093125 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 07:19:25,371] [INFO] [launch.py:256:main] process 1093126 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 07:19:25,371] [INFO] [launch.py:256:main] process 1093127 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 07:19:25,372] [INFO] [launch.py:256:main] process 1093128 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 07:19:25,373] [INFO] [launch.py:256:main] process 1093129 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-008: [2024-07-08 07:19:25,373] [INFO] [launch.py:256:main] process 1093130 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:139:main] 6 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:139:main] 6 NCCL_SOCKET_IFNAME=eno1
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:139:main] 6 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:139:main] 6 NCCL_P2P_LEVEL=NVL
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:139:main] 6 NCCL_DEBUG=WARN
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:139:main] 6 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=6
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-007: [2024-07-08 07:19:25,373] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-007: [2024-07-08 07:19:25,374] [INFO] [launch.py:256:main] process 1099572 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 07:19:25,375] [INFO] [launch.py:256:main] process 1099573 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 07:19:25,376] [INFO] [launch.py:256:main] process 1099574 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 07:19:25,376] [INFO] [launch.py:256:main] process 1099575 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 07:19:25,377] [INFO] [launch.py:256:main] process 1099576 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 07:19:25,376] [INFO] [launch.py:139:main] 12 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-013: [2024-07-08 07:19:25,376] [INFO] [launch.py:139:main] 12 NCCL_SOCKET_IFNAME=eno1
ml-512-node-013: [2024-07-08 07:19:25,376] [INFO] [launch.py:139:main] 12 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-013: [2024-07-08 07:19:25,376] [INFO] [launch.py:139:main] 12 NCCL_P2P_LEVEL=NVL
ml-512-node-013: [2024-07-08 07:19:25,376] [INFO] [launch.py:139:main] 12 NCCL_DEBUG=WARN
ml-512-node-013: [2024-07-08 07:19:25,376] [INFO] [launch.py:139:main] 12 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-013: [2024-07-08 07:19:25,377] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-013: [2024-07-08 07:19:25,377] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=12
ml-512-node-013: [2024-07-08 07:19:25,377] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-013: [2024-07-08 07:19:25,377] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-013: [2024-07-08 07:19:25,377] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-013: [2024-07-08 07:19:25,377] [INFO] [launch.py:256:main] process 1096026 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 07:19:25,378] [INFO] [launch.py:256:main] process 1099577 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 07:19:25,378] [INFO] [launch.py:256:main] process 1099578 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 07:19:25,378] [INFO] [launch.py:256:main] process 1096027 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-007: [2024-07-08 07:19:25,379] [INFO] [launch.py:256:main] process 1099579 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 07:19:25,379] [INFO] [launch.py:256:main] process 1096028 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 07:19:25,379] [INFO] [launch.py:256:main] process 1096029 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 07:19:25,380] [INFO] [launch.py:256:main] process 1096030 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 07:19:25,381] [INFO] [launch.py:256:main] process 1096031 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 07:19:25,381] [INFO] [launch.py:256:main] process 1096032 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-013: [2024-07-08 07:19:25,382] [INFO] [launch.py:256:main] process 1096033 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 28 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 28 NCCL_SOCKET_IFNAME=eno1
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 28 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 28 NCCL_P2P_LEVEL=NVL
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 28 NCCL_DEBUG=WARN
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 28 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=28
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-029: [2024-07-08 07:19:25,403] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-029: [2024-07-08 07:19:25,404] [INFO] [launch.py:256:main] process 1092862 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 07:19:25,405] [INFO] [launch.py:256:main] process 1092863 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 07:19:25,405] [INFO] [launch.py:256:main] process 1092864 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 27 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 27 NCCL_SOCKET_IFNAME=eno1
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 27 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 27 NCCL_P2P_LEVEL=NVL
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 27 NCCL_DEBUG=WARN
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:139:main] 27 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=27
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-028: [2024-07-08 07:19:25,403] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-029: [2024-07-08 07:19:25,406] [INFO] [launch.py:256:main] process 1092865 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 07:19:25,404] [INFO] [launch.py:256:main] process 1088230 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 07:19:25,406] [INFO] [launch.py:256:main] process 1092866 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 07:19:25,407] [INFO] [launch.py:139:main] 25 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-026: [2024-07-08 07:19:25,407] [INFO] [launch.py:139:main] 25 NCCL_SOCKET_IFNAME=eno1
ml-512-node-026: [2024-07-08 07:19:25,408] [INFO] [launch.py:139:main] 25 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-026: [2024-07-08 07:19:25,408] [INFO] [launch.py:139:main] 25 NCCL_P2P_LEVEL=NVL
ml-512-node-029: [2024-07-08 07:19:25,407] [INFO] [launch.py:256:main] process 1092867 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 07:19:25,408] [INFO] [launch.py:139:main] 25 NCCL_DEBUG=WARN
ml-512-node-026: [2024-07-08 07:19:25,408] [INFO] [launch.py:139:main] 25 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-026: [2024-07-08 07:19:25,408] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-026: [2024-07-08 07:19:25,408] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=25
ml-512-node-026: [2024-07-08 07:19:25,408] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-026: [2024-07-08 07:19:25,408] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-026: [2024-07-08 07:19:25,408] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-028: [2024-07-08 07:19:25,405] [INFO] [launch.py:256:main] process 1088231 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 07:19:25,408] [INFO] [launch.py:256:main] process 1092868 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 07:19:25,409] [INFO] [launch.py:256:main] process 1087987 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 07:19:25,406] [INFO] [launch.py:256:main] process 1088232 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-029: [2024-07-08 07:19:25,408] [INFO] [launch.py:256:main] process 1092869 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 07:19:25,409] [INFO] [launch.py:256:main] process 1087988 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 07:19:25,407] [INFO] [launch.py:256:main] process 1088233 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 07:19:25,410] [INFO] [launch.py:256:main] process 1087989 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 07:19:25,407] [INFO] [launch.py:256:main] process 1088234 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 07:19:25,411] [INFO] [launch.py:256:main] process 1087990 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 07:19:25,408] [INFO] [launch.py:256:main] process 1088235 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 07:19:25,411] [INFO] [launch.py:256:main] process 1087991 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 07:19:25,409] [INFO] [launch.py:256:main] process 1088236 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 07:19:25,412] [INFO] [launch.py:256:main] process 1087992 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-028: [2024-07-08 07:19:25,410] [INFO] [launch.py:256:main] process 1088237 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 07:19:25,413] [INFO] [launch.py:256:main] process 1087993 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-026: [2024-07-08 07:19:25,413] [INFO] [launch.py:256:main] process 1087994 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 07:19:25,414] [INFO] [launch.py:139:main] 21 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-022: [2024-07-08 07:19:25,414] [INFO] [launch.py:139:main] 21 NCCL_SOCKET_IFNAME=eno1
ml-512-node-022: [2024-07-08 07:19:25,414] [INFO] [launch.py:139:main] 21 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-022: [2024-07-08 07:19:25,414] [INFO] [launch.py:139:main] 21 NCCL_P2P_LEVEL=NVL
ml-512-node-022: [2024-07-08 07:19:25,414] [INFO] [launch.py:139:main] 21 NCCL_DEBUG=WARN
ml-512-node-022: [2024-07-08 07:19:25,414] [INFO] [launch.py:139:main] 21 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-022: [2024-07-08 07:19:25,415] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-022: [2024-07-08 07:19:25,415] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=21
ml-512-node-022: [2024-07-08 07:19:25,415] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-022: [2024-07-08 07:19:25,415] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-022: [2024-07-08 07:19:25,415] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-022: [2024-07-08 07:19:25,416] [INFO] [launch.py:256:main] process 1088970 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 07:19:25,416] [INFO] [launch.py:256:main] process 1088971 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 07:19:25,417] [INFO] [launch.py:256:main] process 1088972 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 07:19:25,418] [INFO] [launch.py:256:main] process 1088973 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 07:19:25,418] [INFO] [launch.py:256:main] process 1088974 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 07:19:25,419] [INFO] [launch.py:256:main] process 1088975 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 07:19:25,420] [INFO] [launch.py:256:main] process 1088976 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-022: [2024-07-08 07:19:25,420] [INFO] [launch.py:256:main] process 1088977 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:139:main] 22 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:139:main] 22 NCCL_SOCKET_IFNAME=eno1
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:139:main] 22 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:139:main] 22 NCCL_P2P_LEVEL=NVL
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:139:main] 22 NCCL_DEBUG=WARN
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:139:main] 22 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=22
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-023: [2024-07-08 07:19:25,426] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-023: [2024-07-08 07:19:25,427] [INFO] [launch.py:256:main] process 1093372 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 07:19:25,428] [INFO] [launch.py:256:main] process 1093373 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 07:19:25,428] [INFO] [launch.py:256:main] process 1093374 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 07:19:25,429] [INFO] [launch.py:256:main] process 1093375 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 07:19:25,430] [INFO] [launch.py:256:main] process 1093376 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 07:19:25,430] [INFO] [launch.py:256:main] process 1093377 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-023: [2024-07-08 07:19:25,431] [INFO] [launch.py:256:main] process 1093378 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:139:main] 10 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:139:main] 10 NCCL_SOCKET_IFNAME=eno1
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:139:main] 10 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:139:main] 10 NCCL_P2P_LEVEL=NVL
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:139:main] 10 NCCL_DEBUG=WARN
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:139:main] 10 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=10
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-011: [2024-07-08 07:19:25,431] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-023: [2024-07-08 07:19:25,432] [INFO] [launch.py:256:main] process 1093379 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 07:19:25,432] [INFO] [launch.py:256:main] process 1096770 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 07:19:25,433] [INFO] [launch.py:256:main] process 1096771 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 07:19:25,433] [INFO] [launch.py:256:main] process 1096772 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 07:19:25,434] [INFO] [launch.py:256:main] process 1096773 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 07:19:25,435] [INFO] [launch.py:256:main] process 1096774 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 07:19:25,436] [INFO] [launch.py:256:main] process 1096775 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:139:main] 2 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:139:main] 2 NCCL_SOCKET_IFNAME=eno1
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:139:main] 2 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:139:main] 2 NCCL_P2P_LEVEL=NVL
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:139:main] 2 NCCL_DEBUG=WARN
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:139:main] 2 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=2
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-003: [2024-07-08 07:19:25,435] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-011: [2024-07-08 07:19:25,436] [INFO] [launch.py:256:main] process 1096776 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 07:19:25,436] [INFO] [launch.py:256:main] process 1098695 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-011: [2024-07-08 07:19:25,437] [INFO] [launch.py:256:main] process 1096777 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 07:19:25,437] [INFO] [launch.py:256:main] process 1098696 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 07:19:25,438] [INFO] [launch.py:256:main] process 1098697 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 07:19:25,438] [INFO] [launch.py:256:main] process 1098698 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 07:19:25,439] [INFO] [launch.py:256:main] process 1098699 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 07:19:25,439] [INFO] [launch.py:256:main] process 1098700 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-003: [2024-07-08 07:19:25,440] [INFO] [launch.py:256:main] process 1098701 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 11 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 11 NCCL_SOCKET_IFNAME=eno1
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 11 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 11 NCCL_P2P_LEVEL=NVL
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 11 NCCL_DEBUG=WARN
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 11 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=11
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-012: [2024-07-08 07:19:25,441] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-003: [2024-07-08 07:19:25,441] [INFO] [launch.py:256:main] process 1098702 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 26 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 26 NCCL_SOCKET_IFNAME=eno1
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 26 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 26 NCCL_P2P_LEVEL=NVL
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 26 NCCL_DEBUG=WARN
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:139:main] 26 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=26
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-027: [2024-07-08 07:19:25,441] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-012: [2024-07-08 07:19:25,442] [INFO] [launch.py:256:main] process 1091109 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 07:19:25,442] [INFO] [launch.py:256:main] process 1098559 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 07:19:25,443] [INFO] [launch.py:256:main] process 1091110 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 07:19:25,443] [INFO] [launch.py:256:main] process 1098560 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 07:19:25,443] [INFO] [launch.py:256:main] process 1091111 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 07:19:25,444] [INFO] [launch.py:256:main] process 1098561 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 07:19:25,444] [INFO] [launch.py:256:main] process 1091112 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 07:19:25,444] [INFO] [launch.py:256:main] process 1098562 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 07:19:25,445] [INFO] [launch.py:256:main] process 1091113 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 07:19:25,445] [INFO] [launch.py:256:main] process 1098563 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 07:19:25,445] [INFO] [launch.py:256:main] process 1091114 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 07:19:25,446] [INFO] [launch.py:256:main] process 1098564 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 07:19:25,446] [INFO] [launch.py:256:main] process 1091115 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 07:19:25,446] [INFO] [launch.py:256:main] process 1098565 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-012: [2024-07-08 07:19:25,447] [INFO] [launch.py:256:main] process 1091116 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-027: [2024-07-08 07:19:25,447] [INFO] [launch.py:256:main] process 1098566 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:139:main] 29 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:139:main] 29 NCCL_SOCKET_IFNAME=eno1
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:139:main] 29 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:139:main] 29 NCCL_P2P_LEVEL=NVL
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:139:main] 29 NCCL_DEBUG=WARN
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:139:main] 29 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=29
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-030: [2024-07-08 07:19:25,460] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-030: [2024-07-08 07:19:25,461] [INFO] [launch.py:256:main] process 1093265 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 07:19:25,462] [INFO] [launch.py:256:main] process 1093266 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 07:19:25,462] [INFO] [launch.py:256:main] process 1093267 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 07:19:25,463] [INFO] [launch.py:256:main] process 1093268 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 07:19:25,463] [INFO] [launch.py:256:main] process 1093269 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 07:19:25,464] [INFO] [launch.py:256:main] process 1093270 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 07:19:25,465] [INFO] [launch.py:256:main] process 1093271 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-030: [2024-07-08 07:19:25,465] [INFO] [launch.py:256:main] process 1093272 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:139:main] 1 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:139:main] 1 NCCL_SOCKET_IFNAME=eno1
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:139:main] 1 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:139:main] 1 NCCL_P2P_LEVEL=NVL
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:139:main] 1 NCCL_DEBUG=WARN
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:139:main] 1 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=1
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-002: [2024-07-08 07:19:25,468] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-002: [2024-07-08 07:19:25,469] [INFO] [launch.py:256:main] process 1106369 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:139:main] 30 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:139:main] 30 NCCL_SOCKET_IFNAME=eno1
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:139:main] 30 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:139:main] 30 NCCL_P2P_LEVEL=NVL
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:139:main] 30 NCCL_DEBUG=WARN
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:139:main] 30 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=30
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-002: [2024-07-08 07:19:25,470] [INFO] [launch.py:256:main] process 1106370 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-031: [2024-07-08 07:19:25,470] [INFO] [launch.py:256:main] process 1092199 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 07:19:25,471] [INFO] [launch.py:256:main] process 1106371 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 07:19:25,471] [INFO] [launch.py:256:main] process 1092200 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 07:19:25,472] [INFO] [launch.py:256:main] process 1106372 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 07:19:25,472] [INFO] [launch.py:256:main] process 1092201 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 07:19:25,472] [INFO] [launch.py:256:main] process 1106373 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 07:19:25,472] [INFO] [launch.py:256:main] process 1092202 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 07:19:25,473] [INFO] [launch.py:256:main] process 1106374 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 07:19:25,473] [INFO] [launch.py:256:main] process 1092203 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 07:19:25,473] [INFO] [launch.py:256:main] process 1106375 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 07:19:25,474] [INFO] [launch.py:256:main] process 1092204 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-002: [2024-07-08 07:19:25,474] [INFO] [launch.py:256:main] process 1106376 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 07:19:25,474] [INFO] [launch.py:256:main] process 1092205 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-031: [2024-07-08 07:19:25,475] [INFO] [launch.py:256:main] process 1092206 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 07:19:25,486] [INFO] [launch.py:139:main] 24 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-025: [2024-07-08 07:19:25,486] [INFO] [launch.py:139:main] 24 NCCL_SOCKET_IFNAME=eno1
ml-512-node-025: [2024-07-08 07:19:25,486] [INFO] [launch.py:139:main] 24 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-025: [2024-07-08 07:19:25,486] [INFO] [launch.py:139:main] 24 NCCL_P2P_LEVEL=NVL
ml-512-node-025: [2024-07-08 07:19:25,486] [INFO] [launch.py:139:main] 24 NCCL_DEBUG=WARN
ml-512-node-025: [2024-07-08 07:19:25,486] [INFO] [launch.py:139:main] 24 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-025: [2024-07-08 07:19:25,486] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-025: [2024-07-08 07:19:25,486] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=24
ml-512-node-025: [2024-07-08 07:19:25,487] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-025: [2024-07-08 07:19:25,487] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-025: [2024-07-08 07:19:25,487] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-025: [2024-07-08 07:19:25,487] [INFO] [launch.py:256:main] process 1095604 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 07:19:25,488] [INFO] [launch.py:256:main] process 1095605 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 07:19:25,489] [INFO] [launch.py:256:main] process 1095606 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 07:19:25,489] [INFO] [launch.py:256:main] process 1095607 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 07:19:25,490] [INFO] [launch.py:256:main] process 1095608 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 07:19:25,491] [INFO] [launch.py:256:main] process 1095609 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 07:19:25,490] [INFO] [launch.py:139:main] 23 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-024: [2024-07-08 07:19:25,491] [INFO] [launch.py:139:main] 23 NCCL_SOCKET_IFNAME=eno1
ml-512-node-024: [2024-07-08 07:19:25,491] [INFO] [launch.py:139:main] 23 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-024: [2024-07-08 07:19:25,491] [INFO] [launch.py:139:main] 23 NCCL_P2P_LEVEL=NVL
ml-512-node-024: [2024-07-08 07:19:25,491] [INFO] [launch.py:139:main] 23 NCCL_DEBUG=WARN
ml-512-node-024: [2024-07-08 07:19:25,491] [INFO] [launch.py:139:main] 23 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-024: [2024-07-08 07:19:25,491] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-024: [2024-07-08 07:19:25,491] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=23
ml-512-node-024: [2024-07-08 07:19:25,491] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-024: [2024-07-08 07:19:25,491] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-024: [2024-07-08 07:19:25,491] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-025: [2024-07-08 07:19:25,491] [INFO] [launch.py:256:main] process 1095610 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 07:19:25,492] [INFO] [launch.py:256:main] process 1089304 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-025: [2024-07-08 07:19:25,492] [INFO] [launch.py:256:main] process 1095611 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 07:19:25,493] [INFO] [launch.py:256:main] process 1089305 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 07:19:25,493] [INFO] [launch.py:256:main] process 1089306 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 07:19:25,494] [INFO] [launch.py:256:main] process 1089308 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 07:19:25,494] [INFO] [launch.py:256:main] process 1089309 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 07:19:25,495] [INFO] [launch.py:256:main] process 1089310 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 07:19:25,496] [INFO] [launch.py:256:main] process 1089311 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-024: [2024-07-08 07:19:25,496] [INFO] [launch.py:256:main] process 1089312 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:139:main] 17 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:139:main] 17 NCCL_SOCKET_IFNAME=eno1
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:139:main] 17 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:139:main] 17 NCCL_P2P_LEVEL=NVL
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:139:main] 17 NCCL_DEBUG=WARN
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:139:main] 17 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=17
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-018: [2024-07-08 07:19:25,512] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-018: [2024-07-08 07:19:25,513] [INFO] [launch.py:256:main] process 1090761 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 07:19:25,514] [INFO] [launch.py:256:main] process 1090762 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 07:19:25,515] [INFO] [launch.py:256:main] process 1090763 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 07:19:25,515] [INFO] [launch.py:256:main] process 1090764 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 07:19:25,516] [INFO] [launch.py:256:main] process 1090765 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 07:19:25,516] [INFO] [launch.py:256:main] process 1090766 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 07:19:25,517] [INFO] [launch.py:256:main] process 1090767 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-018: [2024-07-08 07:19:25,518] [INFO] [launch.py:256:main] process 1090768 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 07:19:25,542] [INFO] [launch.py:139:main] 16 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-017: [2024-07-08 07:19:25,542] [INFO] [launch.py:139:main] 16 NCCL_SOCKET_IFNAME=eno1
ml-512-node-017: [2024-07-08 07:19:25,542] [INFO] [launch.py:139:main] 16 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-017: [2024-07-08 07:19:25,543] [INFO] [launch.py:139:main] 16 NCCL_P2P_LEVEL=NVL
ml-512-node-017: [2024-07-08 07:19:25,543] [INFO] [launch.py:139:main] 16 NCCL_DEBUG=WARN
ml-512-node-017: [2024-07-08 07:19:25,543] [INFO] [launch.py:139:main] 16 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-017: [2024-07-08 07:19:25,543] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-017: [2024-07-08 07:19:25,543] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=16
ml-512-node-017: [2024-07-08 07:19:25,543] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-017: [2024-07-08 07:19:25,543] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-017: [2024-07-08 07:19:25,543] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:139:main] 9 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:139:main] 9 NCCL_SOCKET_IFNAME=eno1
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:139:main] 9 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:139:main] 9 NCCL_P2P_LEVEL=NVL
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:139:main] 9 NCCL_DEBUG=WARN
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:139:main] 9 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=9
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-010: [2024-07-08 07:19:25,541] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-017: [2024-07-08 07:19:25,544] [INFO] [launch.py:256:main] process 1098966 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 07:19:25,542] [INFO] [launch.py:256:main] process 1090799 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 07:19:25,542] [INFO] [launch.py:256:main] process 1090800 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 07:19:25,544] [INFO] [launch.py:256:main] process 1098967 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 07:19:25,543] [INFO] [launch.py:256:main] process 1090801 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 07:19:25,545] [INFO] [launch.py:256:main] process 1098968 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 07:19:25,544] [INFO] [launch.py:256:main] process 1090802 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 07:19:25,546] [INFO] [launch.py:256:main] process 1098969 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 07:19:25,544] [INFO] [launch.py:256:main] process 1090803 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 07:19:25,546] [INFO] [launch.py:256:main] process 1098970 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 07:19:25,545] [INFO] [launch.py:256:main] process 1090804 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 07:19:25,547] [INFO] [launch.py:256:main] process 1098971 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 07:19:25,548] [INFO] [launch.py:256:main] process 1098972 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 07:19:25,546] [INFO] [launch.py:256:main] process 1090805 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-010: [2024-07-08 07:19:25,546] [INFO] [launch.py:256:main] process 1090806 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-017: [2024-07-08 07:19:25,548] [INFO] [launch.py:256:main] process 1098973 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 07:19:25,570] [INFO] [launch.py:139:main] 31 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:139:main] 31 NCCL_SOCKET_IFNAME=eno1
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:139:main] 31 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:139:main] 31 NCCL_P2P_LEVEL=NVL
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:139:main] 31 NCCL_DEBUG=WARN
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:139:main] 31 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=31
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-032: [2024-07-08 07:19:25,571] [INFO] [launch.py:256:main] process 1083826 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 07:19:25,572] [INFO] [launch.py:256:main] process 1083827 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 07:19:25,573] [INFO] [launch.py:256:main] process 1083828 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 07:19:25,574] [INFO] [launch.py:256:main] process 1083829 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 07:19:25,574] [INFO] [launch.py:256:main] process 1083830 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 07:19:25,575] [INFO] [launch.py:256:main] process 1083831 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 07:19:25,576] [INFO] [launch.py:256:main] process 1083832 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-032: [2024-07-08 07:19:25,577] [INFO] [launch.py:256:main] process 1083833 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 07:19:26,369] [INFO] [launch.py:139:main] 14 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-015: [2024-07-08 07:19:26,369] [INFO] [launch.py:139:main] 14 NCCL_SOCKET_IFNAME=eno1
ml-512-node-015: [2024-07-08 07:19:26,369] [INFO] [launch.py:139:main] 14 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-015: [2024-07-08 07:19:26,369] [INFO] [launch.py:139:main] 14 NCCL_P2P_LEVEL=NVL
ml-512-node-015: [2024-07-08 07:19:26,369] [INFO] [launch.py:139:main] 14 NCCL_DEBUG=WARN
ml-512-node-015: [2024-07-08 07:19:26,369] [INFO] [launch.py:139:main] 14 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-015: [2024-07-08 07:19:26,370] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-015: [2024-07-08 07:19:26,370] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=14
ml-512-node-015: [2024-07-08 07:19:26,370] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-015: [2024-07-08 07:19:26,370] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-015: [2024-07-08 07:19:26,370] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-015: [2024-07-08 07:19:26,371] [INFO] [launch.py:256:main] process 1094669 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 07:19:26,371] [INFO] [launch.py:256:main] process 1094670 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 07:19:26,372] [INFO] [launch.py:256:main] process 1094671 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 07:19:26,373] [INFO] [launch.py:256:main] process 1094672 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 07:19:26,373] [INFO] [launch.py:256:main] process 1094673 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 07:19:26,374] [INFO] [launch.py:256:main] process 1094674 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 07:19:26,375] [INFO] [launch.py:256:main] process 1094675 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-015: [2024-07-08 07:19:26,376] [INFO] [launch.py:256:main] process 1094676 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 07:19:26,425] [INFO] [launch.py:139:main] 20 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-021: [2024-07-08 07:19:26,425] [INFO] [launch.py:139:main] 20 NCCL_SOCKET_IFNAME=eno1
ml-512-node-021: [2024-07-08 07:19:26,425] [INFO] [launch.py:139:main] 20 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-021: [2024-07-08 07:19:26,425] [INFO] [launch.py:139:main] 20 NCCL_P2P_LEVEL=NVL
ml-512-node-021: [2024-07-08 07:19:26,425] [INFO] [launch.py:139:main] 20 NCCL_DEBUG=WARN
ml-512-node-021: [2024-07-08 07:19:26,425] [INFO] [launch.py:139:main] 20 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-021: [2024-07-08 07:19:26,426] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-021: [2024-07-08 07:19:26,426] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=20
ml-512-node-021: [2024-07-08 07:19:26,426] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-021: [2024-07-08 07:19:26,426] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-021: [2024-07-08 07:19:26,426] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-021: [2024-07-08 07:19:26,427] [INFO] [launch.py:256:main] process 1095154 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 07:19:26,427] [INFO] [launch.py:256:main] process 1095155 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 07:19:26,428] [INFO] [launch.py:256:main] process 1095156 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 07:19:26,429] [INFO] [launch.py:256:main] process 1095157 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 07:19:26,429] [INFO] [launch.py:256:main] process 1095158 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 07:19:26,430] [INFO] [launch.py:256:main] process 1095159 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 07:19:26,430] [INFO] [launch.py:256:main] process 1095160 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-021: [2024-07-08 07:19:26,431] [INFO] [launch.py:256:main] process 1095161 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:139:main] 18 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:139:main] 18 NCCL_SOCKET_IFNAME=eno1
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:139:main] 18 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:139:main] 18 NCCL_P2P_LEVEL=NVL
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:139:main] 18 NCCL_DEBUG=WARN
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:139:main] 18 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=18
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-019: [2024-07-08 07:19:26,449] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-019: [2024-07-08 07:19:26,450] [INFO] [launch.py:256:main] process 1095065 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 07:19:26,451] [INFO] [launch.py:256:main] process 1095066 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 07:19:26,452] [INFO] [launch.py:256:main] process 1095067 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 07:19:26,453] [INFO] [launch.py:256:main] process 1095068 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 07:19:26,453] [INFO] [launch.py:256:main] process 1095069 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 07:19:26,454] [INFO] [launch.py:256:main] process 1095070 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 07:19:26,454] [INFO] [launch.py:256:main] process 1095071 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-019: [2024-07-08 07:19:26,454] [INFO] [launch.py:256:main] process 1095072 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:139:main] 13 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:139:main] 13 NCCL_SOCKET_IFNAME=eno1
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:139:main] 13 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:139:main] 13 NCCL_P2P_LEVEL=NVL
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:139:main] 13 NCCL_DEBUG=WARN
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:139:main] 13 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-003': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-004': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-005': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-006': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-007': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-008': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-009': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-010': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-011': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-012': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-013': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-014': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-015': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-016': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-017': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-018': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-019': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-020': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-021': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-022': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-023': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-024': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-025': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-026': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-027': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-028': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-029': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-030': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-031': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-032': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=13
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-001': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-002': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-003': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-004': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-005': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-006': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-007': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-008': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-009': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-010': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-011': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-012': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-013': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-014': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-015': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-016': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-017': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-018': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-019': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-020': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-021': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-022': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-023': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-024': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-025': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-026': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-027': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-028': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-029': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-030': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-031': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-032': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-014: [2024-07-08 07:19:26,484] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-014: [2024-07-08 07:19:26,485] [INFO] [launch.py:256:main] process 1089044 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 07:19:26,486] [INFO] [launch.py:256:main] process 1089045 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 07:19:26,486] [INFO] [launch.py:256:main] process 1089046 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 07:19:26,487] [INFO] [launch.py:256:main] process 1089047 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 07:19:26,487] [INFO] [launch.py:256:main] process 1089048 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 07:19:26,488] [INFO] [launch.py:256:main] process 1089049 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 07:19:26,488] [INFO] [launch.py:256:main] process 1089050 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-014: [2024-07-08 07:19:26,489] [INFO] [launch.py:256:main] process 1089051 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-13b_step1', '--model_name_or_path', 'facebook/opt-13b', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--gradient_checkpointing', '--zero_stage', '0', '--lora_dim', '128', '--lora_module_name', 'decoder.layers.', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-006: [2024-07-08 07:19:28,877] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 07:19:28,925] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 07:19:29,070] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [2024-07-08 07:19:29,736] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 07:19:29,775] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 07:19:30,004] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 07:19:30,120] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [2024-07-08 07:19:30,250] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [2024-07-08 07:19:30,331] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 07:19:30,338] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 07:19:30,348] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 07:19:30,412] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 07:19:30,441] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 07:19:30,448] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 07:19:30,469] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [2024-07-08 07:19:30,480] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 07:19:30,497] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [2024-07-08 07:19:30,506] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [2024-07-08 07:19:30,522] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 07:19:30,527] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [2024-07-08 07:19:30,536] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 07:19:30,538] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 07:19:30,539] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 07:19:30,543] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 07:19:30,555] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 07:19:30,562] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [2024-07-08 07:19:30,564] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 07:19:30,574] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [2024-07-08 07:19:30,588] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [2024-07-08 07:19:30,613] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 07:19:30,615] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 07:19:30,616] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 07:19:30,642] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 07:19:30,645] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 07:19:30,649] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [2024-07-08 07:19:30,657] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 07:19:30,680] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 07:19:30,688] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 07:19:30,701] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 07:19:30,706] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 07:19:30,719] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 07:19:30,719] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [2024-07-08 07:19:30,721] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [2024-07-08 07:19:30,723] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 07:19:30,725] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 07:19:30,724] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 07:19:30,739] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 07:19:30,752] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 07:19:30,754] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 07:19:30,758] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [2024-07-08 07:19:30,765] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [2024-07-08 07:19:30,780] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [2024-07-08 07:19:30,783] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [2024-07-08 07:19:30,785] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [2024-07-08 07:19:30,794] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [2024-07-08 07:19:30,809] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 07:19:30,808] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [2024-07-08 07:19:30,818] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 07:19:30,824] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 07:19:30,823] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 07:19:30,821] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [2024-07-08 07:19:30,828] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 07:19:30,831] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 07:19:30,835] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [2024-07-08 07:19:30,840] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [2024-07-08 07:19:30,850] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 07:19:30,854] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 07:19:30,857] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 07:19:30,858] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 07:19:30,861] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [2024-07-08 07:19:30,858] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 07:19:30,859] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 07:19:30,865] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 07:19:30,870] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [2024-07-08 07:19:30,874] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [2024-07-08 07:19:30,877] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [2024-07-08 07:19:30,894] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [2024-07-08 07:19:30,900] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [2024-07-08 07:19:30,900] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [2024-07-08 07:19:30,902] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 07:19:30,901] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 07:19:30,903] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [2024-07-08 07:19:30,912] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 07:19:30,913] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 07:19:30,920] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [2024-07-08 07:19:30,923] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [2024-07-08 07:19:30,941] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [2024-07-08 07:19:30,948] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 07:19:30,950] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [2024-07-08 07:19:30,954] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 07:19:30,956] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [2024-07-08 07:19:30,957] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 07:19:30,957] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 07:19:30,960] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 07:19:30,962] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 07:19:30,963] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [2024-07-08 07:19:30,971] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [2024-07-08 07:19:30,976] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 07:19:30,979] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [2024-07-08 07:19:30,981] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [2024-07-08 07:19:30,983] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [2024-07-08 07:19:30,984] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [2024-07-08 07:19:30,990] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 07:19:30,991] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 07:19:30,996] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [2024-07-08 07:19:31,008] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [2024-07-08 07:19:31,014] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [2024-07-08 07:19:31,013] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [2024-07-08 07:19:31,019] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 07:19:31,019] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 07:19:31,024] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [2024-07-08 07:19:31,024] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [2024-07-08 07:19:31,030] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 07:19:31,032] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [2024-07-08 07:19:31,052] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [2024-07-08 07:19:31,056] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [2024-07-08 07:19:31,056] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 07:19:31,060] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [2024-07-08 07:19:31,071] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 07:19:31,069] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [2024-07-08 07:19:31,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 07:19:31,084] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 07:19:31,082] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 07:19:31,084] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [2024-07-08 07:19:31,086] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 07:19:31,091] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [2024-07-08 07:19:31,092] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [2024-07-08 07:19:31,093] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [2024-07-08 07:19:31,095] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 07:19:31,096] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 07:19:31,100] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [2024-07-08 07:19:31,099] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [2024-07-08 07:19:31,107] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 07:19:31,108] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 07:19:31,109] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [2024-07-08 07:19:31,111] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [2024-07-08 07:19:31,120] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [2024-07-08 07:19:31,125] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [2024-07-08 07:19:31,136] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 07:19:31,134] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [2024-07-08 07:19:31,146] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [2024-07-08 07:19:31,150] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [2024-07-08 07:19:31,160] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [2024-07-08 07:19:31,163] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [2024-07-08 07:19:31,167] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [2024-07-08 07:19:31,174] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [2024-07-08 07:19:31,182] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 07:19:31,184] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [2024-07-08 07:19:31,186] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [2024-07-08 07:19:31,194] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [2024-07-08 07:19:31,197] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [2024-07-08 07:19:31,202] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [2024-07-08 07:19:31,204] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [2024-07-08 07:19:31,204] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [2024-07-08 07:19:31,202] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [2024-07-08 07:19:31,209] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [2024-07-08 07:19:31,213] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [2024-07-08 07:19:31,219] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [2024-07-08 07:19:31,225] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [2024-07-08 07:19:31,227] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [2024-07-08 07:19:31,237] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [2024-07-08 07:19:31,236] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 07:19:31,236] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [2024-07-08 07:19:31,242] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [2024-07-08 07:19:31,244] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [2024-07-08 07:19:31,246] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [2024-07-08 07:19:31,250] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 07:19:31,250] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [2024-07-08 07:19:31,252] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [2024-07-08 07:19:31,256] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [2024-07-08 07:19:31,261] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 07:19:31,264] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [2024-07-08 07:19:31,266] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [2024-07-08 07:19:31,270] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [2024-07-08 07:19:31,270] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 07:19:31,271] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 07:19:31,271] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 07:19:31,269] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [2024-07-08 07:19:31,272] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 07:19:31,272] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 07:19:31,273] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [2024-07-08 07:19:31,277] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-027: [2024-07-08 07:19:31,279] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [2024-07-08 07:19:31,279] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [2024-07-08 07:19:31,287] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [2024-07-08 07:19:31,288] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [2024-07-08 07:19:31,291] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-013: [2024-07-08 07:19:31,292] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [2024-07-08 07:19:31,295] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [2024-07-08 07:19:31,306] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [2024-07-08 07:19:31,309] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [2024-07-08 07:19:31,311] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [2024-07-08 07:19:31,310] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [2024-07-08 07:19:31,314] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [2024-07-08 07:19:31,326] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [2024-07-08 07:19:31,328] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [2024-07-08 07:19:31,331] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [2024-07-08 07:19:31,334] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [2024-07-08 07:19:31,338] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [2024-07-08 07:19:31,339] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [2024-07-08 07:19:31,351] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [2024-07-08 07:19:31,351] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [2024-07-08 07:19:31,355] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 07:19:31,355] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [2024-07-08 07:19:31,364] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [2024-07-08 07:19:31,364] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 07:19:31,366] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-031: [2024-07-08 07:19:31,367] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [2024-07-08 07:19:31,370] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [2024-07-08 07:19:31,376] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-017: [2024-07-08 07:19:31,378] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [2024-07-08 07:19:31,394] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [2024-07-08 07:19:31,398] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [2024-07-08 07:19:31,410] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [2024-07-08 07:19:31,415] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [2024-07-08 07:19:31,420] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [2024-07-08 07:19:31,428] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [2024-07-08 07:19:31,448] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [2024-07-08 07:19:31,475] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-006: [2024-07-08 07:19:31,475] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [2024-07-08 07:19:31,484] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [2024-07-08 07:19:31,517] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [2024-07-08 07:19:31,527] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-005: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-005: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [2024-07-08 07:19:31,570] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [2024-07-08 07:19:31,574] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [2024-07-08 07:19:31,600] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [2024-07-08 07:19:31,611] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-009: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-009: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [2024-07-08 07:19:31,663] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [2024-07-08 07:19:31,674] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [2024-07-08 07:19:31,693] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [2024-07-08 07:19:31,699] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [2024-07-08 07:19:31,720] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [2024-07-08 07:19:31,728] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [2024-07-08 07:19:31,733] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [2024-07-08 07:19:31,732] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-016: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-016: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [2024-07-08 07:19:31,747] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-020: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-020: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-029: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-006: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-029: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-029: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-029: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-008: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [2024-07-08 07:19:31,795] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-023: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-023: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-004: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-004: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-004: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-020: [2024-07-08 07:19:31,807] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-026: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-026: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-007: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-007: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-027: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [2024-07-08 07:19:31,816] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [2024-07-08 07:19:31,828] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-012: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-012: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-024: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-022: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-022: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-028: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-028: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [2024-07-08 07:19:31,846] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-002: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-002: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-002: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [2024-07-08 07:19:31,858] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-025: [2024-07-08 07:19:31,863] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [2024-07-08 07:19:31,864] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-011: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-011: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-030: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-030: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-025: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-025: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-025: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-003: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-003: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-013: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-013: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-013: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [2024-07-08 07:19:31,907] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [2024-07-08 07:19:31,944] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-017: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-017: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [2024-07-08 07:19:31,962] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-032: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-032: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [2024-07-08 07:19:31,975] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-031: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-018: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-018: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-031: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-031: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [2024-07-08 07:19:32,017] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [2024-07-08 07:19:32,021] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [2024-07-08 07:19:32,040] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [2024-07-08 07:19:32,062] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-027: [2024-07-08 07:19:32,069] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-008: [2024-07-08 07:19:32,070] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 07:19:32,075] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [2024-07-08 07:19:32,079] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-010: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-010: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [2024-07-08 07:19:32,100] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 07:19:32,106] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [2024-07-08 07:19:32,116] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [2024-07-08 07:19:32,126] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [2024-07-08 07:19:32,145] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-019: [2024-07-08 07:19:32,144] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [2024-07-08 07:19:32,152] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [2024-07-08 07:19:32,163] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [2024-07-08 07:19:32,167] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [2024-07-08 07:19:32,182] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-006: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [2024-07-08 07:19:32,187] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [2024-07-08 07:19:32,216] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [2024-07-08 07:19:32,229] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 07:19:32,234] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [2024-07-08 07:19:32,255] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-028: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-027: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-027: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [2024-07-08 07:19:32,257] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [2024-07-08 07:19:32,257] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-005: [2024-07-08 07:19:32,254] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-009: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [2024-07-08 07:19:32,268] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [2024-07-08 07:19:32,275] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-004: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-004: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-023: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [2024-07-08 07:19:32,288] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [2024-07-08 07:19:32,291] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [2024-07-08 07:19:32,297] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-030: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [2024-07-08 07:19:32,303] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [2024-07-08 07:19:32,304] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-008: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [2024-07-08 07:19:32,310] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-005: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-005: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-026: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 07:19:32,320] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-020: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-020: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [2024-07-08 07:19:32,331] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-029: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [2024-07-08 07:19:32,331] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-001: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-026: [2024-07-08 07:19:32,338] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-024: [2024-07-08 07:19:32,345] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-012: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-012: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [2024-07-08 07:19:32,348] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-001: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-001: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-005: [2024-07-08 07:19:32,349] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 07:19:32,352] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [2024-07-08 07:19:32,362] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [2024-07-08 07:19:32,370] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-014: [2024-07-08 07:19:32,373] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-010: [2024-07-08 07:19:32,373] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-024: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-024: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-016: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-016: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [2024-07-08 07:19:32,404] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [2024-07-08 07:19:32,409] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [2024-07-08 07:19:32,411] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-002: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [2024-07-08 07:19:32,422] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-006: [2024-07-08 07:19:32,434] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [2024-07-08 07:19:32,440] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [2024-07-08 07:19:32,439] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-007: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-002: [2024-07-08 07:19:32,450] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-025: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [2024-07-08 07:19:32,453] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 07:19:32,453] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-023: [2024-07-08 07:19:32,456] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-032: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-007: [2024-07-08 07:19:32,490] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [2024-07-08 07:19:32,500] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [2024-07-08 07:19:32,502] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-017: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-017: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-010: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-010: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [2024-07-08 07:19:32,510] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [2024-07-08 07:19:32,513] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-013: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-031: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-031: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 07:19:32,532] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [2024-07-08 07:19:32,534] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-016: [2024-07-08 07:19:32,540] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-003: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [2024-07-08 07:19:32,553] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-009: [2024-07-08 07:19:32,558] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-007: [2024-07-08 07:19:32,566] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-012: [2024-07-08 07:19:32,567] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-003: [2024-07-08 07:19:32,572] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [2024-07-08 07:19:32,572] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-017: [2024-07-08 07:19:32,576] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-016: [2024-07-08 07:19:32,581] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-024: [2024-07-08 07:19:32,583] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [2024-07-08 07:19:32,585] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-018: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-011: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [2024-07-08 07:19:32,610] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [2024-07-08 07:19:32,612] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-004: [2024-07-08 07:19:32,612] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [2024-07-08 07:19:32,616] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-018: [2024-07-08 07:19:32,620] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-022: [2024-07-08 07:19:32,617] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-004: [2024-07-08 07:19:32,625] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [2024-07-08 07:19:32,626] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-007: [2024-07-08 07:19:32,627] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-013: [2024-07-08 07:19:32,630] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 07:19:32,633] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-022: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-003: [2024-07-08 07:19:32,646] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-006: [2024-07-08 07:19:32,653] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-020: [2024-07-08 07:19:32,661] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [2024-07-08 07:19:32,659] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-030: [2024-07-08 07:19:32,670] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-011: [2024-07-08 07:19:32,675] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-020: [2024-07-08 07:19:32,678] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 07:19:32,684] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-017: [2024-07-08 07:19:32,687] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [2024-07-08 07:19:32,691] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-009: [2024-07-08 07:19:32,691] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-024: [2024-07-08 07:19:32,693] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-009: [2024-07-08 07:19:32,697] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-005: [2024-07-08 07:19:32,695] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-009: [2024-07-08 07:19:32,702] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [2024-07-08 07:19:32,702] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-012: [2024-07-08 07:19:32,704] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-016: [2024-07-08 07:19:32,711] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-020: [2024-07-08 07:19:32,713] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-016: [2024-07-08 07:19:32,713] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [2024-07-08 07:19:32,714] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [2024-07-08 07:19:32,729] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [2024-07-08 07:19:32,738] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-005: [2024-07-08 07:19:32,759] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-004: [2024-07-08 07:19:32,761] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-012: [2024-07-08 07:19:32,767] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 07:19:32,767] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-021: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-021: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-009: [2024-07-08 07:19:32,794] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-030: [2024-07-08 07:19:32,805] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-009: [2024-07-08 07:19:32,811] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-030: [2024-07-08 07:19:32,812] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [2024-07-08 07:19:32,815] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-005: [2024-07-08 07:19:32,818] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-022: [2024-07-08 07:19:32,831] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-024: [2024-07-08 07:19:32,834] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 07:19:32,837] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-015: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-015: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-015: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-011: [2024-07-08 07:19:32,851] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-011: [2024-07-08 07:19:32,852] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-011: [2024-07-08 07:19:32,853] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-019: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-019: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-019: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-019: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-014: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-023: [2024-07-08 07:19:32,879] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-012: [2024-07-08 07:19:32,880] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-007: [2024-07-08 07:19:32,881] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-014: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-014: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-001: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-001: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [2024-07-08 07:19:32,895] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [2024-07-08 07:19:32,900] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-006: [2024-07-08 07:19:32,912] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-020: [2024-07-08 07:19:32,917] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-023: [2024-07-08 07:19:32,917] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-006: [2024-07-08 07:19:32,919] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-026: [2024-07-08 07:19:32,922] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-008: [2024-07-08 07:19:32,925] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [2024-07-08 07:19:32,930] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [2024-07-08 07:19:32,942] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [2024-07-08 07:19:32,941] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [2024-07-08 07:19:32,943] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-011: [2024-07-08 07:19:32,951] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [2024-07-08 07:19:32,953] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [2024-07-08 07:19:32,954] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [2024-07-08 07:19:32,958] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [2024-07-08 07:19:32,966] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-022: [2024-07-08 07:19:32,969] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-006: [2024-07-08 07:19:32,978] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 07:19:32,978] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-012: [2024-07-08 07:19:32,991] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-008: [2024-07-08 07:19:32,992] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-004: [2024-07-08 07:19:33,012] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [2024-07-08 07:19:33,012] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-022: [2024-07-08 07:19:33,019] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [2024-07-08 07:19:33,027] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-007: [2024-07-08 07:19:33,027] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-022: [2024-07-08 07:19:33,025] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-011: [2024-07-08 07:19:33,029] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-030: [2024-07-08 07:19:33,029] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-004: [2024-07-08 07:19:33,029] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 07:19:33,037] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-012: [2024-07-08 07:19:33,042] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-028: [2024-07-08 07:19:33,048] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-020: [2024-07-08 07:19:33,055] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-028: [2024-07-08 07:19:33,055] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-020: [2024-07-08 07:19:33,060] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [2024-07-08 07:19:33,059] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-026: [2024-07-08 07:19:33,067] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [2024-07-08 07:19:33,079] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-012: [2024-07-08 07:19:33,085] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [2024-07-08 07:19:33,096] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-026: [2024-07-08 07:19:33,099] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [2024-07-08 07:19:33,100] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 07:19:33,100] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-023: [2024-07-08 07:19:33,101] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-007: [2024-07-08 07:19:33,105] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [2024-07-08 07:19:33,104] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-024: [2024-07-08 07:19:33,105] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-023: [2024-07-08 07:19:33,108] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-026: [2024-07-08 07:19:33,111] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-023: [2024-07-08 07:19:33,122] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-008: [2024-07-08 07:19:33,125] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 07:19:33,126] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [2024-07-08 07:19:33,130] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-008: [2024-07-08 07:19:33,140] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-024: [2024-07-08 07:19:33,143] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [2024-07-08 07:19:33,144] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [2024-07-08 07:19:33,145] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-008: [2024-07-08 07:19:33,146] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [2024-07-08 07:19:33,146] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-024: [2024-07-08 07:19:33,150] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [2024-07-08 07:19:33,152] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [2024-07-08 07:19:33,172] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [2024-07-08 07:19:33,174] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [2024-07-08 07:19:33,175] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-022: [2024-07-08 07:19:33,173] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-029: [2024-07-08 07:19:33,176] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [2024-07-08 07:19:33,180] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-016: [2024-07-08 07:19:33,184] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [2024-07-08 07:19:33,187] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-003: [2024-07-08 07:19:33,197] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 07:19:33,199] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [2024-07-08 07:19:33,216] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-016: [2024-07-08 07:19:33,219] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-031: [2024-07-08 07:19:33,229] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 07:19:33,230] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [2024-07-08 07:19:33,229] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 07:19:33,237] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-027: [2024-07-08 07:19:33,237] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-017: [2024-07-08 07:19:33,241] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [2024-07-08 07:19:33,240] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-010: [2024-07-08 07:19:33,242] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 07:19:33,243] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-002: [2024-07-08 07:19:33,245] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-011: [2024-07-08 07:19:33,258] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-016: [2024-07-08 07:19:33,260] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-018: [2024-07-08 07:19:33,263] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [2024-07-08 07:19:33,276] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [2024-07-08 07:19:33,277] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-025: [2024-07-08 07:19:33,280] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [2024-07-08 07:19:33,284] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-032: [2024-07-08 07:19:33,288] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 07:19:33,287] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-022: [2024-07-08 07:19:33,287] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 07:19:33,304] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-021: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-032: [2024-07-08 07:19:33,314] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-015: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-001: [2024-07-08 07:19:33,317] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 07:19:33,317] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
ml-512-node-017: [2024-07-08 07:19:33,347] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-017: [2024-07-08 07:19:33,363] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-017: [2024-07-08 07:19:33,364] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-013: [2024-07-08 07:19:33,363] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-013: [2024-07-08 07:19:33,364] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [2024-07-08 07:19:33,405] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [2024-07-08 07:19:33,414] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 07:19:33,428] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-014: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-021: [2024-07-08 07:19:33,488] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-019: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-014: [2024-07-08 07:19:33,538] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [2024-07-08 07:19:33,581] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [2024-07-08 07:19:33,711] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 07:19:33,854] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [2024-07-08 07:19:33,874] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 07:19:34,041] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 07:19:34,084] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 07:19:34,109] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 07:19:34,146] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-015: [2024-07-08 07:19:34,160] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [2024-07-08 07:19:34,207] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [2024-07-08 07:19:34,213] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [2024-07-08 07:19:34,216] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 07:19:34,219] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [2024-07-08 07:19:34,241] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-021: [2024-07-08 07:19:34,243] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [2024-07-08 07:19:34,265] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-014: [2024-07-08 07:19:34,267] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 07:19:34,288] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 07:19:34,344] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 07:19:34,373] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-019: [2024-07-08 07:19:34,387] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 07:19:34,672] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 07:19:34,701] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 07:19:34,705] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 07:19:34,705] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 07:19:34,710] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 07:19:34,727] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: [2024-07-08 07:19:34,737] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-001: NCCL version 2.19.4+cuda12.2
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-032:   warnings.warn(
ml-512-node-015:   warnings.warn(
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-018:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-030:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-024:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-016:   warnings.warn(
ml-512-node-019:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-021:   warnings.warn(
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-008:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-021:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-021: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-015: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-021:   warnings.warn(
ml-512-node-015:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-001:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-032:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032:   warnings.warn(
ml-512-node-031:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-013: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-014:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-025:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-031: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-031:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025:   warnings.warn(
ml-512-node-003:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-024:   warnings.warn(
ml-512-node-024: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-024:   warnings.warn(
ml-512-node-002:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-007:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-020:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018:   warnings.warn(
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020:   warnings.warn(
ml-512-node-022:   warnings.warn(
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-009:   warnings.warn(
ml-512-node-020:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-008:   warnings.warn(
ml-512-node-008: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-008:   warnings.warn(
ml-512-node-011:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011:   warnings.warn(
ml-512-node-014:   warnings.warn(
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-011:   warnings.warn(
ml-512-node-029:   warnings.warn(
ml-512-node-003:   warnings.warn(
ml-512-node-003: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-003:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-016:   warnings.warn(
ml-512-node-016: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-016:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-027:   warnings.warn(
ml-512-node-026:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020:   warnings.warn(
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-022: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-022:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-013:   warnings.warn(
ml-512-node-023:   warnings.warn(
ml-512-node-006:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-030:   warnings.warn(
ml-512-node-025:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025:   warnings.warn(
ml-512-node-030:   warnings.warn(
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-011:   warnings.warn(
ml-512-node-017:   warnings.warn(
ml-512-node-025:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-030:   warnings.warn(
ml-512-node-030: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-030:   warnings.warn(
ml-512-node-005:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-018:   warnings.warn(
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-010:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028:   warnings.warn(
ml-512-node-026:   warnings.warn(
ml-512-node-004:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-020:   warnings.warn(
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-028:   warnings.warn(
ml-512-node-014:   warnings.warn(
ml-512-node-020: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-032:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032:   warnings.warn(
ml-512-node-032: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-032:   warnings.warn(
ml-512-node-019:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-019:   warnings.warn(
ml-512-node-019: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-019:   warnings.warn(
ml-512-node-018:   warnings.warn(
ml-512-node-001:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-001:   warnings.warn(
ml-512-node-005: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-005:   warnings.warn(
ml-512-node-027:   warnings.warn(
ml-512-node-018:   warnings.warn(
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-018: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-018:   warnings.warn(
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-026:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-026: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-026:   warnings.warn(
ml-512-node-028:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-025: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028:   warnings.warn(
ml-512-node-025:   warnings.warn(
ml-512-node-014:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-014:   warnings.warn(
ml-512-node-014: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-014:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-010:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-027:   warnings.warn(
ml-512-node-029:   warnings.warn(
ml-512-node-029: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-029:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-020:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-023:   warnings.warn(
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002:   warnings.warn(
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-002: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017:   warnings.warn(
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017:   warnings.warn(
ml-512-node-004:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-006:   warnings.warn(
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-004:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-004:   warnings.warn(
ml-512-node-012:   warnings.warn(
ml-512-node-006: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-006:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-009:   warnings.warn(
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-002:   warnings.warn(
ml-512-node-012: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-012:   warnings.warn(
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023:   warnings.warn(
ml-512-node-028:   warnings.warn(
ml-512-node-010: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017:   warnings.warn(
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-023: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-028: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-007:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-009:   warnings.warn(
ml-512-node-017:   warnings.warn(
ml-512-node-009: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017:   warnings.warn(
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017:   warnings.warn(
ml-512-node-028:   warnings.warn(
ml-512-node-017: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-017:   warnings.warn(
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-010:   warnings.warn(
ml-512-node-007:   warnings.warn(
ml-512-node-009:   warnings.warn(
ml-512-node-007: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-007:   warnings.warn(
ml-512-node-023:   warnings.warn(
ml-512-node-031: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.65s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.18s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.29s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.67s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.68s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.69s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.73s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.77s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.09s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.21s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.11s/it]
ml-512-node-031: Loading checkpoint shards: 100%|██████████| 3/3 [00:56<00:00, 17.65s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:56<00:00, 18.91s/it]
ml-512-node-031: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.23s/it]
ml-512-node-031: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.81s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.26s/it]
ml-512-node-031: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.83s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.28s/it]
ml-512-node-031: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.82s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.27s/it]
ml-512-node-031: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.85s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.31s/it]
ml-512-node-010: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.51s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.21s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.17s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.25s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.24s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.21s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.26s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.96s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.72s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:42<00:21, 21.22s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.67s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.68s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.40s/it]
ml-512-node-031: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.28s/it]
ml-512-node-010: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.44s/it]
ml-512-node-010: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.41s/it]
ml-512-node-026: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.64s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.01s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.82s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.85s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.04s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.60s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.88s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.54s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.25s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.96s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.79s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.93s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.93s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.41s/it]
ml-512-node-026: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.19s/it]
ml-512-node-010: Loading checkpoint shards: 100%|██████████| 3/3 [00:56<00:00, 18.02s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:56<00:00, 18.98s/it]
ml-512-node-010: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.25s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.33s/it]
ml-512-node-010: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.36s/it]
ml-512-node-010: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.35s/it]
ml-512-node-026: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.31s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.48s/it]
ml-512-node-010: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.28s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.35s/it]
ml-512-node-029: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.48s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.19s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.40s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.06s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.90s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.95s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.14s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.27s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.89s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.07s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.09s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.09s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.14s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.16s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.48s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.43s/it]
ml-512-node-026: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.39s/it]
ml-512-node-026: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.39s/it]
ml-512-node-026: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.14s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.31s/it]
ml-512-node-026: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.46s/it]
ml-512-node-026: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.20s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.40s/it]
ml-512-node-002: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.86s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.78s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.83s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.47s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.24s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.32s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.28s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.25s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.18s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.21s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.34s/it]
ml-512-node-011: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.03s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.19s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.39s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.09s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.18s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.14s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.07s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.08s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.91s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.78s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.07s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.06s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.04s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.05s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.32s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.20s/it]
ml-512-node-029: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.42s/it]
ml-512-node-002: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.05s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.28s/it]
ml-512-node-011: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.21s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.34s/it]
ml-512-node-002: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.06s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.28s/it]
ml-512-node-011: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.28s/it]
ml-512-node-029: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.40s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.50s/it]
ml-512-node-002: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.39s/it]
ml-512-node-002: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.13s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.46s/it]
ml-512-node-002: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.07s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.38s/it]
ml-512-node-021: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.32s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.59s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.66s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.02s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.06s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.21s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.30s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.94s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.84s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.16s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.78s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.84s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.72s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:42<00:21, 21.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.89s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.48s/it]
ml-512-node-002: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.39s/it]
ml-512-node-021: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.67s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.53s/it]
ml-512-node-012: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.52s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.89s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.17s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.83s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.85s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.91s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.08s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 24.00s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.88s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.27s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.26s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.27s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.24s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.45s/it]
ml-512-node-002: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.41s/it]
ml-512-node-012: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.61s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.51s/it]
ml-512-node-012: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.48s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.55s/it]
ml-512-node-011: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.28s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.51s/it]
ml-512-node-011: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.26s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.49s/it]
ml-512-node-021: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.49s/it]
ml-512-node-011: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.26s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.48s/it]
ml-512-node-011: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.26s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.49s/it]
ml-512-node-011: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.29s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.51s/it]
ml-512-node-013: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:20<00:41, 20.89s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.59s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.31s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.93s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.15s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.36s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.44s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.98s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.06s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.18s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.11s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.03s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.48s/it]
ml-512-node-029: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.60s/it]
ml-512-node-029: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.62s/it]
ml-512-node-029: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.62s/it]
ml-512-node-013: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.49s/it]
ml-512-node-012: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.69s/it]
ml-512-node-012: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.68s/it]
ml-512-node-013: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.56s/it]
ml-512-node-029: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.69s/it]
ml-512-node-012: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.54s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.70s/it]
ml-512-node-012: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.55s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.73s/it]
ml-512-node-022: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.10s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.02s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.14s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.88s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.97s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.84s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.13s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.77s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.07s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.79s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.95s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.98s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.08s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.02s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.89s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.50s/it]
ml-512-node-012: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.57s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.76s/it]
ml-512-node-021: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.45s/it]
ml-512-node-021: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.11s/it]
ml-512-node-021: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.41s/it]
ml-512-node-021: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.51s/it]
ml-512-node-021: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.53s/it]
ml-512-node-019: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.46s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.82s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.39s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.24s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.21s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.18s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.15s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.03s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.31s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.23s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:43<00:21, 21.71s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.36s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.34s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.28s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.42s/it]
ml-512-node-019: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.49s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.44s/it]
ml-512-node-007: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.64s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.04s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.27s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.48s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.66s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.67s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.61s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.80s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.74s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.95s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.94s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.01s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.54s/it]
ml-512-node-023: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.17s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.99s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.19s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.50s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.49s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.39s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.84s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.57s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.22s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.23s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.48s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.44s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.27s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.34s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.57s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.63s/it]
ml-512-node-023: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.57s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.66s/it]
ml-512-node-003: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.54s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.75s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.90s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.17s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.22s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.24s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.10s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.14s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.18s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.21s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.16s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.17s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.70s/it]
ml-512-node-007: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.36s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.53s/it]
ml-512-node-007: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.31s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.47s/it]
ml-512-node-022: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.52s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.57s/it]
ml-512-node-013: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.65s/it]
ml-512-node-003: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.74s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.74s/it]
ml-512-node-013: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.59s/it]
ml-512-node-013: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.53s/it]
ml-512-node-013: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.52s/it]
ml-512-node-013: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.65s/it]
ml-512-node-003: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.73s/it]
ml-512-node-023: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.71s/it]
ml-512-node-022: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.44s/it]
ml-512-node-003: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.69s/it]
ml-512-node-029: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.63s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.77s/it]
ml-512-node-003: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.67s/it]
ml-512-node-007: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.32s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.57s/it]
ml-512-node-003: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.68s/it]
ml-512-node-007: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.30s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.55s/it]
ml-512-node-023: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.77s/it]
ml-512-node-003: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.49s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.68s/it]
ml-512-node-003: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.72s/it]
ml-512-node-007: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.32s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.58s/it]
ml-512-node-007: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.31s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.57s/it]
ml-512-node-007: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.29s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.53s/it]
ml-512-node-023: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.63s/it]
ml-512-node-019: Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 18.19s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.21s/it]
ml-512-node-023: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.55s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.69s/it]
ml-512-node-027: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:42, 21.38s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.17s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.40s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.68s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.58s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.87s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.93s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.87s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.14s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.27s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.16s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.22s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.76s/it]
ml-512-node-023: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.54s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.68s/it]
ml-512-node-023: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.55s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.68s/it]
ml-512-node-022: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.62s/it]
ml-512-node-022: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.58s/it]
ml-512-node-022: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.52s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.68s/it]
ml-512-node-024: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.11s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.44s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.62s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.10s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.18s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.40s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.25s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.24s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.60s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.64s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.77s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.79s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.76s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.75s/it]
ml-512-node-022: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.48s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.61s/it]
ml-512-node-024: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.74s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.74s/it]
ml-512-node-022: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.55s/it]
ml-512-node-027: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.61s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.49s/it]
ml-512-node-019: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.72s/it]
ml-512-node-019: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.52s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.74s/it]
ml-512-node-019: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.73s/it]
ml-512-node-019: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.46s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.67s/it]
ml-512-node-027: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.66s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.82s/it]
ml-512-node-016: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.09s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.14s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.37s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.85s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.76s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.73s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.86s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.66s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.48s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.60s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.42s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.44s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.35s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.70s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.69s/it]
ml-512-node-019: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.72s/it]
ml-512-node-024: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.83s/it]
ml-512-node-015: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.01s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.57s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.79s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.57s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.54s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.84s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.60s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.02s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.36s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.09s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.27s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:21, 21.98s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.31s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.30s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.70s/it]
ml-512-node-015: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.61s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.69s/it]
ml-512-node-016: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.77s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.76s/it]
ml-512-node-015: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.66s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.76s/it]
ml-512-node-016: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.68s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.78s/it]
ml-512-node-016: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.56s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.71s/it]
ml-512-node-016: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.75s/it]
ml-512-node-016: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.63s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.80s/it]
ml-512-node-016: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.79s/it]
ml-512-node-016: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.61s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.77s/it]
ml-512-node-015: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.52s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.64s/it]
ml-512-node-015: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.90s/it]
ml-512-node-024: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.95s/it]
ml-512-node-015: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.90s/it]
ml-512-node-024: Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 18.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.62s/it]
ml-512-node-006: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.36s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.94s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.10s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.10s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.97s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.08s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.10s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.40s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.28s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.42s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.50s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.49s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.51s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.49s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.46s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.69s/it]
ml-512-node-015: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.70s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.89s/it]
ml-512-node-015: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.71s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.90s/it]
ml-512-node-025: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.32s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.06s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.08s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.03s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.86s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.76s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.93s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.13s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.19s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.27s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.26s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.54s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.68s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.49s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.52s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.32s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.98s/it]
ml-512-node-027: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.68s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.91s/it]
ml-512-node-024: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.85s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.94s/it]
ml-512-node-024: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.98s/it]
ml-512-node-024: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.92s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.04s/it]
ml-512-node-025: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.97s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.04s/it]
ml-512-node-006: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.71s/it]
ml-512-node-027: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.95s/it]
ml-512-node-006: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.70s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.86s/it]
ml-512-node-027: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.68s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.86s/it]
ml-512-node-027: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.79s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.00s/it]
ml-512-node-025: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.06s/it]
ml-512-node-025: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.08s/it]
ml-512-node-006: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.65s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.85s/it]
ml-512-node-006: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.63s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.82s/it]
ml-512-node-006: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.65s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.85s/it]
ml-512-node-006: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.67s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.86s/it]
ml-512-node-006: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.66s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.85s/it]
ml-512-node-005: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.93s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.30s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.35s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.12s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.35s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.77s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.51s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.09s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.21s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.50s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.46s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.30s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.55s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.20s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.77s/it]
ml-512-node-025: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.96s/it]
ml-512-node-025: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.86s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.92s/it]
ml-512-node-025: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.97s/it]
ml-512-node-005: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.53s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.79s/it]
ml-512-node-027: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.83s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.99s/it]
ml-512-node-005: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.61s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.86s/it]
ml-512-node-025: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.03s/it]
ml-512-node-014: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.65s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.16s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.06s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.02s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.10s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.09s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.97s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.11s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.84s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.78s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.73s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.03s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.05s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.06s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.64s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.01s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.94s/it]
ml-512-node-008: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:21<00:43, 21.61s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.24s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.48s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.53s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.43s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.33s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.64s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.27s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.83s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.85s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.78s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.06s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.14s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.03s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.91s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.91s/it]
ml-512-node-005: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.56s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.89s/it]
ml-512-node-008: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.87s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.89s/it]
ml-512-node-005: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.66s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.02s/it]
ml-512-node-005: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.07s/it]
ml-512-node-005: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.70s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.09s/it]
ml-512-node-005: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.80s/it]
ml-512-node-008: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.88s/it]
ml-512-node-020: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.53s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.40s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.51s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.96s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.97s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.07s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.09s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.73s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.95s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.74s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:22, 22.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.71s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.74s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.03s/it]
ml-512-node-020: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.05s/it]
ml-512-node-014: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.99s/it]
ml-512-node-014: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.95s/it]
ml-512-node-020: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.05s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.06s/it]
ml-512-node-020: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.76s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.97s/it]
ml-512-node-020: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.74s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.93s/it]
ml-512-node-020: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.81s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.04s/it]
ml-512-node-020: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.76s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.96s/it]
ml-512-node-020: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.94s/it]
ml-512-node-014: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.76s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.85s/it]
ml-512-node-014: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.99s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.20s/it]
ml-512-node-014: 
ml-512-node-014: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.20s/it]
ml-512-node-014: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.97s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.16s/it]
ml-512-node-008: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.95s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.08s/it]
ml-512-node-008: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 18.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.06s/it]
ml-512-node-008: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.13s/it]
ml-512-node-008: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.20s/it]
ml-512-node-008: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.81s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.85s/it]
ml-512-node-030: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.46s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.82s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.11s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.83s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.15s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.05s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.98s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:44<00:22, 22.51s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.10s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.18s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.06s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.14s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.07s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.11s/it]
ml-512-node-030: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.06s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.06s/it]
ml-512-node-030: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.85s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.80s/it]
ml-512-node-030: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.20s/it]
ml-512-node-009: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.44s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.80s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:44, 22.27s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.84s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.95s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.87s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.85s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.78s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.75s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.99s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.11s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.18s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.23s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.17s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.15s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.10s/it]
ml-512-node-030: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.31s/it]
ml-512-node-030: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.25s/it]
ml-512-node-030: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.11s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.31s/it]
ml-512-node-030: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.28s/it]
ml-512-node-009: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.13s/it]
ml-512-node-009: Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 18.98s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:59<00:00, 19.95s/it]
ml-512-node-001: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.41s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.97s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.89s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.14s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.22s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.21s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.28s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.43s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.50s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.60s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.54s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.57s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.64s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.54s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.61s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.46s/it]
ml-512-node-001: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.34s/it]
ml-512-node-001: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.51s/it]
ml-512-node-001: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.22s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.43s/it]
ml-512-node-001: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.49s/it]
ml-512-node-001: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.28s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.51s/it]
ml-512-node-001: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.28s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.49s/it]
ml-512-node-001: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.33s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.56s/it]
ml-512-node-009: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.22s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.38s/it]
ml-512-node-009: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.20s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.35s/it]
ml-512-node-009: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.21s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.35s/it]
ml-512-node-009: Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.31s/it]
ml-512-node-009: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.22s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.35s/it]
ml-512-node-028: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.86s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.78s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.93s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.45s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.64s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.40s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.40s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.64s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.84s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.88s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.04s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.91s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.92s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:23, 23.99s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.02s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.59s/it]
ml-512-node-028: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.36s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.56s/it]
ml-512-node-028: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.63s/it]
ml-512-node-004: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.55s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.77s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.83s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.93s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.83s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.74s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.74s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.78s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.72s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.71s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.74s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.57s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.51s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.54s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.51s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.37s/it]
ml-512-node-004: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.57s/it]
ml-512-node-004: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.56s/it]
ml-512-node-004: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.73s/it]
ml-512-node-004: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.58s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.71s/it]
ml-512-node-004: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.48s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.61s/it]
ml-512-node-004: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.59s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.71s/it]
ml-512-node-004: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.56s/it]
ml-512-node-028: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.38s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.67s/it]
ml-512-node-028: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.71s/it]
ml-512-node-028: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.64s/it]
ml-512-node-028: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.44s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.74s/it]
ml-512-node-028: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.66s/it]
ml-512-node-018: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.18s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:22<00:45, 22.97s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.29s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.98s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.98s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.13s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.01s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.20s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.71s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.62s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.65s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.86s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.91s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:46<00:23, 23.52s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.87s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.56s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.59s/it]
ml-512-node-018: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.58s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.64s/it]
ml-512-node-018: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.64s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.69s/it]
ml-512-node-018: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.62s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.80s/it]
ml-512-node-018: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.76s/it]
ml-512-node-018: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.77s/it]
ml-512-node-018: Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 19.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:01<00:00, 20.49s/it]
ml-512-node-018: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.61s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.77s/it]
ml-512-node-032: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.34s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.17s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.38s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.32s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.22s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.43s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.38s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.41s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.45s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:49<00:24, 24.53s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.50s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:49<00:24, 24.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:49<00:24, 24.63s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:49<00:24, 24.71s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:49<00:24, 24.66s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 19.92s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.18s/it]
ml-512-node-017: Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.80s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.87s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:47, 23.77s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.24s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.24s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.20s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:23<00:46, 23.47s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.00s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.33s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:24, 24.06s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.32s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.38s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.46s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.15s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.49s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.39s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.57s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.70s/it]
ml-512-node-032: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 19.93s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.18s/it]
ml-512-node-032: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 19.89s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.13s/it]
ml-512-node-032: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 19.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.14s/it]
ml-512-node-032: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 19.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.10s/it]
ml-512-node-032: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 19.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.17s/it]
ml-512-node-032: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 19.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.15s/it]
ml-512-node-032: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 19.92s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.15s/it]
ml-512-node-017: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 20.00s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.17s/it]
ml-512-node-017: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 20.01s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.20s/it]
ml-512-node-017: Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 19.84s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:02<00:00, 20.94s/it]
ml-512-node-017: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 20.04s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.14s/it]
ml-512-node-017: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 20.07s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 20.08s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.17s/it]
ml-512-node-017: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.19s/it]
ml-512-node-017: Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 20.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:03<00:00, 21.21s/it]
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Detected CUDA files, patching ldflags
ml-512-node-026: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-026: Building extension module fused_adam...
ml-512-node-026: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: ninja: no work to do.
ml-512-node-009: Detected CUDA files, patching ldflags
ml-512-node-009: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-009: Building extension module fused_adam...
ml-512-node-009: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-026: Time to load fused_adam op: 0.06692719459533691 seconds
ml-512-node-032: Detected CUDA files, patching ldflags
ml-512-node-032: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-032: Building extension module fused_adam...
ml-512-node-032: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: 
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: ninja: no work to do.
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Time to load fused_adam op: 0.06702136993408203 seconds
ml-512-node-032: ninja: no work to do.
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Detected CUDA files, patching ldflags
ml-512-node-025: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-025: Building extension module fused_adam...
ml-512-node-025: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-032: Time to load fused_adam op: 0.06663751602172852 seconds
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Detected CUDA files, patching ldflags
ml-512-node-003: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-003: Building extension module fused_adam...
ml-512-node-003: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Detected CUDA files, patching ldflags
ml-512-node-015: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-015: Building extension module fused_adam...
ml-512-node-015: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-027: Detected CUDA files, patching ldflags
ml-512-node-027: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-027: Building extension module fused_adam...
ml-512-node-027: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Detected CUDA files, patching ldflags
ml-512-node-017: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-017: Building extension module fused_adam...
ml-512-node-017: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: ninja: no work to do.
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Time to load fused_adam op: 0.06441569328308105 seconds
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: 
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: ninja: no work to do.
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Detected CUDA files, patching ldflags
ml-512-node-032: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Building extension module fused_adam...
ml-512-node-032: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-027: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-015: ninja: no work to do.
ml-512-node-003: Time to load fused_adam op: 0.06628108024597168 seconds
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: 
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-027: ninja: no work to do.
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Time to load fused_adam op: 0.06499862670898438 seconds
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: 
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-001: Detected CUDA files, patching ldflags
ml-512-node-001: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-027: Time to load fused_adam op: 0.06894683837890625 seconds
ml-512-node-001: Building extension module fused_adam...
ml-512-node-001: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-019: Detected CUDA files, patching ldflags
ml-512-node-019: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-019: Building extension module fused_adam...
ml-512-node-019: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: ninja: no work to do.
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Detected CUDA files, patching ldflags
ml-512-node-009: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-009: Building extension module fused_adam...
ml-512-node-009: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-017: Time to load fused_adam op: 0.0648198127746582 seconds
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Detected CUDA files, patching ldflags
ml-512-node-026: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-026: Building extension module fused_adam...
ml-512-node-026: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Detected CUDA files, patching ldflags
ml-512-node-007: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Building extension module fused_adam...
ml-512-node-007: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-020: Detected CUDA files, patching ldflags
ml-512-node-020: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-020: Building extension module fused_adam...
ml-512-node-020: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Detected CUDA files, patching ldflags
ml-512-node-023: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: ninja: no work to do.
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: Building extension module fused_adam...
ml-512-node-023: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-004: Detected CUDA files, patching ldflags
ml-512-node-004: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-004: Building extension module fused_adam...
ml-512-node-004: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-010: Detected CUDA files, patching ldflags
ml-512-node-010: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-032: Time to load fused_adam op: 0.06392192840576172 seconds
ml-512-node-010: Building extension module fused_adam...
ml-512-node-010: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-021: Detected CUDA files, patching ldflags
ml-512-node-021: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-021: Building extension module fused_adam...
ml-512-node-021: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Detected CUDA files, patching ldflags
ml-512-node-012: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-012: Building extension module fused_adam...
ml-512-node-012: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: ninja: no work to do.
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: ninja: no work to do.
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Time to load fused_adam op: 0.06590414047241211 seconds
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Time to load fused_adam op: 0.06599569320678711 seconds
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: ninja: no work to do.
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Time to load fused_adam op: 0.06753849983215332 seconds
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Detected CUDA files, patching ldflags
ml-512-node-025: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-025: Building extension module fused_adam...
ml-512-node-025: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-009: Time to load fused_adam op: 0.1013326644897461 seconds
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-027: Time to load fused_adam op: 0.10139918327331543 seconds
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-026: ninja: no work to do.
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: ninja: no work to do.
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-028: Detected CUDA files, patching ldflags
ml-512-node-028: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-020: ninja: no work to do.
ml-512-node-028: Building extension module fused_adam...
ml-512-node-028: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-027: Time to load fused_adam op: 0.1012108325958252 seconds
ml-512-node-032: Time to load fused_adam op: 0.10480499267578125 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-023: ninja: no work to do.
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Detected CUDA files, patching ldflags
ml-512-node-003: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Time to load fused_adam op: 0.06549382209777832 seconds
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Building extension module fused_adam...
ml-512-node-003: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-007: Time to load fused_adam op: 0.06602311134338379 seconds
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: Time to load fused_adam op: 0.06589150428771973 seconds
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-010: ninja: no work to do.
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: ninja: no work to do.
ml-512-node-023: Time to load fused_adam op: 0.06601810455322266 seconds
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: ninja: no work to do.
ml-512-node-012: ninja: no work to do.
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Time to load fused_adam op: 0.0682210922241211 seconds
ml-512-node-017: Detected CUDA files, patching ldflags
ml-512-node-017: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-017: Building extension module fused_adam...
ml-512-node-017: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-004: Time to load fused_adam op: 0.06690669059753418 seconds
ml-512-node-015: Detected CUDA files, patching ldflags
ml-512-node-015: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-015: Building extension module fused_adam...
ml-512-node-015: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-021: Time to load fused_adam op: 0.06573271751403809 seconds
ml-512-node-012: Time to load fused_adam op: 0.06491589546203613 seconds
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-020: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Time to load fused_adam op: 0.11186504364013672 seconds
ml-512-node-001: Detected CUDA files, patching ldflags
ml-512-node-001: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-001: Building extension module fused_adam...
ml-512-node-001: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Detected CUDA files, patching ldflags
ml-512-node-029: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-029: Building extension module fused_adam...
ml-512-node-029: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: 
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: ninja: no work to do.
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-027: Time to load fused_adam op: 0.11855745315551758 seconds
ml-512-node-025: Time to load fused_adam op: 0.07606124877929688 seconds
ml-512-node-027: Time to load fused_adam op: 0.10419225692749023 seconds
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-028: ninja: no work to do.
ml-512-node-025: Time to load fused_adam op: 0.10206198692321777 seconds
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-019: Detected CUDA files, patching ldflags
ml-512-node-019: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-019: Building extension module fused_adam...
ml-512-node-019: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-002: Detected CUDA files, patching ldflags
ml-512-node-002: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-003: ninja: no work to do.
ml-512-node-002: Building extension module fused_adam...
ml-512-node-002: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-028: Time to load fused_adam op: 0.06656622886657715 seconds
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: Time to load fused_adam op: 0.10495519638061523 seconds
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-003: Time to load fused_adam op: 0.09165835380554199 seconds
ml-512-node-015: ninja: no work to do.
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: ninja: no work to do.
ml-512-node-027: Loading extension module fused_adam...
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-004: Loading extension module fused_adam...Loading extension module fused_adam...
ml-512-node-004: 
ml-512-node-015: Time to load fused_adam op: 0.06360840797424316 seconds
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-020: Detected CUDA files, patching ldflags
ml-512-node-020: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-020: Building extension module fused_adam...
ml-512-node-020: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-004: Time to load fused_adam op: 0.10147261619567871 secondsTime to load fused_adam op: 0.10150909423828125 seconds
ml-512-node-004: 
ml-512-node-017: Time to load fused_adam op: 0.06352877616882324 seconds
ml-512-node-004: Time to load fused_adam op: 0.10166025161743164 seconds
ml-512-node-004: Time to load fused_adam op: 0.10150003433227539 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-026: Time to load fused_adam op: 0.10229659080505371 seconds
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-021: Time to load fused_adam op: 0.10164523124694824 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-004: Time to load fused_adam op: 0.10225081443786621 seconds
ml-512-node-021: Time to load fused_adam op: 0.10219836235046387 seconds
ml-512-node-012: Time to load fused_adam op: 0.10156798362731934 seconds
ml-512-node-026: Time to load fused_adam op: 0.10137748718261719 seconds
ml-512-node-001: ninja: no work to do.
ml-512-node-021: Time to load fused_adam op: 0.10227394104003906 seconds
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-021: Time to load fused_adam op: 0.10640406608581543 seconds
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-001: Time to load fused_adam op: 0.06644630432128906 seconds
ml-512-node-021: Time to load fused_adam op: 0.10133600234985352 seconds
ml-512-node-029: ninja: no work to do.
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-001: [2024-07-08 07:22:59,755] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.4, git-hash=unknown, git-branch=unknown
ml-512-node-001: [2024-07-08 07:22:59,755] [INFO] [comm.py:662:init_distributed] Distributed backend already initialized
ml-512-node-032: Time to load fused_adam op: 0.10177230834960938 seconds
ml-512-node-032: Time to load fused_adam op: 0.10288095474243164 seconds
ml-512-node-030: Detected CUDA files, patching ldflags
ml-512-node-030: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-030: Building extension module fused_adam...
ml-512-node-030: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-032: Time to load fused_adam op: 0.20563364028930664 seconds
ml-512-node-029: Time to load fused_adam op: 0.06759977340698242 seconds
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-003: Time to load fused_adam op: 0.1060795783996582 seconds
ml-512-node-009: Time to load fused_adam op: 0.20163178443908691 seconds
ml-512-node-009: Time to load fused_adam op: 0.20215559005737305 seconds
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Detected CUDA files, patching ldflags
ml-512-node-007: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-007: Building extension module fused_adam...
ml-512-node-007: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-023: Time to load fused_adam op: 0.10137295722961426 seconds
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-027: Time to load fused_adam op: 0.15293455123901367 seconds
ml-512-node-010: Detected CUDA files, patching ldflags
ml-512-node-010: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-010: Building extension module fused_adam...
ml-512-node-010: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-025: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: ninja: no work to do.
ml-512-node-027: Time to load fused_adam op: 0.12260293960571289 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-002: ninja: no work to do.
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-019: Time to load fused_adam op: 0.07346081733703613 seconds
ml-512-node-026: Time to load fused_adam op: 0.20490050315856934 seconds
ml-512-node-002: Time to load fused_adam op: 0.06573486328125 seconds
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-012: Time to load fused_adam op: 0.11265039443969727 seconds
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-017: Time to load fused_adam op: 0.11108899116516113 seconds
ml-512-node-020: ninja: no work to do.
ml-512-node-023: Time to load fused_adam op: 0.10397529602050781 seconds
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-004: Time to load fused_adam op: 0.12144851684570312 seconds
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-001: Time to load fused_adam op: 0.10229134559631348 seconds
ml-512-node-021: Time to load fused_adam op: 0.10505223274230957 seconds
ml-512-node-020: Time to load fused_adam op: 0.07304024696350098 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-026: Time to load fused_adam op: 0.10343599319458008 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-028: Time to load fused_adam op: 0.10142827033996582 seconds
ml-512-node-030: ninja: no work to do.
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-028: Time to load fused_adam op: 0.1016533374786377 seconds
ml-512-node-009: Time to load fused_adam op: 0.20318937301635742 seconds
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-009: Loading extension module fused_adam...
ml-512-node-012: Time to load fused_adam op: 0.10297465324401855 seconds
ml-512-node-012: Time to load fused_adam op: 0.10317611694335938 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-023: Time to load fused_adam op: 0.11533355712890625 secondsTime to load fused_adam op: 0.12166810035705566 seconds
ml-512-node-023: 
ml-512-node-023: Loading extension module fused_adam...Loading extension module fused_adam...
ml-512-node-023: 
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-007: ninja: no work to do.
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-029: Time to load fused_adam op: 0.10149240493774414 seconds
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-023: Time to load fused_adam op: 0.12548446655273438 seconds
ml-512-node-010: ninja: no work to do.
ml-512-node-020: Time to load fused_adam op: 0.1013948917388916 seconds
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-007: Time to load fused_adam op: 0.09163427352905273 seconds
ml-512-node-009: Time to load fused_adam op: 0.21100926399230957 seconds
ml-512-node-009: Time to load fused_adam op: 0.20566511154174805 seconds
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-010: Time to load fused_adam op: 0.08279180526733398 seconds
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Time to load fused_adam op: 0.06761884689331055 seconds
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-022: Detected CUDA files, patching ldflags
ml-512-node-022: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-022: Building extension module fused_adam...
ml-512-node-022: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Time to load fused_adam op: 0.20265412330627441 seconds
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-001: Time to load fused_adam op: 0.10169863700866699 seconds
ml-512-node-001: Time to load fused_adam op: 0.10218095779418945 seconds
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-020: Time to load fused_adam op: 0.12104129791259766 seconds
ml-512-node-012: Time to load fused_adam op: 0.1016087532043457 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-025: Detected CUDA files, patching ldflags
ml-512-node-025: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-025: Building extension module fused_adam...
ml-512-node-025: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-029: Time to load fused_adam op: 0.1114664077758789 secondsTime to load fused_adam op: 0.10221099853515625 seconds
ml-512-node-029: 
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-020: Time to load fused_adam op: 0.11176562309265137 seconds
ml-512-node-020: Time to load fused_adam op: 0.10318565368652344 seconds
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-023: Time to load fused_adam op: 0.1265711784362793 seconds
ml-512-node-020: Time to load fused_adam op: 0.10466885566711426 seconds
ml-512-node-022: ninja: no work to do.
ml-512-node-022: Time to load fused_adam op: 0.06536030769348145 seconds
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-030: Time to load fused_adam op: 0.10169315338134766 seconds
ml-512-node-020: Loading extension module fused_adam...
ml-512-node-030: Time to load fused_adam op: 0.10229921340942383 seconds
ml-512-node-029: Time to load fused_adam op: 0.10411882400512695 seconds
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-019: Time to load fused_adam op: 0.20165109634399414 seconds
ml-512-node-020: Time to load fused_adam op: 0.11972618103027344 seconds
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-030: Time to load fused_adam op: 0.10160517692565918 seconds
ml-512-node-019: Time to load fused_adam op: 0.2018899917602539 seconds
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: 
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Detected CUDA files, patching ldflags
ml-512-node-014: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-019: Time to load fused_adam op: 0.20240306854248047 seconds
ml-512-node-019: Time to load fused_adam op: 0.2024216651916504 seconds
ml-512-node-017: Time to load fused_adam op: 0.10175442695617676 seconds
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-030: Time to load fused_adam op: 0.10162830352783203 seconds
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-030: Time to load fused_adam op: 0.10136651992797852 seconds
ml-512-node-019: Time to load fused_adam op: 0.2040233612060547 seconds
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-017: Time to load fused_adam op: 0.20167779922485352 seconds
ml-512-node-002: Detected CUDA files, patching ldflags
ml-512-node-017: Time to load fused_adam op: 0.20188093185424805 seconds
ml-512-node-002: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-002: Building extension module fused_adam...
ml-512-node-002: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-007: Time to load fused_adam op: 0.20174932479858398 seconds
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Detected CUDA files, patching ldflags
ml-512-node-028: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Building extension module fused_adam...
ml-512-node-028: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: Detected CUDA files, patching ldflags
ml-512-node-024: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-024: Building extension module fused_adam...
ml-512-node-024: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-001: Time to load fused_adam op: 0.20522212982177734 seconds
ml-512-node-001: Time to load fused_adam op: 0.20214581489562988 seconds
ml-512-node-001: Time to load fused_adam op: 0.20250272750854492 seconds
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-001: Loading extension module fused_adam...
ml-512-node-007: Time to load fused_adam op: 0.20162630081176758 seconds
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-007: Time to load fused_adam op: 0.20154285430908203 seconds
ml-512-node-003: Detected CUDA files, patching ldflags
ml-512-node-003: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-015: Detected CUDA files, patching ldflags
ml-512-node-015: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-015: Building extension module fused_adam...
ml-512-node-015: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-014: Building extension module fused_adam...
ml-512-node-014: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-010: Time to load fused_adam op: 0.20182323455810547 seconds
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Time to load fused_adam op: 0.20323491096496582 seconds
ml-512-node-003: Building extension module fused_adam...
ml-512-node-003: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-019: Time to load fused_adam op: 0.21817493438720703 seconds
ml-512-node-019: Loading extension module fused_adam...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: ninja: no work to do.
ml-512-node-017: Time to load fused_adam op: 0.20500683784484863 seconds
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-022: Time to load fused_adam op: 0.10179567337036133 seconds
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-022: Time to load fused_adam op: 0.10136032104492188 seconds
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Time to load fused_adam op: 0.06576848030090332 seconds
ml-512-node-029: Time to load fused_adam op: 0.10221719741821289 seconds
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-002: ninja: no work to do.
ml-512-node-024: ninja: no work to do.
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Time to load fused_adam op: 0.2175753116607666 seconds
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-018: Detected CUDA files, patching ldflags
ml-512-node-018: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-010: Time to load fused_adam op: 0.20277714729309082 seconds
ml-512-node-010: Time to load fused_adam op: 0.20625567436218262 seconds
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-024: Time to load fused_adam op: 0.06692385673522949 seconds
ml-512-node-018: Building extension module fused_adam...
ml-512-node-018: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-010: Time to load fused_adam op: 0.20508146286010742 seconds
ml-512-node-025: ninja: no work to do.
ml-512-node-002: Time to load fused_adam op: 0.0657358169555664 seconds
ml-512-node-032: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-030: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Detected CUDA files, patching ldflags
ml-512-node-006: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-003: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-022: Time to load fused_adam op: 0.1026449203491211 seconds
ml-512-node-028: ninja: no work to do.
ml-512-node-016: Detected CUDA files, patching ldflags
ml-512-node-016: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Building extension module fused_adam...
ml-512-node-016: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-025: Time to load fused_adam op: 0.12079977989196777 seconds
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-006: Building extension module fused_adam...
ml-512-node-006: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Time to load fused_adam op: 0.3019592761993408 seconds
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-014: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Time to load fused_adam op: 0.08275151252746582 seconds
ml-512-node-015: ninja: no work to do.
ml-512-node-010: Time to load fused_adam op: 0.204115629196167 seconds
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-022: Time to load fused_adam op: 0.10204458236694336 seconds
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-005: Detected CUDA files, patching ldflags
ml-512-node-005: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-005: Building extension module fused_adam...
ml-512-node-005: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: ninja: no work to do.
ml-512-node-018: ninja: no work to do.
ml-512-node-015: Time to load fused_adam op: 0.107574462890625 seconds
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: Time to load fused_adam op: 0.06517934799194336 seconds
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: ninja: no work to do.
ml-512-node-015: Time to load fused_adam op: 0.302213191986084 seconds
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Detected CUDA files, patching ldflags
ml-512-node-031: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-031: Building extension module fused_adam...
ml-512-node-031: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: ninja: no work to do.
ml-512-node-006: Time to load fused_adam op: 0.06653976440429688 seconds
ml-512-node-003: Time to load fused_adam op: 0.1190035343170166 seconds
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-024: Time to load fused_adam op: 0.10134148597717285 secondsTime to load fused_adam op: 0.10135459899902344 seconds
ml-512-node-024: 
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Detected CUDA files, patching ldflags
ml-512-node-014: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-014: Building extension module fused_adam...
ml-512-node-014: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-016: Time to load fused_adam op: 0.0645914077758789 seconds
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-015: Time to load fused_adam op: 0.31055474281311035 seconds
ml-512-node-015: Time to load fused_adam op: 0.2026689052581787 seconds
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Detected CUDA files, patching ldflags
ml-512-node-002: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Building extension module fused_adam...
ml-512-node-002: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-030: Detected CUDA files, patching ldflags
ml-512-node-030: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-005: ninja: no work to do.
ml-512-node-030: Building extension module fused_adam...
ml-512-node-030: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-015: Time to load fused_adam op: 0.31131720542907715 seconds
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-005: Time to load fused_adam op: 0.06475615501403809 seconds
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-024: Time to load fused_adam op: 0.11833572387695312 seconds
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-018: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: ninja: no work to do.
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Time to load fused_adam op: 0.10252928733825684 seconds
ml-512-node-028: Time to load fused_adam op: 0.10439109802246094 seconds
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-031: Time to load fused_adam op: 0.06936788558959961 seconds
ml-512-node-013: Detected CUDA files, patching ldflags
ml-512-node-013: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-018: Detected CUDA files, patching ldflags
ml-512-node-018: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-014: ninja: no work to do.
ml-512-node-013: Building extension module fused_adam...
ml-512-node-013: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-018: Building extension module fused_adam...
ml-512-node-018: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Time to load fused_adam op: 0.302767276763916 seconds
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-014: Time to load fused_adam op: 0.06264042854309082 seconds
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-014: Time to load fused_adam op: 0.10121321678161621 seconds
ml-512-node-032: Detected CUDA files, patching ldflags
ml-512-node-032: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-032: Building extension module fused_adam...
ml-512-node-032: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-016: Time to load fused_adam op: 0.1017158031463623 seconds
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: Detected CUDA files, patching ldflags
ml-512-node-008: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-002: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: Building extension module fused_adam...
ml-512-node-008: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-026: Detected CUDA files, patching ldflags
ml-512-node-026: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-026: Building extension module fused_adam...
ml-512-node-026: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-022: Detected CUDA files, patching ldflags
ml-512-node-022: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-022: Building extension module fused_adam...
ml-512-node-022: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-011: Detected CUDA files, patching ldflags
ml-512-node-011: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-011: Building extension module fused_adam...
ml-512-node-011: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-016: Time to load fused_adam op: 0.1014707088470459 seconds
ml-512-node-030: ninja: no work to do.
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-006: Detected CUDA files, patching ldflags
ml-512-node-006: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-006: Building extension module fused_adam...
ml-512-node-006: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-030: Time to load fused_adam op: 0.09703636169433594 seconds
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-025: Loading extension module fused_adam...
ml-512-node-025: Time to load fused_adam op: 0.40204858779907227 seconds
ml-512-node-025: Time to load fused_adam op: 0.40204882621765137 seconds
ml-512-node-013: ninja: no work to do.
ml-512-node-018: ninja: no work to do.
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: ninja: no work to do.
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-031: Time to load fused_adam op: 0.10129165649414062 seconds
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-031: Time to load fused_adam op: 0.10119128227233887 seconds
ml-512-node-018: Time to load fused_adam op: 0.0744943618774414 seconds
ml-512-node-013: Time to load fused_adam op: 0.06721997261047363 seconds
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-031: Time to load fused_adam op: 0.10110259056091309 seconds
ml-512-node-003: Time to load fused_adam op: 0.10208296775817871 seconds
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-005: Detected CUDA files, patching ldflags
ml-512-node-005: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-005: Building extension module fused_adam...
ml-512-node-005: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-028: Time to load fused_adam op: 0.10239267349243164 seconds
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-008: ninja: no work to do.
ml-512-node-002: Time to load fused_adam op: 0.1086580753326416 seconds
ml-512-node-031: Time to load fused_adam op: 0.10570406913757324 seconds
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-016: Time to load fused_adam op: 0.10383319854736328 seconds
ml-512-node-008: Time to load fused_adam op: 0.06486201286315918 seconds
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-031: Time to load fused_adam op: 0.10668230056762695 seconds
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-018: Time to load fused_adam op: 0.10347390174865723 seconds
ml-512-node-011: ninja: no work to do.
ml-512-node-003: Time to load fused_adam op: 0.10683631896972656 seconds
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-030: Time to load fused_adam op: 0.20758461952209473 seconds
ml-512-node-030: Loading extension module fused_adam...
ml-512-node-015: Loading extension module fused_adam...
ml-512-node-016: Time to load fused_adam op: 0.10149145126342773 seconds
ml-512-node-011: Time to load fused_adam op: 0.06602287292480469 seconds
ml-512-node-015: Time to load fused_adam op: 0.2021162509918213 seconds
ml-512-node-010: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-003: Time to load fused_adam op: 0.303088903427124 seconds
ml-512-node-003: Loading extension module fused_adam...
ml-512-node-024: Detected CUDA files, patching ldflags
ml-512-node-024: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-024: Building extension module fused_adam...
ml-512-node-024: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-018: Time to load fused_adam op: 0.10934114456176758 seconds
ml-512-node-006: ninja: no work to do.
ml-512-node-022: ninja: no work to do.
ml-512-node-031: Time to load fused_adam op: 0.11426854133605957 seconds
ml-512-node-031: Loading extension module fused_adam...
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-006: Time to load fused_adam op: 0.06450581550598145 seconds
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-018: Time to load fused_adam op: 0.10879969596862793 seconds
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-002: Time to load fused_adam op: 0.2017955780029297 seconds
ml-512-node-002: Time to load fused_adam op: 0.20235776901245117 seconds
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-022: Time to load fused_adam op: 0.08578944206237793 seconds
ml-512-node-005: ninja: no work to do.
ml-512-node-013: Time to load fused_adam op: 0.10163331031799316 seconds
ml-512-node-013: Time to load fused_adam op: 0.1014411449432373 seconds
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-005: Time to load fused_adam op: 0.06379842758178711 seconds
ml-512-node-018: Time to load fused_adam op: 0.1029670238494873 seconds
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-014: Time to load fused_adam op: 0.20180940628051758 seconds
ml-512-node-013: Time to load fused_adam op: 0.1031498908996582 seconds
ml-512-node-029: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-016: Time to load fused_adam op: 0.11731696128845215 seconds
ml-512-node-016: Time to load fused_adam op: 0.11308073997497559 seconds
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-011: Time to load fused_adam op: 0.10150575637817383 seconds
ml-512-node-011: Time to load fused_adam op: 0.10158634185791016 seconds
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-002: Time to load fused_adam op: 0.20191240310668945 seconds
ml-512-node-002: Time to load fused_adam op: 0.12030744552612305 seconds
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-011: Time to load fused_adam op: 0.1017463207244873 seconds
ml-512-node-014: Time to load fused_adam op: 0.20234990119934082 seconds
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-008: Time to load fused_adam op: 0.10156822204589844 seconds
ml-512-node-014: Time to load fused_adam op: 0.20144152641296387 seconds
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-008: Time to load fused_adam op: 0.1012718677520752 seconds
ml-512-node-018: Time to load fused_adam op: 0.10819220542907715 seconds
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-018: Loading extension module fused_adam...
ml-512-node-014: Loading extension module fused_adam...
ml-512-node-024: ninja: no work to do.
ml-512-node-014: Time to load fused_adam op: 0.20244884490966797 seconds
ml-512-node-014: Time to load fused_adam op: 0.20212793350219727 seconds
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-018: Time to load fused_adam op: 0.10272908210754395 seconds
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-011: Time to load fused_adam op: 0.10260128974914551 seconds
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-022: Time to load fused_adam op: 0.10176420211791992 seconds
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-011: Time to load fused_adam op: 0.11119604110717773 seconds
ml-512-node-029: Detected CUDA files, patching ldflags
ml-512-node-029: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-029: Building extension module fused_adam...
ml-512-node-029: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-008: Time to load fused_adam op: 0.10220146179199219 seconds
ml-512-node-008: Time to load fused_adam op: 0.11579608917236328 seconds
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-024: Time to load fused_adam op: 0.10899782180786133 seconds
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-006: Time to load fused_adam op: 0.10216712951660156 seconds
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-031: Time to load fused_adam op: 0.16818523406982422 seconds
ml-512-node-006: Time to load fused_adam op: 0.20184803009033203 seconds
ml-512-node-006: Time to load fused_adam op: 0.10143089294433594 seconds
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-010: Detected CUDA files, patching ldflags
ml-512-node-010: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-010: Building extension module fused_adam...
ml-512-node-010: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-008: Time to load fused_adam op: 0.1033933162689209 seconds
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-005: Time to load fused_adam op: 0.10221123695373535 seconds
ml-512-node-002: Time to load fused_adam op: 0.10386133193969727 seconds
ml-512-node-002: Loading extension module fused_adam...
ml-512-node-011: Time to load fused_adam op: 0.10430383682250977 seconds
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-006: Time to load fused_adam op: 0.10155773162841797 seconds
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-026: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Detected CUDA files, patching ldflags
ml-512-node-013: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-013: Building extension module fused_adam...
ml-512-node-013: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Detected CUDA files, patching ldflags
ml-512-node-012: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-012: Building extension module fused_adam...
ml-512-node-012: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-008: Time to load fused_adam op: 0.10432958602905273 seconds
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-032: ninja: no work to do.
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-005: Time to load fused_adam op: 0.20192694664001465 seconds
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-005: Time to load fused_adam op: 0.20183348655700684 seconds
ml-512-node-032: Loading extension module fused_adam...
ml-512-node-032: Time to load fused_adam op: 0.26056933403015137 seconds
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-024: Time to load fused_adam op: 0.30472350120544434 seconds
ml-512-node-024: Time to load fused_adam op: 0.20206332206726074 seconds
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-013: ninja: no work to do.
ml-512-node-005: Time to load fused_adam op: 0.20150136947631836 seconds
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-028: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-013: Time to load fused_adam op: 0.1014862060546875 seconds
ml-512-node-029: ninja: no work to do.
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-004: Detected CUDA files, patching ldflags
ml-512-node-004: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-004: Building extension module fused_adam...
ml-512-node-004: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-013: Time to load fused_adam op: 0.20167756080627441 seconds
ml-512-node-029: Time to load fused_adam op: 0.21140766143798828 seconds
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-013: Time to load fused_adam op: 0.10469937324523926 seconds
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-012: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-028: Detected CUDA files, patching ldflags
ml-512-node-028: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-010: ninja: no work to do.
ml-512-node-028: Building extension module fused_adam...
ml-512-node-028: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-029: Time to load fused_adam op: 0.2046830654144287 seconds
ml-512-node-029: Loading extension module fused_adam...
ml-512-node-010: Time to load fused_adam op: 0.23726963996887207 seconds
ml-512-node-010: Loading extension module fused_adam...
ml-512-node-017: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-007: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-026: ninja: no work to do.
ml-512-node-026: Time to load fused_adam op: 0.38872647285461426 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-005: Detected CUDA files, patching ldflags
ml-512-node-005: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-005: Building extension module fused_adam...
ml-512-node-005: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-028: ninja: no work to do.
ml-512-node-028: Loading extension module fused_adam...
ml-512-node-028: Time to load fused_adam op: 0.13608646392822266 seconds
ml-512-node-005: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-004: ninja: no work to do.
ml-512-node-026: Time to load fused_adam op: 0.21341991424560547 seconds
ml-512-node-026: Loading extension module fused_adam...
ml-512-node-004: Loading extension module fused_adam...
ml-512-node-012: ninja: no work to do.
ml-512-node-004: Time to load fused_adam op: 0.37405920028686523 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-012: Time to load fused_adam op: 0.3549487590789795 seconds
ml-512-node-006: Detected CUDA files, patching ldflags
ml-512-node-006: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-006: Building extension module fused_adam...
ml-512-node-006: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-007: Detected CUDA files, patching ldflags
ml-512-node-007: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-007: Building extension module fused_adam...
ml-512-node-007: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-006: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Detected CUDA files, patching ldflags
ml-512-node-017: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-017: Building extension module fused_adam...
ml-512-node-017: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-012: Time to load fused_adam op: 0.20203280448913574 seconds
ml-512-node-012: Loading extension module fused_adam...
ml-512-node-005: ninja: no work to do.
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-005: Time to load fused_adam op: 0.2207491397857666 seconds
ml-512-node-024: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-005: Loading extension module fused_adam...
ml-512-node-005: Time to load fused_adam op: 0.2021927833557129 seconds
ml-512-node-006: ninja: no work to do.
ml-512-node-006: Time to load fused_adam op: 0.28431200981140137 seconds
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-006: Time to load fused_adam op: 0.10241079330444336 seconds
ml-512-node-006: Loading extension module fused_adam...
ml-512-node-007: ninja: no work to do.
ml-512-node-017: ninja: no work to do.
ml-512-node-007: Time to load fused_adam op: 0.31043124198913574 seconds
ml-512-node-007: Loading extension module fused_adam...
ml-512-node-008: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-017: Time to load fused_adam op: 0.4068760871887207 seconds
ml-512-node-017: Loading extension module fused_adam...
ml-512-node-022: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-013: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-024: Detected CUDA files, patching ldflags
ml-512-node-024: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-024: Building extension module fused_adam...
ml-512-node-024: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-022: Detected CUDA files, patching ldflags
ml-512-node-022: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-022: Building extension module fused_adam...
ml-512-node-022: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-011: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-008: Detected CUDA files, patching ldflags
ml-512-node-008: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-008: Building extension module fused_adam...
ml-512-node-008: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-023: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-021: Detected CUDA files, patching ldflags
ml-512-node-021: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-021: Building extension module fused_adam...
ml-512-node-021: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-011: Detected CUDA files, patching ldflags
ml-512-node-011: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-011: Building extension module fused_adam...
ml-512-node-011: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-008: ninja: no work to do.
ml-512-node-008: Time to load fused_adam op: 0.2736074924468994 seconds
ml-512-node-008: Loading extension module fused_adam...
ml-512-node-013: Detected CUDA files, patching ldflags
ml-512-node-013: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-013: Building extension module fused_adam...
ml-512-node-013: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-021: ninja: no work to do.
ml-512-node-021: Loading extension module fused_adam...
ml-512-node-021: Time to load fused_adam op: 0.2517118453979492 seconds
ml-512-node-024: ninja: no work to do.
ml-512-node-023: Detected CUDA files, patching ldflags
ml-512-node-023: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-023: Building extension module fused_adam...
ml-512-node-023: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-024: Loading extension module fused_adam...
ml-512-node-024: Time to load fused_adam op: 0.4723789691925049 seconds
ml-512-node-022: ninja: no work to do.
ml-512-node-016: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-023: ninja: no work to do.
ml-512-node-022: Time to load fused_adam op: 0.3835763931274414 seconds
ml-512-node-022: Loading extension module fused_adam...
ml-512-node-023: Time to load fused_adam op: 0.2830207347869873 seconds
ml-512-node-023: Loading extension module fused_adam...
ml-512-node-011: ninja: no work to do.
ml-512-node-013: ninja: no work to do.
ml-512-node-011: Loading extension module fused_adam...
ml-512-node-013: Loading extension module fused_adam...
ml-512-node-013: Time to load fused_adam op: 0.44364285469055176 seconds
ml-512-node-011: Time to load fused_adam op: 0.3407726287841797 seconds
ml-512-node-016: Detected CUDA files, patching ldflags
ml-512-node-016: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-016: Building extension module fused_adam...
ml-512-node-016: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-016: ninja: no work to do.
ml-512-node-016: Time to load fused_adam op: 0.34102630615234375 seconds
ml-512-node-016: Loading extension module fused_adam...
ml-512-node-001: [2024-07-08 07:24:25,376] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
ml-512-node-001: [2024-07-08 07:24:25,380] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
ml-512-node-001: [2024-07-08 07:24:25,380] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
ml-512-node-001: [2024-07-08 07:24:25,426] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
ml-512-node-001: [2024-07-08 07:24:25,426] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale
ml-512-node-002: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-002:   warnings.warn(
ml-512-node-025: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-025:   warnings.warn(
ml-512-node-002: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-002:   warnings.warn(
ml-512-node-004: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-004:   warnings.warn(
ml-512-node-018: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-018:   warnings.warn(
ml-512-node-022: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-022:   warnings.warn(
ml-512-node-017: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-017:   warnings.warn(
ml-512-node-019: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-019:   warnings.warn(
ml-512-node-017: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-017:   warnings.warn(
ml-512-node-030: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-030:   warnings.warn(
ml-512-node-029: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-029:   warnings.warn(
ml-512-node-007: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-007:   warnings.warn(
ml-512-node-015: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-015:   warnings.warn(
ml-512-node-014: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-014:   warnings.warn(
ml-512-node-014: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-014:   warnings.warn(
ml-512-node-014: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-014:   warnings.warn(
ml-512-node-032: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-032:   warnings.warn(
ml-512-node-016: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-016:   warnings.warn(
ml-512-node-017: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-017:   warnings.warn(
ml-512-node-031: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-031:   warnings.warn(
ml-512-node-026: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-026:   warnings.warn(
ml-512-node-015: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-015:   warnings.warn(
ml-512-node-027: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-027:   warnings.warn(
ml-512-node-027: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-027:   warnings.warn(
ml-512-node-026: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-026:   warnings.warn(
ml-512-node-032: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-032:   warnings.warn(
ml-512-node-018: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-018:   warnings.warn(
ml-512-node-010: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-017: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-010:   warnings.warn(
ml-512-node-017:   warnings.warn(
ml-512-node-013: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-013:   warnings.warn(
ml-512-node-014: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-014:   warnings.warn(
ml-512-node-005: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-005:   warnings.warn(
ml-512-node-021: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-021:   warnings.warn(
ml-512-node-002: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-002:   warnings.warn(
ml-512-node-004: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-004:   warnings.warn(
ml-512-node-013: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-013:   warnings.warn(
ml-512-node-017: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-017:   warnings.warn(
ml-512-node-024: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-024:   warnings.warn(
ml-512-node-011: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-011:   warnings.warn(
ml-512-node-032: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-032:   warnings.warn(
ml-512-node-010: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-010:   warnings.warn(
ml-512-node-012: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-012:   warnings.warn(
ml-512-node-004: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-004:   warnings.warn(
ml-512-node-012: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-012:   warnings.warn(
ml-512-node-031: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-031:   warnings.warn(
ml-512-node-009: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-015: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-009:   warnings.warn(
ml-512-node-016: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-015:   warnings.warn(
ml-512-node-016:   warnings.warn(
ml-512-node-021: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-021:   warnings.warn(
ml-512-node-025: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-025:   warnings.warn(
ml-512-node-009: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-009:   warnings.warn(
ml-512-node-008: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-008:   warnings.warn(
ml-512-node-007: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-007:   warnings.warn(
ml-512-node-031: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-031:   warnings.warn(
ml-512-node-026: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-026:   warnings.warn(
ml-512-node-031: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-031:   warnings.warn(
ml-512-node-018: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-018:   warnings.warn(
ml-512-node-021: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-021:   warnings.warn(
ml-512-node-025: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-025:   warnings.warn(
ml-512-node-016: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-016:   warnings.warn(
ml-512-node-004: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-004:   warnings.warn(
ml-512-node-003: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-003:   warnings.warn(
ml-512-node-030: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-030:   warnings.warn(
ml-512-node-019: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-019:   warnings.warn(
ml-512-node-023: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-023:   warnings.warn(
ml-512-node-023: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-023:   warnings.warn(
ml-512-node-020: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-020:   warnings.warn(
ml-512-node-019: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-019:   warnings.warn(
ml-512-node-003: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-003:   warnings.warn(
ml-512-node-003: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-003:   warnings.warn(
ml-512-node-025: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-025:   warnings.warn(
ml-512-node-005: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-005:   warnings.warn(
ml-512-node-013: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-013:   warnings.warn(
ml-512-node-017: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-017:   warnings.warn(
ml-512-node-027: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-027:   warnings.warn(
ml-512-node-030: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-030:   warnings.warn(
ml-512-node-008: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-008:   warnings.warn(
ml-512-node-010: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-010:   warnings.warn(
ml-512-node-005: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-005:   warnings.warn(
ml-512-node-009: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-009:   warnings.warn(
ml-512-node-024: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-024:   warnings.warn(
ml-512-node-003: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-003:   warnings.warn(
ml-512-node-029: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-029:   warnings.warn(
ml-512-node-008: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-008:   warnings.warn(
ml-512-node-008: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-008:   warnings.warn(
ml-512-node-032: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-032:   warnings.warn(
ml-512-node-021: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-021:   warnings.warn(
ml-512-node-008: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-008:   warnings.warn(
ml-512-node-013: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-013:   warnings.warn(
ml-512-node-003: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-003:   warnings.warn(
ml-512-node-031: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-031:   warnings.warn(
ml-512-node-010: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-010:   warnings.warn(
ml-512-node-030: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-030:   warnings.warn(
ml-512-node-011: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-011:   warnings.warn(
ml-512-node-028: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-028:   warnings.warn(
ml-512-node-019: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-019:   warnings.warn(
ml-512-node-025: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-025:   warnings.warn(
ml-512-node-020: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-020:   warnings.warn(
ml-512-node-009: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-009:   warnings.warn(
ml-512-node-015: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-015:   warnings.warn(
ml-512-node-029: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-029:   warnings.warn(
ml-512-node-006: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-006:   warnings.warn(
ml-512-node-024: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-024:   warnings.warn(
ml-512-node-026: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-026:   warnings.warn(
ml-512-node-032: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-032:   warnings.warn(
ml-512-node-020: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-020:   warnings.warn(
ml-512-node-005: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-005:   warnings.warn(
ml-512-node-003: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-003:   warnings.warn(
ml-512-node-022: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-022:   warnings.warn(
ml-512-node-022: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-022:   warnings.warn(
ml-512-node-009: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-009:   warnings.warn(
ml-512-node-013: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-013:   warnings.warn(
ml-512-node-029: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-029:   warnings.warn(
ml-512-node-011: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-011:   warnings.warn(
ml-512-node-027: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-027:   warnings.warn(
ml-512-node-012: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-012:   warnings.warn(
ml-512-node-003: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-003:   warnings.warn(
ml-512-node-018: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-018:   warnings.warn(
ml-512-node-028: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-028:   warnings.warn(
ml-512-node-023: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-023:   warnings.warn(
ml-512-node-015: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-015:   warnings.warn(
ml-512-node-031: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-031:   warnings.warn(
ml-512-node-004: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-004:   warnings.warn(
ml-512-node-031: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-031:   warnings.warn(
ml-512-node-012: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-012:   warnings.warn(
ml-512-node-010: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-010:   warnings.warn(
ml-512-node-023: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-023:   warnings.warn(
ml-512-node-018: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-018:   warnings.warn(
ml-512-node-007: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-007:   warnings.warn(
ml-512-node-006: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-006:   warnings.warn(
ml-512-node-007: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-007:   warnings.warn(
ml-512-node-016: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-016:   warnings.warn(
ml-512-node-008: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-011: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-011:   warnings.warn(
ml-512-node-008:   warnings.warn(
ml-512-node-004: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-004:   warnings.warn(
ml-512-node-027: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-027:   warnings.warn(
ml-512-node-010: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-010:   warnings.warn(
ml-512-node-003: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-003:   warnings.warn(
ml-512-node-027: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-027:   warnings.warn(
ml-512-node-028: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-028:   warnings.warn(
ml-512-node-019: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-019:   warnings.warn(
ml-512-node-021: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-021:   warnings.warn(
ml-512-node-025: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-025:   warnings.warn(
ml-512-node-030: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-030:   warnings.warn(
ml-512-node-016: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-016:   warnings.warn(
ml-512-node-005: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-005:   warnings.warn(
ml-512-node-006: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-006:   warnings.warn(
ml-512-node-016: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-016:   warnings.warn(
ml-512-node-017: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-017:   warnings.warn(
ml-512-node-002: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-002:   warnings.warn(
ml-512-node-010: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-010:   warnings.warn(
ml-512-node-020: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-020:   warnings.warn(
ml-512-node-020: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-020:   warnings.warn(
ml-512-node-013: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-013:   warnings.warn(
ml-512-node-009: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-009:   warnings.warn(
ml-512-node-026: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-026:   warnings.warn(
ml-512-node-029: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-029:   warnings.warn(
ml-512-node-026: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-026:   warnings.warn(
ml-512-node-032: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-032:   warnings.warn(
ml-512-node-006: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-006:   warnings.warn(
ml-512-node-004: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-004:   warnings.warn(
ml-512-node-028: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-028:   warnings.warn(
ml-512-node-002: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-002:   warnings.warn(
ml-512-node-019: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-019:   warnings.warn(
ml-512-node-032: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-032:   warnings.warn(
ml-512-node-022: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-022:   warnings.warn(
ml-512-node-023: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-023:   warnings.warn(
ml-512-node-030: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-030:   warnings.warn(
ml-512-node-022: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-022:   warnings.warn(
ml-512-node-015: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-015:   warnings.warn(
ml-512-node-006: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-006:   warnings.warn(
ml-512-node-008: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-008:   warnings.warn(
ml-512-node-016: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-016:   warnings.warn(
ml-512-node-025: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-025:   warnings.warn(
ml-512-node-005: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-005:   warnings.warn(
ml-512-node-006: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-006:   warnings.warn(
ml-512-node-021: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-021:   warnings.warn(
ml-512-node-007: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-007:   warnings.warn(
ml-512-node-009: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-009:   warnings.warn(
ml-512-node-006: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-006:   warnings.warn(
ml-512-node-029: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-029:   warnings.warn(
ml-512-node-010: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-010:   warnings.warn(
ml-512-node-028: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-028:   warnings.warn(
ml-512-node-007: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-007:   warnings.warn(
ml-512-node-007: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-007:   warnings.warn(
ml-512-node-012: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-012:   warnings.warn(
ml-512-node-002: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-002:   warnings.warn(
ml-512-node-026: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-026:   warnings.warn(
ml-512-node-022: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-022:   warnings.warn(
ml-512-node-013: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-013:   warnings.warn(
ml-512-node-022: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-022:   warnings.warn(
ml-512-node-018: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-018:   warnings.warn(
ml-512-node-018: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-018:   warnings.warn(
ml-512-node-004: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-004:   warnings.warn(
ml-512-node-014: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-014:   warnings.warn(
ml-512-node-014: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-014:   warnings.warn(
ml-512-node-015: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-015:   warnings.warn(
ml-512-node-024: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-024:   warnings.warn(
ml-512-node-024: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-024:   warnings.warn(
ml-512-node-024: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-024:   warnings.warn(
ml-512-node-017: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-017:   warnings.warn(
ml-512-node-015: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-015:   warnings.warn(
ml-512-node-024: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-024:   warnings.warn(
ml-512-node-014: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-014:   warnings.warn(
ml-512-node-007: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-007:   warnings.warn(
ml-512-node-019: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-019:   warnings.warn(
ml-512-node-028: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-028:   warnings.warn(
ml-512-node-011: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-011:   warnings.warn(
ml-512-node-002: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-002:   warnings.warn(
ml-512-node-023: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-023:   warnings.warn(
ml-512-node-027: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-027:   warnings.warn(
ml-512-node-019: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-019:   warnings.warn(
ml-512-node-020: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-020:   warnings.warn(
ml-512-node-021: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-021:   warnings.warn(
ml-512-node-021: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-021:   warnings.warn(
ml-512-node-005: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-005:   warnings.warn(
ml-512-node-013: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-013:   warnings.warn(
ml-512-node-028: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-028:   warnings.warn(
ml-512-node-012: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-012:   warnings.warn(
ml-512-node-014: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-014:   warnings.warn(
ml-512-node-029: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-029:   warnings.warn(
ml-512-node-002: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-002:   warnings.warn(
ml-512-node-011: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-011:   warnings.warn(
ml-512-node-022: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-022:   warnings.warn(
ml-512-node-030: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-030:   warnings.warn(
ml-512-node-023: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-023:   warnings.warn(
ml-512-node-005: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-005:   warnings.warn(
ml-512-node-032: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-032:   warnings.warn(
ml-512-node-030: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-030:   warnings.warn(
ml-512-node-025: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-025:   warnings.warn(
ml-512-node-011: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-011:   warnings.warn(
ml-512-node-023: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-023:   warnings.warn(
ml-512-node-008: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-008:   warnings.warn(
ml-512-node-006: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-006:   warnings.warn(
ml-512-node-026: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-026:   warnings.warn(
ml-512-node-028: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-028:   warnings.warn(
ml-512-node-020: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-020:   warnings.warn(
ml-512-node-031: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-031:   warnings.warn(
ml-512-node-016: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-016:   warnings.warn(
ml-512-node-024: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-024:   warnings.warn(
ml-512-node-009: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-009:   warnings.warn(
ml-512-node-011: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-011:   warnings.warn(
ml-512-node-012: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-012:   warnings.warn(
ml-512-node-029: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-029:   warnings.warn(
ml-512-node-020: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-020:   warnings.warn(
ml-512-node-027: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-027:   warnings.warn(
ml-512-node-018: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-018:   warnings.warn(
ml-512-node-012: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-012:   warnings.warn(
ml-512-node-001: [2024-07-08 07:24:26,417] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FP16_Optimizer
ml-512-node-001: [2024-07-08 07:24:26,417] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
ml-512-node-001: [2024-07-08 07:24:26,417] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x74480416f6a0>
ml-512-node-001: [2024-07-08 07:24:26,417] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:24:26,418] [INFO] [config.py:997:print] DeepSpeedEngine configuration:
ml-512-node-001: [2024-07-08 07:24:26,418] [INFO] [config.py:1001:print]   activation_checkpointing_config  {
ml-512-node-001:     "partition_activations": false, 
ml-512-node-001:     "contiguous_memory_optimization": false, 
ml-512-node-001:     "cpu_checkpointing": false, 
ml-512-node-001:     "number_checkpoints": null, 
ml-512-node-001:     "synchronize_checkpoint_boundary": false, 
ml-512-node-001:     "profile": false
ml-512-node-001: }
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   amp_enabled .................. False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   amp_params ................... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   autotuning_config ............ {
ml-512-node-001:     "enabled": false, 
ml-512-node-001:     "start_step": null, 
ml-512-node-001:     "end_step": null, 
ml-512-node-001:     "metric_path": null, 
ml-512-node-001:     "arg_mappings": null, 
ml-512-node-001:     "metric": "throughput", 
ml-512-node-001:     "model_info": null, 
ml-512-node-001:     "results_dir": "autotuning_results", 
ml-512-node-001:     "exps_dir": "autotuning_exps", 
ml-512-node-001:     "overwrite": true, 
ml-512-node-001:     "fast": true, 
ml-512-node-001:     "start_profile_step": 3, 
ml-512-node-001:     "end_profile_step": 5, 
ml-512-node-001:     "tuner_type": "gridsearch", 
ml-512-node-001:     "tuner_early_stopping": 5, 
ml-512-node-001:     "tuner_num_trials": 50, 
ml-512-node-001:     "model_info_path": null, 
ml-512-node-001:     "mp_size": 1, 
ml-512-node-001:     "max_train_batch_size": null, 
ml-512-node-001:     "min_train_batch_size": 1, 
ml-512-node-001:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
ml-512-node-001:     "min_train_micro_batch_size_per_gpu": 1, 
ml-512-node-001:     "num_tuning_micro_batch_sizes": 3
ml-512-node-001: }
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   bfloat16_enabled ............. False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   bfloat16_immediate_grad_update  False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   checkpoint_parallel_write_pipeline  False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   checkpoint_tag_validation_enabled  True
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   checkpoint_tag_validation_fail  False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x74480416c4c0>
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   communication_data_type ...... None
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   curriculum_enabled_legacy .... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   curriculum_params_legacy ..... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   data_efficiency_enabled ...... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   dataloader_drop_last ......... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   disable_allgather ............ False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   dump_state ................... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   eigenvalue_enabled ........... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   eigenvalue_gas_boundary_resolution  1
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   eigenvalue_layer_name ........ bert.encoder.layer
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   eigenvalue_layer_num ......... 0
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   eigenvalue_max_iter .......... 100
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   eigenvalue_stability ......... 1e-06
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   eigenvalue_tol ............... 0.01
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   eigenvalue_verbose ........... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   elasticity_enabled ........... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   flops_profiler_config ........ {
ml-512-node-001:     "enabled": false, 
ml-512-node-001:     "recompute_fwd_factor": 0.0, 
ml-512-node-001:     "profile_step": 1, 
ml-512-node-001:     "module_depth": -1, 
ml-512-node-001:     "top_modules": 1, 
ml-512-node-001:     "detailed": true, 
ml-512-node-001:     "output_file": null
ml-512-node-001: }
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   fp16_auto_cast ............... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   fp16_enabled ................. True
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   fp16_master_weights_and_gradients  False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   global_rank .................. 0
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   grad_accum_dtype ............. None
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   gradient_accumulation_steps .. 1
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   gradient_clipping ............ 1.0
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   gradient_predivide_factor .... 1.0
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   graph_harvesting ............. False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   initial_dynamic_scale ........ 65536
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   load_universal_checkpoint .... False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   loss_scale ................... 0
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   memory_breakdown ............. False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   mics_hierarchial_params_gather  False
ml-512-node-001: [2024-07-08 07:24:26,419] [INFO] [config.py:1001:print]   mics_shard_size .............. -1
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step1_tensorboard/ds_tensorboard_logs/', job_name='step1_model_tensorboard') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   nebula_config ................ {
ml-512-node-001:     "enabled": false, 
ml-512-node-001:     "persistent_storage_path": null, 
ml-512-node-001:     "persistent_time_interval": 100, 
ml-512-node-001:     "num_of_version_in_retention": 2, 
ml-512-node-001:     "enable_nebula_load": true, 
ml-512-node-001:     "load_path": null
ml-512-node-001: }
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   optimizer_legacy_fusion ...... False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   optimizer_name ............... None
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   optimizer_params ............. None
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   pld_enabled .................. False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   pld_params ................... False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   prescale_gradients ........... False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   scheduler_name ............... None
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   scheduler_params ............. None
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   seq_parallel_communication_data_type  torch.float32
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   sparse_attention ............. None
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   sparse_gradients_enabled ..... False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   steps_per_print .............. 10
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   timers_config ................ enabled=True synchronized=True
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   train_batch_size ............. 4096
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   train_micro_batch_size_per_gpu  16
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   use_data_before_expert_parallel_  False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   use_node_local_storage ....... False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   wall_clock_breakdown ......... False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   weight_quantization_config ... None
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   world_size ................... 256
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   zero_allow_untested_optimizer  False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   zero_enabled ................. False
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   zero_force_ds_cpu_optimizer .. True
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:1001:print]   zero_optimization_stage ...... 0
ml-512-node-001: [2024-07-08 07:24:26,420] [INFO] [config.py:987:print_user_config]   json = {
ml-512-node-001:     "train_batch_size": 4.096000e+03, 
ml-512-node-001:     "train_micro_batch_size_per_gpu": 16, 
ml-512-node-001:     "steps_per_print": 10, 
ml-512-node-001:     "zero_optimization": {
ml-512-node-001:         "stage": 0, 
ml-512-node-001:         "offload_param": {
ml-512-node-001:             "device": "none"
ml-512-node-001:         }, 
ml-512-node-001:         "offload_optimizer": {
ml-512-node-001:             "device": "none"
ml-512-node-001:         }, 
ml-512-node-001:         "stage3_param_persistence_threshold": 1.000000e+04, 
ml-512-node-001:         "stage3_max_live_parameters": 3.000000e+07, 
ml-512-node-001:         "stage3_prefetch_bucket_size": 3.000000e+07, 
ml-512-node-001:         "memory_efficient_linear": false
ml-512-node-001:     }, 
ml-512-node-001:     "fp16": {
ml-512-node-001:         "enabled": true, 
ml-512-node-001:         "loss_scale_window": 100
ml-512-node-001:     }, 
ml-512-node-001:     "gradient_clipping": 1.0, 
ml-512-node-001:     "prescale_gradients": false, 
ml-512-node-001:     "wall_clock_breakdown": false, 
ml-512-node-001:     "hybrid_engine": {
ml-512-node-001:         "enabled": false, 
ml-512-node-001:         "max_out_tokens": 512, 
ml-512-node-001:         "inference_tp_size": 1, 
ml-512-node-001:         "release_inference_cache": false, 
ml-512-node-001:         "pin_parameters": true, 
ml-512-node-001:         "tp_gather_partition_size": 8
ml-512-node-001:     }, 
ml-512-node-001:     "tensorboard": {
ml-512-node-001:         "enabled": false, 
ml-512-node-001:         "output_path": "step1_tensorboard/ds_tensorboard_logs/", 
ml-512-node-001:         "job_name": "step1_model_tensorboard"
ml-512-node-001:     }
ml-512-node-001: }
ml-512-node-001: ***** Running training *****
ml-512-node-001: Beginning of Epoch 1/100, Total Micro Batches 5
ml-512-node-001: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-001:   warnings.warn(
ml-512-node-001: /usr/lib/python3/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
ml-512-node-001:   warnings.warn(
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-016: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-016: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-016: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-016: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-009: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-020: [2024-07-08 07:24:29,600] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 07:24:29,600] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 0
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-029: Grad overflow on iteration 0
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 0
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-019: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-005: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-005: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-020: [2024-07-08 07:24:29,600] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: Grad overflow on iteration 0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-032: Grad overflow on iteration 0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-014: Grad overflow on iteration 0
ml-512-node-014: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-024: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 0
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-009: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536, reducing to 32768.0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-024: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-030: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-032: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-006: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-008: Grad overflow on iteration 0
ml-512-node-008: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 0
ml-512-node-011: Grad overflow on iteration 0
ml-512-node-011: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 0
ml-512-node-023: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-027: Grad overflow on iteration 0
ml-512-node-013: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 0
ml-512-node-027: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-013: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-017: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-028: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 0
ml-512-node-028: [2024-07-08 07:24:29,596] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 0
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-003: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-022: [2024-07-08 07:24:29,595] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 0
ml-512-node-002: Grad overflow on iteration 0
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-002: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-012: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-004: Grad overflow on iteration 0
ml-512-node-004: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-007: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-007: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-025: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-015: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 0
ml-512-node-031: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-010: Grad overflow on iteration 0
ml-512-node-010: [2024-07-08 07:24:29,597] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-018: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 0
ml-512-node-018: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-021: [2024-07-08 07:24:29,598] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 0
ml-512-node-021: [2024-07-08 07:24:29,599] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 1
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:31,324] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-024: Grad overflow on iteration 1
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-018: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-024: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 1
ml-512-node-027: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-031: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-026: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 07:24:31,324] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-026: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 1
ml-512-node-032: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 1
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-002: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 1
ml-512-node-013: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 07:24:31,324] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 07:24:31,324] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-010: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 1
ml-512-node-012: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-003: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 1
ml-512-node-003: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-030: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 1
ml-512-node-030: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 1
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-011: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-025: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 1
ml-512-node-025: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 07:24:31,324] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-005: [2024-07-08 07:24:31,324] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 1
ml-512-node-005: [2024-07-08 07:24:31,324] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 1
ml-512-node-021: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 1
ml-512-node-022: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 1
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-006: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-016: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-015: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: Grad overflow on iteration 1
ml-512-node-015: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-019: [2024-07-08 07:24:31,325] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 1
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 1
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-017: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-004: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 1
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-014: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-029: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-020: [2024-07-08 07:24:31,327] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 1
ml-512-node-023: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-028: [2024-07-08 07:24:31,323] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-007: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 1
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-009: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 1
ml-512-node-008: [2024-07-08 07:24:31,326] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-001: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-018: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-026: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: Grad overflow on iteration 2
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-011: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 2
ml-512-node-025: Grad overflow on iteration 2
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 2
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-009: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-027: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-019: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-011: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-011: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 2
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: Grad overflow on iteration 2
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-013: Grad overflow on iteration 2
ml-512-node-017: Grad overflow on iteration 2
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-017: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-002: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-032: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 2
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-022: [2024-07-08 07:24:33,060] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-007: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 2
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 2
ml-512-node-028: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 2
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-003: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: Grad overflow on iteration 2
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: [2024-07-08 07:24:33,061] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 2
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-004: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 2
ml-512-node-012: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-010: [2024-07-08 07:24:33,062] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-014: Grad overflow on iteration 2
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-015: Grad overflow on iteration 2
ml-512-node-006: Grad overflow on iteration 2
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-015: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-024: Grad overflow on iteration 2
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-014: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 2
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 2
ml-512-node-006: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 2
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: Grad overflow on iteration 2
ml-512-node-007: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-031: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: Grad overflow on iteration 2
ml-512-node-030: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-020: [2024-07-08 07:24:33,065] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: Grad overflow on iteration 2
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-016: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-024: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: Grad overflow on iteration 2
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-011: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-013: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-029: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-005: [2024-07-08 07:24:33,061] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: Grad overflow on iteration 2
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-021: [2024-07-08 07:24:33,063] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 2
ml-512-node-018: [2024-07-08 07:24:33,064] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-001: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-032: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 3
ml-512-node-032: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-014: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-003: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-008: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-001: [2024-07-08 07:24:34,797] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 3
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-006: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-026: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-002: Grad overflow on iteration 3
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 3
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-019: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-002: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 3
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-028: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-012: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-009: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 3
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-020: [2024-07-08 07:24:34,801] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 3
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 3
ml-512-node-004: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-016: Grad overflow on iteration 3
ml-512-node-016: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,796] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-022: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-022: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-010: [2024-07-08 07:24:34,798] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-014: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 3
ml-512-node-012: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 3
ml-512-node-007: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-023: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-028: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-030: Grad overflow on iteration 3
ml-512-node-024: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-030: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-031: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-031: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-024: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-021: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-021: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-018: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-005: [2024-07-08 07:24:34,797] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: Grad overflow on iteration 3
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 3
ml-512-node-029: Grad overflow on iteration 3
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-014: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-027: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-013: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: Grad overflow on iteration 3
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-017: [2024-07-08 07:24:34,800] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-029: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: Grad overflow on iteration 3
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-025: [2024-07-08 07:24:34,799] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-022: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-022: [2024-07-08 07:24:36,538] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 4
ml-512-node-028: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-014: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-001: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: [2024-07-08 07:24:36,539] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-001: Beginning of Epoch 2/100, Total Micro Batches 5
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 4
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-020: [2024-07-08 07:24:36,543] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 4
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-027: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 4
ml-512-node-018: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 4
ml-512-node-010: [2024-07-08 07:24:36,540] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: Grad overflow on iteration 4
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-024: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 4
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-016: Grad overflow on iteration 4
ml-512-node-014: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 4
ml-512-node-013: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 4
ml-512-node-008: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-019: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-021: Grad overflow on iteration 4
ml-512-node-021: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 4
ml-512-node-025: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-006: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-016: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-012: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-014: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 4
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-004: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: Grad overflow on iteration 4
ml-512-node-031: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-031: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: Grad overflow on iteration 4
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-002: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-007: Grad overflow on iteration 4
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-017: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-014: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 4
ml-512-node-011: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-014: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-014: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 4
ml-512-node-014: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 4
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 4
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-023: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 4
ml-512-node-015: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 4
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-003: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-007: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-005: [2024-07-08 07:24:36,539] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 4
ml-512-node-026: [2024-07-08 07:24:36,542] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-029: [2024-07-08 07:24:36,541] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-032: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 5
ml-512-node-032: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 2048.0, reducing to 1024.0
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-001: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-003: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 5
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-003: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 5
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-005: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-015: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-029: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-012: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-004: Grad overflow on iteration 5
ml-512-node-004: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 5
ml-512-node-030: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-012: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: Grad overflow on iteration 5
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-017: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 5
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-021: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 5
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-008: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: Grad overflow on iteration 5
ml-512-node-024: Grad overflow on iteration 5
ml-512-node-027: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-010: [2024-07-08 07:24:38,279] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-016: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 5
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-024: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 5
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-002: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-022: [2024-07-08 07:24:38,277] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 5
ml-512-node-022: [2024-07-08 07:24:38,278] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 5
ml-512-node-018: Grad overflow on iteration 5
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-018: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-006: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 5
ml-512-node-009: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-006: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 5
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-020: [2024-07-08 07:24:38,282] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-026: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-031: Grad overflow on iteration 5
ml-512-node-031: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-014: [2024-07-08 07:24:38,280] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 5
ml-512-node-014: [2024-07-08 07:24:38,281] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 6
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 6
ml-512-node-019: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-025: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-025: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-025: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:40,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-025: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 6
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-032: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 6
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-001: [2024-07-08 07:24:40,021] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 1024.0, reducing to 512.0
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-005: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-013: Grad overflow on iteration 6
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-013: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-005: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-005: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-025: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-005: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-005: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-025: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 6
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-018: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-025: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: Grad overflow on iteration 6
ml-512-node-002: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-009: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-017: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: Grad overflow on iteration 6
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-022: Grad overflow on iteration 6
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-017: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-017: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-017: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-017: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-010: Grad overflow on iteration 6
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-022: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-029: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-012: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-014: Grad overflow on iteration 6
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: Grad overflow on iteration 6
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-021: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 07:24:40,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 07:24:40,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 07:24:40,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-017: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 07:24:40,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 6
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-031: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 07:24:40,022] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: Grad overflow on iteration 6
ml-512-node-005: Grad overflow on iteration 6
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 07:24:40,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-005: [2024-07-08 07:24:40,022] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 6
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-015: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 6
ml-512-node-020: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-026: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-024: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 6
ml-512-node-008: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: Grad overflow on iteration 6
ml-512-node-023: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-002: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-030: Grad overflow on iteration 6
ml-512-node-030: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-015: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-016: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 6
ml-512-node-028: [2024-07-08 07:24:40,021] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-011: Grad overflow on iteration 6
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 6
ml-512-node-026: [2024-07-08 07:24:40,025] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-007: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: Grad overflow on iteration 6
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-003: [2024-07-08 07:24:40,023] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-006: Grad overflow on iteration 6
ml-512-node-006: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 6
ml-512-node-027: [2024-07-08 07:24:40,024] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 7
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-004: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 7
ml-512-node-032: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 7
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 7
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-008: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 7
ml-512-node-002: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: Grad overflow on iteration 7
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-028: Grad overflow on iteration 7
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-028: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-031: Grad overflow on iteration 7
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-011: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-031: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-011: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-005: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-006: Grad overflow on iteration 7
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-030: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-030: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-025: Grad overflow on iteration 7
ml-512-node-025: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: Grad overflow on iteration 7
ml-512-node-007: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: Grad overflow on iteration 7
ml-512-node-007: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-006: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 7
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-014: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-027: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-020: Grad overflow on iteration 7
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:41,765] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: Grad overflow on iteration 7
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-019: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-027: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 7
ml-512-node-029: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 7
ml-512-node-022: Grad overflow on iteration 7
ml-512-node-023: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-021: Grad overflow on iteration 7
ml-512-node-001: Grad overflow on iteration 7
ml-512-node-023: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:41,760] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: Grad overflow on iteration 7
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-018: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-012: Grad overflow on iteration 7
ml-512-node-012: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 512.0, reducing to 256.0
ml-512-node-021: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-016: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-001: [2024-07-08 07:24:41,761] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-010: Grad overflow on iteration 7
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:41,762] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: Grad overflow on iteration 7
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-015: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: Grad overflow on iteration 7
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-003: [2024-07-08 07:24:41,763] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-026: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-009: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 7
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-017: [2024-07-08 07:24:41,764] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-032: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-032: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 8
ml-512-node-032: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 8
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 8
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-023: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-018: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-003: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 8
ml-512-node-003: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 8
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-007: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-008: Grad overflow on iteration 8
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 8
ml-512-node-021: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: Grad overflow on iteration 8
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 8
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-009: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-006: Grad overflow on iteration 8
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-019: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-017: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-021: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-002: Grad overflow on iteration 8
ml-512-node-002: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 8
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-029: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: Grad overflow on iteration 8
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-026: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 8
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-001: [2024-07-08 07:24:43,507] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 256.0, reducing to 128.0
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 8
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-028: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-030: Grad overflow on iteration 8
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-030: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: Grad overflow on iteration 8
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 8
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-014: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: Grad overflow on iteration 8
ml-512-node-006: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-028: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-013: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-022: [2024-07-08 07:24:43,507] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 8
ml-512-node-027: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: Grad overflow on iteration 8
ml-512-node-012: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-025: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 8
ml-512-node-031: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-020: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 8
ml-512-node-015: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:43,511] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-005: Grad overflow on iteration 8
ml-512-node-024: Grad overflow on iteration 8
ml-512-node-005: [2024-07-08 07:24:43,508] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-024: [2024-07-08 07:24:43,509] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 8
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-011: [2024-07-08 07:24:43,510] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-006: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:45,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-009: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-006: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 9
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-025: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-025: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-025: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-019: Grad overflow on iteration 9
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-019: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 9
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-011: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 9
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-028: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 9
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-007: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-018: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 9
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 9
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-032: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-017: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-017: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 128.0, reducing to 64.0
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-024: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-001: Grad overflow on iteration 9
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,251] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 9
ml-512-node-001: [2024-07-08 07:24:45,251] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=10, lr=[0.0, 0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-004: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-010: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 9
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 9
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-031: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 9
ml-512-node-014: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 9
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-029: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-026: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-006: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: [2024-07-08 07:24:45,251] [INFO] [timer.py:258:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=2353.7827785158142, CurrSamplesPerSec=2350.70182037108, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-001: Beginning of Epoch 3/100, Total Micro Batches 5
ml-512-node-026: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 9
ml-512-node-023: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 9
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-012: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-030: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-030: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-008: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-008: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:45,252] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-005: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:45,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: Grad overflow on iteration 9
ml-512-node-005: [2024-07-08 07:24:45,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:45,251] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-022: [2024-07-08 07:24:45,250] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-020: Grad overflow on iteration 9
ml-512-node-020: [2024-07-08 07:24:45,254] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-015: [2024-07-08 07:24:45,253] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 10
ml-512-node-004: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-032: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 10
ml-512-node-032: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-002: Grad overflow on iteration 10
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 10
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-022: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-008: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-002: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-005: Grad overflow on iteration 10
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-027: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-005: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 10
ml-512-node-013: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 10
ml-512-node-030: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-027: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-031: Grad overflow on iteration 10
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 10
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 10
ml-512-node-029: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 10
ml-512-node-007: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 10
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-003: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 10
ml-512-node-025: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-025: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 10
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 10
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-031: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 10
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-021: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: Grad overflow on iteration 10
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-006: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: Grad overflow on iteration 10
ml-512-node-006: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-016: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 10
ml-512-node-028: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-011: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-020: [2024-07-08 07:24:46,994] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-017: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 10
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 10
ml-512-node-023: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-014: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 10
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: Grad overflow on iteration 10
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-019: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-001: [2024-07-08 07:24:46,990] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 64.0, reducing to 32.0
ml-512-node-012: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-010: [2024-07-08 07:24:46,991] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 10
ml-512-node-010: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-015: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 10
ml-512-node-015: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-026: Grad overflow on iteration 10
ml-512-node-026: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-018: [2024-07-08 07:24:46,993] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 10
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-024: [2024-07-08 07:24:46,992] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 11
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-009: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 11
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-010: [2024-07-08 07:24:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-013: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 11
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-027: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 11
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-005: [2024-07-08 07:24:48,725] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 11
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-019: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-010: [2024-07-08 07:24:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-006: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-004: Grad overflow on iteration 11
ml-512-node-017: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-003: Grad overflow on iteration 11
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-002: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-017: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-002: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-002: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-004: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-010: [2024-07-08 07:24:48,725] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-032: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 11
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 11
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-014: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 11
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-010: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: Grad overflow on iteration 11
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-022: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-011: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-031: Grad overflow on iteration 11
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-031: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32.0, reducing to 16.0
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-030: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-030: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 11
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-024: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: Grad overflow on iteration 11
ml-512-node-012: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-015: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-025: [2024-07-08 07:24:48,726] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 11
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-018: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-026: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-006: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-026: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 11
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-026: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-016: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-025: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-023: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 11
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-021: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-028: [2024-07-08 07:24:48,724] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 11
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-008: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 11
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-007: [2024-07-08 07:24:48,727] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-020: [2024-07-08 07:24:48,728] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16.0, reducing to 8.0
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 12
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-001: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-023: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-030: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-023: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 12
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 12
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-004: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-025: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: Grad overflow on iteration 12
ml-512-node-015: Grad overflow on iteration 12
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-030: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-015: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-006: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: Grad overflow on iteration 12
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-013: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 12
ml-512-node-032: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 12
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 12
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-029: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-021: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 12
ml-512-node-007: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-016: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-027: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-009: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 12
ml-512-node-022: [2024-07-08 07:24:50,462] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-027: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 12
ml-512-node-017: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-024: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-029: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 12
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 12
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-005: [2024-07-08 07:24:50,463] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: Grad overflow on iteration 12
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-019: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 12
ml-512-node-009: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 12
ml-512-node-026: [2024-07-08 07:24:50,466] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-003: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: Grad overflow on iteration 12
ml-512-node-018: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-011: Grad overflow on iteration 12
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-018: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-011: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-010: [2024-07-08 07:24:50,464] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 12
ml-512-node-002: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 12
ml-512-node-014: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-031: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-012: [2024-07-08 07:24:50,465] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-001: Beginning of Epoch 4/100, Total Micro Batches 5
ml-512-node-001: [2024-07-08 07:25:03,190] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=13, lr=[7e-11, 0.00035, 7e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:25:03,200] [INFO] [timer.py:258:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=2314.1079539580605, CurrSamplesPerSec=2281.301969928546, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-001: Beginning of Epoch 5/100, Total Micro Batches 5
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 21
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 21
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 21
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 21
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 21
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 21
ml-512-node-030: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 21
ml-512-node-030: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 21
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-030: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 21
ml-512-node-030: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 21
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 21
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 21
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-030: Grad overflow on iteration 21
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: Grad overflow on iteration 21
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 21
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: Grad overflow on iteration 21
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 21
ml-512-node-023: Grad overflow on iteration 21
ml-512-node-010: Grad overflow on iteration 21
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: Grad overflow on iteration 21
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 21
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 21
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 21
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-008: Grad overflow on iteration 21
ml-512-node-013: Grad overflow on iteration 21
ml-512-node-025: Grad overflow on iteration 21
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 21
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 21
ml-512-node-021: Grad overflow on iteration 21
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 21
ml-512-node-020: Grad overflow on iteration 21
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 21
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: Grad overflow on iteration 21
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 21
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 21
ml-512-node-006: Grad overflow on iteration 21
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 21
ml-512-node-019: Grad overflow on iteration 21
ml-512-node-022: Grad overflow on iteration 21
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: Grad overflow on iteration 21
ml-512-node-009: Grad overflow on iteration 21
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 21
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 21
ml-512-node-003: Grad overflow on iteration 21
ml-512-node-003: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 21
ml-512-node-003: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 21
ml-512-node-003: Grad overflow on iteration 21
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 21
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 21
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: Grad overflow on iteration 21
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 21
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 21
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 21
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 21
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 21
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 21
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 21
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 21
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-010: Grad overflow on iteration 21
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-010: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: Grad overflow on iteration 21
ml-512-node-015: Grad overflow on iteration 21
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: Grad overflow on iteration 21
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-030: Grad overflow on iteration 21
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 21
ml-512-node-024: Grad overflow on iteration 21
ml-512-node-026: Grad overflow on iteration 21
ml-512-node-005: Grad overflow on iteration 21
ml-512-node-002: Grad overflow on iteration 21
ml-512-node-030: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: Grad overflow on iteration 21
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 21
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 21
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: Grad overflow on iteration 21
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: Grad overflow on iteration 21
ml-512-node-027: Grad overflow on iteration 21
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: Grad overflow on iteration 21
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 21
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 21
ml-512-node-007: Grad overflow on iteration 21
ml-512-node-004: Grad overflow on iteration 21
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: Grad overflow on iteration 21
ml-512-node-008: Grad overflow on iteration 21
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: Grad overflow on iteration 21
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 21
ml-512-node-008: Grad overflow on iteration 21
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 21
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 21
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: Grad overflow on iteration 21
ml-512-node-004: Grad overflow on iteration 21
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 21
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 21
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 21
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 21
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 21
ml-512-node-009: Grad overflow on iteration 21
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 21
ml-512-node-012: Grad overflow on iteration 21
ml-512-node-014: Grad overflow on iteration 21
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: Grad overflow on iteration 21
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: Grad overflow on iteration 21
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: Grad overflow on iteration 21
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 21
ml-512-node-016: Grad overflow on iteration 21
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 21
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 21
ml-512-node-017: Grad overflow on iteration 21
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: Grad overflow on iteration 21
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 21
ml-512-node-003: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: Grad overflow on iteration 21
ml-512-node-027: Grad overflow on iteration 21
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 21
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 21
ml-512-node-013: Grad overflow on iteration 21
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: Grad overflow on iteration 21
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 21
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: Grad overflow on iteration 21
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: Grad overflow on iteration 21
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-014: Grad overflow on iteration 21
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: Grad overflow on iteration 21
ml-512-node-022: Grad overflow on iteration 21
ml-512-node-017: Grad overflow on iteration 21
ml-512-node-019: Grad overflow on iteration 21
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 21
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 21
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 21
ml-512-node-017: Grad overflow on iteration 21
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 21
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 21
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: Grad overflow on iteration 21
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: Grad overflow on iteration 21
ml-512-node-023: Grad overflow on iteration 21
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 21
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-023: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-014: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-022: Grad overflow on iteration 21
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 21
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-022: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: Grad overflow on iteration 21
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: Grad overflow on iteration 21
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: Grad overflow on iteration 21
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 21
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: Grad overflow on iteration 21
ml-512-node-011: Grad overflow on iteration 21
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 21
ml-512-node-023: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: Grad overflow on iteration 21
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-023: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 21
ml-512-node-023: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: Grad overflow on iteration 21
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 21
ml-512-node-013: Grad overflow on iteration 21
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-017: Grad overflow on iteration 21
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 21
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: Grad overflow on iteration 21
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 21
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 21
ml-512-node-003: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: Grad overflow on iteration 21
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: Grad overflow on iteration 21
ml-512-node-025: Grad overflow on iteration 21
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 21
ml-512-node-006: Grad overflow on iteration 21
ml-512-node-015: Grad overflow on iteration 21
ml-512-node-003: Grad overflow on iteration 21
ml-512-node-021: Grad overflow on iteration 21
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-015: Grad overflow on iteration 21
ml-512-node-001: Grad overflow on iteration 21
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: Grad overflow on iteration 21
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-015: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-020: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: Grad overflow on iteration 21
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: Grad overflow on iteration 21
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 21
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8.0, reducing to 4.0
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-023: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: Grad overflow on iteration 21
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: Grad overflow on iteration 21
ml-512-node-023: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 21
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 21
ml-512-node-031: Grad overflow on iteration 21
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: Grad overflow on iteration 21
ml-512-node-031: Grad overflow on iteration 21
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 21
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: Grad overflow on iteration 21
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: Grad overflow on iteration 21
ml-512-node-026: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 21
ml-512-node-026: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 21
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 21
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-008: Grad overflow on iteration 21
ml-512-node-017: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: Grad overflow on iteration 21
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 21
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: Grad overflow on iteration 21
ml-512-node-012: Grad overflow on iteration 21
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-012: Grad overflow on iteration 21
ml-512-node-012: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-004: Grad overflow on iteration 21
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 21
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: Grad overflow on iteration 21
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 21
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: Grad overflow on iteration 21
ml-512-node-016: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-016: Grad overflow on iteration 21
ml-512-node-016: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-005: Grad overflow on iteration 21
ml-512-node-021: Grad overflow on iteration 21
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 21
ml-512-node-021: Grad overflow on iteration 21
ml-512-node-031: Grad overflow on iteration 21
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-021: Grad overflow on iteration 21
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-021: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-031: Grad overflow on iteration 21
ml-512-node-029: Grad overflow on iteration 21
ml-512-node-002: Grad overflow on iteration 21
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 21
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-031: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 21
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-004: Grad overflow on iteration 21
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: Grad overflow on iteration 21
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: Grad overflow on iteration 21
ml-512-node-002: Grad overflow on iteration 21
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 21
ml-512-node-004: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-008: Grad overflow on iteration 21
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: Grad overflow on iteration 21
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-006: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: Grad overflow on iteration 21
ml-512-node-011: Grad overflow on iteration 21
ml-512-node-001: Grad overflow on iteration 21
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: Grad overflow on iteration 21
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-027: Grad overflow on iteration 21
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 21
ml-512-node-003: Grad overflow on iteration 21
ml-512-node-027: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: Grad overflow on iteration 21
ml-512-node-029: Grad overflow on iteration 21
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-029: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: Grad overflow on iteration 21
ml-512-node-018: Grad overflow on iteration 21
ml-512-node-028: Grad overflow on iteration 21
ml-512-node-005: Grad overflow on iteration 21
ml-512-node-019: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: Grad overflow on iteration 21
ml-512-node-001: Grad overflow on iteration 21
ml-512-node-025: Grad overflow on iteration 21
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-009: Grad overflow on iteration 21
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-018: Grad overflow on iteration 21
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-009: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 21
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: Grad overflow on iteration 21
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: Grad overflow on iteration 21
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: Grad overflow on iteration 21
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-024: Grad overflow on iteration 21
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-011: Grad overflow on iteration 21
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: Grad overflow on iteration 21
ml-512-node-003: Grad overflow on iteration 21
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-019: Grad overflow on iteration 21
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-011: Grad overflow on iteration 21
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: Grad overflow on iteration 21
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 21
ml-512-node-011: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: Grad overflow on iteration 21
ml-512-node-024: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 21
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 21
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: Grad overflow on iteration 21
ml-512-node-007: Grad overflow on iteration 21
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-007: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-019: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-018: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-001: Grad overflow on iteration 21
ml-512-node-001: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: Grad overflow on iteration 21
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-026: Grad overflow on iteration 21
ml-512-node-026: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: Grad overflow on iteration 21
ml-512-node-003: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: [2024-07-08 07:25:06,737] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-003: Grad overflow on iteration 21
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-003: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: Grad overflow on iteration 21
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-005: [2024-07-08 07:25:06,736] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 21
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-032: Grad overflow on iteration 21
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: Grad overflow on iteration 21
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-002: Grad overflow on iteration 21
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-008: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: Grad overflow on iteration 21
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-028: [2024-07-08 07:25:06,735] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: Grad overflow on iteration 21
ml-512-node-013: Grad overflow on iteration 21
ml-512-node-032: [2024-07-08 07:25:06,739] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-013: Grad overflow on iteration 21
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-002: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-025: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-013: [2024-07-08 07:25:06,738] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8.0 to 4.0
ml-512-node-001: Beginning of Epoch 6/100, Total Micro Batches 5
ml-512-node-001: [2024-07-08 07:25:21,036] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=14, lr=[9.996300896035338e-11, 0.0004998150448017669, 9.996300896035338e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:25:21,046] [INFO] [timer.py:258:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=2307.7379028222226, CurrSamplesPerSec=2295.213332752623, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-001: Beginning of Epoch 7/100, Total Micro Batches 5
ml-512-node-001: Beginning of Epoch 8/100, Total Micro Batches 5
ml-512-node-001: [2024-07-08 07:25:38,845] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=14, lr=[9.973715078832288e-11, 0.0004986857539416143, 9.973715078832288e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:25:38,855] [INFO] [timer.py:258:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=2306.0049519646936, CurrSamplesPerSec=2301.6992221590745, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-001: Beginning of Epoch 9/100, Total Micro Batches 5
ml-512-node-001: Beginning of Epoch 10/100, Total Micro Batches 5
ml-512-node-001: [2024-07-08 07:25:56,613] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=14, lr=[9.930691199511774e-11, 0.0004965345599755888, 9.930691199511774e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:25:56,623] [INFO] [timer.py:258:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=2306.128406813724, CurrSamplesPerSec=2309.2230754703664, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-001: Beginning of Epoch 11/100, Total Micro Batches 5
ml-512-node-001: Beginning of Epoch 12/100, Total Micro Batches 5
ml-512-node-001: [2024-07-08 07:26:14,357] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=14, lr=[9.867406052422525e-11, 0.0004933703026211262, 9.867406052422525e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:26:14,367] [INFO] [timer.py:258:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=2306.7240793681917, CurrSamplesPerSec=2298.906898111349, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-001: Beginning of Epoch 13/100, Total Micro Batches 5
ml-512-node-001: Beginning of Epoch 14/100, Total Micro Batches 5
ml-512-node-001: [2024-07-08 07:26:32,127] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=14, lr=[9.784119689808544e-11, 0.0004892059844904272, 9.784119689808544e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:26:32,137] [INFO] [timer.py:258:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=2306.6471659116924, CurrSamplesPerSec=2298.4421693231625, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-001: Beginning of Epoch 15/100, Total Micro Batches 5
ml-512-node-001: Beginning of Epoch 16/100, Total Micro Batches 5
ml-512-node-001: [2024-07-08 07:26:50,010] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=14, lr=[9.681174353198687e-11, 0.0004840587176599343, 9.681174353198687e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:26:50,020] [INFO] [timer.py:258:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=2304.723100852186, CurrSamplesPerSec=2282.192029456708, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-001: Beginning of Epoch 17/100, Total Micro Batches 5
ml-512-node-001: Beginning of Epoch 18/100, Total Micro Batches 5
ml-512-node-001: [2024-07-08 07:27:07,914] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=14, lr=[9.558993067062784e-11, 0.00047794965335313925, 9.558993067062784e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:27:07,924] [INFO] [timer.py:258:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=2302.916403118734, CurrSamplesPerSec=2289.7589662472565, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-001: Beginning of Epoch 19/100, Total Micro Batches 5
ml-512-node-001: Beginning of Epoch 20/100, Total Micro Batches 5
ml-512-node-001: [2024-07-08 07:27:25,827] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=14, lr=[9.418077900513376e-11, 0.0004709038950256688, 9.418077900513376e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:27:25,837] [INFO] [timer.py:258:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=2301.3603410768737, CurrSamplesPerSec=2285.5694702001647, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-001: Beginning of Epoch 21/100, Total Micro Batches 5
ml-512-node-001: Beginning of Epoch 22/100, Total Micro Batches 5
ml-512-node-001: [2024-07-08 07:27:43,763] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=14, lr=[9.259007904196022e-11, 0.0004629503952098011, 9.259007904196022e-11], mom=[(0.9, 0.95), (0.9, 0.95), (0.9, 0.95)]
ml-512-node-001: [2024-07-08 07:27:43,773] [INFO] [timer.py:258:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=2299.825933186107, CurrSamplesPerSec=2287.1279623225414, MemAllocated=33.95GB, MaxMemAllocated=40.72GB
ml-512-node-001: ======================================================================
ml-512-node-001: Execution time: 178.5198 seconds for 100 steps
ml-512-node-001: Throughput: 2294.4230 samples/sec
ml-512-node-001: [2024-07-08 07:27:47,874] [INFO] [launch.py:351:main] Process 2031566 exits successfully.
ml-512-node-001: [2024-07-08 07:27:47,874] [INFO] [launch.py:351:main] Process 2031568 exits successfully.
ml-512-node-004: [2024-07-08 07:27:48,008] [INFO] [launch.py:351:main] Process 1094650 exits successfully.
ml-512-node-004: [2024-07-08 07:27:48,008] [INFO] [launch.py:351:main] Process 1094652 exits successfully.
ml-512-node-004: [2024-07-08 07:27:48,008] [INFO] [launch.py:351:main] Process 1094645 exits successfully.
ml-512-node-004: [2024-07-08 07:27:48,009] [INFO] [launch.py:351:main] Process 1094649 exits successfully.
ml-512-node-007: [2024-07-08 07:27:48,014] [INFO] [launch.py:351:main] Process 1099576 exits successfully.
ml-512-node-007: [2024-07-08 07:27:48,015] [INFO] [launch.py:351:main] Process 1099575 exits successfully.
ml-512-node-007: [2024-07-08 07:27:48,015] [INFO] [launch.py:351:main] Process 1099579 exits successfully.
ml-512-node-006: [2024-07-08 07:27:48,081] [INFO] [launch.py:351:main] Process 1094225 exits successfully.
ml-512-node-006: [2024-07-08 07:27:48,081] [INFO] [launch.py:351:main] Process 1094226 exits successfully.
ml-512-node-006: [2024-07-08 07:27:48,081] [INFO] [launch.py:351:main] Process 1094228 exits successfully.
ml-512-node-016: [2024-07-08 07:27:48,091] [INFO] [launch.py:351:main] Process 1089900 exits successfully.
ml-512-node-016: [2024-07-08 07:27:48,091] [INFO] [launch.py:351:main] Process 1089899 exits successfully.
ml-512-node-016: [2024-07-08 07:27:48,091] [INFO] [launch.py:351:main] Process 1089895 exits successfully.
ml-512-node-016: [2024-07-08 07:27:48,091] [INFO] [launch.py:351:main] Process 1089894 exits successfully.
ml-512-node-008: [2024-07-08 07:27:48,104] [INFO] [launch.py:351:main] Process 1093125 exits successfully.
ml-512-node-008: [2024-07-08 07:27:48,104] [INFO] [launch.py:351:main] Process 1093123 exits successfully.
ml-512-node-008: [2024-07-08 07:27:48,104] [INFO] [launch.py:351:main] Process 1093127 exits successfully.
ml-512-node-008: [2024-07-08 07:27:48,104] [INFO] [launch.py:351:main] Process 1093128 exits successfully.
ml-512-node-008: [2024-07-08 07:27:48,104] [INFO] [launch.py:351:main] Process 1093126 exits successfully.
ml-512-node-026: [2024-07-08 07:27:48,120] [INFO] [launch.py:351:main] Process 1087992 exits successfully.
ml-512-node-026: [2024-07-08 07:27:48,120] [INFO] [launch.py:351:main] Process 1087990 exits successfully.
ml-512-node-026: [2024-07-08 07:27:48,120] [INFO] [launch.py:351:main] Process 1087988 exits successfully.
ml-512-node-026: [2024-07-08 07:27:48,120] [INFO] [launch.py:351:main] Process 1087994 exits successfully.
ml-512-node-026: [2024-07-08 07:27:48,120] [INFO] [launch.py:351:main] Process 1087987 exits successfully.
ml-512-node-027: [2024-07-08 07:27:48,126] [INFO] [launch.py:351:main] Process 1098565 exits successfully.
ml-512-node-027: [2024-07-08 07:27:48,126] [INFO] [launch.py:351:main] Process 1098564 exits successfully.
ml-512-node-027: [2024-07-08 07:27:48,126] [INFO] [launch.py:351:main] Process 1098562 exits successfully.
ml-512-node-027: [2024-07-08 07:27:48,126] [INFO] [launch.py:351:main] Process 1098560 exits successfully.
ml-512-node-027: [2024-07-08 07:27:48,126] [INFO] [launch.py:351:main] Process 1098566 exits successfully.
ml-512-node-027: [2024-07-08 07:27:48,126] [INFO] [launch.py:351:main] Process 1098559 exits successfully.
ml-512-node-003: [2024-07-08 07:27:48,139] [INFO] [launch.py:351:main] Process 1098698 exits successfully.
ml-512-node-003: [2024-07-08 07:27:48,140] [INFO] [launch.py:351:main] Process 1098695 exits successfully.
ml-512-node-003: [2024-07-08 07:27:48,140] [INFO] [launch.py:351:main] Process 1098699 exits successfully.
ml-512-node-003: [2024-07-08 07:27:48,140] [INFO] [launch.py:351:main] Process 1098701 exits successfully.
ml-512-node-018: [2024-07-08 07:27:48,144] [INFO] [launch.py:351:main] Process 1090765 exits successfully.
ml-512-node-018: [2024-07-08 07:27:48,145] [INFO] [launch.py:351:main] Process 1090766 exits successfully.
ml-512-node-018: [2024-07-08 07:27:48,145] [INFO] [launch.py:351:main] Process 1090764 exits successfully.
ml-512-node-018: [2024-07-08 07:27:48,145] [INFO] [launch.py:351:main] Process 1090762 exits successfully.
ml-512-node-018: [2024-07-08 07:27:48,145] [INFO] [launch.py:351:main] Process 1090761 exits successfully.
ml-512-node-022: [2024-07-08 07:27:48,146] [INFO] [launch.py:351:main] Process 1088972 exits successfully.
ml-512-node-022: [2024-07-08 07:27:48,146] [INFO] [launch.py:351:main] Process 1088970 exits successfully.
ml-512-node-022: [2024-07-08 07:27:48,146] [INFO] [launch.py:351:main] Process 1088976 exits successfully.
ml-512-node-022: [2024-07-08 07:27:48,146] [INFO] [launch.py:351:main] Process 1088973 exits successfully.
ml-512-node-022: [2024-07-08 07:27:48,146] [INFO] [launch.py:351:main] Process 1088977 exits successfully.
ml-512-node-028: [2024-07-08 07:27:48,158] [INFO] [launch.py:351:main] Process 1088236 exits successfully.
ml-512-node-028: [2024-07-08 07:27:48,158] [INFO] [launch.py:351:main] Process 1088233 exits successfully.
ml-512-node-028: [2024-07-08 07:27:48,158] [INFO] [launch.py:351:main] Process 1088231 exits successfully.
ml-512-node-028: [2024-07-08 07:27:48,159] [INFO] [launch.py:351:main] Process 1088237 exits successfully.
ml-512-node-028: [2024-07-08 07:27:48,159] [INFO] [launch.py:351:main] Process 1088232 exits successfully.
ml-512-node-028: [2024-07-08 07:27:48,159] [INFO] [launch.py:351:main] Process 1088234 exits successfully.
ml-512-node-010: [2024-07-08 07:27:48,195] [INFO] [launch.py:351:main] Process 1090804 exits successfully.
ml-512-node-010: [2024-07-08 07:27:48,196] [INFO] [launch.py:351:main] Process 1090802 exits successfully.
ml-512-node-010: [2024-07-08 07:27:48,196] [INFO] [launch.py:351:main] Process 1090806 exits successfully.
ml-512-node-010: [2024-07-08 07:27:48,196] [INFO] [launch.py:351:main] Process 1090801 exits successfully.
ml-512-node-010: [2024-07-08 07:27:48,196] [INFO] [launch.py:351:main] Process 1090799 exits successfully.
ml-512-node-002: [2024-07-08 07:27:48,201] [INFO] [launch.py:351:main] Process 1106375 exits successfully.
ml-512-node-002: [2024-07-08 07:27:48,202] [INFO] [launch.py:351:main] Process 1106370 exits successfully.
ml-512-node-002: [2024-07-08 07:27:48,202] [INFO] [launch.py:351:main] Process 1106371 exits successfully.
ml-512-node-002: [2024-07-08 07:27:48,202] [INFO] [launch.py:351:main] Process 1106369 exits successfully.
ml-512-node-017: [2024-07-08 07:27:48,240] [INFO] [launch.py:351:main] Process 1098966 exits successfully.
ml-512-node-017: [2024-07-08 07:27:48,240] [INFO] [launch.py:351:main] Process 1098970 exits successfully.
ml-512-node-017: [2024-07-08 07:27:48,240] [INFO] [launch.py:351:main] Process 1098972 exits successfully.
ml-512-node-017: [2024-07-08 07:27:48,240] [INFO] [launch.py:351:main] Process 1098971 exits successfully.
ml-512-node-017: [2024-07-08 07:27:48,240] [INFO] [launch.py:351:main] Process 1098967 exits successfully.
ml-512-node-017: [2024-07-08 07:27:48,241] [INFO] [launch.py:351:main] Process 1098973 exits successfully.
ml-512-node-032: [2024-07-08 07:27:48,244] [INFO] [launch.py:351:main] Process 1083826 exits successfully.
ml-512-node-009: [2024-07-08 07:27:48,837] [INFO] [launch.py:351:main] Process 1096806 exits successfully.
ml-512-node-009: [2024-07-08 07:27:48,837] [INFO] [launch.py:351:main] Process 1096803 exits successfully.
ml-512-node-009: [2024-07-08 07:27:48,837] [INFO] [launch.py:351:main] Process 1096804 exits successfully.
ml-512-node-001: [2024-07-08 07:27:48,875] [INFO] [launch.py:351:main] Process 2031570 exits successfully.
ml-512-node-001: [2024-07-08 07:27:48,875] [INFO] [launch.py:351:main] Process 2031569 exits successfully.
ml-512-node-001: [2024-07-08 07:27:48,876] [INFO] [launch.py:351:main] Process 2031567 exits successfully.
ml-512-node-001: [2024-07-08 07:27:48,876] [INFO] [launch.py:351:main] Process 2031565 exits successfully.
ml-512-node-001: [2024-07-08 07:27:48,876] [INFO] [launch.py:351:main] Process 2031571 exits successfully.
ml-512-node-001: [2024-07-08 07:27:48,876] [INFO] [launch.py:351:main] Process 2031564 exits successfully.
ml-512-node-005: [2024-07-08 07:27:48,924] [INFO] [launch.py:351:main] Process 1112899 exits successfully.
ml-512-node-005: [2024-07-08 07:27:48,924] [INFO] [launch.py:351:main] Process 1112896 exits successfully.
ml-512-node-005: [2024-07-08 07:27:48,924] [INFO] [launch.py:351:main] Process 1112894 exits successfully.
ml-512-node-005: [2024-07-08 07:27:48,924] [INFO] [launch.py:351:main] Process 1112895 exits successfully.
ml-512-node-005: [2024-07-08 07:27:48,924] [INFO] [launch.py:351:main] Process 1112893 exits successfully.
ml-512-node-004: [2024-07-08 07:27:49,010] [INFO] [launch.py:351:main] Process 1094646 exits successfully.
ml-512-node-004: [2024-07-08 07:27:49,010] [INFO] [launch.py:351:main] Process 1094651 exits successfully.
ml-512-node-004: [2024-07-08 07:27:49,010] [INFO] [launch.py:351:main] Process 1094648 exits successfully.
ml-512-node-004: [2024-07-08 07:27:49,010] [INFO] [launch.py:351:main] Process 1094647 exits successfully.
ml-512-node-007: [2024-07-08 07:27:49,016] [INFO] [launch.py:351:main] Process 1099578 exits successfully.
ml-512-node-007: [2024-07-08 07:27:49,016] [INFO] [launch.py:351:main] Process 1099577 exits successfully.
ml-512-node-007: [2024-07-08 07:27:49,016] [INFO] [launch.py:351:main] Process 1099573 exits successfully.
ml-512-node-007: [2024-07-08 07:27:49,016] [INFO] [launch.py:351:main] Process 1099574 exits successfully.
ml-512-node-007: [2024-07-08 07:27:49,016] [INFO] [launch.py:351:main] Process 1099572 exits successfully.
ml-512-node-020: [2024-07-08 07:27:49,019] [INFO] [launch.py:351:main] Process 1088933 exits successfully.
ml-512-node-020: [2024-07-08 07:27:49,019] [INFO] [launch.py:351:main] Process 1088928 exits successfully.
ml-512-node-020: [2024-07-08 07:27:49,020] [INFO] [launch.py:351:main] Process 1088934 exits successfully.
ml-512-node-020: [2024-07-08 07:27:49,020] [INFO] [launch.py:351:main] Process 1088929 exits successfully.
ml-512-node-020: [2024-07-08 07:27:49,020] [INFO] [launch.py:351:main] Process 1088927 exits successfully.
ml-512-node-015: [2024-07-08 07:27:49,058] [INFO] [launch.py:351:main] Process 1094671 exits successfully.
ml-512-node-015: [2024-07-08 07:27:49,058] [INFO] [launch.py:351:main] Process 1094669 exits successfully.
ml-512-node-015: [2024-07-08 07:27:49,058] [INFO] [launch.py:351:main] Process 1094674 exits successfully.
ml-512-node-015: [2024-07-08 07:27:49,058] [INFO] [launch.py:351:main] Process 1094672 exits successfully.
ml-512-node-015: [2024-07-08 07:27:49,058] [INFO] [launch.py:351:main] Process 1094676 exits successfully.
ml-512-node-029: [2024-07-08 07:27:49,071] [INFO] [launch.py:351:main] Process 1092868 exits successfully.
ml-512-node-029: [2024-07-08 07:27:49,071] [INFO] [launch.py:351:main] Process 1092867 exits successfully.
ml-512-node-029: [2024-07-08 07:27:49,072] [INFO] [launch.py:351:main] Process 1092865 exits successfully.
ml-512-node-029: [2024-07-08 07:27:49,072] [INFO] [launch.py:351:main] Process 1092863 exits successfully.
ml-512-node-029: [2024-07-08 07:27:49,072] [INFO] [launch.py:351:main] Process 1092869 exits successfully.
ml-512-node-029: [2024-07-08 07:27:49,072] [INFO] [launch.py:351:main] Process 1092864 exits successfully.
ml-512-node-029: [2024-07-08 07:27:49,072] [INFO] [launch.py:351:main] Process 1092866 exits successfully.
ml-512-node-023: [2024-07-08 07:27:49,078] [INFO] [launch.py:351:main] Process 1093375 exits successfully.
ml-512-node-023: [2024-07-08 07:27:49,079] [INFO] [launch.py:351:main] Process 1093379 exits successfully.
ml-512-node-023: [2024-07-08 07:27:49,079] [INFO] [launch.py:351:main] Process 1093374 exits successfully.
ml-512-node-023: [2024-07-08 07:27:49,079] [INFO] [launch.py:351:main] Process 1093372 exits successfully.
ml-512-node-023: [2024-07-08 07:27:49,079] [INFO] [launch.py:351:main] Process 1093376 exits successfully.
ml-512-node-006: [2024-07-08 07:27:49,082] [INFO] [launch.py:351:main] Process 1094223 exits successfully.
ml-512-node-006: [2024-07-08 07:27:49,082] [INFO] [launch.py:351:main] Process 1094221 exits successfully.
ml-512-node-006: [2024-07-08 07:27:49,082] [INFO] [launch.py:351:main] Process 1094227 exits successfully.
ml-512-node-006: [2024-07-08 07:27:49,082] [INFO] [launch.py:351:main] Process 1094224 exits successfully.
ml-512-node-006: [2024-07-08 07:27:49,083] [INFO] [launch.py:351:main] Process 1094222 exits successfully.
ml-512-node-016: [2024-07-08 07:27:49,092] [INFO] [launch.py:351:main] Process 1089897 exits successfully.
ml-512-node-016: [2024-07-08 07:27:49,092] [INFO] [launch.py:351:main] Process 1089896 exits successfully.
ml-512-node-016: [2024-07-08 07:27:49,092] [INFO] [launch.py:351:main] Process 1089901 exits successfully.
ml-512-node-016: [2024-07-08 07:27:49,092] [INFO] [launch.py:351:main] Process 1089898 exits successfully.
ml-512-node-008: [2024-07-08 07:27:49,105] [INFO] [launch.py:351:main] Process 1093130 exits successfully.
ml-512-node-008: [2024-07-08 07:27:49,106] [INFO] [launch.py:351:main] Process 1093124 exits successfully.
ml-512-node-008: [2024-07-08 07:27:49,106] [INFO] [launch.py:351:main] Process 1093129 exits successfully.
ml-512-node-026: [2024-07-08 07:27:49,121] [INFO] [launch.py:351:main] Process 1087991 exits successfully.
ml-512-node-026: [2024-07-08 07:27:49,122] [INFO] [launch.py:351:main] Process 1087993 exits successfully.
ml-512-node-026: [2024-07-08 07:27:49,122] [INFO] [launch.py:351:main] Process 1087989 exits successfully.
ml-512-node-011: [2024-07-08 07:27:49,122] [INFO] [launch.py:351:main] Process 1096770 exits successfully.
ml-512-node-011: [2024-07-08 07:27:49,122] [INFO] [launch.py:351:main] Process 1096775 exits successfully.
ml-512-node-011: [2024-07-08 07:27:49,122] [INFO] [launch.py:351:main] Process 1096777 exits successfully.
ml-512-node-027: [2024-07-08 07:27:49,127] [INFO] [launch.py:351:main] Process 1098563 exits successfully.
ml-512-node-027: [2024-07-08 07:27:49,128] [INFO] [launch.py:351:main] Process 1098561 exits successfully.
ml-512-node-012: [2024-07-08 07:27:49,130] [INFO] [launch.py:351:main] Process 1091112 exits successfully.
ml-512-node-019: [2024-07-08 07:27:49,130] [INFO] [launch.py:351:main] Process 1095071 exits successfully.
ml-512-node-019: [2024-07-08 07:27:49,130] [INFO] [launch.py:351:main] Process 1095068 exits successfully.
ml-512-node-019: [2024-07-08 07:27:49,130] [INFO] [launch.py:351:main] Process 1095066 exits successfully.
ml-512-node-031: [2024-07-08 07:27:49,134] [INFO] [launch.py:351:main] Process 1092201 exits successfully.
ml-512-node-031: [2024-07-08 07:27:49,134] [INFO] [launch.py:351:main] Process 1092199 exits successfully.
ml-512-node-031: [2024-07-08 07:27:49,134] [INFO] [launch.py:351:main] Process 1092203 exits successfully.
ml-512-node-031: [2024-07-08 07:27:49,134] [INFO] [launch.py:351:main] Process 1092205 exits successfully.
ml-512-node-031: [2024-07-08 07:27:49,135] [INFO] [launch.py:351:main] Process 1092204 exits successfully.
ml-512-node-031: [2024-07-08 07:27:49,135] [INFO] [launch.py:351:main] Process 1092202 exits successfully.
ml-512-node-031: [2024-07-08 07:27:49,135] [INFO] [launch.py:351:main] Process 1092200 exits successfully.
ml-512-node-013: [2024-07-08 07:27:49,136] [INFO] [launch.py:351:main] Process 1096028 exits successfully.
ml-512-node-013: [2024-07-08 07:27:49,136] [INFO] [launch.py:351:main] Process 1096026 exits successfully.
ml-512-node-013: [2024-07-08 07:27:49,136] [INFO] [launch.py:351:main] Process 1096030 exits successfully.
ml-512-node-013: [2024-07-08 07:27:49,136] [INFO] [launch.py:351:main] Process 1096032 exits successfully.
ml-512-node-013: [2024-07-08 07:27:49,136] [INFO] [launch.py:351:main] Process 1096031 exits successfully.
ml-512-node-013: [2024-07-08 07:27:49,137] [INFO] [launch.py:351:main] Process 1096029 exits successfully.
ml-512-node-013: [2024-07-08 07:27:49,137] [INFO] [launch.py:351:main] Process 1096027 exits successfully.
ml-512-node-013: [2024-07-08 07:27:49,137] [INFO] [launch.py:351:main] Process 1096033 exits successfully.
ml-512-node-003: [2024-07-08 07:27:49,141] [INFO] [launch.py:351:main] Process 1098702 exits successfully.
ml-512-node-003: [2024-07-08 07:27:49,141] [INFO] [launch.py:351:main] Process 1098700 exits successfully.
ml-512-node-003: [2024-07-08 07:27:49,141] [INFO] [launch.py:351:main] Process 1098696 exits successfully.
ml-512-node-003: [2024-07-08 07:27:49,141] [INFO] [launch.py:351:main] Process 1098697 exits successfully.
ml-512-node-018: [2024-07-08 07:27:49,146] [INFO] [launch.py:351:main] Process 1090767 exits successfully.
ml-512-node-018: [2024-07-08 07:27:49,146] [INFO] [launch.py:351:main] Process 1090763 exits successfully.
ml-512-node-018: [2024-07-08 07:27:49,146] [INFO] [launch.py:351:main] Process 1090768 exits successfully.
ml-512-node-024: [2024-07-08 07:27:49,145] [INFO] [launch.py:351:main] Process 1089311 exits successfully.
ml-512-node-024: [2024-07-08 07:27:49,145] [INFO] [launch.py:351:main] Process 1089308 exits successfully.
ml-512-node-030: [2024-07-08 07:27:49,147] [INFO] [launch.py:351:main] Process 1093269 exits successfully.
ml-512-node-030: [2024-07-08 07:27:49,147] [INFO] [launch.py:351:main] Process 1093271 exits successfully.
ml-512-node-030: [2024-07-08 07:27:49,147] [INFO] [launch.py:351:main] Process 1093268 exits successfully.
ml-512-node-022: [2024-07-08 07:27:49,147] [INFO] [launch.py:351:main] Process 1088974 exits successfully.
ml-512-node-022: [2024-07-08 07:27:49,147] [INFO] [launch.py:351:main] Process 1088975 exits successfully.
ml-512-node-022: [2024-07-08 07:27:49,147] [INFO] [launch.py:351:main] Process 1088971 exits successfully.
ml-512-node-021: [2024-07-08 07:27:49,152] [INFO] [launch.py:351:main] Process 1095156 exits successfully.
ml-512-node-021: [2024-07-08 07:27:49,152] [INFO] [launch.py:351:main] Process 1095154 exits successfully.
ml-512-node-021: [2024-07-08 07:27:49,152] [INFO] [launch.py:351:main] Process 1095158 exits successfully.
ml-512-node-021: [2024-07-08 07:27:49,152] [INFO] [launch.py:351:main] Process 1095160 exits successfully.
ml-512-node-021: [2024-07-08 07:27:49,152] [INFO] [launch.py:351:main] Process 1095159 exits successfully.
ml-512-node-021: [2024-07-08 07:27:49,152] [INFO] [launch.py:351:main] Process 1095157 exits successfully.
ml-512-node-021: [2024-07-08 07:27:49,153] [INFO] [launch.py:351:main] Process 1095155 exits successfully.
ml-512-node-021: [2024-07-08 07:27:49,153] [INFO] [launch.py:351:main] Process 1095161 exits successfully.
ml-512-node-014: [2024-07-08 07:27:49,162] [INFO] [launch.py:351:main] Process 1089048 exits successfully.
ml-512-node-014: [2024-07-08 07:27:49,162] [INFO] [launch.py:351:main] Process 1089050 exits successfully.
ml-512-node-014: [2024-07-08 07:27:49,162] [INFO] [launch.py:351:main] Process 1089049 exits successfully.
ml-512-node-014: [2024-07-08 07:27:49,162] [INFO] [launch.py:351:main] Process 1089047 exits successfully.
ml-512-node-014: [2024-07-08 07:27:49,162] [INFO] [launch.py:351:main] Process 1089044 exits successfully.
ml-512-node-028: [2024-07-08 07:27:49,160] [INFO] [launch.py:351:main] Process 1088230 exits successfully.
ml-512-node-028: [2024-07-08 07:27:49,160] [INFO] [launch.py:351:main] Process 1088235 exits successfully.
ml-512-node-010: [2024-07-08 07:27:49,197] [INFO] [launch.py:351:main] Process 1090803 exits successfully.
ml-512-node-010: [2024-07-08 07:27:49,197] [INFO] [launch.py:351:main] Process 1090800 exits successfully.
ml-512-node-010: [2024-07-08 07:27:49,197] [INFO] [launch.py:351:main] Process 1090805 exits successfully.
ml-512-node-002: [2024-07-08 07:27:49,203] [INFO] [launch.py:351:main] Process 1106373 exits successfully.
ml-512-node-002: [2024-07-08 07:27:49,203] [INFO] [launch.py:351:main] Process 1106374 exits successfully.
ml-512-node-002: [2024-07-08 07:27:49,203] [INFO] [launch.py:351:main] Process 1106372 exits successfully.
ml-512-node-002: [2024-07-08 07:27:49,203] [INFO] [launch.py:351:main] Process 1106376 exits successfully.
ml-512-node-025: [2024-07-08 07:27:49,211] [INFO] [launch.py:351:main] Process 1095608 exits successfully.
ml-512-node-025: [2024-07-08 07:27:49,211] [INFO] [launch.py:351:main] Process 1095610 exits successfully.
ml-512-node-025: [2024-07-08 07:27:49,211] [INFO] [launch.py:351:main] Process 1095609 exits successfully.
ml-512-node-025: [2024-07-08 07:27:49,211] [INFO] [launch.py:351:main] Process 1095607 exits successfully.
ml-512-node-025: [2024-07-08 07:27:49,211] [INFO] [launch.py:351:main] Process 1095605 exits successfully.
ml-512-node-025: [2024-07-08 07:27:49,211] [INFO] [launch.py:351:main] Process 1095611 exits successfully.
ml-512-node-025: [2024-07-08 07:27:49,211] [INFO] [launch.py:351:main] Process 1095606 exits successfully.
ml-512-node-025: [2024-07-08 07:27:49,212] [INFO] [launch.py:351:main] Process 1095604 exits successfully.
ml-512-node-017: [2024-07-08 07:27:49,242] [INFO] [launch.py:351:main] Process 1098968 exits successfully.
ml-512-node-017: [2024-07-08 07:27:49,242] [INFO] [launch.py:351:main] Process 1098969 exits successfully.
ml-512-node-032: [2024-07-08 07:27:49,245] [INFO] [launch.py:351:main] Process 1083828 exits successfully.
ml-512-node-032: [2024-07-08 07:27:49,245] [INFO] [launch.py:351:main] Process 1083830 exits successfully.
ml-512-node-032: [2024-07-08 07:27:49,245] [INFO] [launch.py:351:main] Process 1083832 exits successfully.
ml-512-node-032: [2024-07-08 07:27:49,245] [INFO] [launch.py:351:main] Process 1083831 exits successfully.
ml-512-node-032: [2024-07-08 07:27:49,245] [INFO] [launch.py:351:main] Process 1083829 exits successfully.
ml-512-node-032: [2024-07-08 07:27:49,246] [INFO] [launch.py:351:main] Process 1083827 exits successfully.
ml-512-node-032: [2024-07-08 07:27:49,246] [INFO] [launch.py:351:main] Process 1083833 exits successfully.
ml-512-node-009: [2024-07-08 07:27:49,839] [INFO] [launch.py:351:main] Process 1096808 exits successfully.
ml-512-node-009: [2024-07-08 07:27:49,839] [INFO] [launch.py:351:main] Process 1096807 exits successfully.
ml-512-node-009: [2024-07-08 07:27:49,839] [INFO] [launch.py:351:main] Process 1096805 exits successfully.
ml-512-node-009: [2024-07-08 07:27:49,839] [INFO] [launch.py:351:main] Process 1096809 exits successfully.
ml-512-node-009: [2024-07-08 07:27:49,839] [INFO] [launch.py:351:main] Process 1096802 exits successfully.
ml-512-node-005: [2024-07-08 07:27:49,925] [INFO] [launch.py:351:main] Process 1112897 exits successfully.
ml-512-node-005: [2024-07-08 07:27:49,926] [INFO] [launch.py:351:main] Process 1112898 exits successfully.
ml-512-node-005: [2024-07-08 07:27:49,926] [INFO] [launch.py:351:main] Process 1112900 exits successfully.
ml-512-node-020: [2024-07-08 07:27:50,021] [INFO] [launch.py:351:main] Process 1088931 exits successfully.
ml-512-node-020: [2024-07-08 07:27:50,021] [INFO] [launch.py:351:main] Process 1088932 exits successfully.
ml-512-node-020: [2024-07-08 07:27:50,021] [INFO] [launch.py:351:main] Process 1088930 exits successfully.
ml-512-node-015: [2024-07-08 07:27:50,059] [INFO] [launch.py:351:main] Process 1094673 exits successfully.
ml-512-node-015: [2024-07-08 07:27:50,060] [INFO] [launch.py:351:main] Process 1094670 exits successfully.
ml-512-node-015: [2024-07-08 07:27:50,060] [INFO] [launch.py:351:main] Process 1094675 exits successfully.
ml-512-node-029: [2024-07-08 07:27:50,073] [INFO] [launch.py:351:main] Process 1092862 exits successfully.
ml-512-node-023: [2024-07-08 07:27:50,080] [INFO] [launch.py:351:main] Process 1093378 exits successfully.
ml-512-node-023: [2024-07-08 07:27:50,080] [INFO] [launch.py:351:main] Process 1093377 exits successfully.
ml-512-node-023: [2024-07-08 07:27:50,080] [INFO] [launch.py:351:main] Process 1093373 exits successfully.
ml-512-node-011: [2024-07-08 07:27:50,123] [INFO] [launch.py:351:main] Process 1096772 exits successfully.
ml-512-node-011: [2024-07-08 07:27:50,123] [INFO] [launch.py:351:main] Process 1096774 exits successfully.
ml-512-node-011: [2024-07-08 07:27:50,123] [INFO] [launch.py:351:main] Process 1096776 exits successfully.
ml-512-node-011: [2024-07-08 07:27:50,123] [INFO] [launch.py:351:main] Process 1096773 exits successfully.
ml-512-node-011: [2024-07-08 07:27:50,123] [INFO] [launch.py:351:main] Process 1096771 exits successfully.
ml-512-node-012: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1091113 exits successfully.
ml-512-node-012: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1091115 exits successfully.
ml-512-node-012: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1091114 exits successfully.
ml-512-node-012: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1091110 exits successfully.
ml-512-node-012: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1091116 exits successfully.
ml-512-node-012: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1091111 exits successfully.
ml-512-node-012: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1091109 exits successfully.
ml-512-node-019: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1095067 exits successfully.
ml-512-node-019: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1095065 exits successfully.
ml-512-node-019: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1095069 exits successfully.
ml-512-node-019: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1095070 exits successfully.
ml-512-node-019: [2024-07-08 07:27:50,132] [INFO] [launch.py:351:main] Process 1095072 exits successfully.
ml-512-node-031: [2024-07-08 07:27:50,136] [INFO] [launch.py:351:main] Process 1092206 exits successfully.
ml-512-node-024: [2024-07-08 07:27:50,147] [INFO] [launch.py:351:main] Process 1089306 exits successfully.
ml-512-node-024: [2024-07-08 07:27:50,147] [INFO] [launch.py:351:main] Process 1089304 exits successfully.
ml-512-node-024: [2024-07-08 07:27:50,147] [INFO] [launch.py:351:main] Process 1089309 exits successfully.
ml-512-node-024: [2024-07-08 07:27:50,147] [INFO] [launch.py:351:main] Process 1089310 exits successfully.
ml-512-node-024: [2024-07-08 07:27:50,147] [INFO] [launch.py:351:main] Process 1089305 exits successfully.
ml-512-node-024: [2024-07-08 07:27:50,147] [INFO] [launch.py:351:main] Process 1089312 exits successfully.
ml-512-node-030: [2024-07-08 07:27:50,148] [INFO] [launch.py:351:main] Process 1093270 exits successfully.
ml-512-node-030: [2024-07-08 07:27:50,148] [INFO] [launch.py:351:main] Process 1093266 exits successfully.
ml-512-node-030: [2024-07-08 07:27:50,149] [INFO] [launch.py:351:main] Process 1093272 exits successfully.
ml-512-node-030: [2024-07-08 07:27:50,149] [INFO] [launch.py:351:main] Process 1093267 exits successfully.
ml-512-node-030: [2024-07-08 07:27:50,149] [INFO] [launch.py:351:main] Process 1093265 exits successfully.
ml-512-node-014: [2024-07-08 07:27:50,163] [INFO] [launch.py:351:main] Process 1089045 exits successfully.
ml-512-node-014: [2024-07-08 07:27:50,163] [INFO] [launch.py:351:main] Process 1089046 exits successfully.
ml-512-node-014: [2024-07-08 07:27:50,164] [INFO] [launch.py:351:main] Process 1089051 exits successfully.
