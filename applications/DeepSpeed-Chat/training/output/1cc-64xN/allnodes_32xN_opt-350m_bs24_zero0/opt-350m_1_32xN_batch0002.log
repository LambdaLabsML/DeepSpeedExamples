ml-512-node-033 slots=8
ml-512-node-034 slots=8
ml-512-node-035 slots=8
ml-512-node-036 slots=8
ml-512-node-037 slots=8
ml-512-node-038 slots=8
ml-512-node-039 slots=8
ml-512-node-040 slots=8
ml-512-node-041 slots=8
ml-512-node-042 slots=8
ml-512-node-043 slots=8
ml-512-node-044 slots=8
ml-512-node-045 slots=8
ml-512-node-046 slots=8
ml-512-node-047 slots=8
ml-512-node-048 slots=8
ml-512-node-049 slots=8
ml-512-node-050 slots=8
ml-512-node-051 slots=8
ml-512-node-052 slots=8
ml-512-node-053 slots=8
ml-512-node-054 slots=8
ml-512-node-055 slots=8
ml-512-node-056 slots=8
ml-512-node-057 slots=8
ml-512-node-058 slots=8
ml-512-node-059 slots=8
ml-512-node-060 slots=8
ml-512-node-061 slots=8
ml-512-node-062 slots=8
ml-512-node-063 slots=8
ml-512-node-064 slots=8
[2024-07-08 06:03:04,114] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-07-08 06:03:05.505875: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-07-08 06:03:05.544308: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
[93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
[93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
[93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
[2024-07-08 06:03:07,019] [INFO] [runner.py:557:main] deepspeed_env file = ./.deepspeed_env
[2024-07-08 06:03:07,020] [INFO] [multinode_runner.py:81:get_cmd] Running on the following workers: ml-512-node-033,ml-512-node-034,ml-512-node-035,ml-512-node-036,ml-512-node-037,ml-512-node-038,ml-512-node-039,ml-512-node-040,ml-512-node-041,ml-512-node-042,ml-512-node-043,ml-512-node-044,ml-512-node-045,ml-512-node-046,ml-512-node-047,ml-512-node-048,ml-512-node-049,ml-512-node-050,ml-512-node-051,ml-512-node-052,ml-512-node-053,ml-512-node-054,ml-512-node-055,ml-512-node-056,ml-512-node-057,ml-512-node-058,ml-512-node-059,ml-512-node-060,ml-512-node-061,ml-512-node-062,ml-512-node-063,ml-512-node-064
[2024-07-08 06:03:07,020] [INFO] [runner.py:568:main] cmd = pdsh -S -f 1024 -w ml-512-node-033,ml-512-node-034,ml-512-node-035,ml-512-node-036,ml-512-node-037,ml-512-node-038,ml-512-node-039,ml-512-node-040,ml-512-node-041,ml-512-node-042,ml-512-node-043,ml-512-node-044,ml-512-node-045,ml-512-node-046,ml-512-node-047,ml-512-node-048,ml-512-node-049,ml-512-node-050,ml-512-node-051,ml-512-node-052,ml-512-node-053,ml-512-node-054,ml-512-node-055,ml-512-node-056,ml-512-node-057,ml-512-node-058,ml-512-node-059,ml-512-node-060,ml-512-node-061,ml-512-node-062,ml-512-node-063,ml-512-node-064 export PYTHONPATH=/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training; export PROJECT_PATH=/home/ubuntu/ml-1cc/benchmark; export OMPI_MCA_btl_tcp_if_include=eno1; export UCX_TLS=self,shm,tcp; export NCCL_P2P_LEVEL=NVL; export NCCL_NET_GDR_LEVEL=PIX; export NCCL_IB_HCA='=mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8'; export NCCL_IB_PCI_RELAXED_ORDERING=1; export NCCL_SOCKET_IFNAME=eno1; export NCCL_DEBUG=WARN;  cd /home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training; /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJtbC01MTItbm9kZS0wMzMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wMzkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNDkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTUiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTYiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTciOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTgiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNTkiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjAiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjEiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjIiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjMiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN10sICJtbC01MTItbm9kZS0wNjQiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --node_rank=%n --master_addr=ml-512-node-033 --master_port=29500 /home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py --data_path Dahoas/full-hh-rlhf --data_split 2,4,4 --data_output_path /home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1 --model_name_or_path facebook/opt-350m --per_device_train_batch_size 24 --per_device_eval_batch_size 4 --max_seq_len 512 --learning_rate 1e-10 --weight_decay 0.1 --disable_dropout --gradient_accumulation_steps 1 --lr_scheduler_type cosine --seed 1234 --zero_stage 0 --deepspeed --num_warmup_steps 10 --num_train_epochs 100 --max_steps 100
ml-512-node-033: [2024-07-08 06:03:08,422] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: 2024-07-08 06:03:09.924590: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-033: 2024-07-08 06:03:09.966517: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-033: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-036: [2024-07-08 06:03:10,617] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:03:10,622] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:03:10,636] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:03:10,655] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:03:10,658] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:03:10,659] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:03:10,667] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:03:10,668] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:03:10,670] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:03:10,680] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:03:10,683] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 06:03:10,688] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:03:10,691] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:03:10,702] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:03:10,720] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-040: [2024-07-08 06:03:10,848] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 06:03:11,037] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 06:03:11,051] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 06:03:11,054] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [2024-07-08 06:03:11,058] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [2024-07-08 06:03:11,067] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 06:03:11,067] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [2024-07-08 06:03:11,070] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 06:03:11,077] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 06:03:11,079] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 06:03:11,085] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [2024-07-08 06:03:11,088] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [2024-07-08 06:03:11,101] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [2024-07-08 06:03:11,111] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-056: [2024-07-08 06:03:11,286] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:139:main] 0 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:139:main] 0 NCCL_SOCKET_IFNAME=eno1
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:139:main] 0 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:139:main] 0 NCCL_P2P_LEVEL=NVL
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:139:main] 0 NCCL_DEBUG=WARN
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:139:main] 0 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=0
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-033: [2024-07-08 06:03:11,352] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-033: [2024-07-08 06:03:11,354] [INFO] [launch.py:256:main] process 1069269 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:03:11,354] [INFO] [launch.py:256:main] process 1069270 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:03:11,355] [INFO] [launch.py:256:main] process 1069271 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:03:11,356] [INFO] [launch.py:256:main] process 1069272 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:03:11,356] [INFO] [launch.py:256:main] process 1069273 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:03:11,357] [INFO] [launch.py:256:main] process 1069274 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:03:11,357] [INFO] [launch.py:256:main] process 1069275 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:03:11,358] [INFO] [launch.py:256:main] process 1069276 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: 2024-07-08 06:03:11.974724: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: 2024-07-08 06:03:11.999264: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-042: 2024-07-08 06:03:11.998346: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-047: 2024-07-08 06:03:12.000390: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: 2024-07-08 06:03:12.012448: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-045: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-043: 2024-07-08 06:03:12.026212: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-034: 2024-07-08 06:03:12.029122: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-036: 2024-07-08 06:03:12.036787: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-036: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-047: 2024-07-08 06:03:12.037970: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-047: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-042: 2024-07-08 06:03:12.037802: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-042: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-039: 2024-07-08 06:03:12.047120: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-038: 2024-07-08 06:03:12.047048: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-041: 2024-07-08 06:03:12.046997: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-046: 2024-07-08 06:03:12.050583: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-044: 2024-07-08 06:03:12.051099: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-063: [2024-07-08 06:03:12,053] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: 2024-07-08 06:03:12.060553: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-043: 2024-07-08 06:03:12.065256: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-043: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-034: 2024-07-08 06:03:12.068293: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-034: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-060: 2024-07-08 06:03:12.070992: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-048: 2024-07-08 06:03:12.083624: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-039: 2024-07-08 06:03:12.085365: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-039: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-041: 2024-07-08 06:03:12.086052: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-041: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-038: 2024-07-08 06:03:12.086673: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-038: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-046: 2024-07-08 06:03:12.089950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-046: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-044: 2024-07-08 06:03:12.090552: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-044: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-037: 2024-07-08 06:03:12.094758: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-035: 2024-07-08 06:03:12.098998: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-035: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-060: 2024-07-08 06:03:12.110776: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-060: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-048: 2024-07-08 06:03:12.121163: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-048: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-037: 2024-07-08 06:03:12.132451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-037: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: 2024-07-08 06:03:12.402158: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-049: 2024-07-08 06:03:12.418724: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-051: 2024-07-08 06:03:12.419524: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-052: 2024-07-08 06:03:12.426935: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-057: 2024-07-08 06:03:12.428753: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-050: 2024-07-08 06:03:12.439569: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-050: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-055: 2024-07-08 06:03:12.445961: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-059: 2024-07-08 06:03:12.447236: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-064: 2024-07-08 06:03:12.448756: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-053: 2024-07-08 06:03:12.453005: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-049: 2024-07-08 06:03:12.457523: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-049: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-051: 2024-07-08 06:03:12.458700: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-051: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-052: 2024-07-08 06:03:12.465856: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-052: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-054: 2024-07-08 06:03:12.467011: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-057: 2024-07-08 06:03:12.468525: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-057: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-055: 2024-07-08 06:03:12.484496: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-055: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-059: 2024-07-08 06:03:12.485259: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-059: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-058: 2024-07-08 06:03:12.487448: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-064: 2024-07-08 06:03:12.488777: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-064: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-040: 2024-07-08 06:03:12.489061: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-053: 2024-07-08 06:03:12.494138: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-053: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-054: 2024-07-08 06:03:12.505053: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-054: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-040: 2024-07-08 06:03:12.524904: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-040: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-058: 2024-07-08 06:03:12.526485: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-058: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-062: 2024-07-08 06:03:12.554750: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: 2024-07-08 06:03:12.577696: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: 2024-07-08 06:03:12.596424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-062: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-061: 2024-07-08 06:03:12.617394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-061: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: 2024-07-08 06:03:12.965965: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-056: 2024-07-08 06:03:13.002027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-056: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:139:main] 12 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:139:main] 12 NCCL_SOCKET_IFNAME=eno1
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:139:main] 12 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:139:main] 12 NCCL_P2P_LEVEL=NVL
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:139:main] 12 NCCL_DEBUG=WARN
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:139:main] 12 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=12
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-045: [2024-07-08 06:03:13,261] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-045: [2024-07-08 06:03:13,262] [INFO] [launch.py:256:main] process 1061689 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:03:13,263] [INFO] [launch.py:256:main] process 1061690 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:03:13,264] [INFO] [launch.py:256:main] process 1061691 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:03:13,264] [INFO] [launch.py:256:main] process 1061692 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:03:13,265] [INFO] [launch.py:256:main] process 1061693 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:03:13,265] [INFO] [launch.py:256:main] process 1061694 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:03:13,266] [INFO] [launch.py:256:main] process 1061695 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-045: [2024-07-08 06:03:13,267] [INFO] [launch.py:256:main] process 1061696 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:139:main] 9 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:139:main] 9 NCCL_SOCKET_IFNAME=eno1
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:139:main] 9 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:139:main] 9 NCCL_P2P_LEVEL=NVL
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:139:main] 9 NCCL_DEBUG=WARN
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:139:main] 9 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=9
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-042: [2024-07-08 06:03:13,294] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-042: [2024-07-08 06:03:13,295] [INFO] [launch.py:256:main] process 1057921 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:03:13,295] [INFO] [launch.py:256:main] process 1057922 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:03:13,296] [INFO] [launch.py:256:main] process 1057923 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:03:13,297] [INFO] [launch.py:256:main] process 1057924 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:03:13,298] [INFO] [launch.py:256:main] process 1057925 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:03:13,298] [INFO] [launch.py:256:main] process 1057926 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:03:13,299] [INFO] [launch.py:256:main] process 1057927 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-042: [2024-07-08 06:03:13,299] [INFO] [launch.py:256:main] process 1057928 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:139:main] 3 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:139:main] 3 NCCL_SOCKET_IFNAME=eno1
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:139:main] 3 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:139:main] 3 NCCL_P2P_LEVEL=NVL
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:139:main] 3 NCCL_DEBUG=WARN
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:139:main] 3 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=3
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-036: [2024-07-08 06:03:13,309] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-036: [2024-07-08 06:03:13,310] [INFO] [launch.py:256:main] process 1058815 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:03:13,311] [INFO] [launch.py:256:main] process 1058816 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:03:13,312] [INFO] [launch.py:256:main] process 1058817 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:03:13,313] [INFO] [launch.py:256:main] process 1058818 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:03:13,314] [INFO] [launch.py:256:main] process 1058819 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:03:13,314] [INFO] [launch.py:256:main] process 1058820 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:03:13,315] [INFO] [launch.py:256:main] process 1058821 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-036: [2024-07-08 06:03:13,315] [INFO] [launch.py:256:main] process 1058822 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:139:main] 14 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:139:main] 14 NCCL_SOCKET_IFNAME=eno1
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:139:main] 14 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:139:main] 14 NCCL_P2P_LEVEL=NVL
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:139:main] 14 NCCL_DEBUG=WARN
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:139:main] 14 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=14
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-047: [2024-07-08 06:03:13,331] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-047: [2024-07-08 06:03:13,332] [INFO] [launch.py:256:main] process 1059873 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:03:13,333] [INFO] [launch.py:256:main] process 1059874 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:03:13,334] [INFO] [launch.py:256:main] process 1059875 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:03:13,335] [INFO] [launch.py:256:main] process 1059876 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:03:13,335] [INFO] [launch.py:256:main] process 1059877 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:03:13,336] [INFO] [launch.py:256:main] process 1059878 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:03:13,337] [INFO] [launch.py:256:main] process 1059879 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-047: [2024-07-08 06:03:13,337] [INFO] [launch.py:256:main] process 1059880 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:139:main] 10 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:139:main] 10 NCCL_SOCKET_IFNAME=eno1
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:139:main] 10 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:139:main] 10 NCCL_P2P_LEVEL=NVL
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:139:main] 10 NCCL_DEBUG=WARN
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:139:main] 10 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=10
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-043: [2024-07-08 06:03:13,340] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-043: [2024-07-08 06:03:13,341] [INFO] [launch.py:256:main] process 1061736 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:03:13,342] [INFO] [launch.py:256:main] process 1061737 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:03:13,343] [INFO] [launch.py:256:main] process 1061738 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:03:13,343] [INFO] [launch.py:256:main] process 1061739 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:03:13,344] [INFO] [launch.py:256:main] process 1061740 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:03:13,345] [INFO] [launch.py:256:main] process 1061741 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:03:13,345] [INFO] [launch.py:256:main] process 1061742 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-043: [2024-07-08 06:03:13,346] [INFO] [launch.py:256:main] process 1061743 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:03:13,347] [INFO] [launch.py:139:main] 1 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-034: [2024-07-08 06:03:13,348] [INFO] [launch.py:139:main] 1 NCCL_SOCKET_IFNAME=eno1
ml-512-node-034: [2024-07-08 06:03:13,348] [INFO] [launch.py:139:main] 1 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-034: [2024-07-08 06:03:13,348] [INFO] [launch.py:139:main] 1 NCCL_P2P_LEVEL=NVL
ml-512-node-034: [2024-07-08 06:03:13,348] [INFO] [launch.py:139:main] 1 NCCL_DEBUG=WARN
ml-512-node-034: [2024-07-08 06:03:13,348] [INFO] [launch.py:139:main] 1 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-034: [2024-07-08 06:03:13,348] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-034: [2024-07-08 06:03:13,348] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=1
ml-512-node-034: [2024-07-08 06:03:13,348] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-034: [2024-07-08 06:03:13,348] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-034: [2024-07-08 06:03:13,348] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-034: [2024-07-08 06:03:13,349] [INFO] [launch.py:256:main] process 1059477 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:03:13,349] [INFO] [launch.py:256:main] process 1059478 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:03:13,350] [INFO] [launch.py:256:main] process 1059479 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:03:13,351] [INFO] [launch.py:256:main] process 1059480 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:03:13,352] [INFO] [launch.py:256:main] process 1059481 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:03:13,352] [INFO] [launch.py:256:main] process 1059482 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:03:13,353] [INFO] [launch.py:256:main] process 1059483 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-034: [2024-07-08 06:03:13,353] [INFO] [launch.py:256:main] process 1059484 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:139:main] 8 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:139:main] 8 NCCL_SOCKET_IFNAME=eno1
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:139:main] 8 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:139:main] 8 NCCL_P2P_LEVEL=NVL
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:139:main] 8 NCCL_DEBUG=WARN
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:139:main] 8 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=8
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-041: [2024-07-08 06:03:13,356] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-041: [2024-07-08 06:03:13,357] [INFO] [launch.py:256:main] process 1064390 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:03:13,358] [INFO] [launch.py:256:main] process 1064391 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:03:13,359] [INFO] [launch.py:256:main] process 1064392 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:03:13,359] [INFO] [launch.py:256:main] process 1064393 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:03:13,360] [INFO] [launch.py:256:main] process 1064394 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:03:13,361] [INFO] [launch.py:256:main] process 1064395 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:03:13,361] [INFO] [launch.py:256:main] process 1064396 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-041: [2024-07-08 06:03:13,362] [INFO] [launch.py:256:main] process 1064397 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:03:13,363] [INFO] [launch.py:139:main] 6 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-039: [2024-07-08 06:03:13,363] [INFO] [launch.py:139:main] 6 NCCL_SOCKET_IFNAME=eno1
ml-512-node-039: [2024-07-08 06:03:13,363] [INFO] [launch.py:139:main] 6 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-039: [2024-07-08 06:03:13,363] [INFO] [launch.py:139:main] 6 NCCL_P2P_LEVEL=NVL
ml-512-node-039: [2024-07-08 06:03:13,363] [INFO] [launch.py:139:main] 6 NCCL_DEBUG=WARN
ml-512-node-039: [2024-07-08 06:03:13,363] [INFO] [launch.py:139:main] 6 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-039: [2024-07-08 06:03:13,363] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-039: [2024-07-08 06:03:13,363] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=6
ml-512-node-039: [2024-07-08 06:03:13,364] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-039: [2024-07-08 06:03:13,364] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-039: [2024-07-08 06:03:13,364] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-039: [2024-07-08 06:03:13,365] [INFO] [launch.py:256:main] process 1145670 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:03:13,365] [INFO] [launch.py:256:main] process 1145671 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:139:main] 5 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:139:main] 5 NCCL_SOCKET_IFNAME=eno1
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:139:main] 5 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:139:main] 5 NCCL_P2P_LEVEL=NVL
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:139:main] 5 NCCL_DEBUG=WARN
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:139:main] 5 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=5
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-038: [2024-07-08 06:03:13,365] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-039: [2024-07-08 06:03:13,366] [INFO] [launch.py:256:main] process 1145672 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:03:13,366] [INFO] [launch.py:256:main] process 1058371 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:03:13,366] [INFO] [launch.py:256:main] process 1145673 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:03:13,367] [INFO] [launch.py:256:main] process 1058372 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:03:13,367] [INFO] [launch.py:256:main] process 1145674 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:139:main] 15 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:139:main] 15 NCCL_SOCKET_IFNAME=eno1
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:139:main] 15 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:139:main] 15 NCCL_P2P_LEVEL=NVL
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:139:main] 15 NCCL_DEBUG=WARN
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:139:main] 15 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=15
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-048: [2024-07-08 06:03:13,367] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-039: [2024-07-08 06:03:13,368] [INFO] [launch.py:256:main] process 1145675 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:03:13,367] [INFO] [launch.py:256:main] process 1058373 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:03:13,368] [INFO] [launch.py:256:main] process 1056103 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:03:13,368] [INFO] [launch.py:256:main] process 1058374 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:03:13,368] [INFO] [launch.py:256:main] process 1145676 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:03:13,369] [INFO] [launch.py:256:main] process 1056104 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:03:13,368] [INFO] [launch.py:256:main] process 1058375 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-039: [2024-07-08 06:03:13,369] [INFO] [launch.py:256:main] process 1145677 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:03:13,369] [INFO] [launch.py:256:main] process 1056105 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:03:13,369] [INFO] [launch.py:256:main] process 1058376 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:03:13,370] [INFO] [launch.py:256:main] process 1056106 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:03:13,370] [INFO] [launch.py:256:main] process 1058377 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:03:13,371] [INFO] [launch.py:256:main] process 1056107 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-038: [2024-07-08 06:03:13,370] [INFO] [launch.py:256:main] process 1058378 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:03:13,371] [INFO] [launch.py:256:main] process 1056108 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:03:13,372] [INFO] [launch.py:256:main] process 1056109 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-048: [2024-07-08 06:03:13,373] [INFO] [launch.py:256:main] process 1056110 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:139:main] 13 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:139:main] 13 NCCL_SOCKET_IFNAME=eno1
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:139:main] 13 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:139:main] 13 NCCL_P2P_LEVEL=NVL
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:139:main] 13 NCCL_DEBUG=WARN
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:139:main] 13 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=13
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-046: [2024-07-08 06:03:13,379] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-046: [2024-07-08 06:03:13,380] [INFO] [launch.py:256:main] process 1057860 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:03:13,381] [INFO] [launch.py:256:main] process 1057861 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:03:13,382] [INFO] [launch.py:256:main] process 1057862 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:03:13,382] [INFO] [launch.py:256:main] process 1057863 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:03:13,383] [INFO] [launch.py:256:main] process 1057864 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:03:13,384] [INFO] [launch.py:256:main] process 1057865 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:03:13,384] [INFO] [launch.py:256:main] process 1057866 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-046: [2024-07-08 06:03:13,384] [INFO] [launch.py:256:main] process 1057867 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:139:main] 2 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:139:main] 2 NCCL_SOCKET_IFNAME=eno1
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:139:main] 2 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:139:main] 2 NCCL_P2P_LEVEL=NVL
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:139:main] 2 NCCL_DEBUG=WARN
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:139:main] 2 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=2
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-035: [2024-07-08 06:03:13,385] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:139:main] 4 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:139:main] 4 NCCL_SOCKET_IFNAME=eno1
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:139:main] 4 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:139:main] 4 NCCL_P2P_LEVEL=NVL
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:139:main] 4 NCCL_DEBUG=WARN
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:139:main] 4 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=4
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-037: [2024-07-08 06:03:13,386] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-035: [2024-07-08 06:03:13,386] [INFO] [launch.py:256:main] process 1066311 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:03:13,387] [INFO] [launch.py:256:main] process 1062862 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:03:13,387] [INFO] [launch.py:256:main] process 1066312 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:03:13,388] [INFO] [launch.py:256:main] process 1062863 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:03:13,388] [INFO] [launch.py:256:main] process 1066313 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:03:13,389] [INFO] [launch.py:256:main] process 1062864 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:03:13,389] [INFO] [launch.py:256:main] process 1066314 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:03:13,390] [INFO] [launch.py:256:main] process 1062865 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:03:13,389] [INFO] [launch.py:256:main] process 1066315 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:03:13,390] [INFO] [launch.py:256:main] process 1066316 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:03:13,390] [INFO] [launch.py:256:main] process 1062866 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:03:13,390] [INFO] [launch.py:256:main] process 1066317 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:03:13,391] [INFO] [launch.py:256:main] process 1062867 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-035: [2024-07-08 06:03:13,391] [INFO] [launch.py:256:main] process 1066318 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:03:13,392] [INFO] [launch.py:256:main] process 1062868 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-037: [2024-07-08 06:03:13,392] [INFO] [launch.py:256:main] process 1062869 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:03:13,392] [INFO] [launch.py:139:main] 27 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-060: [2024-07-08 06:03:13,393] [INFO] [launch.py:139:main] 27 NCCL_SOCKET_IFNAME=eno1
ml-512-node-060: [2024-07-08 06:03:13,393] [INFO] [launch.py:139:main] 27 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-060: [2024-07-08 06:03:13,393] [INFO] [launch.py:139:main] 27 NCCL_P2P_LEVEL=NVL
ml-512-node-060: [2024-07-08 06:03:13,393] [INFO] [launch.py:139:main] 27 NCCL_DEBUG=WARN
ml-512-node-060: [2024-07-08 06:03:13,393] [INFO] [launch.py:139:main] 27 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-060: [2024-07-08 06:03:13,393] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-060: [2024-07-08 06:03:13,393] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=27
ml-512-node-060: [2024-07-08 06:03:13,393] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-060: [2024-07-08 06:03:13,393] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-060: [2024-07-08 06:03:13,393] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-060: [2024-07-08 06:03:13,394] [INFO] [launch.py:256:main] process 1053122 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:03:13,394] [INFO] [launch.py:256:main] process 1053123 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:03:13,395] [INFO] [launch.py:256:main] process 1053124 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:03:13,396] [INFO] [launch.py:256:main] process 1053125 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:03:13,396] [INFO] [launch.py:256:main] process 1053126 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:03:13,397] [INFO] [launch.py:256:main] process 1053127 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-060: [2024-07-08 06:03:13,398] [INFO] [launch.py:256:main] process 1053128 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:139:main] 11 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:139:main] 11 NCCL_SOCKET_IFNAME=eno1
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:139:main] 11 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:139:main] 11 NCCL_P2P_LEVEL=NVL
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:139:main] 11 NCCL_DEBUG=WARN
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:139:main] 11 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=11
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-044: [2024-07-08 06:03:13,398] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-060: [2024-07-08 06:03:13,398] [INFO] [launch.py:256:main] process 1053129 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:03:13,399] [INFO] [launch.py:256:main] process 1056246 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:03:13,400] [INFO] [launch.py:256:main] process 1056247 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:03:13,401] [INFO] [launch.py:256:main] process 1056248 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:03:13,401] [INFO] [launch.py:256:main] process 1056249 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:03:13,402] [INFO] [launch.py:256:main] process 1056250 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:03:13,402] [INFO] [launch.py:256:main] process 1056251 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:03:13,402] [INFO] [launch.py:256:main] process 1056252 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-044: [2024-07-08 06:03:13,403] [INFO] [launch.py:256:main] process 1056253 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: 2024-07-08 06:03:13.449235: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
ml-512-node-063: 2024-07-08 06:03:13.487170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
ml-512-node-063: To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 17 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 17 NCCL_SOCKET_IFNAME=eno1
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 17 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 17 NCCL_P2P_LEVEL=NVL
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 17 NCCL_DEBUG=WARN
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 17 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=17
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-050: [2024-07-08 06:03:13,727] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-050: [2024-07-08 06:03:13,728] [INFO] [launch.py:256:main] process 1055627 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 19 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 19 NCCL_SOCKET_IFNAME=eno1
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 19 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 19 NCCL_P2P_LEVEL=NVL
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 19 NCCL_DEBUG=WARN
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:139:main] 19 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=19
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-052: [2024-07-08 06:03:13,727] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-050: [2024-07-08 06:03:13,728] [INFO] [launch.py:256:main] process 1055628 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:03:13,728] [INFO] [launch.py:256:main] process 1055136 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:03:13,729] [INFO] [launch.py:256:main] process 1055629 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:03:13,729] [INFO] [launch.py:256:main] process 1055137 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:03:13,730] [INFO] [launch.py:256:main] process 1055630 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:03:13,729] [INFO] [launch.py:256:main] process 1055138 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:03:13,731] [INFO] [launch.py:256:main] process 1055631 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:03:13,730] [INFO] [launch.py:256:main] process 1055139 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:139:main] 18 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:139:main] 18 NCCL_SOCKET_IFNAME=eno1
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:139:main] 18 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:139:main] 18 NCCL_P2P_LEVEL=NVL
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:139:main] 18 NCCL_DEBUG=WARN
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:139:main] 18 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=18
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-051: [2024-07-08 06:03:13,730] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-052: [2024-07-08 06:03:13,730] [INFO] [launch.py:256:main] process 1055140 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:03:13,731] [INFO] [launch.py:256:main] process 1055632 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:03:13,731] [INFO] [launch.py:256:main] process 1055141 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:03:13,731] [INFO] [launch.py:256:main] process 1059696 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:03:13,732] [INFO] [launch.py:256:main] process 1055633 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:03:13,731] [INFO] [launch.py:256:main] process 1055142 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-052: [2024-07-08 06:03:13,732] [INFO] [launch.py:256:main] process 1055143 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-050: [2024-07-08 06:03:13,733] [INFO] [launch.py:256:main] process 1055634 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:03:13,732] [INFO] [launch.py:256:main] process 1059697 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:03:13,732] [INFO] [launch.py:256:main] process 1059698 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:03:13,733] [INFO] [launch.py:256:main] process 1059699 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:03:13,734] [INFO] [launch.py:256:main] process 1059700 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:03:13,734] [INFO] [launch.py:256:main] process 1059701 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:03:13,735] [INFO] [launch.py:256:main] process 1059702 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-051: [2024-07-08 06:03:13,736] [INFO] [launch.py:256:main] process 1059703 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:139:main] 16 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:139:main] 16 NCCL_SOCKET_IFNAME=eno1
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:139:main] 16 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:139:main] 16 NCCL_P2P_LEVEL=NVL
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:139:main] 16 NCCL_DEBUG=WARN
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:139:main] 16 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=16
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-049: [2024-07-08 06:03:13,737] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-049: [2024-07-08 06:03:13,738] [INFO] [launch.py:256:main] process 1063208 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:03:13,739] [INFO] [launch.py:256:main] process 1063209 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:03:13,740] [INFO] [launch.py:256:main] process 1063210 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:03:13,740] [INFO] [launch.py:256:main] process 1063211 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:03:13,741] [INFO] [launch.py:256:main] process 1063212 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:139:main] 24 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:139:main] 24 NCCL_SOCKET_IFNAME=eno1
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:139:main] 24 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:139:main] 24 NCCL_P2P_LEVEL=NVL
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:139:main] 24 NCCL_DEBUG=WARN
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:139:main] 24 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=24
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-057: [2024-07-08 06:03:13,740] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-049: [2024-07-08 06:03:13,742] [INFO] [launch.py:256:main] process 1063213 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:03:13,741] [INFO] [launch.py:256:main] process 1059192 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:03:13,742] [INFO] [launch.py:256:main] process 1063214 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-049: [2024-07-08 06:03:13,743] [INFO] [launch.py:256:main] process 1063215 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:03:13,742] [INFO] [launch.py:256:main] process 1059193 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:03:13,743] [INFO] [launch.py:256:main] process 1059194 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:03:13,744] [INFO] [launch.py:256:main] process 1059195 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:03:13,744] [INFO] [launch.py:256:main] process 1059196 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:03:13,745] [INFO] [launch.py:256:main] process 1059197 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:03:13,746] [INFO] [launch.py:256:main] process 1059198 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-057: [2024-07-08 06:03:13,746] [INFO] [launch.py:256:main] process 1059199 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:139:main] 26 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:139:main] 26 NCCL_SOCKET_IFNAME=eno1
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:139:main] 26 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:139:main] 26 NCCL_P2P_LEVEL=NVL
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:139:main] 26 NCCL_DEBUG=WARN
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:139:main] 26 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=26
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-059: [2024-07-08 06:03:13,747] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-059: [2024-07-08 06:03:13,748] [INFO] [launch.py:256:main] process 1056651 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:03:13,749] [INFO] [launch.py:256:main] process 1056652 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:03:13,750] [INFO] [launch.py:256:main] process 1056653 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:03:13,751] [INFO] [launch.py:256:main] process 1056654 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:03:13,751] [INFO] [launch.py:256:main] process 1056655 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:139:main] 31 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:139:main] 31 NCCL_SOCKET_IFNAME=eno1
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:139:main] 31 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:139:main] 31 NCCL_P2P_LEVEL=NVL
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:139:main] 31 NCCL_DEBUG=WARN
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:139:main] 31 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=31
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-064: [2024-07-08 06:03:13,751] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-059: [2024-07-08 06:03:13,752] [INFO] [launch.py:256:main] process 1056656 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:03:13,752] [INFO] [launch.py:256:main] process 1050711 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-059: [2024-07-08 06:03:13,753] [INFO] [launch.py:256:main] process 1056657 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:139:main] 22 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-059: [2024-07-08 06:03:13,753] [INFO] [launch.py:256:main] process 1056658 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:139:main] 22 NCCL_SOCKET_IFNAME=eno1
ml-512-node-064: [2024-07-08 06:03:13,753] [INFO] [launch.py:256:main] process 1050712 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:139:main] 22 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:139:main] 22 NCCL_P2P_LEVEL=NVL
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:139:main] 22 NCCL_DEBUG=WARN
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:139:main] 22 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=22
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-055: [2024-07-08 06:03:13,752] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-055: [2024-07-08 06:03:13,753] [INFO] [launch.py:256:main] process 1077536 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:03:13,754] [INFO] [launch.py:256:main] process 1050713 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:03:13,754] [INFO] [launch.py:256:main] process 1050714 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:03:13,754] [INFO] [launch.py:256:main] process 1077537 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:03:13,755] [INFO] [launch.py:256:main] process 1050715 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:03:13,755] [INFO] [launch.py:256:main] process 1077538 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:03:13,756] [INFO] [launch.py:256:main] process 1050716 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:03:13,756] [INFO] [launch.py:256:main] process 1077539 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:03:13,756] [INFO] [launch.py:256:main] process 1050717 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-064: [2024-07-08 06:03:13,757] [INFO] [launch.py:256:main] process 1050718 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:03:13,756] [INFO] [launch.py:256:main] process 1077540 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:03:13,757] [INFO] [launch.py:256:main] process 1077541 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:03:13,758] [INFO] [launch.py:256:main] process 1077542 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-055: [2024-07-08 06:03:13,758] [INFO] [launch.py:256:main] process 1077543 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:03:13,779] [INFO] [launch.py:139:main] 21 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-054: [2024-07-08 06:03:13,779] [INFO] [launch.py:139:main] 21 NCCL_SOCKET_IFNAME=eno1
ml-512-node-054: [2024-07-08 06:03:13,779] [INFO] [launch.py:139:main] 21 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-054: [2024-07-08 06:03:13,780] [INFO] [launch.py:139:main] 21 NCCL_P2P_LEVEL=NVL
ml-512-node-054: [2024-07-08 06:03:13,780] [INFO] [launch.py:139:main] 21 NCCL_DEBUG=WARN
ml-512-node-054: [2024-07-08 06:03:13,780] [INFO] [launch.py:139:main] 21 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-054: [2024-07-08 06:03:13,780] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-054: [2024-07-08 06:03:13,780] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=21
ml-512-node-054: [2024-07-08 06:03:13,780] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-054: [2024-07-08 06:03:13,780] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-054: [2024-07-08 06:03:13,780] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-054: [2024-07-08 06:03:13,780] [INFO] [launch.py:256:main] process 1053116 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:03:13,781] [INFO] [launch.py:256:main] process 1053117 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:03:13,782] [INFO] [launch.py:256:main] process 1053118 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:03:13,782] [INFO] [launch.py:256:main] process 1053119 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:03:13,783] [INFO] [launch.py:256:main] process 1053120 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:03:13,784] [INFO] [launch.py:256:main] process 1053121 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:03:13,784] [INFO] [launch.py:256:main] process 1053122 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-054: [2024-07-08 06:03:13,785] [INFO] [launch.py:256:main] process 1053123 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:139:main] 20 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:139:main] 20 NCCL_SOCKET_IFNAME=eno1
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:139:main] 20 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:139:main] 20 NCCL_P2P_LEVEL=NVL
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:139:main] 20 NCCL_DEBUG=WARN
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:139:main] 20 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=20
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-053: [2024-07-08 06:03:13,787] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-053: [2024-07-08 06:03:13,788] [INFO] [launch.py:256:main] process 1061460 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:03:13,789] [INFO] [launch.py:256:main] process 1061461 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:03:13,790] [INFO] [launch.py:256:main] process 1061462 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:03:13,790] [INFO] [launch.py:256:main] process 1061463 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:03:13,791] [INFO] [launch.py:256:main] process 1061464 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:03:13,791] [INFO] [launch.py:256:main] process 1061465 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:03:13,792] [INFO] [launch.py:256:main] process 1061466 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-053: [2024-07-08 06:03:13,793] [INFO] [launch.py:256:main] process 1061467 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:139:main] 25 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:139:main] 25 NCCL_SOCKET_IFNAME=eno1
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:139:main] 25 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:139:main] 25 NCCL_P2P_LEVEL=NVL
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:139:main] 25 NCCL_DEBUG=WARN
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:139:main] 25 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=25
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-058: [2024-07-08 06:03:13,823] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-058: [2024-07-08 06:03:13,824] [INFO] [launch.py:256:main] process 1052273 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:03:13,825] [INFO] [launch.py:256:main] process 1052274 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:03:13,825] [INFO] [launch.py:256:main] process 1052275 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:03:13,826] [INFO] [launch.py:256:main] process 1052276 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:03:13,827] [INFO] [launch.py:256:main] process 1052277 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:03:13,827] [INFO] [launch.py:256:main] process 1052278 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:03:13,828] [INFO] [launch.py:256:main] process 1052279 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-058: [2024-07-08 06:03:13,829] [INFO] [launch.py:256:main] process 1052280 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:139:main] 29 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:139:main] 29 NCCL_SOCKET_IFNAME=eno1
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:139:main] 29 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:139:main] 29 NCCL_P2P_LEVEL=NVL
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:139:main] 29 NCCL_DEBUG=WARN
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:139:main] 29 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=29
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-062: [2024-07-08 06:03:13,870] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-062: [2024-07-08 06:03:13,871] [INFO] [launch.py:256:main] process 1052260 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:03:13,872] [INFO] [launch.py:256:main] process 1052261 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:03:13,872] [INFO] [launch.py:256:main] process 1052262 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:03:13,873] [INFO] [launch.py:256:main] process 1052263 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:03:13,874] [INFO] [launch.py:256:main] process 1052264 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:03:13,874] [INFO] [launch.py:256:main] process 1052265 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:03:13,875] [INFO] [launch.py:256:main] process 1052266 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-062: [2024-07-08 06:03:13,875] [INFO] [launch.py:256:main] process 1052267 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:03:13,878] [INFO] [launch.py:139:main] 28 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-061: [2024-07-08 06:03:13,878] [INFO] [launch.py:139:main] 28 NCCL_SOCKET_IFNAME=eno1
ml-512-node-061: [2024-07-08 06:03:13,878] [INFO] [launch.py:139:main] 28 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-061: [2024-07-08 06:03:13,879] [INFO] [launch.py:139:main] 28 NCCL_P2P_LEVEL=NVL
ml-512-node-061: [2024-07-08 06:03:13,879] [INFO] [launch.py:139:main] 28 NCCL_DEBUG=WARN
ml-512-node-061: [2024-07-08 06:03:13,879] [INFO] [launch.py:139:main] 28 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-061: [2024-07-08 06:03:13,879] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-061: [2024-07-08 06:03:13,879] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=28
ml-512-node-061: [2024-07-08 06:03:13,879] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-061: [2024-07-08 06:03:13,879] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-061: [2024-07-08 06:03:13,879] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-061: [2024-07-08 06:03:13,880] [INFO] [launch.py:256:main] process 1058758 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:03:13,881] [INFO] [launch.py:256:main] process 1058759 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:03:13,881] [INFO] [launch.py:256:main] process 1058760 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:03:13,882] [INFO] [launch.py:256:main] process 1058761 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:03:13,883] [INFO] [launch.py:256:main] process 1058762 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:03:13,883] [INFO] [launch.py:256:main] process 1058763 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:03:13,884] [INFO] [launch.py:256:main] process 1058764 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-061: [2024-07-08 06:03:13,885] [INFO] [launch.py:256:main] process 1058765 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:139:main] 7 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:139:main] 7 NCCL_SOCKET_IFNAME=eno1
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:139:main] 7 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:139:main] 7 NCCL_P2P_LEVEL=NVL
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:139:main] 7 NCCL_DEBUG=WARN
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:139:main] 7 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=7
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-040: [2024-07-08 06:03:13,933] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-040: [2024-07-08 06:03:13,934] [INFO] [launch.py:256:main] process 1113526 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:03:13,934] [INFO] [launch.py:256:main] process 1113527 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:03:13,935] [INFO] [launch.py:256:main] process 1113528 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:03:13,936] [INFO] [launch.py:256:main] process 1113529 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:03:13,937] [INFO] [launch.py:256:main] process 1113530 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:03:13,937] [INFO] [launch.py:256:main] process 1113531 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:03:13,938] [INFO] [launch.py:256:main] process 1113532 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-040: [2024-07-08 06:03:13,939] [INFO] [launch.py:256:main] process 1113533 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:139:main] 23 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:139:main] 23 NCCL_SOCKET_IFNAME=eno1
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:139:main] 23 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:139:main] 23 NCCL_P2P_LEVEL=NVL
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:139:main] 23 NCCL_DEBUG=WARN
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:139:main] 23 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=23
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-056: [2024-07-08 06:03:14,358] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-056: [2024-07-08 06:03:14,359] [INFO] [launch.py:256:main] process 1069765 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:03:14,360] [INFO] [launch.py:256:main] process 1069766 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:03:14,360] [INFO] [launch.py:256:main] process 1069767 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:03:14,361] [INFO] [launch.py:256:main] process 1069768 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:03:14,362] [INFO] [launch.py:256:main] process 1069769 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:03:14,362] [INFO] [launch.py:256:main] process 1069770 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:03:14,363] [INFO] [launch.py:256:main] process 1069771 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-056: [2024-07-08 06:03:14,364] [INFO] [launch.py:256:main] process 1069772 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:139:main] 30 NCCL_IB_PCI_RELAXED_ORDERING=1
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:139:main] 30 NCCL_SOCKET_IFNAME=eno1
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:139:main] 30 NCCL_NET_GDR_LEVEL=PIX
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:139:main] 30 NCCL_P2P_LEVEL=NVL
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:139:main] 30 NCCL_DEBUG=WARN
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:139:main] 30 NCCL_IB_HCA==mlx5_1,mlx5_2,mlx5_3,mlx5_4,mlx5_5,mlx5_6,mlx5_7,mlx5_8
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:146:main] WORLD INFO DICT: {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-035': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-036': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-037': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-038': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-039': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-040': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-041': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-042': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-043': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-044': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-045': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-046': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-047': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-048': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-049': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-050': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-051': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-052': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-053': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-054': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-055': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-056': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-057': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-058': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-059': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-060': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-061': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-062': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-063': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-064': [0, 1, 2, 3, 4, 5, 6, 7]}
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:152:main] nnodes=32, num_local_procs=8, node_rank=30
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'ml-512-node-033': [0, 1, 2, 3, 4, 5, 6, 7], 'ml-512-node-034': [8, 9, 10, 11, 12, 13, 14, 15], 'ml-512-node-035': [16, 17, 18, 19, 20, 21, 22, 23], 'ml-512-node-036': [24, 25, 26, 27, 28, 29, 30, 31], 'ml-512-node-037': [32, 33, 34, 35, 36, 37, 38, 39], 'ml-512-node-038': [40, 41, 42, 43, 44, 45, 46, 47], 'ml-512-node-039': [48, 49, 50, 51, 52, 53, 54, 55], 'ml-512-node-040': [56, 57, 58, 59, 60, 61, 62, 63], 'ml-512-node-041': [64, 65, 66, 67, 68, 69, 70, 71], 'ml-512-node-042': [72, 73, 74, 75, 76, 77, 78, 79], 'ml-512-node-043': [80, 81, 82, 83, 84, 85, 86, 87], 'ml-512-node-044': [88, 89, 90, 91, 92, 93, 94, 95], 'ml-512-node-045': [96, 97, 98, 99, 100, 101, 102, 103], 'ml-512-node-046': [104, 105, 106, 107, 108, 109, 110, 111], 'ml-512-node-047': [112, 113, 114, 115, 116, 117, 118, 119], 'ml-512-node-048': [120, 121, 122, 123, 124, 125, 126, 127], 'ml-512-node-049': [128, 129, 130, 131, 132, 133, 134, 135], 'ml-512-node-050': [136, 137, 138, 139, 140, 141, 142, 143], 'ml-512-node-051': [144, 145, 146, 147, 148, 149, 150, 151], 'ml-512-node-052': [152, 153, 154, 155, 156, 157, 158, 159], 'ml-512-node-053': [160, 161, 162, 163, 164, 165, 166, 167], 'ml-512-node-054': [168, 169, 170, 171, 172, 173, 174, 175], 'ml-512-node-055': [176, 177, 178, 179, 180, 181, 182, 183], 'ml-512-node-056': [184, 185, 186, 187, 188, 189, 190, 191], 'ml-512-node-057': [192, 193, 194, 195, 196, 197, 198, 199], 'ml-512-node-058': [200, 201, 202, 203, 204, 205, 206, 207], 'ml-512-node-059': [208, 209, 210, 211, 212, 213, 214, 215], 'ml-512-node-060': [216, 217, 218, 219, 220, 221, 222, 223], 'ml-512-node-061': [224, 225, 226, 227, 228, 229, 230, 231], 'ml-512-node-062': [232, 233, 234, 235, 236, 237, 238, 239], 'ml-512-node-063': [240, 241, 242, 243, 244, 245, 246, 247], 'ml-512-node-064': [248, 249, 250, 251, 252, 253, 254, 255]})
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:164:main] dist_world_size=256
ml-512-node-063: [2024-07-08 06:03:14,763] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
ml-512-node-063: [2024-07-08 06:03:14,764] [INFO] [launch.py:256:main] process 1056519 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=0', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:03:14,765] [INFO] [launch.py:256:main] process 1056520 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=1', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:03:14,765] [INFO] [launch.py:256:main] process 1056521 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=2', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:03:14,766] [INFO] [launch.py:256:main] process 1056522 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=3', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:03:14,767] [INFO] [launch.py:256:main] process 1056523 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=4', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:03:14,767] [INFO] [launch.py:256:main] process 1056524 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=5', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:03:14,768] [INFO] [launch.py:256:main] process 1056525 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=6', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-063: [2024-07-08 06:03:14,769] [INFO] [launch.py:256:main] process 1056526 spawned with command: ['/usr/bin/python3', '-u', '/home/ubuntu/ml-1cc/benchmark/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/main.py', '--local_rank=7', '--data_path', 'Dahoas/full-hh-rlhf', '--data_split', '2,4,4', '--data_output_path', '/home/ubuntu/ml-1cc/benchmark/.cache/data_files/opt-350m_step1', '--model_name_or_path', 'facebook/opt-350m', '--per_device_train_batch_size', '24', '--per_device_eval_batch_size', '4', '--max_seq_len', '512', '--learning_rate', '1e-10', '--weight_decay', '0.1', '--disable_dropout', '--gradient_accumulation_steps', '1', '--lr_scheduler_type', 'cosine', '--seed', '1234', '--zero_stage', '0', '--deepspeed', '--num_warmup_steps', '10', '--num_train_epochs', '100', '--max_steps', '100']
ml-512-node-033: [2024-07-08 06:03:16,558] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:16,699] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:16,885] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:16,904] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 06:03:17,084] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:03:17,190] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:17,196] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [2024-07-08 06:03:17,232] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 06:03:17,265] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [2024-07-08 06:03:17,312] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [2024-07-08 06:03:17,319] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-033: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-033: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [2024-07-08 06:03:17,847] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [2024-07-08 06:03:17,961] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [2024-07-08 06:03:18,141] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-033: [2024-07-08 06:03:18,166] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:03:18,214] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [2024-07-08 06:03:18,252] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-033: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [2024-07-08 06:03:18,351] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [2024-07-08 06:03:18,363] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 06:03:18,377] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:03:18,391] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:03:18,393] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:03:18,401] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:03:18,429] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:03:18,438] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:03:18,444] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:03:18,475] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [2024-07-08 06:03:18,489] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 06:03:18,528] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [2024-07-08 06:03:18,529] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:18,534] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:03:18,549] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:03:18,558] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 06:03:18,588] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [2024-07-08 06:03:18,608] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:03:18,619] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:03:18,629] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:03:18,658] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:18,668] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: [2024-07-08 06:03:18,668] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
ml-512-node-035: [2024-07-08 06:03:18,674] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [2024-07-08 06:03:18,686] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [2024-07-08 06:03:18,704] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:03:18,708] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:03:18,738] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [2024-07-08 06:03:18,765] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:03:18,767] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [2024-07-08 06:03:18,776] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:03:18,790] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:03:18,794] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:03:18,795] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [2024-07-08 06:03:18,808] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:03:18,809] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:03:18,819] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:03:18,829] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:03:18,836] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [2024-07-08 06:03:18,853] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:03:18,853] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 06:03:18,853] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:03:18,855] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [2024-07-08 06:03:18,858] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:03:18,860] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:18,855] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:03:18,860] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:03:18,861] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-033: [2024-07-08 06:03:18,868] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:03:18,871] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [2024-07-08 06:03:18,882] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 06:03:18,882] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 06:03:18,885] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 06:03:18,888] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [2024-07-08 06:03:18,888] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:03:18,893] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:03:18,904] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:03:18,903] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [2024-07-08 06:03:18,918] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 06:03:18,930] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:03:18,931] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [2024-07-08 06:03:18,945] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:03:18,946] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 06:03:18,952] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [2024-07-08 06:03:18,954] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [2024-07-08 06:03:18,971] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 06:03:18,974] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [2024-07-08 06:03:18,997] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:03:19,001] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:03:19,000] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [2024-07-08 06:03:19,004] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [2024-07-08 06:03:19,007] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 06:03:19,013] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-040: [2024-07-08 06:03:19,015] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [2024-07-08 06:03:19,019] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 06:03:19,023] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:19,020] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:03:19,025] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:19,021] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [2024-07-08 06:03:19,034] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:03:19,044] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [2024-07-08 06:03:19,053] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:03:19,063] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [2024-07-08 06:03:19,067] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:03:19,068] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [2024-07-08 06:03:19,077] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [2024-07-08 06:03:19,089] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 06:03:19,089] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [2024-07-08 06:03:19,091] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [2024-07-08 06:03:19,094] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-033: [2024-07-08 06:03:19,091] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:03:19,099] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 06:03:19,102] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 06:03:19,103] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [2024-07-08 06:03:19,104] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:03:19,105] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [2024-07-08 06:03:19,109] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [2024-07-08 06:03:19,112] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [2024-07-08 06:03:19,115] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 06:03:19,121] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [2024-07-08 06:03:19,123] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [2024-07-08 06:03:19,128] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:03:19,134] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 06:03:19,135] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:03:19,137] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [2024-07-08 06:03:19,139] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:03:19,144] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 06:03:19,145] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:03:19,151] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:03:19,152] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:03:19,153] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:03:19,154] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:03:19,156] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [2024-07-08 06:03:19,158] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [2024-07-08 06:03:19,159] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 06:03:19,162] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [2024-07-08 06:03:19,168] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [2024-07-08 06:03:19,172] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [2024-07-08 06:03:19,176] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [2024-07-08 06:03:19,177] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [2024-07-08 06:03:19,177] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:03:19,182] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:03:19,183] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:03:19,184] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:03:19,185] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:03:19,187] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [2024-07-08 06:03:19,192] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [2024-07-08 06:03:19,192] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:03:19,193] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [2024-07-08 06:03:19,196] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [2024-07-08 06:03:19,198] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [2024-07-08 06:03:19,197] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 06:03:19,202] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 06:03:19,202] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [2024-07-08 06:03:19,214] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 06:03:19,216] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [2024-07-08 06:03:19,218] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [2024-07-08 06:03:19,222] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:03:19,223] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:03:19,224] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:03:19,227] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [2024-07-08 06:03:19,229] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [2024-07-08 06:03:19,231] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [2024-07-08 06:03:19,232] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:03:19,236] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [2024-07-08 06:03:19,248] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [2024-07-08 06:03:19,249] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [2024-07-08 06:03:19,252] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [2024-07-08 06:03:19,255] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [2024-07-08 06:03:19,260] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [2024-07-08 06:03:19,260] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [2024-07-08 06:03:19,265] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [2024-07-08 06:03:19,269] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 06:03:19,270] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [2024-07-08 06:03:19,276] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [2024-07-08 06:03:19,298] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [2024-07-08 06:03:19,313] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [2024-07-08 06:03:19,313] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 06:03:19,313] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 06:03:19,316] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [2024-07-08 06:03:19,319] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [2024-07-08 06:03:19,322] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [2024-07-08 06:03:19,326] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [2024-07-08 06:03:19,327] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [2024-07-08 06:03:19,349] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [2024-07-08 06:03:19,358] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [2024-07-08 06:03:19,366] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [2024-07-08 06:03:19,374] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [2024-07-08 06:03:19,388] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 06:03:19,393] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [2024-07-08 06:03:19,396] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 06:03:19,416] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [2024-07-08 06:03:19,429] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [2024-07-08 06:03:19,437] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [2024-07-08 06:03:19,442] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [2024-07-08 06:03:19,448] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 06:03:19,449] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 06:03:19,456] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 06:03:19,458] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 06:03:19,476] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [2024-07-08 06:03:19,483] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [2024-07-08 06:03:19,486] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [2024-07-08 06:03:19,487] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [2024-07-08 06:03:19,495] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 06:03:19,498] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [2024-07-08 06:03:19,502] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-063: [2024-07-08 06:03:19,517] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [2024-07-08 06:03:19,527] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [2024-07-08 06:03:19,531] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [2024-07-08 06:03:19,532] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [2024-07-08 06:03:19,535] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [2024-07-08 06:03:19,542] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:03:19,544] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [2024-07-08 06:03:19,558] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 06:03:19,563] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [2024-07-08 06:03:19,566] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [2024-07-08 06:03:19,573] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [2024-07-08 06:03:19,574] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [2024-07-08 06:03:19,592] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [2024-07-08 06:03:19,595] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [2024-07-08 06:03:19,601] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [2024-07-08 06:03:19,603] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 06:03:19,605] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [2024-07-08 06:03:19,614] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [2024-07-08 06:03:19,620] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-053: [2024-07-08 06:03:19,620] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [2024-07-08 06:03:19,621] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [2024-07-08 06:03:19,622] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [2024-07-08 06:03:19,632] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [2024-07-08 06:03:19,632] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [2024-07-08 06:03:19,641] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [2024-07-08 06:03:19,646] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [2024-07-08 06:03:19,651] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 06:03:19,652] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [2024-07-08 06:03:19,658] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [2024-07-08 06:03:19,676] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [2024-07-08 06:03:19,677] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [2024-07-08 06:03:19,681] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [2024-07-08 06:03:19,683] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-047: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [2024-07-08 06:03:19,699] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [2024-07-08 06:03:19,703] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-039: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [2024-07-08 06:03:19,707] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-047: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-047: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-047: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-039: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-039: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 06:03:19,725] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-036: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-036: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-042: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-042: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-045: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-045: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 06:03:19,774] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [2024-07-08 06:03:19,780] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-060: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-060: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [2024-07-08 06:03:19,785] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-046: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-046: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-046: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 06:03:19,793] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-037: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-037: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-041: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-041: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [2024-07-08 06:03:19,812] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-044: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-044: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-035: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-035: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-035: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-034: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-034: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-044: [2024-07-08 06:03:19,842] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:03:19,843] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:19,849] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-043: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-043: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [2024-07-08 06:03:19,869] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [2024-07-08 06:03:19,885] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [2024-07-08 06:03:19,911] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-048: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-048: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-056: [2024-07-08 06:03:19,943] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-038: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-038: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [2024-07-08 06:03:19,975] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [2024-07-08 06:03:19,986] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: 
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 06:03:19,999] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [2024-07-08 06:03:20,016] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:03:20,018] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [2024-07-08 06:03:20,029] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [2024-07-08 06:03:20,044] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [2024-07-08 06:03:20,096] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:03:20,097] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [2024-07-08 06:03:20,100] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-042: [2024-07-08 06:03:20,100] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-043: [2024-07-08 06:03:20,107] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-059: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-059: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-057: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-057: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [2024-07-08 06:03:20,123] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-045: [2024-07-08 06:03:20,125] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [2024-07-08 06:03:20,140] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [2024-07-08 06:03:20,151] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-050: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-050: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-037: [2024-07-08 06:03:20,175] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-054: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-054: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-049: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-049: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-049: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-042: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-036: [2024-07-08 06:03:20,199] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-052: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-052: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [2024-07-08 06:03:20,206] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-055: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-055: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-048: [2024-07-08 06:03:20,213] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-051: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-051: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [2024-07-08 06:03:20,221] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-047: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-041: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 06:03:20,259] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [2024-07-08 06:03:20,268] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [2024-07-08 06:03:20,274] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:03:20,275] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-053: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-053: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [2024-07-08 06:03:20,283] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 06:03:20,287] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-064: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-064: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-064: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-042: [2024-07-08 06:03:20,290] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-058: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [2024-07-08 06:03:20,302] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-060: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-034: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-034: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-036: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 06:03:20,328] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 06:03:20,331] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-062: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-043: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-062: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-062: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-038: [2024-07-08 06:03:20,347] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-038: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 06:03:20,371] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [2024-07-08 06:03:20,374] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-037: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-061: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-061: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [2024-07-08 06:03:20,396] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-048: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-048: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 06:03:20,401] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-060: [2024-07-08 06:03:20,409] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-045: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-036: [2024-07-08 06:03:20,419] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:03:20,428] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [2024-07-08 06:03:20,448] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-039: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-045: [2024-07-08 06:03:20,453] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-039: [2024-07-08 06:03:20,502] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-035: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [2024-07-08 06:03:20,516] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-038: [2024-07-08 06:03:20,524] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:03:20,529] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:03:20,529] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:03:20,533] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:03:20,535] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:03:20,538] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:03:20,543] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [2024-07-08 06:03:20,548] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:03:20,553] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:03:20,558] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 06:03:20,568] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-047: [2024-07-08 06:03:20,574] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:03:20,578] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:03:20,584] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:03:20,592] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:03:20,595] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:03:20,595] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-036: [2024-07-08 06:03:20,596] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:03:20,598] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:03:20,607] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-046: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [2024-07-08 06:03:20,622] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-059: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-054: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-041: [2024-07-08 06:03:20,627] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-056: [2024-07-08 06:03:20,639] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-035: [2024-07-08 06:03:20,642] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:03:20,659] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:03:20,658] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:03:20,662] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-045: [2024-07-08 06:03:20,667] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:03:20,670] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-044: [2024-07-08 06:03:20,684] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 06:03:20,685] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:03:20,686] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:03:20,691] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:03:20,698] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:03:20,699] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:20,702] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-059: [2024-07-08 06:03:20,703] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 06:03:20,704] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-046: [2024-07-08 06:03:20,717] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 06:03:20,720] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-057: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [2024-07-08 06:03:20,741] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:03:20,748] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-064: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 06:03:20,756] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:20,756] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-037: [2024-07-08 06:03:20,760] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-053: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-064: [2024-07-08 06:03:20,764] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-049: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-049: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [2024-07-08 06:03:20,777] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-039: [2024-07-08 06:03:20,798] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-050: [2024-07-08 06:03:20,807] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:03:20,815] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-050: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-050: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-053: [2024-07-08 06:03:20,828] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:03:20,837] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [2024-07-08 06:03:20,846] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-058: [2024-07-08 06:03:20,853] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-058: [2024-07-08 06:03:20,854] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:03:20,853] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:03:20,857] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-039: [2024-07-08 06:03:20,880] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:03:20,887] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:03:20,893] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:03:20,906] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-058: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-054: [2024-07-08 06:03:20,919] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:03:20,920] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:03:20,928] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-055: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-040: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-049: [2024-07-08 06:03:20,958] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-040: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-040: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 06:03:20,966] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:03:20,977] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-051: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-043: [2024-07-08 06:03:20,981] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:03:20,998] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-061: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [2024-07-08 06:03:21,008] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-061: [2024-07-08 06:03:21,015] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-060: [2024-07-08 06:03:21,023] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:03:21,025] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:03:21,030] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-034: [2024-07-08 06:03:21,032] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-035: [2024-07-08 06:03:21,033] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-052: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-053: [2024-07-08 06:03:21,040] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:03:21,045] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:03:21,045] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-042: [2024-07-08 06:03:21,048] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 06:03:21,060] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:03:21,060] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:03:21,065] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 06:03:21,068] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:03:21,075] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:03:21,076] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 06:03:21,076] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-034: [2024-07-08 06:03:21,082] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:03:21,082] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:03:21,087] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [2024-07-08 06:03:21,090] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-037: [2024-07-08 06:03:21,100] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:03:21,105] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [2024-07-08 06:03:21,106] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-042: [2024-07-08 06:03:21,109] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-045: [2024-07-08 06:03:21,112] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:03:21,116] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:03:21,116] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:03:21,116] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-047: [2024-07-08 06:03:21,122] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:03:21,125] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:03:21,126] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [2024-07-08 06:03:21,130] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-057: [2024-07-08 06:03:21,130] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:03:21,131] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:03:21,136] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:03:21,137] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:03:21,138] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-036: [2024-07-08 06:03:21,139] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-048: [2024-07-08 06:03:21,144] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-060: [2024-07-08 06:03:21,144] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-043: [2024-07-08 06:03:21,150] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:03:21,152] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:03:21,151] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:03:21,158] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:03:21,158] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-052: [2024-07-08 06:03:21,164] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:03:21,166] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:03:21,171] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-062: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-062: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-052: [2024-07-08 06:03:21,185] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-047: [2024-07-08 06:03:21,188] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:03:21,196] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:03:21,199] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-039: [2024-07-08 06:03:21,199] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:03:21,206] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:03:21,205] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 06:03:21,206] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:03:21,207] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:03:21,208] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-048: [2024-07-08 06:03:21,209] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-041: [2024-07-08 06:03:21,217] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-035: [2024-07-08 06:03:21,230] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 06:03:21,241] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [2024-07-08 06:03:21,266] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:03:21,268] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-063: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-063: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-051: [2024-07-08 06:03:21,268] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-046: [2024-07-08 06:03:21,272] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:03:21,273] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:03:21,283] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:03:21,288] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:03:21,291] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:03:21,292] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 06:03:21,293] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-055: [2024-07-08 06:03:21,310] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-038: [2024-07-08 06:03:21,315] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-059: [2024-07-08 06:03:21,344] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:03:21,358] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-038: [2024-07-08 06:03:21,366] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:03:21,366] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:03:21,371] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:03:21,373] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:03:21,387] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:03:21,393] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 06:03:21,407] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-044: [2024-07-08 06:03:21,411] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-044: [2024-07-08 06:03:21,416] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m async_io: please install the libaio-dev package with apt
ml-512-node-056: [93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
ml-512-node-056: [93m [WARNING] [0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
ml-512-node-057: [2024-07-08 06:03:21,434] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:03:21,435] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:03:21,437] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:03:21,450] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:03:21,463] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-058: [2024-07-08 06:03:21,492] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:03:21,496] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:03:21,510] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:03:21,513] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:03:21,513] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-062: [2024-07-08 06:03:21,517] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-040: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-057: [2024-07-08 06:03:21,525] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-049: [2024-07-08 06:03:21,531] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:03:21,548] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:03:21,554] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-059: [2024-07-08 06:03:21,583] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-053: [2024-07-08 06:03:21,596] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:03:21,600] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-058: [2024-07-08 06:03:21,602] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:03:21,608] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-050: [2024-07-08 06:03:21,615] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:03:21,615] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-059: [2024-07-08 06:03:21,616] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:03:21,622] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:03:21,630] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:03:21,631] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:03:21,639] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-054: [2024-07-08 06:03:21,640] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:03:21,663] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:03:21,665] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:03:21,670] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-064: [2024-07-08 06:03:21,671] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-051: [2024-07-08 06:03:21,695] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-052: [2024-07-08 06:03:21,696] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-055: [2024-07-08 06:03:21,710] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-040: [2024-07-08 06:03:21,747] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:03:21,760] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:03:21,787] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:03:21,805] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:03:21,810] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-061: [2024-07-08 06:03:21,849] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-063: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-062: [2024-07-08 06:03:21,878] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:03:21,912] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:03:21,925] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [93m [WARNING] [0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2
ml-512-node-056: [93m [WARNING] [0m please install triton==1.0.0 if you want to use sparse attention
ml-512-node-063: [2024-07-08 06:03:21,980] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:03:21,999] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:03:22,003] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:03:22,027] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:03:22,071] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:22,101] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:22,107] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:22,160] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:03:22,196] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:22,217] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:03:22,339] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:22,339] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-040: [2024-07-08 06:03:22,379] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:03:22,536] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-063: [2024-07-08 06:03:22,575] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:22,872] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:22,879] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-056: [2024-07-08 06:03:22,897] [INFO] [comm.py:637:init_distributed] cdb=None
ml-512-node-033: NCCL version 2.19.4+cuda12.2
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-057: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-057:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-063:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-035:   warnings.warn(
ml-512-node-049:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-063:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-049:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-063:   warnings.warn(
ml-512-node-049:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-039:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-036:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-035:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-035:   warnings.warn(
ml-512-node-036: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-036:   warnings.warn(
ml-512-node-035: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-035:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-047:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-062:   warnings.warn(
ml-512-node-047: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-060:   warnings.warn(
ml-512-node-034:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-037:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-045:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-055:   warnings.warn(
ml-512-node-050:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-048:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-048:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-051:   warnings.warn(
ml-512-node-039: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-039:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-047:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-064: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-060: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-060:   warnings.warn(
ml-512-node-054:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-049: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-049:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-063:   warnings.warn(
ml-512-node-063: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-063:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-033: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-033:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-055: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-055:   warnings.warn(
ml-512-node-050:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-038:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-038: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-051:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-052:   warnings.warn(
ml-512-node-052: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-064:   warnings.warn(
ml-512-node-052:   warnings.warn(
ml-512-node-048:   warnings.warn(
ml-512-node-059:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-048:   warnings.warn(
ml-512-node-034:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-061:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-053:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-042:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-053: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-053:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-051: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-051:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-044:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-037:   warnings.warn(
ml-512-node-044: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-044:   warnings.warn(
ml-512-node-058:   warnings.warn(
ml-512-node-061:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-054:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-034: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-034:   warnings.warn(
ml-512-node-038:   warnings.warn(
ml-512-node-050: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-050:   warnings.warn(
ml-512-node-046:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-062:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-041:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-048:   warnings.warn(
ml-512-node-048: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-048:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-054:   warnings.warn(
ml-512-node-061:   warnings.warn(
ml-512-node-061: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-061:   warnings.warn(
ml-512-node-056:   warnings.warn(
ml-512-node-042:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-042: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-056: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-056:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-041: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-041:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-058: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-058:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-059: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-059:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-054:   warnings.warn(
ml-512-node-045: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-045:   warnings.warn(
ml-512-node-042:   warnings.warn(
ml-512-node-040:   warnings.warn(
ml-512-node-040: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-040:   warnings.warn(
ml-512-node-062:   warnings.warn(
ml-512-node-062: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-062:   warnings.warn(
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-043: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-043:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-054:   warnings.warn(
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-037:   warnings.warn(
ml-512-node-054:   warnings.warn(
ml-512-node-046: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-054: /home/ubuntu/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
ml-512-node-046:   warnings.warn(
ml-512-node-054:   warnings.warn(
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: ninja: no work to do.
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Time to load fused_adam op: 0.1007988452911377 seconds
ml-512-node-056: Detected CUDA files, patching ldflags
ml-512-node-056: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-056: Building extension module fused_adam...
ml-512-node-056: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: ninja: no work to do.
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.10428690910339355 seconds
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: ninja: no work to do.
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.1884465217590332 seconds
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.2042849063873291 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.3075118064880371 seconds
ml-512-node-040: Time to load fused_adam op: 0.3018956184387207 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-040: Time to load fused_adam op: 0.2017195224761963 seconds
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-043: ninja: no work to do.
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.06387758255004883 seconds
ml-512-node-056: Detected CUDA files, patching ldflags
ml-512-node-056: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-056: Building extension module fused_adam...
ml-512-node-056: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Detected CUDA files, patching ldflags
ml-512-node-053: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-053: Building extension module fused_adam...
ml-512-node-053: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Detected CUDA files, patching ldflags
ml-512-node-052: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-052: Building extension module fused_adam...
ml-512-node-052: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: 
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: ninja: no work to do.
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: ninja: no work to do.
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.062410831451416016 seconds
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.3459148406982422 seconds
ml-512-node-036: ninja: no work to do.
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Detected CUDA files, patching ldflags
ml-512-node-063: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-063: Building extension module fused_adam...
ml-512-node-063: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-052: ninja: no work to do.
ml-512-node-036: Time to load fused_adam op: 0.06509947776794434 seconds
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Time to load fused_adam op: 0.06315398216247559 seconds
ml-512-node-055: Detected CUDA files, patching ldflags
ml-512-node-055: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-055: Building extension module fused_adam...
ml-512-node-055: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Time to load fused_adam op: 0.502220630645752 seconds
ml-512-node-059: Detected CUDA files, patching ldflags
ml-512-node-059: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: Building extension module fused_adam...
ml-512-node-059: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: ninja: no work to do.
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.06515860557556152 seconds
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: ninja: no work to do.
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: ninja: no work to do.
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-057: Detected CUDA files, patching ldflags
ml-512-node-057: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-057: Building extension module fused_adam...
ml-512-node-057: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Time to load fused_adam op: 0.06775879859924316 seconds
ml-512-node-053: Time to load fused_adam op: 0.10165071487426758 seconds
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-042: ninja: no work to do.
ml-512-node-055: Time to load fused_adam op: 0.06341314315795898 seconds
ml-512-node-059: ninja: no work to do.
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 0.30193114280700684 seconds
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Time to load fused_adam op: 0.0642232894897461 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-059: Time to load fused_adam op: 0.06334662437438965 seconds
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: ninja: no work to do.
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.06168413162231445 seconds
ml-512-node-052: Time to load fused_adam op: 0.10147714614868164 seconds
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Detected CUDA files, patching ldflags
ml-512-node-060: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-060: Building extension module fused_adam...
ml-512-node-060: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Time to load fused_adam op: 0.5021822452545166 seconds
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: ninja: no work to do.
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Time to load fused_adam op: 0.06173563003540039 seconds
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Detected CUDA files, patching ldflags
ml-512-node-062: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Building extension module fused_adam...
ml-512-node-062: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: ninja: no work to do.
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Time to load fused_adam op: 0.4028592109680176 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.06546926498413086 seconds
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-056: Time to load fused_adam op: 0.401965856552124 seconds
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Detected CUDA files, patching ldflags
ml-512-node-046: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Building extension module fused_adam...
ml-512-node-046: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: ninja: no work to do.
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Time to load fused_adam op: 0.10165119171142578 seconds
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: Detected CUDA files, patching ldflags
ml-512-node-055: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-055: Building extension module fused_adam...
ml-512-node-055: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Detected CUDA files, patching ldflags
ml-512-node-059: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-059: Building extension module fused_adam...
ml-512-node-059: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-049: Detected CUDA files, patching ldflags
ml-512-node-049: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-060: Time to load fused_adam op: 0.06344962120056152 seconds
ml-512-node-049: Building extension module fused_adam...
ml-512-node-049: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Detected CUDA files, patching ldflags
ml-512-node-051: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-051: Building extension module fused_adam...
ml-512-node-051: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: ninja: no work to do.
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.06198692321777344 seconds
ml-512-node-039: Time to load fused_adam op: 0.10150909423828125 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-039: Time to load fused_adam op: 0.10140776634216309 seconds
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Time to load fused_adam op: 0.10486674308776855 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Time to load fused_adam op: 0.10164928436279297 seconds
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Time to load fused_adam op: 0.10164046287536621 seconds
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Time to load fused_adam op: 0.1106114387512207 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-050: Detected CUDA files, patching ldflags
ml-512-node-050: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Building extension module fused_adam...
ml-512-node-050: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: ninja: no work to do.
ml-512-node-046: ninja: no work to do.
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: ninja: no work to do.
ml-512-node-051: ninja: no work to do.
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Time to load fused_adam op: 0.0650489330291748 seconds
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.09575510025024414 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-049: Time to load fused_adam op: 0.06261682510375977 seconds
ml-512-node-051: Time to load fused_adam op: 0.06206560134887695 seconds
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Detected CUDA files, patching ldflags
ml-512-node-052: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-052: Building extension module fused_adam...
ml-512-node-052: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Detected CUDA files, patching ldflags
ml-512-node-062: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Building extension module fused_adam...
ml-512-node-062: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-039: Time to load fused_adam op: 0.1015007495880127 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Time to load fused_adam op: 0.10156512260437012 seconds
ml-512-node-063: Time to load fused_adam op: 0.1014862060546875 seconds
ml-512-node-063: Time to load fused_adam op: 0.10139584541320801 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Detected CUDA files, patching ldflags
ml-512-node-034: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Building extension module fused_adam...
ml-512-node-034: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: ninja: no work to do.
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-050: ninja: no work to do.
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Detected CUDA files, patching ldflags
ml-512-node-057: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-057: Building extension module fused_adam...
ml-512-node-057: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Time to load fused_adam op: 0.10134339332580566 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Time to load fused_adam op: 0.06427764892578125 seconds
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-041: ninja: no work to do.
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Time to load fused_adam op: 0.10165596008300781 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-059: Time to load fused_adam op: 0.09334707260131836 seconds
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Time to load fused_adam op: 0.10127854347229004 seconds
ml-512-node-059: Time to load fused_adam op: 0.10138845443725586 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-033: ninja: no work to do.
ml-512-node-041: Time to load fused_adam op: 0.10887980461120605 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.06419873237609863 seconds
ml-512-node-060: Time to load fused_adam op: 0.1014704704284668 seconds
ml-512-node-051: Time to load fused_adam op: 0.10147881507873535 seconds
ml-512-node-038: ninja: no work to do.
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-034: ninja: no work to do.
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: ninja: no work to do.
ml-512-node-042: ninja: no work to do.
ml-512-node-051: Time to load fused_adam op: 0.10156989097595215 seconds
ml-512-node-038: Time to load fused_adam op: 0.06395339965820312 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: ninja: no work to do.
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.06329035758972168 seconds
ml-512-node-060: Time to load fused_adam op: 0.10168123245239258 seconds
ml-512-node-060: Time to load fused_adam op: 0.10664701461791992 seconds
ml-512-node-060: Time to load fused_adam op: 0.10781335830688477 seconds
ml-512-node-059: Time to load fused_adam op: 0.10134029388427734 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-045: ninja: no work to do.
ml-512-node-055: Time to load fused_adam op: 0.1308305263519287 seconds
ml-512-node-042: Time to load fused_adam op: 0.1034400463104248 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Time to load fused_adam op: 0.0795443058013916 seconds
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Time to load fused_adam op: 0.20166563987731934 seconds
ml-512-node-037: ninja: no work to do.
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.06255340576171875 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Time to load fused_adam op: 0.06341433525085449 seconds
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-043: ninja: no work to do.
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-042: Time to load fused_adam op: 0.20486879348754883 seconds
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Time to load fused_adam op: 0.2016315460205078 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Detected CUDA files, patching ldflags
ml-512-node-046: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-046: Building extension module fused_adam...
ml-512-node-046: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.10161328315734863 seconds
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: 
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Time to load fused_adam op: 0.14399218559265137 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: 
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Detected CUDA files, patching ldflags
ml-512-node-049: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-052: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Building extension module fused_adam...
ml-512-node-049: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-051: Time to load fused_adam op: 0.10150551795959473 seconds
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Time to load fused_adam op: 0.1166377067565918 seconds
ml-512-node-051: Time to load fused_adam op: 0.10149264335632324 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-050: Detected CUDA files, patching ldflags
ml-512-node-050: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Building extension module fused_adam...
ml-512-node-050: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: Time to load fused_adam op: 0.11777114868164062 seconds
ml-512-node-033: Time to load fused_adam op: 0.10152745246887207 seconds
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-057: ninja: no work to do.
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Time to load fused_adam op: 0.10249829292297363 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-041: Time to load fused_adam op: 0.10164451599121094 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Time to load fused_adam op: 0.10150742530822754 seconds
ml-512-node-038: Time to load fused_adam op: 0.10150361061096191 seconds
ml-512-node-057: Time to load fused_adam op: 0.10045504570007324 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-035: ninja: no work to do.
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Time to load fused_adam op: 0.06252551078796387 seconds
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: ninja: no work to do.
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Time to load fused_adam op: 0.10234522819519043 seconds
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-061: Detected CUDA files, patching ldflags
ml-512-node-061: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Building extension module fused_adam...
ml-512-node-061: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Time to load fused_adam op: 0.10085320472717285 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-064: Detected CUDA files, patching ldflags
ml-512-node-064: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-064: Building extension module fused_adam...
ml-512-node-064: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-041: Time to load fused_adam op: 0.11231565475463867 seconds
ml-512-node-041: Time to load fused_adam op: 0.10960721969604492 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-042: Time to load fused_adam op: 0.20244145393371582 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Time to load fused_adam op: 0.1015019416809082 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-059: Loading extension module fused_adam...
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-038: Time to load fused_adam op: 0.1016836166381836 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Time to load fused_adam op: 0.204176664352417 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-054: Detected CUDA files, patching ldflags
ml-512-node-054: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Time to load fused_adam op: 0.10148835182189941 seconds
ml-512-node-054: Building extension module fused_adam...
ml-512-node-054: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-059: Time to load fused_adam op: 0.20186734199523926 seconds
ml-512-node-053: Detected CUDA files, patching ldflags
ml-512-node-053: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-053: Building extension module fused_adam...
ml-512-node-053: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-062: Time to load fused_adam op: 0.10150694847106934 seconds
ml-512-node-052: ninja: no work to do.
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-047: ninja: no work to do.
ml-512-node-062: Time to load fused_adam op: 0.201676607131958 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-034: Time to load fused_adam op: 0.10230422019958496 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-052: Time to load fused_adam op: 0.17754387855529785 seconds
ml-512-node-047: Time to load fused_adam op: 0.06265425682067871 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-044: ninja: no work to do.
ml-512-node-055: Detected CUDA files, patching ldflags
ml-512-node-055: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-055: Building extension module fused_adam...
ml-512-node-055: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.10132455825805664 seconds
ml-512-node-038: Time to load fused_adam op: 0.10233497619628906 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.06314659118652344 seconds
ml-512-node-061: ninja: no work to do.
ml-512-node-062: Time to load fused_adam op: 0.10240650177001953 seconds
ml-512-node-048: Time to load fused_adam op: 0.10180449485778809 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-061: Time to load fused_adam op: 0.06307697296142578 seconds
ml-512-node-064: ninja: no work to do.
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.06444358825683594 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-042: Time to load fused_adam op: 0.10242223739624023 seconds
ml-512-node-054: ninja: no work to do.
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Time to load fused_adam op: 0.11530733108520508 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-050: ninja: no work to do.
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-054: Time to load fused_adam op: 0.06195998191833496 seconds
ml-512-node-049: ninja: no work to do.
ml-512-node-045: ninja: no work to do.
ml-512-node-038: Time to load fused_adam op: 0.12197184562683105 seconds
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-046: ninja: no work to do.
ml-512-node-050: Time to load fused_adam op: 0.11931204795837402 seconds
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-050: Time to load fused_adam op: 0.10138797760009766 seconds
ml-512-node-052: Time to load fused_adam op: 0.3032238483428955 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-049: Time to load fused_adam op: 0.1327500343322754 seconds
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: Time to load fused_adam op: 0.08064508438110352 seconds
ml-512-node-042: Time to load fused_adam op: 0.3017723560333252 seconds
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.20173931121826172 seconds
ml-512-node-046: Time to load fused_adam op: 0.13446044921875 seconds
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-052: Loading extension module fused_adam...Loading extension module fused_adam...
ml-512-node-052: 
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-052: Time to load fused_adam op: 0.31322669982910156 seconds
ml-512-node-052: Time to load fused_adam op: 0.10184788703918457 seconds
ml-512-node-052: Time to load fused_adam op: 0.10342979431152344 seconds
ml-512-node-037: ninja: no work to do.
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-046: Time to load fused_adam op: 0.2016310691833496 seconds
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-037: Time to load fused_adam op: 0.09902524948120117 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-046: Time to load fused_adam op: 0.20722317695617676 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-050: Time to load fused_adam op: 0.10190129280090332 seconds
ml-512-node-048: Time to load fused_adam op: 0.1016244888305664 seconds
ml-512-node-045: Time to load fused_adam op: 0.10151433944702148 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-053: ninja: no work to do.
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Time to load fused_adam op: 0.10161542892456055 seconds
ml-512-node-064: Time to load fused_adam op: 0.10161209106445312 seconds
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.10136246681213379 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-049: Time to load fused_adam op: 0.20163655281066895 seconds
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Time to load fused_adam op: 0.22170114517211914 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Detected CUDA files, patching ldflags
ml-512-node-051: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Time to load fused_adam op: 0.20165085792541504 seconds
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-052: Time to load fused_adam op: 0.10152697563171387 seconds
ml-512-node-052: Loading extension module fused_adam...
ml-512-node-051: Building extension module fused_adam...
ml-512-node-051: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: ninja: no work to do.
ml-512-node-045: Time to load fused_adam op: 0.10140156745910645 seconds
ml-512-node-045: Time to load fused_adam op: 0.10133481025695801 seconds
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.10142779350280762 seconds
ml-512-node-064: Time to load fused_adam op: 0.10231971740722656 seconds
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.143174409866333 seconds
ml-512-node-054: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Time to load fused_adam op: 0.20147085189819336 seconds
ml-512-node-049: Time to load fused_adam op: 0.2013847827911377 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-061: Time to load fused_adam op: 0.10209822654724121 seconds
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-054: Detected CUDA files, patching ldflags
ml-512-node-054: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-054: Building extension module fused_adam...
ml-512-node-054: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: Time to load fused_adam op: 0.20157194137573242 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: Time to load fused_adam op: 0.10153865814208984 seconds
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Time to load fused_adam op: 0.10678219795227051 seconds
ml-512-node-057: Detected CUDA files, patching ldflags
ml-512-node-057: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-057: Building extension module fused_adam...
ml-512-node-057: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: ninja: no work to do.
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.20180487632751465 seconds
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-033: ninja: no work to do.
ml-512-node-058: Detected CUDA files, patching ldflags
ml-512-node-058: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Time to load fused_adam op: 0.10155606269836426 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Building extension module fused_adam...
ml-512-node-058: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Time to load fused_adam op: 0.2073216438293457 seconds
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Time to load fused_adam op: 0.15738630294799805 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.14980769157409668 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-057: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-049: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: ninja: no work to do.
ml-512-node-046: Time to load fused_adam op: 0.3016798496246338 seconds
ml-512-node-046: Time to load fused_adam op: 0.30166101455688477 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-046: Time to load fused_adam op: 0.3049347400665283 seconds
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Time to load fused_adam op: 0.10166049003601074 seconds
ml-512-node-033: Time to load fused_adam op: 0.10167670249938965 seconds
ml-512-node-047: Time to load fused_adam op: 0.10680294036865234 seconds
ml-512-node-047: Time to load fused_adam op: 0.10146689414978027 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.1015009880065918 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-054: ninja: no work to do.
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: ninja: no work to do.
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Time to load fused_adam op: 0.06345891952514648 seconds
ml-512-node-054: Time to load fused_adam op: 0.09842467308044434 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-054: Time to load fused_adam op: 0.10238337516784668 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-035: ninja: no work to do.
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Time to load fused_adam op: 0.20172715187072754 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Time to load fused_adam op: 0.10143423080444336 seconds
ml-512-node-033: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Time to load fused_adam op: 0.11771631240844727 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.3019404411315918 seconds
ml-512-node-043: Time to load fused_adam op: 0.3017764091491699 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-054: Time to load fused_adam op: 0.20160794258117676 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-051: ninja: no work to do.
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Time to load fused_adam op: 0.10176467895507812 seconds
ml-512-node-055: Detected CUDA files, patching ldflags
ml-512-node-055: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-055: Building extension module fused_adam...
ml-512-node-055: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-054: Time to load fused_adam op: 0.20156598091125488 seconds
ml-512-node-054: Time to load fused_adam op: 0.10241198539733887 seconds
ml-512-node-054: Time to load fused_adam op: 0.2048192024230957 seconds
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-054: Loading extension module fused_adam...
ml-512-node-057: ninja: no work to do.
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-051: Time to load fused_adam op: 0.21220040321350098 seconds
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-057: Time to load fused_adam op: 0.2454371452331543 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-058: Time to load fused_adam op: 0.10162925720214844 seconds
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-037: ninja: no work to do.
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-058: Time to load fused_adam op: 0.10143256187438965 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Time to load fused_adam op: 0.10230803489685059 seconds
ml-512-node-057: Time to load fused_adam op: 0.11686825752258301 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.18550658226013184 seconds
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-058: Time to load fused_adam op: 0.10221242904663086 seconds
ml-512-node-058: Time to load fused_adam op: 0.10221552848815918 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.20249342918395996 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-055: ninja: no work to do.
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Time to load fused_adam op: 0.3017241954803467 seconds
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-050: Detected CUDA files, patching ldflags
ml-512-node-050: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Building extension module fused_adam...
ml-512-node-050: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-033: Detected CUDA files, patching ldflags
ml-512-node-033: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-033: Building extension module fused_adam...
ml-512-node-033: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-049: Detected CUDA files, patching ldflags
ml-512-node-049: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-049: Building extension module fused_adam...
ml-512-node-049: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-062: Detected CUDA files, patching ldflags
ml-512-node-062: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Building extension module fused_adam...
ml-512-node-062: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-058: Time to load fused_adam op: 0.11105847358703613 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.175797700881958 seconds
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-055: Time to load fused_adam op: 0.31027698516845703 seconds
ml-512-node-037: Time to load fused_adam op: 0.30171680450439453 seconds
ml-512-node-044: ninja: no work to do.
ml-512-node-044: Time to load fused_adam op: 0.164703369140625 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-057: Time to load fused_adam op: 0.5049004554748535 seconds
ml-512-node-046: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.3017446994781494 seconds
ml-512-node-058: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-057: Loading extension module fused_adam...
ml-512-node-057: Time to load fused_adam op: 0.5118086338043213 seconds
ml-512-node-055: Time to load fused_adam op: 0.3020458221435547 seconds
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-055: Time to load fused_adam op: 0.4018681049346924 seconds
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-036: ninja: no work to do.
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-036: Time to load fused_adam op: 0.23418784141540527 seconds
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-055: Time to load fused_adam op: 0.4019954204559326 seconds
ml-512-node-055: Loading extension module fused_adam...
ml-512-node-053: Detected CUDA files, patching ldflags
ml-512-node-053: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-053: Building extension module fused_adam...
ml-512-node-053: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Time to load fused_adam op: 0.10218095779418945 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-061: Detected CUDA files, patching ldflags
ml-512-node-061: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: Building extension module fused_adam...
ml-512-node-061: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Time to load fused_adam op: 0.21062278747558594 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.20632100105285645 seconds
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: ninja: no work to do.
ml-512-node-035: ninja: no work to do.
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-050: Time to load fused_adam op: 0.21343398094177246 seconds
ml-512-node-035: Time to load fused_adam op: 0.17387843132019043 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-048: ninja: no work to do.
ml-512-node-041: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: ninja: no work to do.
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.35329580307006836 seconds
ml-512-node-034: Detected CUDA files, patching ldflags
ml-512-node-034: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: Time to load fused_adam op: 0.1556863784790039 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-047: ninja: no work to do.
ml-512-node-036: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Building extension module fused_adam...
ml-512-node-034: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.20283913612365723 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-049: ninja: no work to do.
ml-512-node-061: Time to load fused_adam op: 0.10409379005432129 seconds
ml-512-node-047: Time to load fused_adam op: 0.22127580642700195 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-033: ninja: no work to do.
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Time to load fused_adam op: 0.28529834747314453 seconds
ml-512-node-033: [2024-07-08 06:03:56,587] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.4, git-hash=unknown, git-branch=unknown
ml-512-node-033: [2024-07-08 06:03:56,588] [INFO] [comm.py:662:init_distributed] Distributed backend already initialized
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: ninja: no work to do.
ml-512-node-050: Time to load fused_adam op: 0.20201444625854492 seconds
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.4020843505859375 seconds
ml-512-node-049: Time to load fused_adam op: 0.3350210189819336 seconds
ml-512-node-058: Detected CUDA files, patching ldflags
ml-512-node-058: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-053: ninja: no work to do.
ml-512-node-058: Building extension module fused_adam...
ml-512-node-058: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-061: Time to load fused_adam op: 0.10513687133789062 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Time to load fused_adam op: 0.33518457412719727 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-033: Time to load fused_adam op: 0.30227065086364746 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-061: Time to load fused_adam op: 0.20288944244384766 seconds
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-033: Time to load fused_adam op: 0.608558177947998 seconds
ml-512-node-033: Loading extension module fused_adam...
ml-512-node-046: Detected CUDA files, patching ldflags
ml-512-node-046: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.43573832511901855 seconds
ml-512-node-046: Building extension module fused_adam...
ml-512-node-046: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-062: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: ninja: no work to do.
ml-512-node-034: Time to load fused_adam op: 0.36893773078918457 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-049: Time to load fused_adam op: 0.4338996410369873 seconds
ml-512-node-049: Loading extension module fused_adam...
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.40322303771972656 seconds
ml-512-node-043: ninja: no work to do.
ml-512-node-043: Time to load fused_adam op: 0.2526719570159912 seconds
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-037: ninja: no work to do.
ml-512-node-036: Detected CUDA files, patching ldflags
ml-512-node-036: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-036: Building extension module fused_adam...
ml-512-node-036: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Detected CUDA files, patching ldflags
ml-512-node-060: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-060: Building extension module fused_adam...
ml-512-node-060: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-058: ninja: no work to do.
ml-512-node-037: Time to load fused_adam op: 0.3507659435272217 seconds
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-046: ninja: no work to do.
ml-512-node-058: Time to load fused_adam op: 0.3795204162597656 seconds
ml-512-node-058: Loading extension module fused_adam...
ml-512-node-041: Detected CUDA files, patching ldflags
ml-512-node-041: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: ninja: no work to do.
ml-512-node-046: Time to load fused_adam op: 0.40270233154296875 seconds
ml-512-node-046: Loading extension module fused_adam...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Building extension module fused_adam...
ml-512-node-041: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-035: Time to load fused_adam op: 0.18948936462402344 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-062: Detected CUDA files, patching ldflags
ml-512-node-062: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-062: Building extension module fused_adam...
ml-512-node-062: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-039: ninja: no work to do.
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-044: ninja: no work to do.
ml-512-node-039: Time to load fused_adam op: 0.2859382629394531 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-036: ninja: no work to do.
ml-512-node-064: Detected CUDA files, patching ldflags
ml-512-node-064: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-064: Building extension module fused_adam...
ml-512-node-064: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-038: Detected CUDA files, patching ldflags
ml-512-node-038: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-038: Building extension module fused_adam...
ml-512-node-038: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-036: Time to load fused_adam op: 0.37749719619750977 seconds
ml-512-node-036: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.37116360664367676 seconds
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: ninja: no work to do.
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.4114689826965332 seconds
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-048: Time to load fused_adam op: 0.9161853790283203 seconds
ml-512-node-060: ninja: no work to do.
ml-512-node-041: ninja: no work to do.
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Time to load fused_adam op: 0.39258599281311035 seconds
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-038: ninja: no work to do.
ml-512-node-034: Detected CUDA files, patching ldflags
ml-512-node-034: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Building extension module fused_adam...
ml-512-node-034: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-038: Loading extension module fused_adam...
ml-512-node-038: Time to load fused_adam op: 0.4539361000061035 seconds
ml-512-node-061: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-041: Time to load fused_adam op: 0.5589768886566162 seconds
ml-512-node-041: Loading extension module fused_adam...
ml-512-node-064: ninja: no work to do.
ml-512-node-062: ninja: no work to do.
ml-512-node-062: Loading extension module fused_adam...
ml-512-node-062: Time to load fused_adam op: 0.44544196128845215 seconds
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.38971495628356934 seconds
ml-512-node-047: ninja: no work to do.
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-047: Time to load fused_adam op: 0.39147090911865234 seconds
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-047: Time to load fused_adam op: 0.40192580223083496 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-061: Detected CUDA files, patching ldflags
ml-512-node-061: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-061: Building extension module fused_adam...
ml-512-node-061: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-034: ninja: no work to do.
ml-512-node-034: Time to load fused_adam op: 0.42502617835998535 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-045: ninja: no work to do.
ml-512-node-037: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.28159165382385254 seconds
ml-512-node-040: ninja: no work to do.
ml-512-node-040: Time to load fused_adam op: 0.9170176982879639 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-037: Detected CUDA files, patching ldflags
ml-512-node-037: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-037: Building extension module fused_adam...
ml-512-node-037: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-035: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-045: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-061: ninja: no work to do.
ml-512-node-061: Loading extension module fused_adam...
ml-512-node-061: Time to load fused_adam op: 0.5211293697357178 seconds
ml-512-node-037: ninja: no work to do.
ml-512-node-037: Loading extension module fused_adam...
ml-512-node-037: Time to load fused_adam op: 0.29601001739501953 seconds
ml-512-node-035: Detected CUDA files, patching ldflags
ml-512-node-035: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-035: Building extension module fused_adam...
ml-512-node-035: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-045: Detected CUDA files, patching ldflags
ml-512-node-045: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-045: Building extension module fused_adam...
ml-512-node-045: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-034: Detected CUDA files, patching ldflags
ml-512-node-034: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-034: Building extension module fused_adam...
ml-512-node-034: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-035: ninja: no work to do.
ml-512-node-045: ninja: no work to do.
ml-512-node-045: Loading extension module fused_adam...
ml-512-node-035: Time to load fused_adam op: 0.4046366214752197 seconds
ml-512-node-035: Loading extension module fused_adam...
ml-512-node-045: Time to load fused_adam op: 0.28940916061401367 seconds
ml-512-node-044: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-034: ninja: no work to do.
ml-512-node-034: Time to load fused_adam op: 0.3927333354949951 seconds
ml-512-node-034: Loading extension module fused_adam...
ml-512-node-063: Detected CUDA files, patching ldflags
ml-512-node-063: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-063: Building extension module fused_adam...
ml-512-node-063: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-050: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-042: Detected CUDA files, patching ldflags
ml-512-node-042: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-042: Building extension module fused_adam...
ml-512-node-042: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: Detected CUDA files, patching ldflags
ml-512-node-044: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-044: Building extension module fused_adam...
ml-512-node-044: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-056: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-043: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-060: Detected CUDA files, patching ldflags
ml-512-node-060: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-060: Building extension module fused_adam...
ml-512-node-060: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-063: ninja: no work to do.
ml-512-node-042: ninja: no work to do.
ml-512-node-063: Time to load fused_adam op: 0.3378419876098633 seconds
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-042: Loading extension module fused_adam...
ml-512-node-042: Time to load fused_adam op: 0.3094611167907715 seconds
ml-512-node-043: Detected CUDA files, patching ldflags
ml-512-node-043: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-043: Building extension module fused_adam...
ml-512-node-043: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-044: ninja: no work to do.
ml-512-node-044: Loading extension module fused_adam...
ml-512-node-044: Time to load fused_adam op: 0.392132043838501 seconds
ml-512-node-050: Detected CUDA files, patching ldflags
ml-512-node-050: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-050: Building extension module fused_adam...
ml-512-node-050: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-060: ninja: no work to do.
ml-512-node-060: Loading extension module fused_adam...
ml-512-node-060: Time to load fused_adam op: 0.41774678230285645 seconds
ml-512-node-043: ninja: no work to do.
ml-512-node-043: Loading extension module fused_adam...
ml-512-node-043: Time to load fused_adam op: 0.3534581661224365 seconds
ml-512-node-050: ninja: no work to do.
ml-512-node-050: Time to load fused_adam op: 0.4890005588531494 seconds
ml-512-node-050: Loading extension module fused_adam...
ml-512-node-063: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: Detected CUDA files, patching ldflags
ml-512-node-063: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-063: Building extension module fused_adam...
ml-512-node-063: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-051: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-063: ninja: no work to do.
ml-512-node-063: Loading extension module fused_adam...
ml-512-node-063: Time to load fused_adam op: 0.2480332851409912 seconds
ml-512-node-047: Detected CUDA files, patching ldflags
ml-512-node-047: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-047: Building extension module fused_adam...
ml-512-node-047: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-056: Detected CUDA files, patching ldflags
ml-512-node-056: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-056: Building extension module fused_adam...
ml-512-node-056: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-039: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-051: Detected CUDA files, patching ldflags
ml-512-node-051: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-051: Building extension module fused_adam...
ml-512-node-051: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-053: Detected CUDA files, patching ldflags
ml-512-node-053: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-053: Building extension module fused_adam...
ml-512-node-053: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-053: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-047: ninja: no work to do.
ml-512-node-047: Time to load fused_adam op: 0.48703503608703613 seconds
ml-512-node-047: Loading extension module fused_adam...
ml-512-node-051: ninja: no work to do.
ml-512-node-051: Loading extension module fused_adam...
ml-512-node-051: Time to load fused_adam op: 0.38575100898742676 seconds
ml-512-node-053: ninja: no work to do.
ml-512-node-040: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.3795461654663086 seconds
ml-512-node-053: Loading extension module fused_adam...
ml-512-node-053: Time to load fused_adam op: 0.20406007766723633 seconds
ml-512-node-039: Detected CUDA files, patching ldflags
ml-512-node-039: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-039: Building extension module fused_adam...
ml-512-node-039: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-056: ninja: no work to do.
ml-512-node-039: ninja: no work to do.
ml-512-node-039: Time to load fused_adam op: 0.4296145439147949 seconds
ml-512-node-039: Loading extension module fused_adam...
ml-512-node-056: Loading extension module fused_adam...
ml-512-node-056: Time to load fused_adam op: 1.2178401947021484 seconds
ml-512-node-040: Detected CUDA files, patching ldflags
ml-512-node-040: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-040: Building extension module fused_adam...
ml-512-node-040: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-040: ninja: no work to do.
ml-512-node-040: Time to load fused_adam op: 0.8016083240509033 seconds
ml-512-node-040: Loading extension module fused_adam...
ml-512-node-064: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-048: Using /home/ubuntu/.cache/torch_extensions/py310_cu122 as PyTorch extensions root...
ml-512-node-064: Detected CUDA files, patching ldflags
ml-512-node-064: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-064: Building extension module fused_adam...
ml-512-node-064: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-048: Detected CUDA files, patching ldflags
ml-512-node-048: Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py310_cu122/fused_adam/build.ninja...
ml-512-node-048: Building extension module fused_adam...
ml-512-node-048: Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ml-512-node-064: ninja: no work to do.
ml-512-node-064: Loading extension module fused_adam...
ml-512-node-064: Time to load fused_adam op: 0.6131901741027832 seconds
ml-512-node-048: ninja: no work to do.
ml-512-node-048: Time to load fused_adam op: 0.5185985565185547 seconds
ml-512-node-048: Loading extension module fused_adam...
ml-512-node-033: [2024-07-08 06:04:16,548] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
ml-512-node-033: [2024-07-08 06:04:16,549] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
ml-512-node-033: [2024-07-08 06:04:16,549] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
ml-512-node-033: [2024-07-08 06:04:16,558] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
ml-512-node-033: [2024-07-08 06:04:16,558] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 optimizer with dynamic loss scale
ml-512-node-033: [2024-07-08 06:04:16,752] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FP16_Optimizer
ml-512-node-033: [2024-07-08 06:04:16,753] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
ml-512-node-033: [2024-07-08 06:04:16,753] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7e675c3eb580>
ml-512-node-033: [2024-07-08 06:04:16,753] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:16,753] [INFO] [config.py:997:print] DeepSpeedEngine configuration:
ml-512-node-033: [2024-07-08 06:04:16,754] [INFO] [config.py:1001:print]   activation_checkpointing_config  {
ml-512-node-033:     "partition_activations": false, 
ml-512-node-033:     "contiguous_memory_optimization": false, 
ml-512-node-033:     "cpu_checkpointing": false, 
ml-512-node-033:     "number_checkpoints": null, 
ml-512-node-033:     "synchronize_checkpoint_boundary": false, 
ml-512-node-033:     "profile": false
ml-512-node-033: }
ml-512-node-033: [2024-07-08 06:04:16,754] [INFO] [config.py:1001:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
ml-512-node-033: [2024-07-08 06:04:16,754] [INFO] [config.py:1001:print]   amp_enabled .................. False
ml-512-node-033: [2024-07-08 06:04:16,754] [INFO] [config.py:1001:print]   amp_params ................... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   autotuning_config ............ {
ml-512-node-033:     "enabled": false, 
ml-512-node-033:     "start_step": null, 
ml-512-node-033:     "end_step": null, 
ml-512-node-033:     "metric_path": null, 
ml-512-node-033:     "arg_mappings": null, 
ml-512-node-033:     "metric": "throughput", 
ml-512-node-033:     "model_info": null, 
ml-512-node-033:     "results_dir": "autotuning_results", 
ml-512-node-033:     "exps_dir": "autotuning_exps", 
ml-512-node-033:     "overwrite": true, 
ml-512-node-033:     "fast": true, 
ml-512-node-033:     "start_profile_step": 3, 
ml-512-node-033:     "end_profile_step": 5, 
ml-512-node-033:     "tuner_type": "gridsearch", 
ml-512-node-033:     "tuner_early_stopping": 5, 
ml-512-node-033:     "tuner_num_trials": 50, 
ml-512-node-033:     "model_info_path": null, 
ml-512-node-033:     "mp_size": 1, 
ml-512-node-033:     "max_train_batch_size": null, 
ml-512-node-033:     "min_train_batch_size": 1, 
ml-512-node-033:     "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
ml-512-node-033:     "min_train_micro_batch_size_per_gpu": 1, 
ml-512-node-033:     "num_tuning_micro_batch_sizes": 3
ml-512-node-033: }
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   bfloat16_enabled ............. False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   bfloat16_immediate_grad_update  False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   checkpoint_parallel_write_pipeline  False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   checkpoint_tag_validation_enabled  True
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   checkpoint_tag_validation_fail  False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7e675c3e8430>
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   communication_data_type ...... None
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   curriculum_enabled_legacy .... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   curriculum_params_legacy ..... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   data_efficiency_enabled ...... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   dataloader_drop_last ......... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   disable_allgather ............ False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   dump_state ................... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'consecutive_hysteresis': False, 'min_scale': 1}
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   eigenvalue_enabled ........... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   eigenvalue_gas_boundary_resolution  1
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   eigenvalue_layer_name ........ bert.encoder.layer
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   eigenvalue_layer_num ......... 0
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   eigenvalue_max_iter .......... 100
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   eigenvalue_stability ......... 1e-06
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   eigenvalue_tol ............... 0.01
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   eigenvalue_verbose ........... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   elasticity_enabled ........... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   flops_profiler_config ........ {
ml-512-node-033:     "enabled": false, 
ml-512-node-033:     "recompute_fwd_factor": 0.0, 
ml-512-node-033:     "profile_step": 1, 
ml-512-node-033:     "module_depth": -1, 
ml-512-node-033:     "top_modules": 1, 
ml-512-node-033:     "detailed": true, 
ml-512-node-033:     "output_file": null
ml-512-node-033: }
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   fp16_auto_cast ............... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   fp16_enabled ................. True
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   fp16_master_weights_and_gradients  False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   global_rank .................. 0
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   grad_accum_dtype ............. None
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   gradient_accumulation_steps .. 1
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   gradient_clipping ............ 1.0
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   gradient_predivide_factor .... 1.0
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   graph_harvesting ............. False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   initial_dynamic_scale ........ 65536
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   load_universal_checkpoint .... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   loss_scale ................... 0
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   memory_breakdown ............. False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   mics_hierarchial_params_gather  False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   mics_shard_size .............. -1
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='step1_tensorboard/ds_tensorboard_logs/', job_name='step1_model_tensorboard') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   nebula_config ................ {
ml-512-node-033:     "enabled": false, 
ml-512-node-033:     "persistent_storage_path": null, 
ml-512-node-033:     "persistent_time_interval": 100, 
ml-512-node-033:     "num_of_version_in_retention": 2, 
ml-512-node-033:     "enable_nebula_load": true, 
ml-512-node-033:     "load_path": null
ml-512-node-033: }
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   optimizer_legacy_fusion ...... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   optimizer_name ............... None
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   optimizer_params ............. None
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   pld_enabled .................. False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   pld_params ................... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   prescale_gradients ........... False
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   scheduler_name ............... None
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   scheduler_params ............. None
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   seq_parallel_communication_data_type  torch.float32
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   sparse_attention ............. None
ml-512-node-033: [2024-07-08 06:04:16,755] [INFO] [config.py:1001:print]   sparse_gradients_enabled ..... False
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   steps_per_print .............. 10
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   timers_config ................ enabled=True synchronized=True
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   train_batch_size ............. 6144
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   train_micro_batch_size_per_gpu  24
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   use_data_before_expert_parallel_  False
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   use_node_local_storage ....... False
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   wall_clock_breakdown ......... False
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   weight_quantization_config ... None
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   world_size ................... 256
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   zero_allow_untested_optimizer  False
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=False pipeline_loading_checkpoint=False override_module_apply=True
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   zero_enabled ................. False
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   zero_force_ds_cpu_optimizer .. True
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:1001:print]   zero_optimization_stage ...... 0
ml-512-node-033: [2024-07-08 06:04:16,756] [INFO] [config.py:987:print_user_config]   json = {
ml-512-node-033:     "train_batch_size": 6.144000e+03, 
ml-512-node-033:     "train_micro_batch_size_per_gpu": 24, 
ml-512-node-033:     "steps_per_print": 10, 
ml-512-node-033:     "zero_optimization": {
ml-512-node-033:         "stage": 0, 
ml-512-node-033:         "offload_param": {
ml-512-node-033:             "device": "none"
ml-512-node-033:         }, 
ml-512-node-033:         "offload_optimizer": {
ml-512-node-033:             "device": "none"
ml-512-node-033:         }, 
ml-512-node-033:         "stage3_param_persistence_threshold": 1.000000e+04, 
ml-512-node-033:         "stage3_max_live_parameters": 3.000000e+07, 
ml-512-node-033:         "stage3_prefetch_bucket_size": 3.000000e+07, 
ml-512-node-033:         "memory_efficient_linear": false
ml-512-node-033:     }, 
ml-512-node-033:     "fp16": {
ml-512-node-033:         "enabled": true, 
ml-512-node-033:         "loss_scale_window": 100
ml-512-node-033:     }, 
ml-512-node-033:     "gradient_clipping": 1.0, 
ml-512-node-033:     "prescale_gradients": false, 
ml-512-node-033:     "wall_clock_breakdown": false, 
ml-512-node-033:     "hybrid_engine": {
ml-512-node-033:         "enabled": false, 
ml-512-node-033:         "max_out_tokens": 512, 
ml-512-node-033:         "inference_tp_size": 1, 
ml-512-node-033:         "release_inference_cache": false, 
ml-512-node-033:         "pin_parameters": true, 
ml-512-node-033:         "tp_gather_partition_size": 8
ml-512-node-033:     }, 
ml-512-node-033:     "tensorboard": {
ml-512-node-033:         "enabled": false, 
ml-512-node-033:         "output_path": "step1_tensorboard/ds_tensorboard_logs/", 
ml-512-node-033:         "job_name": "step1_model_tensorboard"
ml-512-node-033:     }
ml-512-node-033: }
ml-512-node-033: ***** Running training *****
ml-512-node-033: Beginning of Epoch 1/100, Total Micro Batches 3
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 65536, reducing to 32768.0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:04:17,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: [2024-07-08 06:04:17,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-033: [2024-07-08 06:04:17,809] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:17,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 0
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:17,810] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-033: Grad overflow on iteration 0
ml-512-node-047: Grad overflow on iteration 0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:17,810] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-057: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-046: Grad overflow on iteration 0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-046: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 0
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-055: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-036: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-038: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-038: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-047: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 0
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-064: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-041: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 0
ml-512-node-041: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-035: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 0
ml-512-node-035: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-044: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-058: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-054: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-053: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-054: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 0
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-062: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-061: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-042: [2024-07-08 06:04:17,812] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-051: Grad overflow on iteration 0
ml-512-node-051: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 0
ml-512-node-034: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 0
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-048: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-056: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-045: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-059: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-052: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-039: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: Grad overflow on iteration 0
ml-512-node-060: [2024-07-08 06:04:17,813] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-060: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 0
ml-512-node-037: [2024-07-08 06:04:17,814] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 65536 to 32768.0
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 1
ml-512-node-064: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-037: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-046: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-046: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 1
ml-512-node-039: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-057: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-057: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: Grad overflow on iteration 1
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-063: Grad overflow on iteration 1
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-056: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-063: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 1
ml-512-node-037: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 1
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-038: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-051: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-051: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 1
ml-512-node-041: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-061: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 1
ml-512-node-061: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-058: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-049: Grad overflow on iteration 1
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-051: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-055: Grad overflow on iteration 1
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 1
ml-512-node-049: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-044: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:17,999] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-036: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 1
ml-512-node-052: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 1
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-062: Grad overflow on iteration 1
ml-512-node-062: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-050: Grad overflow on iteration 1
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-050: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-047: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-047: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 1
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-060: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-033: Grad overflow on iteration 1
ml-512-node-033: [2024-07-08 06:04:17,996] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-053: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-048: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 1
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 1
ml-512-node-054: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: Grad overflow on iteration 1
ml-512-node-040: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-035: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-034: [2024-07-08 06:04:18,001] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 1
ml-512-node-045: [2024-07-08 06:04:18,000] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32768.0 to 16384.0
ml-512-node-064: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-064: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 2
ml-512-node-064: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-053: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-034: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:04:18,184] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 2
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-053: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-056: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-055: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-056: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-063: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-063: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 2
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-048: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 2
ml-512-node-046: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:04:18,184] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:04:18,184] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-035: Grad overflow on iteration 2
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-041: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,184] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-062: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 2
ml-512-node-033: [2024-07-08 06:04:18,182] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Beginning of Epoch 2/100, Total Micro Batches 3
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: Grad overflow on iteration 2
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-035: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-049: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 2
ml-512-node-047: Grad overflow on iteration 2
ml-512-node-047: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:04:18,184] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 2
ml-512-node-058: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-058: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: Grad overflow on iteration 2
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-057: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-054: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:04:18,184] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-059: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 2
ml-512-node-050: Grad overflow on iteration 2
ml-512-node-051: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-039: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-061: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:04:18,184] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,187] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-061: [2024-07-08 06:04:18,187] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-038: Grad overflow on iteration 2
ml-512-node-038: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-044: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-042: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: [2024-07-08 06:04:18,184] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 2
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-042: Grad overflow on iteration 2
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-036: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-045: Grad overflow on iteration 2
ml-512-node-045: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 2
ml-512-node-060: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,186] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-040: [2024-07-08 06:04:18,185] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-043: [2024-07-08 06:04:18,190] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 2
ml-512-node-043: [2024-07-08 06:04:18,190] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16384.0 to 8192.0
ml-512-node-060: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-060: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 3
ml-512-node-060: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-053: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-053: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 3
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-034: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-051: Grad overflow on iteration 3
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 3
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-045: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-040: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-055: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 3
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-050: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-052: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-047: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-035: Grad overflow on iteration 3
ml-512-node-038: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-038: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-058: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-036: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-035: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-046: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-061: Grad overflow on iteration 3
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 3
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-056: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-064: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-063: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-056: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-062: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-062: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 3
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-059: Grad overflow on iteration 3
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-033: [2024-07-08 06:04:18,369] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-054: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-049: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: Grad overflow on iteration 3
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 3
ml-512-node-037: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 3
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-044: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-048: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-041: Grad overflow on iteration 3
ml-512-node-041: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-043: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 3
ml-512-node-057: [2024-07-08 06:04:18,373] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-042: [2024-07-08 06:04:18,371] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 3
ml-512-node-042: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-057: [2024-07-08 06:04:18,372] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 8192.0 to 4096.0
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 4
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-036: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,554] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: Grad overflow on iteration 4
ml-512-node-033: Grad overflow on iteration 4
ml-512-node-033: [2024-07-08 06:04:18,555] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-036: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 4
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-061: Grad overflow on iteration 4
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-063: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 4
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: Grad overflow on iteration 4
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-039: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-043: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-043: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: Grad overflow on iteration 4
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 4
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-053: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-038: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-045: Grad overflow on iteration 4
ml-512-node-045: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-037: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 4
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-062: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 4
ml-512-node-034: Grad overflow on iteration 4
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-044: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-034: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-057: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 4
ml-512-node-047: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: Grad overflow on iteration 4
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-056: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-052: Grad overflow on iteration 4
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-052: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-060: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-056: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-035: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-055: Grad overflow on iteration 4
ml-512-node-055: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-054: Grad overflow on iteration 4
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 4
ml-512-node-041: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: Grad overflow on iteration 4
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-035: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 4
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: Grad overflow on iteration 4
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-059: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-054: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-050: [2024-07-08 06:04:18,559] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-064: [2024-07-08 06:04:18,558] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 4
ml-512-node-042: [2024-07-08 06:04:18,557] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 4096.0 to 2048.0
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 5
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:04:18,740] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 5
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-056: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 5
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-039: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-058: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 5
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-060: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-036: Grad overflow on iteration 5
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-036: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 5
ml-512-node-051: Grad overflow on iteration 5
ml-512-node-051: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-034: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-045: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 2048.0, reducing to 1024.0
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 5
ml-512-node-033: [2024-07-08 06:04:18,741] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-033: Beginning of Epoch 3/100, Total Micro Batches 3
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-059: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-061: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-060: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 5
ml-512-node-049: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-044: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 5
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-048: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 5
ml-512-node-062: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 5
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: Grad overflow on iteration 5
ml-512-node-057: Grad overflow on iteration 5
ml-512-node-057: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-063: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-064: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-040: Grad overflow on iteration 5
ml-512-node-040: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-052: Grad overflow on iteration 5
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-038: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 5
ml-512-node-035: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-047: Grad overflow on iteration 5
ml-512-node-047: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 5
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-050: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: Grad overflow on iteration 5
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-043: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,745] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-052: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-053: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-055: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 5
ml-512-node-042: [2024-07-08 06:04:18,743] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-042: [2024-07-08 06:04:18,744] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 2048.0 to 1024.0
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 6
ml-512-node-049: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 6
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 1024.0, reducing to 512.0
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-060: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 6
ml-512-node-035: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-051: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-033: [2024-07-08 06:04:18,928] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 6
ml-512-node-043: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 6
ml-512-node-042: [2024-07-08 06:04:18,931] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 6
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-036: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-039: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-040: Grad overflow on iteration 6
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 6
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-061: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-039: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-048: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 6
ml-512-node-048: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-064: Grad overflow on iteration 6
ml-512-node-037: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 6
ml-512-node-064: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-037: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-045: Grad overflow on iteration 6
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-040: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-052: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-044: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 6
ml-512-node-044: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 6
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-034: Grad overflow on iteration 6
ml-512-node-052: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: Grad overflow on iteration 6
ml-512-node-056: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-038: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 6
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 6
ml-512-node-041: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-057: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 6
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-055: Grad overflow on iteration 6
ml-512-node-046: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-055: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 6
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-050: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 6
ml-512-node-063: [2024-07-08 06:04:18,932] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-050: [2024-07-08 06:04:18,933] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 1024.0 to 512.0
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:04:19,111] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:04:19,111] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-043: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-041: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:04:19,111] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:04:19,111] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:04:19,112] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:04:19,111] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:04:19,112] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:04:19,111] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:04:19,112] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:04:19,111] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:04:19,112] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:04:19,112] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:04:19,112] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 512.0, reducing to 256.0
ml-512-node-033: [2024-07-08 06:04:19,112] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 7
ml-512-node-033: [2024-07-08 06:04:19,112] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:04:19,112] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:04:19,112] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-043: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-053: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-053: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 7
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-049: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-042: [2024-07-08 06:04:19,114] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 7
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 7
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-042: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 7
ml-512-node-048: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 7
ml-512-node-064: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-050: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 7
ml-512-node-050: [2024-07-08 06:04:19,117] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 7
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 7
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-037: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: Grad overflow on iteration 7
ml-512-node-060: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-039: Grad overflow on iteration 7
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-056: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-052: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-044: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-047: Grad overflow on iteration 7
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-062: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-047: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-046: Grad overflow on iteration 7
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-063: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: Grad overflow on iteration 7
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-054: Grad overflow on iteration 7
ml-512-node-054: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-059: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-063: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-051: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 7
ml-512-node-034: Grad overflow on iteration 7
ml-512-node-034: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 7
ml-512-node-055: [2024-07-08 06:04:19,115] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: Grad overflow on iteration 7
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-061: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-040: Grad overflow on iteration 7
ml-512-node-040: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-060: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-045: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-035: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-058: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 7
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-036: [2024-07-08 06:04:19,116] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 512.0 to 256.0
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 256.0, reducing to 128.0
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,296] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-033: Beginning of Epoch 4/100, Total Micro Batches 3
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 8
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-057: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 8
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-055: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-051: Grad overflow on iteration 8
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-051: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-056: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 8
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-056: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-049: Grad overflow on iteration 8
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 8
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 8
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-061: Grad overflow on iteration 8
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-048: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-062: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-043: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-047: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 8
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-058: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-050: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-063: Grad overflow on iteration 8
ml-512-node-037: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-059: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-063: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-037: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-042: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:04:19,299] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-042: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: Grad overflow on iteration 8
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-038: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 8
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-040: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 8
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-060: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-064: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 8
ml-512-node-039: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 8
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-053: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-044: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 8
ml-512-node-054: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-034: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-045: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-035: [2024-07-08 06:04:19,301] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 8
ml-512-node-041: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 8
ml-512-node-052: [2024-07-08 06:04:19,300] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 256.0 to 128.0
ml-512-node-046: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 9
ml-512-node-046: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 9
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-053: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-051: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-051: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 9
ml-512-node-042: [2024-07-08 06:04:19,486] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-043: Grad overflow on iteration 9
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-060: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-060: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: Grad overflow on iteration 9
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-036: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-038: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-037: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-041: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: Grad overflow on iteration 9
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-041: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 9
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: Grad overflow on iteration 9
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 9
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-049: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 9
ml-512-node-054: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 9
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-047: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-055: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-056: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-063: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-059: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-034: Grad overflow on iteration 9
ml-512-node-035: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 128.0, reducing to 64.0
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-039: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-039: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,483] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,484] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=10, lr=[0.0, 0.0], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-044: Grad overflow on iteration 9
ml-512-node-044: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-044: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-040: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-057: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: Grad overflow on iteration 9
ml-512-node-058: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-058: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 9
ml-512-node-050: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: Grad overflow on iteration 9
ml-512-node-062: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-033: [2024-07-08 06:04:19,484] [INFO] [timer.py:258:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=33244.80726669679, CurrSamplesPerSec=33374.0037919995, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 9
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-050: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-034: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-048: [2024-07-08 06:04:19,488] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-062: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 9
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-045: [2024-07-08 06:04:19,487] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 128.0 to 64.0
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 10
ml-512-node-064: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:04:19,672] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-056: Grad overflow on iteration 10
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:04:19,672] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-060: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-056: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,672] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 10
ml-512-node-060: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-053: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,672] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:04:19,672] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-062: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-046: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-063: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-058: Grad overflow on iteration 10
ml-512-node-042: [2024-07-08 06:04:19,672] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-059: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-035: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-058: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 64.0, reducing to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,669] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: Grad overflow on iteration 10
ml-512-node-048: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 10
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: Grad overflow on iteration 10
ml-512-node-037: Grad overflow on iteration 10
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-039: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-037: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 10
ml-512-node-041: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-052: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-047: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 10
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-057: Grad overflow on iteration 10
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-054: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-036: Grad overflow on iteration 10
ml-512-node-055: Grad overflow on iteration 10
ml-512-node-036: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-048: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: Grad overflow on iteration 10
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-059: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 10
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-042: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: Grad overflow on iteration 10
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-044: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-051: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 10
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-045: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-050: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: Grad overflow on iteration 10
ml-512-node-055: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-057: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-041: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-043: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-038: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 10
ml-512-node-040: [2024-07-08 06:04:19,673] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 10
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-061: [2024-07-08 06:04:19,674] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 64.0 to 32.0
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-056: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-060: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-048: [2024-07-08 06:04:19,858] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 11
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-059: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 11
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-041: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-064: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-062: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 11
ml-512-node-057: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-063: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-056: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-048: [2024-07-08 06:04:19,858] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: Grad overflow on iteration 11
ml-512-node-046: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-042: Grad overflow on iteration 11
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-055: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-055: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-039: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-052: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-052: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-045: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 32.0, reducing to 16.0
ml-512-node-044: Grad overflow on iteration 11
ml-512-node-043: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-053: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-044: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-050: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-051: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:19,856] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-038: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-033: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:04:19,853] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 11
ml-512-node-061: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: Grad overflow on iteration 11
ml-512-node-061: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: Beginning of Epoch 5/100, Total Micro Batches 3
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: Grad overflow on iteration 11
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 11
ml-512-node-037: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:04:19,858] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-034: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 11
ml-512-node-034: [2024-07-08 06:04:19,858] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-054: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-036: [2024-07-08 06:04:19,857] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 32.0 to 16.0
ml-512-node-033: [2024-07-08 06:04:20,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:04:20,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:04:20,037] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 16.0, reducing to 8.0
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: Grad overflow on iteration 12
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-033: [2024-07-08 06:04:20,038] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-037: Grad overflow on iteration 12
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-037: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-044: Grad overflow on iteration 12
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-044: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-064: Grad overflow on iteration 12
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-064: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-040: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-040: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-061: Grad overflow on iteration 12
ml-512-node-061: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-047: Grad overflow on iteration 12
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-055: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-047: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-063: Grad overflow on iteration 12
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-063: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-038: Grad overflow on iteration 12
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-038: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: Grad overflow on iteration 12
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-041: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-036: Grad overflow on iteration 12
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-060: Grad overflow on iteration 12
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-035: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-036: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: Grad overflow on iteration 12
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: Grad overflow on iteration 12
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: Grad overflow on iteration 12
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-045: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-053: Grad overflow on iteration 12
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-053: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: Grad overflow on iteration 12
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-034: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-046: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-060: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-049: Grad overflow on iteration 12
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: Grad overflow on iteration 12
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-052: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-062: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-059: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-051: Grad overflow on iteration 12
ml-512-node-051: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-039: Grad overflow on iteration 12
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-039: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-049: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-048: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:04:20,040] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-042: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: Grad overflow on iteration 12
ml-512-node-042: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: Grad overflow on iteration 12
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: Grad overflow on iteration 12
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-043: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-050: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-042: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-056: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-057: [2024-07-08 06:04:20,041] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-058: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-058: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:392:_update_scale] 
ml-512-node-054: Grad overflow on iteration 12
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-054: [2024-07-08 06:04:20,042] [INFO] [fused_optimizer.py:393:_update_scale] Reducing dynamic loss scale from 16.0 to 8.0
ml-512-node-033: Beginning of Epoch 6/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 7/100, Total Micro Batches 3
ml-512-node-033: [2024-07-08 06:04:21,524] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=13, lr=[7e-11, 7e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:21,528] [INFO] [timer.py:258:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=31459.697252399834, CurrSamplesPerSec=29588.90261422299, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 8/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 9/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 10/100, Total Micro Batches 3
ml-512-node-033: [2024-07-08 06:04:23,599] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=13, lr=[9.985630828985835e-11, 9.985630828985835e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:23,603] [INFO] [timer.py:258:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=30814.746799341287, CurrSamplesPerSec=29724.259859140308, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 11/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 12/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 13/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 14/100, Total Micro Batches 3
ml-512-node-033: [2024-07-08 06:04:25,671] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=13, lr=[9.915449963090551e-11, 9.915449963090551e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:25,675] [INFO] [timer.py:258:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=30534.617544283497, CurrSamplesPerSec=29629.046316864195, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 15/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 16/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 17/100, Total Micro Batches 3
ml-512-node-033: [2024-07-08 06:04:27,740] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=13, lr=[9.787639940616788e-11, 9.787639940616788e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:27,744] [INFO] [timer.py:258:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=30377.742084433998, CurrSamplesPerSec=29815.22262780901, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 18/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 19/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 20/100, Total Micro Batches 3
ml-512-node-033: [2024-07-08 06:04:29,806] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=13, lr=[9.603699217220239e-11, 9.603699217220239e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:29,810] [INFO] [timer.py:258:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=30285.71633820519, CurrSamplesPerSec=29781.902561471146, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 21/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 22/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 23/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 24/100, Total Micro Batches 3
ml-512-node-033: [2024-07-08 06:04:31,871] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=13, lr=[9.365784329704114e-11, 9.365784329704114e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:31,875] [INFO] [timer.py:258:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=30223.74195437832, CurrSamplesPerSec=29870.033389318338, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 25/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 26/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 27/100, Total Micro Batches 3
ml-512-node-033: [2024-07-08 06:04:33,936] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=13, lr=[9.076684612596891e-11, 9.076684612596891e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:33,940] [INFO] [timer.py:258:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=30176.07928019551, CurrSamplesPerSec=29716.958832992186, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 28/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 29/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 30/100, Total Micro Batches 3
ml-512-node-033: [2024-07-08 06:04:36,007] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=13, lr=[8.739789495755253e-11, 8.739789495755253e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:36,011] [INFO] [timer.py:258:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=30130.597239418592, CurrSamplesPerSec=29567.209148579514, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 31/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 32/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 33/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 34/100, Total Micro Batches 3
ml-512-node-033: [2024-07-08 06:04:38,074] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=13, lr=[8.35904876639803e-11, 8.35904876639803e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:38,078] [INFO] [timer.py:258:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=30101.230829494238, CurrSamplesPerSec=29736.8136663451, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: Beginning of Epoch 35/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 36/100, Total Micro Batches 3
ml-512-node-033: Beginning of Epoch 37/100, Total Micro Batches 3
ml-512-node-033: [2024-07-08 06:04:40,139] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=13, lr=[7.938926261462367e-11, 7.938926261462367e-11], mom=[(0.9, 0.95), (0.9, 0.95)]
ml-512-node-033: [2024-07-08 06:04:40,143] [INFO] [timer.py:258:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=30077.53996244915, CurrSamplesPerSec=29789.097796144844, MemAllocated=5.53GB, MaxMemAllocated=33.78GB
ml-512-node-033: ======================================================================
ml-512-node-033: Execution time: 20.6593 seconds for 100 steps
ml-512-node-033: Throughput: 29739.6137 samples/sec
ml-512-node-056: [2024-07-08 06:04:43,476] [INFO] [launch.py:351:main] Process 1069772 exits successfully.
ml-512-node-060: [2024-07-08 06:04:43,551] [INFO] [launch.py:351:main] Process 1053127 exits successfully.
ml-512-node-052: [2024-07-08 06:04:43,840] [INFO] [launch.py:351:main] Process 1055141 exits successfully.
ml-512-node-052: [2024-07-08 06:04:43,840] [INFO] [launch.py:351:main] Process 1055137 exits successfully.
ml-512-node-052: [2024-07-08 06:04:43,840] [INFO] [launch.py:351:main] Process 1055143 exits successfully.
ml-512-node-051: [2024-07-08 06:04:43,843] [INFO] [launch.py:351:main] Process 1059697 exits successfully.
ml-512-node-059: [2024-07-08 06:04:43,861] [INFO] [launch.py:351:main] Process 1056658 exits successfully.
ml-512-node-059: [2024-07-08 06:04:43,861] [INFO] [launch.py:351:main] Process 1056653 exits successfully.
ml-512-node-059: [2024-07-08 06:04:43,861] [INFO] [launch.py:351:main] Process 1056651 exits successfully.
ml-512-node-064: [2024-07-08 06:04:43,869] [INFO] [launch.py:351:main] Process 1050716 exits successfully.
ml-512-node-064: [2024-07-08 06:04:43,869] [INFO] [launch.py:351:main] Process 1050711 exits successfully.
ml-512-node-063: [2024-07-08 06:04:43,880] [INFO] [launch.py:351:main] Process 1056521 exits successfully.
ml-512-node-055: [2024-07-08 06:04:43,879] [INFO] [launch.py:351:main] Process 1077541 exits successfully.
ml-512-node-055: [2024-07-08 06:04:43,880] [INFO] [launch.py:351:main] Process 1077538 exits successfully.
ml-512-node-055: [2024-07-08 06:04:43,880] [INFO] [launch.py:351:main] Process 1077540 exits successfully.
ml-512-node-049: [2024-07-08 06:04:43,881] [INFO] [launch.py:351:main] Process 1063210 exits successfully.
ml-512-node-049: [2024-07-08 06:04:43,882] [INFO] [launch.py:351:main] Process 1063209 exits successfully.
ml-512-node-054: [2024-07-08 06:04:43,887] [INFO] [launch.py:351:main] Process 1053120 exits successfully.
ml-512-node-054: [2024-07-08 06:04:43,887] [INFO] [launch.py:351:main] Process 1053121 exits successfully.
ml-512-node-054: [2024-07-08 06:04:43,888] [INFO] [launch.py:351:main] Process 1053117 exits successfully.
ml-512-node-057: [2024-07-08 06:04:43,888] [INFO] [launch.py:351:main] Process 1059196 exits successfully.
ml-512-node-057: [2024-07-08 06:04:43,888] [INFO] [launch.py:351:main] Process 1059198 exits successfully.
ml-512-node-053: [2024-07-08 06:04:43,899] [INFO] [launch.py:351:main] Process 1061463 exits successfully.
ml-512-node-058: [2024-07-08 06:04:43,935] [INFO] [launch.py:351:main] Process 1052278 exits successfully.
ml-512-node-058: [2024-07-08 06:04:43,935] [INFO] [launch.py:351:main] Process 1052274 exits successfully.
ml-512-node-062: [2024-07-08 06:04:43,987] [INFO] [launch.py:351:main] Process 1052266 exits successfully.
ml-512-node-062: [2024-07-08 06:04:43,987] [INFO] [launch.py:351:main] Process 1052265 exits successfully.
ml-512-node-062: [2024-07-08 06:04:43,987] [INFO] [launch.py:351:main] Process 1052263 exits successfully.
ml-512-node-061: [2024-07-08 06:04:44,014] [INFO] [launch.py:351:main] Process 1058763 exits successfully.
ml-512-node-061: [2024-07-08 06:04:44,014] [INFO] [launch.py:351:main] Process 1058761 exits successfully.
ml-512-node-061: [2024-07-08 06:04:44,014] [INFO] [launch.py:351:main] Process 1058759 exits successfully.
ml-512-node-040: [2024-07-08 06:04:44,058] [INFO] [launch.py:351:main] Process 1113530 exits successfully.
ml-512-node-040: [2024-07-08 06:04:44,058] [INFO] [launch.py:351:main] Process 1113532 exits successfully.
ml-512-node-040: [2024-07-08 06:04:44,058] [INFO] [launch.py:351:main] Process 1113531 exits successfully.
ml-512-node-040: [2024-07-08 06:04:44,058] [INFO] [launch.py:351:main] Process 1113533 exits successfully.
ml-512-node-040: [2024-07-08 06:04:44,058] [INFO] [launch.py:351:main] Process 1113528 exits successfully.
ml-512-node-040: [2024-07-08 06:04:44,058] [INFO] [launch.py:351:main] Process 1113526 exits successfully.
ml-512-node-045: [2024-07-08 06:04:44,392] [INFO] [launch.py:351:main] Process 1061693 exits successfully.
ml-512-node-045: [2024-07-08 06:04:44,392] [INFO] [launch.py:351:main] Process 1061692 exits successfully.
ml-512-node-045: [2024-07-08 06:04:44,392] [INFO] [launch.py:351:main] Process 1061690 exits successfully.
ml-512-node-045: [2024-07-08 06:04:44,392] [INFO] [launch.py:351:main] Process 1061691 exits successfully.
ml-512-node-045: [2024-07-08 06:04:44,393] [INFO] [launch.py:351:main] Process 1061689 exits successfully.
ml-512-node-036: [2024-07-08 06:04:44,417] [INFO] [launch.py:351:main] Process 1058819 exits successfully.
ml-512-node-036: [2024-07-08 06:04:44,417] [INFO] [launch.py:351:main] Process 1058821 exits successfully.
ml-512-node-036: [2024-07-08 06:04:44,417] [INFO] [launch.py:351:main] Process 1058820 exits successfully.
ml-512-node-036: [2024-07-08 06:04:44,417] [INFO] [launch.py:351:main] Process 1058818 exits successfully.
ml-512-node-036: [2024-07-08 06:04:44,417] [INFO] [launch.py:351:main] Process 1058816 exits successfully.
ml-512-node-036: [2024-07-08 06:04:44,417] [INFO] [launch.py:351:main] Process 1058822 exits successfully.
ml-512-node-036: [2024-07-08 06:04:44,417] [INFO] [launch.py:351:main] Process 1058817 exits successfully.
ml-512-node-036: [2024-07-08 06:04:44,417] [INFO] [launch.py:351:main] Process 1058815 exits successfully.
ml-512-node-042: [2024-07-08 06:04:44,423] [INFO] [launch.py:351:main] Process 1057925 exits successfully.
ml-512-node-042: [2024-07-08 06:04:44,423] [INFO] [launch.py:351:main] Process 1057926 exits successfully.
ml-512-node-042: [2024-07-08 06:04:44,423] [INFO] [launch.py:351:main] Process 1057922 exits successfully.
ml-512-node-042: [2024-07-08 06:04:44,423] [INFO] [launch.py:351:main] Process 1057928 exits successfully.
ml-512-node-042: [2024-07-08 06:04:44,423] [INFO] [launch.py:351:main] Process 1057923 exits successfully.
ml-512-node-042: [2024-07-08 06:04:44,423] [INFO] [launch.py:351:main] Process 1057921 exits successfully.
ml-512-node-043: [2024-07-08 06:04:44,457] [INFO] [launch.py:351:main] Process 1061741 exits successfully.
ml-512-node-043: [2024-07-08 06:04:44,457] [INFO] [launch.py:351:main] Process 1061737 exits successfully.
ml-512-node-043: [2024-07-08 06:04:44,457] [INFO] [launch.py:351:main] Process 1061738 exits successfully.
ml-512-node-043: [2024-07-08 06:04:44,457] [INFO] [launch.py:351:main] Process 1061736 exits successfully.
ml-512-node-043: [2024-07-08 06:04:44,457] [INFO] [launch.py:351:main] Process 1061740 exits successfully.
ml-512-node-034: [2024-07-08 06:04:44,469] [INFO] [launch.py:351:main] Process 1059481 exits successfully.
ml-512-node-034: [2024-07-08 06:04:44,470] [INFO] [launch.py:351:main] Process 1059483 exits successfully.
ml-512-node-034: [2024-07-08 06:04:44,470] [INFO] [launch.py:351:main] Process 1059482 exits successfully.
ml-512-node-034: [2024-07-08 06:04:44,470] [INFO] [launch.py:351:main] Process 1059480 exits successfully.
ml-512-node-034: [2024-07-08 06:04:44,470] [INFO] [launch.py:351:main] Process 1059478 exits successfully.
ml-512-node-034: [2024-07-08 06:04:44,470] [INFO] [launch.py:351:main] Process 1059484 exits successfully.
ml-512-node-034: [2024-07-08 06:04:44,470] [INFO] [launch.py:351:main] Process 1059479 exits successfully.
ml-512-node-034: [2024-07-08 06:04:44,470] [INFO] [launch.py:351:main] Process 1059477 exits successfully.
ml-512-node-048: [2024-07-08 06:04:44,476] [INFO] [launch.py:351:main] Process 1056110 exits successfully.
ml-512-node-056: [2024-07-08 06:04:44,477] [INFO] [launch.py:351:main] Process 1069767 exits successfully.
ml-512-node-056: [2024-07-08 06:04:44,477] [INFO] [launch.py:351:main] Process 1069765 exits successfully.
ml-512-node-056: [2024-07-08 06:04:44,477] [INFO] [launch.py:351:main] Process 1069769 exits successfully.
ml-512-node-056: [2024-07-08 06:04:44,477] [INFO] [launch.py:351:main] Process 1069771 exits successfully.
ml-512-node-056: [2024-07-08 06:04:44,477] [INFO] [launch.py:351:main] Process 1069770 exits successfully.
ml-512-node-056: [2024-07-08 06:04:44,478] [INFO] [launch.py:351:main] Process 1069768 exits successfully.
ml-512-node-056: [2024-07-08 06:04:44,478] [INFO] [launch.py:351:main] Process 1069766 exits successfully.
ml-512-node-038: [2024-07-08 06:04:44,480] [INFO] [launch.py:351:main] Process 1058373 exits successfully.
ml-512-node-038: [2024-07-08 06:04:44,480] [INFO] [launch.py:351:main] Process 1058371 exits successfully.
ml-512-node-038: [2024-07-08 06:04:44,480] [INFO] [launch.py:351:main] Process 1058375 exits successfully.
ml-512-node-038: [2024-07-08 06:04:44,480] [INFO] [launch.py:351:main] Process 1058377 exits successfully.
ml-512-node-038: [2024-07-08 06:04:44,480] [INFO] [launch.py:351:main] Process 1058376 exits successfully.
ml-512-node-038: [2024-07-08 06:04:44,480] [INFO] [launch.py:351:main] Process 1058374 exits successfully.
ml-512-node-038: [2024-07-08 06:04:44,480] [INFO] [launch.py:351:main] Process 1058372 exits successfully.
ml-512-node-038: [2024-07-08 06:04:44,481] [INFO] [launch.py:351:main] Process 1058378 exits successfully.
ml-512-node-041: [2024-07-08 06:04:44,482] [INFO] [launch.py:351:main] Process 1064392 exits successfully.
ml-512-node-041: [2024-07-08 06:04:44,483] [INFO] [launch.py:351:main] Process 1064390 exits successfully.
ml-512-node-041: [2024-07-08 06:04:44,483] [INFO] [launch.py:351:main] Process 1064396 exits successfully.
ml-512-node-041: [2024-07-08 06:04:44,483] [INFO] [launch.py:351:main] Process 1064395 exits successfully.
ml-512-node-041: [2024-07-08 06:04:44,483] [INFO] [launch.py:351:main] Process 1064393 exits successfully.
ml-512-node-041: [2024-07-08 06:04:44,483] [INFO] [launch.py:351:main] Process 1064391 exits successfully.
ml-512-node-039: [2024-07-08 06:04:44,484] [INFO] [launch.py:351:main] Process 1145672 exits successfully.
ml-512-node-039: [2024-07-08 06:04:44,484] [INFO] [launch.py:351:main] Process 1145670 exits successfully.
ml-512-node-039: [2024-07-08 06:04:44,484] [INFO] [launch.py:351:main] Process 1145674 exits successfully.
ml-512-node-039: [2024-07-08 06:04:44,484] [INFO] [launch.py:351:main] Process 1145676 exits successfully.
ml-512-node-039: [2024-07-08 06:04:44,484] [INFO] [launch.py:351:main] Process 1145675 exits successfully.
ml-512-node-039: [2024-07-08 06:04:44,485] [INFO] [launch.py:351:main] Process 1145673 exits successfully.
ml-512-node-039: [2024-07-08 06:04:44,485] [INFO] [launch.py:351:main] Process 1145671 exits successfully.
ml-512-node-037: [2024-07-08 06:04:44,496] [INFO] [launch.py:351:main] Process 1062864 exits successfully.
ml-512-node-037: [2024-07-08 06:04:44,497] [INFO] [launch.py:351:main] Process 1062862 exits successfully.
ml-512-node-037: [2024-07-08 06:04:44,497] [INFO] [launch.py:351:main] Process 1062866 exits successfully.
ml-512-node-037: [2024-07-08 06:04:44,497] [INFO] [launch.py:351:main] Process 1062868 exits successfully.
ml-512-node-037: [2024-07-08 06:04:44,497] [INFO] [launch.py:351:main] Process 1062867 exits successfully.
ml-512-node-037: [2024-07-08 06:04:44,497] [INFO] [launch.py:351:main] Process 1062865 exits successfully.
ml-512-node-037: [2024-07-08 06:04:44,497] [INFO] [launch.py:351:main] Process 1062863 exits successfully.
ml-512-node-037: [2024-07-08 06:04:44,497] [INFO] [launch.py:351:main] Process 1062869 exits successfully.
ml-512-node-047: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1059877 exits successfully.
ml-512-node-047: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1059879 exits successfully.
ml-512-node-047: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1059878 exits successfully.
ml-512-node-047: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1059876 exits successfully.
ml-512-node-047: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1059874 exits successfully.
ml-512-node-047: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1059880 exits successfully.
ml-512-node-047: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1059875 exits successfully.
ml-512-node-035: [2024-07-08 06:04:44,511] [INFO] [launch.py:351:main] Process 1066315 exits successfully.
ml-512-node-035: [2024-07-08 06:04:44,511] [INFO] [launch.py:351:main] Process 1066317 exits successfully.
ml-512-node-035: [2024-07-08 06:04:44,511] [INFO] [launch.py:351:main] Process 1066316 exits successfully.
ml-512-node-035: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1066312 exits successfully.
ml-512-node-035: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1066313 exits successfully.
ml-512-node-035: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1066311 exits successfully.
ml-512-node-047: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1059873 exits successfully.
ml-512-node-046: [2024-07-08 06:04:44,515] [INFO] [launch.py:351:main] Process 1057862 exits successfully.
ml-512-node-046: [2024-07-08 06:04:44,516] [INFO] [launch.py:351:main] Process 1057860 exits successfully.
ml-512-node-046: [2024-07-08 06:04:44,516] [INFO] [launch.py:351:main] Process 1057864 exits successfully.
ml-512-node-046: [2024-07-08 06:04:44,516] [INFO] [launch.py:351:main] Process 1057866 exits successfully.
ml-512-node-046: [2024-07-08 06:04:44,516] [INFO] [launch.py:351:main] Process 1057865 exits successfully.
ml-512-node-046: [2024-07-08 06:04:44,516] [INFO] [launch.py:351:main] Process 1057863 exits successfully.
ml-512-node-046: [2024-07-08 06:04:44,516] [INFO] [launch.py:351:main] Process 1057861 exits successfully.
ml-512-node-046: [2024-07-08 06:04:44,516] [INFO] [launch.py:351:main] Process 1057867 exits successfully.
ml-512-node-044: [2024-07-08 06:04:44,517] [INFO] [launch.py:351:main] Process 1056250 exits successfully.
ml-512-node-044: [2024-07-08 06:04:44,517] [INFO] [launch.py:351:main] Process 1056252 exits successfully.
ml-512-node-044: [2024-07-08 06:04:44,517] [INFO] [launch.py:351:main] Process 1056251 exits successfully.
ml-512-node-044: [2024-07-08 06:04:44,517] [INFO] [launch.py:351:main] Process 1056249 exits successfully.
ml-512-node-044: [2024-07-08 06:04:44,517] [INFO] [launch.py:351:main] Process 1056247 exits successfully.
ml-512-node-044: [2024-07-08 06:04:44,517] [INFO] [launch.py:351:main] Process 1056253 exits successfully.
ml-512-node-044: [2024-07-08 06:04:44,517] [INFO] [launch.py:351:main] Process 1056248 exits successfully.
ml-512-node-044: [2024-07-08 06:04:44,517] [INFO] [launch.py:351:main] Process 1056246 exits successfully.
ml-512-node-033: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1069271 exits successfully.
ml-512-node-033: [2024-07-08 06:04:44,512] [INFO] [launch.py:351:main] Process 1069269 exits successfully.
ml-512-node-033: [2024-07-08 06:04:44,513] [INFO] [launch.py:351:main] Process 1069273 exits successfully.
ml-512-node-033: [2024-07-08 06:04:44,513] [INFO] [launch.py:351:main] Process 1069275 exits successfully.
ml-512-node-033: [2024-07-08 06:04:44,513] [INFO] [launch.py:351:main] Process 1069274 exits successfully.
ml-512-node-033: [2024-07-08 06:04:44,513] [INFO] [launch.py:351:main] Process 1069272 exits successfully.
ml-512-node-033: [2024-07-08 06:04:44,513] [INFO] [launch.py:351:main] Process 1069270 exits successfully.
ml-512-node-033: [2024-07-08 06:04:44,513] [INFO] [launch.py:351:main] Process 1069276 exits successfully.
ml-512-node-060: [2024-07-08 06:04:44,552] [INFO] [launch.py:351:main] Process 1053126 exits successfully.
ml-512-node-060: [2024-07-08 06:04:44,552] [INFO] [launch.py:351:main] Process 1053128 exits successfully.
ml-512-node-060: [2024-07-08 06:04:44,552] [INFO] [launch.py:351:main] Process 1053125 exits successfully.
ml-512-node-060: [2024-07-08 06:04:44,552] [INFO] [launch.py:351:main] Process 1053123 exits successfully.
ml-512-node-060: [2024-07-08 06:04:44,553] [INFO] [launch.py:351:main] Process 1053129 exits successfully.
ml-512-node-060: [2024-07-08 06:04:44,553] [INFO] [launch.py:351:main] Process 1053124 exits successfully.
ml-512-node-060: [2024-07-08 06:04:44,553] [INFO] [launch.py:351:main] Process 1053122 exits successfully.
ml-512-node-050: [2024-07-08 06:04:44,838] [INFO] [launch.py:351:main] Process 1055629 exits successfully.
ml-512-node-050: [2024-07-08 06:04:44,838] [INFO] [launch.py:351:main] Process 1055627 exits successfully.
ml-512-node-050: [2024-07-08 06:04:44,838] [INFO] [launch.py:351:main] Process 1055631 exits successfully.
ml-512-node-050: [2024-07-08 06:04:44,838] [INFO] [launch.py:351:main] Process 1055633 exits successfully.
ml-512-node-050: [2024-07-08 06:04:44,839] [INFO] [launch.py:351:main] Process 1055632 exits successfully.
ml-512-node-050: [2024-07-08 06:04:44,839] [INFO] [launch.py:351:main] Process 1055630 exits successfully.
ml-512-node-050: [2024-07-08 06:04:44,839] [INFO] [launch.py:351:main] Process 1055628 exits successfully.
ml-512-node-050: [2024-07-08 06:04:44,839] [INFO] [launch.py:351:main] Process 1055634 exits successfully.
ml-512-node-052: [2024-07-08 06:04:44,841] [INFO] [launch.py:351:main] Process 1055142 exits successfully.
ml-512-node-052: [2024-07-08 06:04:44,841] [INFO] [launch.py:351:main] Process 1055139 exits successfully.
ml-512-node-052: [2024-07-08 06:04:44,842] [INFO] [launch.py:351:main] Process 1055138 exits successfully.
ml-512-node-052: [2024-07-08 06:04:44,842] [INFO] [launch.py:351:main] Process 1055136 exits successfully.
ml-512-node-052: [2024-07-08 06:04:44,842] [INFO] [launch.py:351:main] Process 1055140 exits successfully.
ml-512-node-051: [2024-07-08 06:04:44,845] [INFO] [launch.py:351:main] Process 1059698 exits successfully.
ml-512-node-051: [2024-07-08 06:04:44,845] [INFO] [launch.py:351:main] Process 1059696 exits successfully.
ml-512-node-051: [2024-07-08 06:04:44,845] [INFO] [launch.py:351:main] Process 1059700 exits successfully.
ml-512-node-051: [2024-07-08 06:04:44,845] [INFO] [launch.py:351:main] Process 1059702 exits successfully.
ml-512-node-051: [2024-07-08 06:04:44,845] [INFO] [launch.py:351:main] Process 1059701 exits successfully.
ml-512-node-051: [2024-07-08 06:04:44,845] [INFO] [launch.py:351:main] Process 1059699 exits successfully.
ml-512-node-051: [2024-07-08 06:04:44,845] [INFO] [launch.py:351:main] Process 1059703 exits successfully.
ml-512-node-059: [2024-07-08 06:04:44,862] [INFO] [launch.py:351:main] Process 1056657 exits successfully.
ml-512-node-059: [2024-07-08 06:04:44,862] [INFO] [launch.py:351:main] Process 1056656 exits successfully.
ml-512-node-059: [2024-07-08 06:04:44,862] [INFO] [launch.py:351:main] Process 1056654 exits successfully.
ml-512-node-059: [2024-07-08 06:04:44,863] [INFO] [launch.py:351:main] Process 1056652 exits successfully.
ml-512-node-059: [2024-07-08 06:04:44,863] [INFO] [launch.py:351:main] Process 1056655 exits successfully.
ml-512-node-064: [2024-07-08 06:04:44,870] [INFO] [launch.py:351:main] Process 1050717 exits successfully.
ml-512-node-064: [2024-07-08 06:04:44,871] [INFO] [launch.py:351:main] Process 1050714 exits successfully.
ml-512-node-064: [2024-07-08 06:04:44,871] [INFO] [launch.py:351:main] Process 1050712 exits successfully.
ml-512-node-064: [2024-07-08 06:04:44,871] [INFO] [launch.py:351:main] Process 1050718 exits successfully.
ml-512-node-064: [2024-07-08 06:04:44,871] [INFO] [launch.py:351:main] Process 1050713 exits successfully.
ml-512-node-064: [2024-07-08 06:04:44,871] [INFO] [launch.py:351:main] Process 1050715 exits successfully.
ml-512-node-063: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1056525 exits successfully.
ml-512-node-063: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1056524 exits successfully.
ml-512-node-063: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1056522 exits successfully.
ml-512-node-063: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1056520 exits successfully.
ml-512-node-063: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1056526 exits successfully.
ml-512-node-063: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1056519 exits successfully.
ml-512-node-063: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1056523 exits successfully.
ml-512-node-055: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1077539 exits successfully.
ml-512-node-055: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1077537 exits successfully.
ml-512-node-055: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1077543 exits successfully.
ml-512-node-055: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1077536 exits successfully.
ml-512-node-055: [2024-07-08 06:04:44,881] [INFO] [launch.py:351:main] Process 1077542 exits successfully.
ml-512-node-049: [2024-07-08 06:04:44,883] [INFO] [launch.py:351:main] Process 1063208 exits successfully.
ml-512-node-049: [2024-07-08 06:04:44,883] [INFO] [launch.py:351:main] Process 1063212 exits successfully.
ml-512-node-049: [2024-07-08 06:04:44,883] [INFO] [launch.py:351:main] Process 1063214 exits successfully.
ml-512-node-049: [2024-07-08 06:04:44,883] [INFO] [launch.py:351:main] Process 1063213 exits successfully.
ml-512-node-049: [2024-07-08 06:04:44,883] [INFO] [launch.py:351:main] Process 1063211 exits successfully.
ml-512-node-049: [2024-07-08 06:04:44,883] [INFO] [launch.py:351:main] Process 1063215 exits successfully.
ml-512-node-054: [2024-07-08 06:04:44,889] [INFO] [launch.py:351:main] Process 1053118 exits successfully.
ml-512-node-054: [2024-07-08 06:04:44,889] [INFO] [launch.py:351:main] Process 1053116 exits successfully.
ml-512-node-054: [2024-07-08 06:04:44,889] [INFO] [launch.py:351:main] Process 1053122 exits successfully.
ml-512-node-054: [2024-07-08 06:04:44,889] [INFO] [launch.py:351:main] Process 1053119 exits successfully.
ml-512-node-054: [2024-07-08 06:04:44,889] [INFO] [launch.py:351:main] Process 1053123 exits successfully.
ml-512-node-057: [2024-07-08 06:04:44,889] [INFO] [launch.py:351:main] Process 1059197 exits successfully.
ml-512-node-057: [2024-07-08 06:04:44,890] [INFO] [launch.py:351:main] Process 1059195 exits successfully.
ml-512-node-057: [2024-07-08 06:04:44,890] [INFO] [launch.py:351:main] Process 1059193 exits successfully.
ml-512-node-057: [2024-07-08 06:04:44,890] [INFO] [launch.py:351:main] Process 1059199 exits successfully.
ml-512-node-057: [2024-07-08 06:04:44,890] [INFO] [launch.py:351:main] Process 1059194 exits successfully.
ml-512-node-057: [2024-07-08 06:04:44,890] [INFO] [launch.py:351:main] Process 1059192 exits successfully.
ml-512-node-053: [2024-07-08 06:04:44,900] [INFO] [launch.py:351:main] Process 1061464 exits successfully.
ml-512-node-053: [2024-07-08 06:04:44,901] [INFO] [launch.py:351:main] Process 1061466 exits successfully.
ml-512-node-053: [2024-07-08 06:04:44,901] [INFO] [launch.py:351:main] Process 1061465 exits successfully.
ml-512-node-053: [2024-07-08 06:04:44,901] [INFO] [launch.py:351:main] Process 1061461 exits successfully.
ml-512-node-053: [2024-07-08 06:04:44,901] [INFO] [launch.py:351:main] Process 1061467 exits successfully.
ml-512-node-053: [2024-07-08 06:04:44,901] [INFO] [launch.py:351:main] Process 1061462 exits successfully.
ml-512-node-053: [2024-07-08 06:04:44,901] [INFO] [launch.py:351:main] Process 1061460 exits successfully.
ml-512-node-058: [2024-07-08 06:04:44,936] [INFO] [launch.py:351:main] Process 1052277 exits successfully.
ml-512-node-058: [2024-07-08 06:04:44,936] [INFO] [launch.py:351:main] Process 1052279 exits successfully.
ml-512-node-058: [2024-07-08 06:04:44,936] [INFO] [launch.py:351:main] Process 1052276 exits successfully.
ml-512-node-058: [2024-07-08 06:04:44,936] [INFO] [launch.py:351:main] Process 1052280 exits successfully.
ml-512-node-058: [2024-07-08 06:04:44,937] [INFO] [launch.py:351:main] Process 1052275 exits successfully.
ml-512-node-058: [2024-07-08 06:04:44,937] [INFO] [launch.py:351:main] Process 1052273 exits successfully.
ml-512-node-062: [2024-07-08 06:04:44,988] [INFO] [launch.py:351:main] Process 1052262 exits successfully.
ml-512-node-062: [2024-07-08 06:04:44,988] [INFO] [launch.py:351:main] Process 1052260 exits successfully.
ml-512-node-062: [2024-07-08 06:04:44,988] [INFO] [launch.py:351:main] Process 1052264 exits successfully.
ml-512-node-062: [2024-07-08 06:04:44,989] [INFO] [launch.py:351:main] Process 1052261 exits successfully.
ml-512-node-062: [2024-07-08 06:04:44,989] [INFO] [launch.py:351:main] Process 1052267 exits successfully.
ml-512-node-061: [2024-07-08 06:04:45,015] [INFO] [launch.py:351:main] Process 1058760 exits successfully.
ml-512-node-061: [2024-07-08 06:04:45,016] [INFO] [launch.py:351:main] Process 1058758 exits successfully.
ml-512-node-061: [2024-07-08 06:04:45,016] [INFO] [launch.py:351:main] Process 1058762 exits successfully.
ml-512-node-061: [2024-07-08 06:04:45,016] [INFO] [launch.py:351:main] Process 1058764 exits successfully.
ml-512-node-061: [2024-07-08 06:04:45,016] [INFO] [launch.py:351:main] Process 1058765 exits successfully.
ml-512-node-040: [2024-07-08 06:04:45,060] [INFO] [launch.py:351:main] Process 1113527 exits successfully.
ml-512-node-040: [2024-07-08 06:04:45,060] [INFO] [launch.py:351:main] Process 1113529 exits successfully.
ml-512-node-045: [2024-07-08 06:04:45,394] [INFO] [launch.py:351:main] Process 1061694 exits successfully.
ml-512-node-045: [2024-07-08 06:04:45,394] [INFO] [launch.py:351:main] Process 1061695 exits successfully.
ml-512-node-045: [2024-07-08 06:04:45,394] [INFO] [launch.py:351:main] Process 1061696 exits successfully.
ml-512-node-042: [2024-07-08 06:04:45,424] [INFO] [launch.py:351:main] Process 1057927 exits successfully.
ml-512-node-042: [2024-07-08 06:04:45,425] [INFO] [launch.py:351:main] Process 1057924 exits successfully.
ml-512-node-043: [2024-07-08 06:04:45,458] [INFO] [launch.py:351:main] Process 1061742 exits successfully.
ml-512-node-043: [2024-07-08 06:04:45,458] [INFO] [launch.py:351:main] Process 1061739 exits successfully.
ml-512-node-043: [2024-07-08 06:04:45,459] [INFO] [launch.py:351:main] Process 1061743 exits successfully.
ml-512-node-048: [2024-07-08 06:04:45,477] [INFO] [launch.py:351:main] Process 1056107 exits successfully.
ml-512-node-048: [2024-07-08 06:04:45,477] [INFO] [launch.py:351:main] Process 1056109 exits successfully.
ml-512-node-048: [2024-07-08 06:04:45,477] [INFO] [launch.py:351:main] Process 1056108 exits successfully.
ml-512-node-048: [2024-07-08 06:04:45,477] [INFO] [launch.py:351:main] Process 1056106 exits successfully.
ml-512-node-048: [2024-07-08 06:04:45,477] [INFO] [launch.py:351:main] Process 1056104 exits successfully.
ml-512-node-048: [2024-07-08 06:04:45,477] [INFO] [launch.py:351:main] Process 1056105 exits successfully.
ml-512-node-048: [2024-07-08 06:04:45,478] [INFO] [launch.py:351:main] Process 1056103 exits successfully.
ml-512-node-041: [2024-07-08 06:04:45,484] [INFO] [launch.py:351:main] Process 1064397 exits successfully.
ml-512-node-041: [2024-07-08 06:04:45,484] [INFO] [launch.py:351:main] Process 1064394 exits successfully.
ml-512-node-039: [2024-07-08 06:04:45,486] [INFO] [launch.py:351:main] Process 1145677 exits successfully.
ml-512-node-035: [2024-07-08 06:04:45,513] [INFO] [launch.py:351:main] Process 1066314 exits successfully.
ml-512-node-035: [2024-07-08 06:04:45,513] [INFO] [launch.py:351:main] Process 1066318 exits successfully.
